{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5npwAXYBXu8L"
   },
   "source": [
    "# Vectores de conteo de términos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sat8Hl159O21"
   },
   "source": [
    "Cada par consulta-documento $(q,d)$ de los archivos de entrada proporciona información relativa a los diferentes términos de cada consulta en cinco campos diferentes de cada documento, a saber: <b>url</b>, <b>title</b>, <b>headers</b>, <b>body</b> y <b>anchors</b> (el campo <b>pagerank</b> adicional no se utilizará hasta más adelante).\n",
    "\n",
    "Las funciones de _ranking_ construirán inicialmente los correspondientes cinco vectores de conteo de términos crudos ($rs$, de _raw score_) para cada uno de estos pares $(q,d)$, precisamente a partir de las coincidencias (_hits_) en estos cinco diferentes campos. Estos vectores $rs$ simplemente contarán cuantas veces ocurre cada término de búsqueda en un determinado campo. Para el campo <b>anchor</b>, se asumirá la simplificación de que hay un gran documento que contiene todos los enlaces, con el texto del enlace multiplicado por el campo <b>stanford_anchor_count</b>. Seguiremos un enfoque análogo también para el campo <b>header</b>.\n",
    "    \n",
    "Así, para el par $(q,d)$ de ejemplo donde la consulta era $q=[\\text{stanford aoerc pool hours}]^T$ y el documento $d=$\"http://events.stanford.edu/2014/February/18/\" (mostrado en el ejemplo de una celda anterior de este mismo notebook), el vector ${rs}_{b}$ correspondiente al campo <b>body</b> será $[{10 \\ 7 \\ 1 \\ 0}]^T$, dado que había 10 apariciones del término \"stanford\" en dicho campo, 7 para el término \"aoerc\", 1 para el término \"pool\" y ninguna para el término \"hours\". Análogamente, el vector ${rs}_{a}$ para el campo <b>anchor</b> será simplemente $[\\text{0 0 0 0}]^T$, dado que no hay ningún enlace (<b>anchor</b>) para este documento. Finalmente el vector ${rs}_{t}$ para el campo <b>title</b> será $[\\text{1 0 0 0}]^T$, $[\\text{1 0 0 0}]^T$ también para el vector ${rs}_{u}$ del campo <b>url</b> (estos dos fácilmente deducibles desde los correspondientes campos `title` y `url`, que son únicos en cada documento), y ${rs}_{h}$ $[\\text{5 0 0 1}]^T$ para el campo <b>header</b> (este último acumulado para las distintas cabeceras --esto es, \"subtítulos\"-- presentes en el documento). Todo esto se puede corroborar fácilmente observando el contenido de dicho documento en el archivo de señal original:\n",
    "    \n",
    "```   \n",
    "query: stanford aoerc pool hours\n",
    " url: http://events.stanford.edu/2014/February/18/\n",
    "  title: events at stanford tuesday february 18 2014\n",
    "  header: stanford university event calendar\n",
    "  header: teaching sex at stanford\n",
    "  header: rodin the complete stanford collection\n",
    "  header: stanford rec trx suspension training\n",
    "  header: memorial church open visiting hours\n",
    "  header: alternative transportation counseling tm 3 hour stanford univ shc employees retirees family members\n",
    "  body_hits: stanford 239 271 318 457 615 642 663 960 966 971\n",
    "  body_hits: aoerc 349 401 432 530 549 578 596\n",
    "  body_hits: pool 521\n",
    "  body_length: 981\n",
    "  pagerank: 1    \n",
    "```\n",
    "    \n",
    "Un ejemplo adicional, usando la misma consulta, pero un documento de respuesta diferente, para ilustrar los vectores correspondientes a los campos <b>anchor</b>, no presentes en el documento anterior:\n",
    "```\n",
    "  url: https://cardinalrec.stanford.edu/facilities/aoerc/\n",
    "    ...\n",
    "    anchor_text: gyms aoerc\n",
    "      stanford_anchor_count: 3\n",
    "    anchor_text: aoerc\n",
    "      stanford_anchor_count: 13\n",
    "    anchor_text: http cardinalrec stanford edu facilities aoerc\n",
    "      stanford_anchor_count: 4\n",
    "    anchor_text: arrillaga outdoor education and recreation center aoerc link is external\n",
    "      stanford_anchor_count: 1\n",
    "    anchor_text: the arrillaga outdoor education and research center aoerc\n",
    "      stanford_anchor_count: 2\n",
    "    anchor_text: aoerc will shutdown for maintenance\n",
    "      stanford_anchor_count: 2\n",
    "```\n",
    "\n",
    "Aquí, el vector para  <b>anchor</b> será $[\\text{4 25 0 0}]^T$, dado que sólo hay un total de 4 enlaces (campo <b>stanford_anchor_count</b>) para el término \"stanford\", pero 25 (=3+13+4+1+2+2) para el término “aoerc”.\n",
    "\n",
    "(Nótese que, en lo referente al campo  <b>url</b> es necesario _\"tokenizar\"_ previamente sólo los caracteres alfanuméricos. Nótese también que, al calcular los conteos de términos crudos, todo se hace convirtiendo previamente los _tokens_ a minúsculas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KctGIAoX9O24"
   },
   "source": [
    "# Clase base para todos los _scorers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpiKjGh4dVxU"
   },
   "source": [
    "## Clase _AbstractScorer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ouo50wcPXu8L"
   },
   "source": [
    "Construimos ahora una clase base abstracta, de la que habrá que ir reimplementando métodos en las clases hijas, conforme vayamos implementando los diferentes métodos de _scoring_. En todo caso, esta clase AbstractScorer recogerá una funcionalidad básica común a todos. Lo fundamental serán los distintos métodos `parse_`_field_, que transforman la información textual disponible en el archivo de señal para cada campo en la correspondiente información numérica. Aprovechamos también aquí para añadir los posibles esquemas de _weighting_ SMART vistos en teoría (si bien en esta práctica no programaremos todas las posibilidades disponibles, sino sólo alguna de las más comúnmente utilizadas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ARI8fuJ9O25"
   },
   "outputs": [],
   "source": [
    "class AbstractScorer:\n",
    "    \"\"\" Una clase básica abstracta para un scorer.\n",
    "        Implementa una funcionalidad básica de construcción de vectores de consulta y de documento.\n",
    "        Tendrá que ser extendida adecuadamente por cada scorer específico.\n",
    "    \"\"\"\n",
    "    def __init__(self, idf, query_weight_scheme=None, doc_weight_scheme=None):\n",
    "        self.idf = idf\n",
    "        self.TFTYPES = [\"url\", \"title\", \"body_hits\", \"header\", \"anchor\"]\n",
    "        # Esquemas por defecto:\n",
    "        self.default_query_weight_scheme = {\"tf\": 'n', \"df\": 'n', \"norm\": None} # Esquema natural, no, none\n",
    "        self.default_doc_weight_scheme = {\"tf\": 'n', \"df\": 'n', \"norm\": None}   # Esquema natural, no, none\n",
    "        self.query_weight_scheme = query_weight_scheme if query_weight_scheme is not None \\\n",
    "                                   else self.default_query_weight_scheme\n",
    "        self.doc_weight_scheme = doc_weight_scheme if doc_weight_scheme is not None \\\n",
    "                                 else self.default_doc_weight_scheme\n",
    "\n",
    "    def parse_url(self, url):\n",
    "        \"\"\"Parsea la URL del documento, devolviendo un Counter de los tokens encontrados en la URL.\n",
    "        Args:\n",
    "            url: el url del que se va a hacer el parsing.\n",
    "        Returns:\n",
    "            Lista de tokens del URL (una vez limpios), y Counter resultado.\n",
    "        \"\"\"\n",
    "        if url:\n",
    "            url_token_in_term = url.replace(\"http:\",\".\").replace('/','.').replace('?','.') \\\n",
    "                                   .replace('=','.').replace(\"%20\",\".\").replace(\"...\",\".\").replace(\"..\",\".\")\\\n",
    "                                   .replace('-','.').lower();\n",
    "            url_token = url_token_in_term.strip(\".\").split('.')\n",
    "            return url_token, Counter(url_token)\n",
    "        else:\n",
    "            return [], Counter([])\n",
    "\n",
    "    def parse_title(self, title):\n",
    "        \"\"\"Parsea el campo title del documento, devolviendo un Counter de los tokens encontrados en el mismo.\n",
    "        Args:\n",
    "            title: el title del que se va a hacer el parsing.\n",
    "        Returns:\n",
    "            El Counter resultado.\n",
    "        \"\"\"\n",
    "        if title:\n",
    "            return Counter(title.split(\" \"))\n",
    "        else:\n",
    "            return Counter([])\n",
    "\n",
    "    def parse_headers(self, headers):\n",
    "        \"\"\"Parsea los campos headers del documento, devolviendo un Counter de los tokens encontrados en los mismos.\n",
    "        Args:\n",
    "            headers: la lista de headers sobre los que se va a hacer el parsing.\n",
    "        Returns:\n",
    "            El Counter resultado.\n",
    "        \"\"\"\n",
    "        headers_token = []\n",
    "        # BEGIN YOUR CODE\n",
    "        \n",
    "        # END YOUR CODE\n",
    "        return Counter(headers_token)\n",
    "\n",
    "    def parse_anchors(self, anchors):\n",
    "        \"\"\"Parsea los campos anchors del documento, devolviendo un Counter de los tokens encontrados en los mismos.\n",
    "        Args:\n",
    "            anchors: la lista de anchors sobre los que se va a hacer el parsing.\n",
    "        Returns:\n",
    "            El Counter resultado.\n",
    "        \"\"\"\n",
    "        anchor_count_map = Counter({})\n",
    "        if anchors is not None:\n",
    "            for anchor in anchors:\n",
    "                count = anchors[anchor]\n",
    "                anchor_tokens = anchor.split(\" \")\n",
    "                for anchor_token in anchor_tokens:\n",
    "                    if(anchor_token in anchor_count_map.keys()):\n",
    "                        anchor_count_map[anchor_token] += count\n",
    "                    else:\n",
    "                        anchor_count_map[anchor_token] = count\n",
    "        return anchor_count_map\n",
    "\n",
    "    def parse_body_hits(self, body_hits):\n",
    "        \"\"\"Parsea los campos body_hits del documento, devolviendo un Counter de los tokens encontrados en los mismos.\n",
    "        Args:\n",
    "            body_hits: la lista de anchors sobre los que se va a hacer el parsing.\n",
    "        Returns:\n",
    "            El Counter resultado.\n",
    "        \"\"\"\n",
    "        body_hits_count_map = Counter({})\n",
    "        #BEGIN YOUR CODE\n",
    "       \n",
    "        #END YOUR CODE\n",
    "        return body_hits_count_map\n",
    "\n",
    "    def get_query_vector(self, q, query_weight_scheme = None):\n",
    "        \"\"\" Obtiene un vector numérico para la consulta q.\n",
    "        Args:\n",
    "            q (Query): Query(\"Una consulta determinada\")\n",
    "        Returns:\n",
    "            query_vec (dict): El vector resultado.\n",
    "        \"\"\"\n",
    "        # En subclases de esta AbstractScorer, podrían tenerse en cuenta todas las\n",
    "        # posibilidades SMART, usando diferentes esquemas de frecuencia del término (tf),\n",
    "        # frecuencia de documento (idf) y normalización. En todo caso, nótese que en\n",
    "        # general no se suele necesitar normalización para la consulta en ningún caso, ya que\n",
    "        # dicha normalización no variaría con respecto a todos los documentos resultados de una\n",
    "        # misma consulta, lo que resultaría en un simple factor de escalado común que no\n",
    "        # afectaría al posterior ranking de los mismos.\n",
    "        #\n",
    "        # if query_weight_scheme is None:\n",
    "        #     query_weight_scheme = self.query_weight_scheme\n",
    "\n",
    "        query_vec = {}\n",
    "        ### BEGIN YOUR CODE (FIXME)\n",
    "        # En nuestro caso base, usaremos simplemente el contador básico de términos, sin\n",
    "        # normalización ni uso de idf:\n",
    "\n",
    "        \n",
    "        ### END YOUR CODE (FIXME)\n",
    "        return query_vec\n",
    "\n",
    "    def get_doc_vector(self, q, d, doc_weight_scheme=None):\n",
    "        \"\"\" Obtiene un vector numérico para el documento d.\n",
    "        Args:\n",
    "        q (Query) : Query(\"Una consulta\")\n",
    "        d (Document) : Query(\"Una consulta\")[\"Un URL\"]\n",
    "        Returns:\n",
    "        doc_vec (dict) : Un diccionario de conteo de la frecuencia de términos, con un subdiccionario para\n",
    "                         cada tipo de campo (tipo_de_campo -> (término -> conteo))\n",
    "                    Ejemplo: \"{'url':   {'stanford': 1, 'aoerc': 0, 'pool': 0, 'hours': 0},\n",
    "                               'title': {'stanford': 1, 'aoerc': 0, 'pool': 0, 'hours': 0},\n",
    "                               ...\n",
    "                               }\"\n",
    "        \"\"\"\n",
    "        # De nuevo, podrían considerarse todas las posibilidades SMART en las subclases\n",
    "        # de esta AbstractScorer, si bien en esta clase base nos contentaremos con un simple\n",
    "        # conteo crudo de los términos en los distintos campos:\n",
    "        #\n",
    "        # if doc_weight_scheme is None:\n",
    "        #    doc_weight_scheme = self.doc_weight_scheme\n",
    "\n",
    "        doc_vec = {}\n",
    "        ### BEGIN YOUR CODE (FIXME)\n",
    "        # Sólo para depurar:\n",
    "        # print(f\"URL:        {d.url}          ->   {self.parse_url(d.url)}\")\n",
    "        # print(f\"TITLE:      {d.title}        ->   {self.parse_title(d.title)}\")\n",
    "        # print(f\"HEADERS:    {d.headers}      ->   {self.parse_headers(d.headers)}\")\n",
    "        # print(f\"ANCHORS:    {d.anchors}      ->   {self.parse_anchors(d.anchors)}\")\n",
    "        # print(f\"BODY_HITS:  {d.body_hits}    ->   {self.parse_body_hits(d.body_hits)}\")\n",
    "        #\n",
    "        # Simple conteo crudo de los términos por campos:\n",
    "\n",
    "        \n",
    "        ### END YOUR CODE (FIXME)\n",
    "        return doc_vec\n",
    "\n",
    "    # Métodos no implementados en la clase base; en su caso, serán reimplementados en cada scorer concreto:\n",
    "\n",
    "    def normalize_doc_vec(self, q, d, doc_vec):\n",
    "        \"\"\" Normalizar el vector de documento.\n",
    "        Args:\n",
    "            q (Query) : La consulta.\n",
    "            d (Document) : El documento.\n",
    "            doc_vec (dict) : El vector de documento\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_sim_score(self, q, d):\n",
    "        \"\"\" Devuelve la puntuación para una consulta q y documento d dados.\n",
    "        Args:\n",
    "            q (Query): la consulta.\n",
    "            d (Document) : el documento.\n",
    "        Returns:\n",
    "            La puntuación para el par (q,d).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_net_score(self, q, d):\n",
    "        \"\"\" Calcular el scoring neto entre la consulta y el documento.\n",
    "        Args:\n",
    "            q (Query) : La consulta.\n",
    "            d (Document) : El documento.\n",
    "        Return:\n",
    "            score (float) : La puntuación resultado.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUaAmqMFXu8O"
   },
   "source": [
    "Probamos la clase abstracta con una consulta y un documento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOEnHyJR9O24",
    "outputId": "4d9ab66e-6755-4185-dad3-7367300f6ac4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = Query(\"stanford aoerc pool hours\")\n",
    "d = query_dict[q]['http://events.stanford.edu/2014/February/18/']\n",
    "print(\"Query q: \", q)\n",
    "print()\n",
    "print(\"Document d: \", d)\n",
    "\n",
    "a_scorer = AbstractScorer(theIDF)\n",
    "query_vec = a_scorer.get_query_vector(q)\n",
    "print(f\"Vector consulta:\")\n",
    "print(f\"  {query_vec}\")\n",
    "print()\n",
    "doc_vec = a_scorer.get_doc_vector(q, d)\n",
    "print(f\"Vector documento:\")\n",
    "for k, v in doc_vec.items():\n",
    "    print(f\"  {k:10s} -> {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida tendría que ser la siguiente:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Query q:  stanford aoerc pool hours\n",
    "\n",
    "Document d:  url: http://events.stanford.edu/2014/February/18/\n",
    " title: events at stanford tuesday february 18 2014\n",
    " headers: ['stanford university event calendar', 'teaching sex at stanford', 'rodin the complete stanford collection', 'stanford rec trx suspension training', 'memorial church open visiting hours', 'alternative transportation counseling tm 3 hour stanford univ shc employees retirees family members']\n",
    " body_hits: {'stanford': [239, 271, 318, 457, 615, 642, 663, 960, 966, 971], 'aoerc': [349, 401, 432, 530, 549, 578, 596], 'pool': [521]}\n",
    " body_length: 981\n",
    " pagerank: 1\n",
    "\n",
    "Vector consulta:\n",
    "  Counter({'stanford': 1, 'aoerc': 1, 'pool': 1, 'hours': 1})\n",
    "\n",
    "Vector documento:\n",
    "  url        -> Counter({'events': 1, 'stanford': 1, 'edu': 1, '2014': 1, 'february': 1, '18': 1})\n",
    "  title      -> Counter({'events': 1, 'at': 1, 'stanford': 1, 'tuesday': 1, 'february': 1, '18': 1, '2014': 1})\n",
    "  headers    -> Counter({'stanford': 5, 'university': 1, 'event': 1, 'calendar': 1, 'teaching': 1, 'sex': 1, 'at': 1, 'rodin': 1, 'the': 1, 'complete': 1, 'collection': 1, 'rec': 1, 'trx': 1, 'suspension': 1, 'training': 1, 'memorial': 1, 'church': 1, 'open': 1, 'visiting': 1, 'hours': 1, 'alternative': 1, 'transportation': 1, 'counseling': 1, 'tm': 1, '3': 1, 'hour': 1, 'univ': 1, 'shc': 1, 'employees': 1, 'retirees': 1, 'family': 1, 'members': 1})\n",
    "  anchors    -> Counter()\n",
    "  body_hits  -> Counter({'stanford': 10, 'aoerc': 7, 'pool': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDKy2-qXXu8P"
   },
   "source": [
    "## Clase _BaselineScorer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92wK25zfXu8P"
   },
   "source": [
    "Definimos aquí un simple _\"scorer baseline\"_, que nos servirá para probar la funcionalidad de la clase abstracta base. La clase `BaselineScorer` heredará directamente de la clase `AbstractScorer`, reimplementando solamente el método `get_sim_score`, que simplemente acumulará, para aquellos términos en la consulta, los contadores absolutos de dichos términos (TFs) en el vector de documento correspondiente, utilizando en cada caso el campo `url`, `title`, `headers`, `anchors`, o `body_hits` que se le indique en cada momento mediante el método `set_field_type(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qHe3qn09O26"
   },
   "outputs": [],
   "source": [
    "class BaselineScorer(AbstractScorer):\n",
    "    def __init__(self, idf):\n",
    "        super().__init__(idf)\n",
    "        self.field_type = \"url\"  # Campo por defecto de inicialización de la clase.\n",
    "\n",
    "    def set_field_type(self, field_type):\n",
    "        self.field_type = field_type\n",
    "\n",
    "    def get_sim_score(self, q, d):\n",
    "        score = 0\n",
    "        # BEGIN YOUR CODE\n",
    "        # Simplemente acumularemos los TFs de cada término de la query para el documento dado\n",
    "        \n",
    "        # END YOUR CODE\n",
    "        return score\n",
    "\n",
    "    # En este caso el scoring neto coincide con el devuelto por get_sim_score\n",
    "    # (no se combinan los distintos campos, simplemente se tiene en cuenta el\n",
    "    #  campo fijado previamente con set_field_type):\n",
    "    def get_net_score(self, q, d):\n",
    "        return self.get_sim_score(q, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hw43K2JRXu8P"
   },
   "source": [
    "Probamos el _baseline scorer_ con una consulta y un par de documentos de ejemplo, para todos los campos posibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVlIJ1Xk9O26",
    "outputId": "7eec5ee6-d4c8-4fc5-be89-960b9d813a57"
   },
   "outputs": [],
   "source": [
    "baseline_scorer = BaselineScorer(theIDF)\n",
    "\n",
    "q = Query(\"stanford aoerc pool hours\")\n",
    "print(\"---------\\n\")\n",
    "print(\"Consulta: \", q)\n",
    "print(f\"Vector de consulta:\\n{baseline_scorer.get_query_vector(q)}\")\n",
    "print(\"\\n---------\\n\")\n",
    "\n",
    "d1 = query_dict[q]['http://events.stanford.edu/2014/February/18/']          # Ejemplo que tiene \"body_hits\".\n",
    "d2 = query_dict[q]['https://cardinalrec.stanford.edu/facilities/aoerc/']    # Ejemplo que tiene \"anchors\".\n",
    "\n",
    "for i,d in enumerate([d1,d2]):\n",
    "    doc_vectors = baseline_scorer.get_doc_vector(q,d)\n",
    "    print(\"Documento:\\n\", d)\n",
    "    print(f\"Vectores de documento:\")\n",
    "    similarities = {}\n",
    "    for k in doc_vectors.keys(): # Para cada campo:\n",
    "        baseline_scorer.set_field_type(k)\n",
    "        similarity = baseline_scorer.get_sim_score(q,d)\n",
    "        print(f\"  {k} vector (computed similarity={similarity}):\\n  {doc_vectors[k]}\\n\")\n",
    "        similarities[k] = similarity\n",
    "    # print(similarities)\n",
    "    if i==0:\n",
    "        assert similarities == {'url': 1, 'title': 1, 'headers': 6, 'anchors': 0, 'body_hits': 18}, \\\n",
    "          \"Scorer de similaridad baseline utilizando pesos por defecto no obtiene resultado esperado para d1\"\n",
    "    elif i==1:\n",
    "        assert similarities == {'url': 2, 'title': 0, 'headers': 0, 'anchors': 29, 'body_hits': 0}, \\\n",
    "          \"Scorer de similaridad baseline utilizando pesos por defecto no obtiene resultado esperado para d2\"\n",
    "    print(\"---------\\n\")\n",
    "\n",
    "print(\"Tests de clase BaselineScorer() superados.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
