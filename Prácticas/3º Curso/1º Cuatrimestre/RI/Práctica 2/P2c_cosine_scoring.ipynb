{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hsV88l89O24"
   },
   "source": [
    "# Función de _ranking_ 1: Similaridad del coseno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_b6g67dI9O24"
   },
   "source": [
    "Mas allá del _scoring_ _baseline_ (un tanto _naive_) anterior, la primera función de _ranking_ más elaborada que aplicaremos consistirá en una variante clásica de la similitud coseno (con la norma L1). Se trata esencialmente de construir el vector del documento y el vector de la consulta para luego tomar el producto escalar como resultado.\n",
    "En realidad, es exactamente lo mismo que hemos hecho ya para el simple conteo de términos anterior (suponiendo que el vector consulta era siempre un vector binario con 1 en los términos contenidos en la consulta, y 0 en el resto). Ahora, sin embargo, en lugar de tomar simplemente los conteos de términos (tanto en la consulta como en el documento), podrían considerarse varias alternativas para calcular el peso (=componente) de cada término, decidiendo:\n",
    "\n",
    "1. Cómo se calcula exactamente la frecuencia de cada término.\n",
    "2. Cómo se realiza la ponderación por frecuencia de documento de cada término.\n",
    "3. La estrategia de normalización seguida.\n",
    "\n",
    "De nuevo, la figura 6.15 de la página 128 del libro de Manning ([enlace](http://nlp.stanford.edu/IR-book/pdf/06vect.pdf)) nos recuerda todas las posibles alternativas para ello, según la notación SMART.\n",
    "\n",
    "En lo que sigue discutiremos las opciones para ambos vectores por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeJBuqVgXu8P"
   },
   "source": [
    "## Vectores de consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLSmX-K49O24"
   },
   "source": [
    "* **Frecuencia del término** (_tf_):\n",
    "Las frecuencias crudas pueden computarse de forma sencilla a partir de los términos de la consulta. Deberían corresponderse, en la mayoría de los casos, con un simple 1 para cada término que apareciese en la consulta, equivalente a la opción _\"boolean\"_ (pero no necesariamente, ya que algún término podría aparecer repetido). Dicha frecuencia cruda podría, si se desease, ser escalada sublinealmente (usando el logaritmo). En todo caso, en este notebook mantendremos el enfoque simple del conteo natural de términos, muy similar al vector booleano, dado que la inmensa mayoría de las consultas del _dataset_ no contienen términos repetidos.\n",
    "\n",
    "* **Frecuencia del documento** (_df_):\n",
    "Cada uno de los términos en el vector de la consulta deberá entonces ser pesado (=multiplicado) usando el valor de IDF correspondiente para cada término. Usaremos, como ya se comentó antes en este mismo notebook, el IDF computado a partir del corpus de la práctica 1. Recuérdese que, para el caso de palabras que no apareciesen en dicho corpus, se usará la técnica del suavizado Laplaciano (es decir, simplemente sumar 1 en el numerador y en el denominador; esto equivale esencialmente a asumir la existencia de un hipotético documento _\"dummy\"_ que contiene todos los posibles términos)\n",
    "\n",
    "* **Normalización** (_norm_):\n",
    "En ningún caso será necesario normalizar el vector de consulta, ya que cualquier posible normalización se aplicaría por igual al cruzarlo con todos los correspondientes documentos resultado, obteniéndose un simple escalado uniforme de los valores de _scoring_, lo que obviamente no influiría en absoluto en el correspondiente _ranking_ de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0gv0n8SXu8Q"
   },
   "source": [
    "## Vectores de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXjTFreN9O24"
   },
   "source": [
    "* **Frecuencia del término** (_tf_):\n",
    "Al igual que con el vector de consulta, podremos utilizar directamente las frecuencias crudas, o, alternativamente, aplicar algún tipo de escalado sublineal. En particular, el escalado sublineal típico es $tf_i = 1 + log(rs_i)$ si $rs_i > 0$, o simplemente $0$ en caso contrario. Así, por ejemplo, para el anterior vector _tf_ del campo **body** del documento _d_, el vector resultante sería $[\\text{1+log(10)  1+log(7)  1+log(1)  0}]^T$ (de nuevo, puede encontrarse más información sobre el escalado sublineal del término _tf_ en la página 126, sección 6.4.1 del [libro de Manning](http://nlp.stanford.edu/IR-book/pdf/06vect.pdf)).\n",
    "\n",
    "* **Frecuencia del documento** (_df_):\n",
    "No utilizaremos ningún tipo de frecuencia del documento en el vector de documento. En lugar de ello, se incorporará este peso únicamente en el vector de consulta, como se describía en el apartado anterior.\n",
    "\n",
    "* **Normalización** (_norm_):\n",
    "En este caso, no podemos usar la normalización del coseno, dado que nuestros archivos de entrenamiento no proporcionan acceso al contenido del documento en sí, sino solo un resumen de campos. Por lo tanto, no sabemos ni qué otros términos aparecen, ni el recuento de los mismos, en el campo **body**. En lugar de ello, por tanto, utilizaremos la normalización de longitud. Además, dado que puede haber enormes discrepancias entre las longitudes de los diferentes campos, dividimos todos los campos por el mismo factor de normalización, la propia longitud del campo **body**. Dado, además, el hecho de que algunos documentos aparecen con una longitud de 0, una buena estrategia es, de nuevo, agregar un valor (p.e. 500), a la longitud del cuerpo de cada documento. El valor concreto a utilizar, además, puede ser también utilizado para experimentar con ésta u otras estrategias de suavizado, y observar su posible influencia en los resultados de _ranking_ obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6rDDMYUXu8Q"
   },
   "source": [
    "## Pesado relativo de los diferentes campos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4P5hJ8kYXu8Q"
   },
   "source": [
    "Dado un documento $d$ y una consulta $q$, si $qv_q$ es el vector resultante de la consulta y $tf_{d,u}$, $tf_{d,t}$, $tf_{d,b}$, $tf_{d,h}$ y $tf_{d,a}$ son los vectores resultantes para cada uno de los campos **url**, **title**, **body**, **header** and **anchor**, respectivamente, definimos el _scoring_ global neto como (nótese que el símbolo $\\cdot$ se usa en la siguiente expresión tanto para el producto escalar entre vectores como para el producto de un escalar por un vector):\n",
    "\n",
    "$$qv_q \\cdot (c_u \\cdot tf_{d,u} + c_t \\cdot tf_{d,t} + c_b \\cdot tf_{d,b} + c_h \\cdot tf_{d,h} + c_a \\cdot tf_{d,a})$$\n",
    "\n",
    "Donde $c_u$, $c_t$, $c_b$, $c_h$ y $c_a$ son los pesos dados a los campos **url**, **title**, **body**, **header** y **anchor**, respectivamente.\n",
    "\n",
    "Por supuesto, para usar la expresión anterior necesitamos determinar de una forma sensata los pesos para cada uno de estos cinco campos. En este sentido, trataremos de escogerlos de forma que la función NDCG de evaluación (que describiremos más adelante) obtenga un valor lo más optimizado posible cuando sea aplicada al conjunto de test completo. Usaremos el conjunto de _training_ para intentar derivar dicho valor óptimo de los cinco parámetros mencionados, para luego evaluar su rendimiento en el conjunto de _test_. En una primera instancia, lo intentaremos hacer manualmente, intentando razonar simplemente sobre la importancia relativa de los diferentes pesos. Al final del notebook sustituiremos esta suerte de \"razonamiento manual\" por una śencilla técnica de _machine learning_.\n",
    "\n",
    "Nótese que el valor absoluto de dichos pesos no importará, sólo la relación (ratio) entre ellos (valores relativos), dado que si multiplicamos todos los pesos por la misma constante, el _scoring_ final quedará simplemente multiplicado por dicha constante para todos los documentos por igual, lo que obviamente no afectará en absoluto a la ordenación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O25xXnvz3aCC"
   },
   "source": [
    "### Esquema de _weighting_ inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x2v0V6v9O24"
   },
   "source": [
    "Proporcionamos aquí un esquema de pesado por defecto de partida, que puede después variarse para intentar mejorar el rendimiento (medido con NDGC). Nótese que:\n",
    "* En estos primeros pesos por defecto se asigna una importancia del peso de la URL 100 veces superior a la del resto de pesos, a los que, por otro lado, se da un peso equivalente.\n",
    "* Se añade al conjunto de parámetros ajustables un parámetro de suavizado de la longitud del documento (`smoothing_body_length`), término que podrá ser modificado para influir en la función de _scoring_ final. Dicho término será simplemente sumado a la longitud original de cada documento (con lo que, en todo caso, y como se comentó anteriormente, se evitará siempre la posible división por cero para documentos en los cuales la longitud indicada en el documento del dataset de entrada sea cero). Se deduce, pues, que dar un valor cada vez mayor para este parámetro implicará una influencia progresivamente menor del campo `body_length` original de cada documento particular, ya que el correspondiente factor de influencia de la longitud tenderá con ello a homogeneizarse más para todos los documentos, al disminuir progresivamente el peso relativo del valor inicial de `body_length` en la suma total del denominador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e46XW4OH9O26"
   },
   "outputs": [],
   "source": [
    "params_cosine = {\n",
    "    \"url_weight\" : 10,\n",
    "    \"title_weight\": 0.1,\n",
    "    \"body_hits_weight\" : 0.1,\n",
    "    \"header_weight\" : 0.1,\n",
    "    \"anchor_weight\" : 0.1,\n",
    "    \"smoothing_body_length\" : 500,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7NxyuAB3j46"
   },
   "source": [
    "## Clase _CosineSimilarityScorer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53E1MUCo3yab"
   },
   "source": [
    "He aquí la definición de una clase para realizar un _scoring_ basado en la similaridad del coseno (basada en la clase `AbstractScorer` definida anteriormente, y reimplementando los métodos adecuados):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Número total de documentos de la colección: 98998\n",
      "Número total de términos: 347071\n",
      "\n",
      "Datos cargados: 731 consultas\n"
     ]
    }
   ],
   "source": [
    "# Imports necesarios\n",
    "import sys\n",
    "import array\n",
    "import os\n",
    "import timeit\n",
    "import contextlib\n",
    "import math\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, Counter, defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Definiciones de clases del notebook anterior (P2a)\n",
    "class Query:\n",
    "    \"\"\"Clase utilizada para almacenar una consulta.\"\"\"\n",
    "    def __init__(self, query):\n",
    "        self.query_words = query.split(\" \")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for w in self.query_words:\n",
    "            yield w\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Query):\n",
    "            return False\n",
    "        return self.query_words == other.query_words\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(str(self))\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" \".join(self.query_words)\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "class Document:\n",
    "    \"\"\"Clase utilizada para almacenar información útil para un documento.\"\"\"\n",
    "    def __init__(self, url):\n",
    "        self.url = url        # Cadena\n",
    "        self.title = None     # Cadena\n",
    "        self.headers = None   # [Lista de cadenas]\n",
    "        self.body_hits = None # Diccionario: Término->[Lista de posiciones]\n",
    "        self.body_length = 0  # Entero\n",
    "        self.pagerank = 0     # Entero\n",
    "        self.anchors = None   # Diccionario: Cadena->[Conteo total de ocurrencias (anchor_counts)]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for u in self.url:\n",
    "            yield u\n",
    "\n",
    "    def __str__(self):\n",
    "        result = [];\n",
    "        NEW_LINE = \"\\n\"\n",
    "        result.append(\"url: \"+ self.url + NEW_LINE);\n",
    "        if (self.title is not None): result.append(\"title: \" + self.title + NEW_LINE);\n",
    "        if (self.headers is not None): result.append(\"headers: \" + str(self.headers) + NEW_LINE);\n",
    "        if (self.body_hits is not None): result.append(\"body_hits: \" + str(self.body_hits) + NEW_LINE);\n",
    "        if (self.body_length != 0): result.append(\"body_length: \" + str(self.body_length) + NEW_LINE);\n",
    "        if (self.pagerank != 0): result.append(\"pagerank: \" + str(self.pagerank) + NEW_LINE);\n",
    "        if (self.anchors is not None): result.append(\"anchors: \" + str(self.anchors) + NEW_LINE);\n",
    "        return \" \".join(result)\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "class Idf:\n",
    "    \"\"\"Construye un diccionario para poder devolver el IDF de un término.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Construcción del diccionario IDF\"\"\"\n",
    "        try:\n",
    "            with open(\"pa3-data/docs.dict\", 'rb') as f:\n",
    "                docs = pkl.load(f)\n",
    "            self.total_doc_num = len(docs)\n",
    "            print(\"Número total de documentos de la colección:\", self.total_doc_num)\n",
    "\n",
    "            with open(\"pa3-data/terms.dict\", 'rb') as f:\n",
    "                terms = pkl.load(f)\n",
    "            self.total_term_num = len(terms)\n",
    "            print(\"Número total de términos:\", self.total_term_num)\n",
    "\n",
    "            with open('pa3-data/BSBI.dict', 'rb') as f:\n",
    "                postings_dict, termsID = pkl.load(f)\n",
    "\n",
    "            self.idf = {}\n",
    "            self.raw = {}\n",
    "            for term_id, term_str in enumerate(terms.id_to_str):\n",
    "                if term_id in postings_dict:\n",
    "                    num_docs_with_term = postings_dict[term_id][1]\n",
    "                    self.raw[term_str] = num_docs_with_term\n",
    "                    self.idf[term_str] = math.log((self.total_doc_num + 1) / (num_docs_with_term + 1))\n",
    "        except FileNotFoundError:\n",
    "            print(\"¡Ficheros de diccionario de documentos / términos / índice no encontrados!\")\n",
    "\n",
    "    def get_raw(self, term):\n",
    "        return self.raw.get(term, 0)\n",
    "\n",
    "    def get_idf(self, term):\n",
    "        if term in self.idf:\n",
    "            return self.idf[term]\n",
    "        else:\n",
    "            return math.log(self.total_doc_num + 1)\n",
    "\n",
    "def load_train_data(feature_file_name):\n",
    "    \"\"\"Carga los datos de entrenamiento.\"\"\"\n",
    "    line = None\n",
    "    url = None\n",
    "    anchor_text = None\n",
    "    query = None\n",
    "    query_dict = {}\n",
    "    try:\n",
    "        with open(feature_file_name, 'r', encoding = 'utf8') as f:\n",
    "            for line in f:\n",
    "                token_index = line.index(\":\")\n",
    "                key = line[:token_index].strip()\n",
    "                value = line[token_index + 1:].strip()\n",
    "                if key == \"query\":\n",
    "                    query = Query(value)\n",
    "                    query_dict[query] = {}\n",
    "                elif key == \"url\":\n",
    "                    url = value;\n",
    "                    query_dict[query][url] = Document(url);\n",
    "                elif key == \"title\":\n",
    "                    query_dict[query][url].title = str(value);\n",
    "                elif key == \"header\":\n",
    "                    if query_dict[query][url].headers is None:\n",
    "                        query_dict[query][url].headers = []\n",
    "                    query_dict[query][url].headers.append(value)\n",
    "                elif key == \"body_hits\":\n",
    "                    if query_dict[query][url].body_hits is None:\n",
    "                        query_dict[query][url].body_hits = {}\n",
    "                    temp = value.split(\" \",maxsplit=1);\n",
    "                    term = temp[0].strip();\n",
    "                    if term not in query_dict[query][url].body_hits:\n",
    "                        positions_int = []\n",
    "                        query_dict[query][url].body_hits[term] = positions_int\n",
    "                    else:\n",
    "                        positions_int = query_dict[query][url].body_hits[term]\n",
    "                    positions = temp[1].strip().split(\" \")\n",
    "                    for position in positions:\n",
    "                        positions_int.append(int(position))\n",
    "                elif key == \"body_length\":\n",
    "                    query_dict[query][url].body_length = int(value);\n",
    "                elif key == \"pagerank\":\n",
    "                    query_dict[query][url].pagerank = int(value);\n",
    "                elif key == \"anchor_text\":\n",
    "                    anchor_text = value\n",
    "                    if query_dict[query][url].anchors is None:\n",
    "                        query_dict[query][url].anchors = {}\n",
    "                elif key == \"stanford_anchor_count\":\n",
    "                    query_dict[query][url].anchors[anchor_text] = int(value)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fichero {feature_file_name} no encontrado!\")\n",
    "    return query_dict\n",
    "\n",
    "class IdMap:\n",
    "    \"\"\"Clase auxiliar para almacenar mapeos entre strings e identificadores numéricos de tokens.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor de la clase IdMap.\"\"\"\n",
    "        self.str_to_id = {}  # Diccionario: string -> id numérico\n",
    "        self.id_to_str = []  # Lista: índice = id, valor = string\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Devuelve el número de elementos en el mapeo.\"\"\"\n",
    "        return len(self.id_to_str)\n",
    "    \n",
    "    def _get_str(self, i):\n",
    "        \"\"\"Devuelve el string correspondiente al id numérico i.\n",
    "        \n",
    "        Args:\n",
    "            i (int): Identificador numérico.\n",
    "            \n",
    "        Returns:\n",
    "            str: String correspondiente al id.\n",
    "        \"\"\"\n",
    "        return self.id_to_str[i]\n",
    "    \n",
    "    def _get_id(self, s):\n",
    "        \"\"\"Devuelve el id numérico correspondiente al string s.\n",
    "        Si el string no existe, lo añade y devuelve su nuevo id.\n",
    "        \n",
    "        Args:\n",
    "            s (str): String del que obtener su id.\n",
    "            \n",
    "        Returns:\n",
    "            int: Identificador numérico del string.\n",
    "        \"\"\"\n",
    "        if s not in self.str_to_id:\n",
    "            # Si no existe, lo añadimos\n",
    "            new_id = len(self.id_to_str)\n",
    "            self.str_to_id[s] = new_id\n",
    "            self.id_to_str.append(s)\n",
    "            return new_id\n",
    "        return self.str_to_id[s]\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"Permite acceso mediante corchetes: idmap[key]\n",
    "        Si key es int, devuelve el string.\n",
    "        Si key es str, devuelve el id.\n",
    "        \n",
    "        Args:\n",
    "            key: Puede ser int (devuelve string) o str (devuelve id).\n",
    "            \n",
    "        Returns:\n",
    "            El string o id correspondiente.\n",
    "        \"\"\"\n",
    "        if isinstance(key, int):\n",
    "            return self._get_str(key)\n",
    "        elif isinstance(key, str):\n",
    "            return self._get_id(key)\n",
    "        else:\n",
    "            raise TypeError(\"La clave debe ser int o str\")\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        \"\"\"Permite usar 'in' para verificar existencia.\n",
    "        \n",
    "        Args:\n",
    "            key: Puede ser int o str.\n",
    "            \n",
    "        Returns:\n",
    "            bool: True si existe, False en caso contrario.\n",
    "        \"\"\"\n",
    "        if isinstance(key, int):\n",
    "            return 0 <= key < len(self.id_to_str)\n",
    "        elif isinstance(key, str):\n",
    "            return key in self.str_to_id\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"Representación en string del objeto.\"\"\"\n",
    "        return f\"IdMap(size={len(self)})\"\n",
    "    \n",
    "class AbstractScorer:\n",
    "    \"\"\" Una clase básica abstracta para un scorer.\n",
    "        Implementa una funcionalidad básica de construcción de vectores de consulta y de documento.\n",
    "        Tendrá que ser extendida adecuadamente por cada scorer específico.\n",
    "    \"\"\"\n",
    "    def __init__(self, idf, query_weight_scheme=None, doc_weight_scheme=None):\n",
    "        self.idf = idf\n",
    "        self.TFTYPES = [\"url\", \"title\", \"body_hits\", \"header\", \"anchor\"]\n",
    "        # Esquemas por defecto:\n",
    "        self.default_query_weight_scheme = {\"tf\": 'n', \"df\": 'n', \"norm\": None} # Esquema natural, no, none\n",
    "        self.default_doc_weight_scheme = {\"tf\": 'n', \"df\": 'n', \"norm\": None}   # Esquema natural, no, none\n",
    "        self.query_weight_scheme = query_weight_scheme if query_weight_scheme is not None \\\n",
    "                                   else self.default_query_weight_scheme\n",
    "        self.doc_weight_scheme = doc_weight_scheme if doc_weight_scheme is not None \\\n",
    "                                 else self.default_doc_weight_scheme\n",
    "\n",
    "    def parse_url(self, url):\n",
    "        \"\"\"Parsea la URL del documento, devolviendo un Counter de los tokens encontrados en la URL.\n",
    "        Args:\n",
    "            url: el url del que se va a hacer el parsing.\n",
    "        Returns:\n",
    "            Lista de tokens del URL (una vez limpios), y Counter resultado.\n",
    "        \"\"\"\n",
    "        if url:\n",
    "            url_token_in_term = url.replace(\"http:\",\".\").replace('/','.').replace('?','.') \\\n",
    "                                   .replace('=','.').replace(\"%20\",\".\").replace(\"...\",\".\").replace(\"..\",\".\")\\\n",
    "                                   .replace('-','.').lower();\n",
    "            url_token = url_token_in_term.strip(\".\").split('.')\n",
    "            return url_token, Counter(url_token)\n",
    "        else:\n",
    "            return [], Counter([])\n",
    "\n",
    "    def parse_title(self, title):\n",
    "        \"\"\"Parsea el campo title del documento, devolviendo un Counter de los tokens encontrados en el mismo.\n",
    "        Args:\n",
    "            title: el title del que se va a hacer el parsing.\n",
    "        Returns:\n",
    "            El Counter resultado.\n",
    "        \"\"\"\n",
    "        if title:\n",
    "            return Counter(title.split(\" \"))\n",
    "        else:\n",
    "            return Counter([])\n",
    "\n",
    "    def parse_headers(self, headers):\n",
    "        \"\"\"Parsea los campos headers del documento, devolviendo un Counter de los tokens encontrados en los mismos.\n",
    "        Args:\n",
    "            headers: la lista de headers sobre los que se va a hacer el parsing.\n",
    "        Returns:\n",
    "            El Counter resultado.\n",
    "        \"\"\"\n",
    "        headers_token = []\n",
    "        # BEGIN YOUR CODE\n",
    "        if headers is not None:\n",
    "            for header in headers:\n",
    "                # Dividir cada header en tokens y añadirlos a la lista\n",
    "                header_tokens = header.split(\" \")\n",
    "                headers_token.extend(header_tokens)\n",
    "        # END YOUR CODE\n",
    "        return Counter(headers_token)\n",
    "\n",
    "    def parse_anchors(self, anchors):\n",
    "        \"\"\"Parsea los campos anchors del documento, devolviendo un Counter de los tokens encontrados en los mismos.\n",
    "        Args:\n",
    "            anchors: la lista de anchors sobre los que se va a hacer el parsing.\n",
    "        Returns:\n",
    "            El Counter resultado.\n",
    "        \"\"\"\n",
    "        anchor_count_map = Counter({})\n",
    "        if anchors is not None:\n",
    "            for anchor in anchors:\n",
    "                count = anchors[anchor]\n",
    "                anchor_tokens = anchor.split(\" \")\n",
    "                for anchor_token in anchor_tokens:\n",
    "                    if(anchor_token in anchor_count_map.keys()):\n",
    "                        anchor_count_map[anchor_token] += count\n",
    "                    else:\n",
    "                        anchor_count_map[anchor_token] = count\n",
    "        return anchor_count_map\n",
    "\n",
    "    def parse_body_hits(self, body_hits):\n",
    "        \"\"\"Parsea los campos body_hits del documento, devolviendo un Counter de los tokens encontrados en los mismos.\n",
    "        Args:\n",
    "            body_hits: la lista de anchors sobre los que se va a hacer el parsing.\n",
    "        Returns:\n",
    "            El Counter resultado.\n",
    "        \"\"\"\n",
    "        body_hits_count_map = Counter({})\n",
    "        #BEGIN YOUR CODE\n",
    "        if body_hits is not None:\n",
    "            # body_hits es un diccionario: término -> lista de posiciones\n",
    "            # El conteo es simplemente la longitud de la lista de posiciones\n",
    "            for term, positions in body_hits.items():\n",
    "                body_hits_count_map[term] = len(positions)\n",
    "        #END YOUR CODE\n",
    "        return body_hits_count_map\n",
    "\n",
    "    def get_query_vector(self, q, query_weight_scheme = None):\n",
    "        \"\"\" Obtiene un vector numérico para la consulta q.\n",
    "        Args:\n",
    "            q (Query): Query(\"Una consulta determinada\")\n",
    "        Returns:\n",
    "            query_vec (dict): El vector resultado.\n",
    "        \"\"\"\n",
    "        # En subclases de esta AbstractScorer, podrían tenerse en cuenta todas las\n",
    "        # posibilidades SMART, usando diferentes esquemas de frecuencia del término (tf),\n",
    "        # frecuencia de documento (idf) y normalización. En todo caso, nótese que en\n",
    "        # general no se suele necesitar normalización para la consulta en ningún caso, ya que\n",
    "        # dicha normalización no variaría con respecto a todos los documentos resultados de una\n",
    "        # misma consulta, lo que resultaría en un simple factor de escalado común que no\n",
    "        # afectaría al posterior ranking de los mismos.\n",
    "        #\n",
    "        # if query_weight_scheme is None:\n",
    "        #     query_weight_scheme = self.query_weight_scheme\n",
    "\n",
    "        query_vec = {}\n",
    "        ### BEGIN YOUR CODE (FIXME)\n",
    "        # En nuestro caso base, usaremos simplemente el contador básico de términos, sin\n",
    "        # normalización ni uso de idf:\n",
    "        query_vec = Counter(q.query_words)\n",
    "        ### END YOUR CODE (FIXME)\n",
    "        return query_vec\n",
    "\n",
    "    def get_doc_vector(self, q, d, doc_weight_scheme=None):\n",
    "        \"\"\" Obtiene un vector numérico para el documento d.\n",
    "        Args:\n",
    "        q (Query) : Query(\"Una consulta\")\n",
    "        d (Document) : Query(\"Una consulta\")[\"Un URL\"]\n",
    "        Returns:\n",
    "        doc_vec (dict) : Un diccionario de conteo de la frecuencia de términos, con un subdiccionario para\n",
    "                         cada tipo de campo (tipo_de_campo -> (término -> conteo))\n",
    "                    Ejemplo: \"{'url':   {'stanford': 1, 'aoerc': 0, 'pool': 0, 'hours': 0},\n",
    "                               'title': {'stanford': 1, 'aoerc': 0, 'pool': 0, 'hours': 0},\n",
    "                               ...\n",
    "                               }\"\n",
    "        \"\"\"\n",
    "        # De nuevo, podrían considerarse todas las posibilidades SMART en las subclases\n",
    "        # de esta AbstractScorer, si bien en esta clase base nos contentaremos con un simple\n",
    "        # conteo crudo de los términos en los distintos campos:\n",
    "        #\n",
    "        # if doc_weight_scheme is None:\n",
    "        #    doc_weight_scheme = self.doc_weight_scheme\n",
    "\n",
    "        doc_vec = {}\n",
    "        ### BEGIN YOUR CODE (FIXME)\n",
    "        # Sólo para depurar:\n",
    "        # print(f\"URL:        {d.url}          ->   {self.parse_url(d.url)}\")\n",
    "        # print(f\"TITLE:      {d.title}        ->   {self.parse_title(d.title)}\")\n",
    "        # print(f\"HEADERS:    {d.headers}      ->   {self.parse_headers(d.headers)}\")\n",
    "        # print(f\"ANCHORS:    {d.anchors}      ->   {self.parse_anchors(d.anchors)}\")\n",
    "        # print(f\"BODY_HITS:  {d.body_hits}    ->   {self.parse_body_hits(d.body_hits)}\")\n",
    "        #\n",
    "        # Simple conteo crudo de los términos por campos:\n",
    "        _, url_counter = self.parse_url(d.url)\n",
    "        doc_vec['url'] = url_counter\n",
    "        doc_vec['title'] = self.parse_title(d.title)\n",
    "        doc_vec['headers'] = self.parse_headers(d.headers)\n",
    "        doc_vec['anchors'] = self.parse_anchors(d.anchors)\n",
    "        doc_vec['body_hits'] = self.parse_body_hits(d.body_hits)\n",
    "        ### END YOUR CODE (FIXME)\n",
    "        return doc_vec\n",
    "\n",
    "    # Métodos no implementados en la clase base; en su caso, serán reimplementados en cada scorer concreto:\n",
    "\n",
    "    def normalize_doc_vec(self, q, d, doc_vec):\n",
    "        \"\"\" Normalizar el vector de documento.\n",
    "        Args:\n",
    "            q (Query) : La consulta.\n",
    "            d (Document) : El documento.\n",
    "            doc_vec (dict) : El vector de documento\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_sim_score(self, q, d):\n",
    "        \"\"\" Devuelve la puntuación para una consulta q y documento d dados.\n",
    "        Args:\n",
    "            q (Query): la consulta.\n",
    "            d (Document) : el documento.\n",
    "        Returns:\n",
    "            La puntuación para el par (q,d).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_net_score(self, q, d):\n",
    "        \"\"\" Calcular el scoring neto entre la consulta y el documento.\n",
    "        Args:\n",
    "            q (Query) : La consulta.\n",
    "            d (Document) : El documento.\n",
    "        Return:\n",
    "            score (float) : La puntuación resultado.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "# Cargar datos necesarios\n",
    "print(\"Cargando datos...\")\n",
    "data_dir = 'pa3-data'\n",
    "theIDF = Idf()\n",
    "print()\n",
    "file_name = os.path.join(data_dir, \"pa3.signal.train\")\n",
    "query_dict = load_train_data(file_name)\n",
    "print(f\"Datos cargados: {len(query_dict)} consultas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gtG8AVtv9O27"
   },
   "outputs": [],
   "source": [
    "class CosineSimilarityScorer(AbstractScorer):\n",
    "\n",
    "    def __init__(self, idf, query_dict, params, query_weight_scheme=None, doc_weight_scheme=None):\n",
    "        # Inicializamos clase base \"AbstractScorer\", ...\n",
    "        super().__init__(idf, query_weight_scheme=query_weight_scheme, doc_weight_scheme=doc_weight_scheme)\n",
    "        self.query_dict = query_dict\n",
    "        # ... y añadimos los parámetros necesarios (5 pesos de los 5 campos + factor suavizado longitud):\n",
    "        try:\n",
    "            self.smoothing_body_length = params[\"smoothing_body_length\"]\n",
    "        except:\n",
    "            self.smoothing_body_length = 0\n",
    "        self.weights = {\"url\": params[\"url_weight\"], \"title\": params[\"title_weight\"],\n",
    "                        \"headers\": params[\"header_weight\"], \"anchors\": params[\"anchor_weight\"],\n",
    "                        \"body_hits\": params[\"body_hits_weight\"]}\n",
    "\n",
    "    def get_query_vector(self, q):\n",
    "        \"\"\" Usando los vectores de conteo crudos de la clase base, aplica diferentes variantes\n",
    "            SMART para obtener el correspondiente vector numéricos de consulta modificado.\n",
    "        Args:\n",
    "            q (Query): Query(\"Una consulta determinada\")\n",
    "        Returns:\n",
    "            query_vec (dict): El vector resultado.\n",
    "        \"\"\"\n",
    "        # Método de conteo de la clase base:\n",
    "        query_vec = super().get_query_vector(q)\n",
    "\n",
    "        # Frecuencia de término (implementadas las variantes n y b SMART):\n",
    "        if self.query_weight_scheme[\"tf\"] == \"b\":   # Vector query_vec booleano:\n",
    "            ### BEGIN YOUR CODE (FIXME)\n",
    "            # Convertir todos los valores > 0 a 1 (representación booleana)\n",
    "            for term in query_vec:\n",
    "                if query_vec[term] > 0:\n",
    "                    query_vec[term] = 1\n",
    "            ### END YOUR CODE (FIXME)\n",
    "            \n",
    "        # Frecuencia de documento (implementadas las variantes n y t SMART):\n",
    "        if self.query_weight_scheme[\"df\"] == \"n\":     # No se modifica query_vec:\n",
    "            pass\n",
    "        elif self.query_weight_scheme[\"df\"] == \"t\":   # Modificación IDF de query_vec:\n",
    "            ### BEGIN YOUR CODE (FIXME)\n",
    "            # Multiplicar cada término por su IDF\n",
    "            for term in query_vec:\n",
    "                query_vec[term] = query_vec[term] * self.idf.get_idf(term)\n",
    "            ### END YOUR CODE (FIXME)\n",
    "        return query_vec\n",
    "\n",
    "    def get_doc_vector(self, q, d):\n",
    "        \"\"\" Usando los vectores de conteo crudos de la clase base, aplica diferentes variantes\n",
    "            SMART para obtener los correspondientes vectores numéricos de documento modificados.\n",
    "        Args:\n",
    "        q (Query) : Query(\"Una consulta\")\n",
    "        d (Document) : Query(\"Una consulta\")[\"Un URL\"]\n",
    "        Returns:\n",
    "        doc_vec (dict) : Vectores numéricos modificados, de nuevo con esquema (tipo_de_campo -> (término -> conteo))\n",
    "                    Ejemplo: \"{'url':   {'stanford': 0.13, 'aoerc': 0, 'pool': 0, 'hours': 0},\n",
    "                               'title': {'stanford': 0.11, 'aoerc': 0, 'pool': 0, 'hours': 0},\n",
    "                               ...\n",
    "                               }\"\n",
    "        \"\"\"\n",
    "        # Método de conteo de la clase base:\n",
    "        doc_vec = super().get_doc_vector(q, d)\n",
    "\n",
    "        # Frecuencia de término (implementadas las variantes n y l SMART):\n",
    "        if self.doc_weight_scheme[\"tf\"] == \"n\":   # No se modifica doc_vec:\n",
    "            pass\n",
    "        elif self.doc_weight_scheme[\"tf\"] == \"l\": # Modificación logarítmica (sublineal) de doc_vec\n",
    "            ### BEGIN YOUR CODE (FIXME)\n",
    "            # Para cada campo del documento\n",
    "            for field_type in doc_vec:\n",
    "                # Para cada término en ese campo\n",
    "                for term in doc_vec[field_type]:\n",
    "                    raw_count = doc_vec[field_type][term]\n",
    "                    if raw_count > 0:\n",
    "                        # Aplicar escalado logarítmico: 1 + log(raw_count)\n",
    "                        doc_vec[field_type][term] = 1 + math.log(raw_count)\n",
    "                    # Si raw_count == 0, se mantiene en 0\n",
    "            ### END YOUR CODE (FIXME)\n",
    "            \n",
    "        # Normalización:\n",
    "        if self.doc_weight_scheme['norm'] == \"default\":\n",
    "            doc_vec = self.normalize_doc_vec(q, d, doc_vec)\n",
    "\n",
    "        return doc_vec\n",
    "\n",
    "    def get_sim_score(self, q, d, field_type):\n",
    "        \"\"\" Cálculo del scoring para un campo individual:\n",
    "        Args:\n",
    "            q (Query) : La consulta.\n",
    "            d (Document) : El documento.\n",
    "            field_type (str) : El campo del que se usará el vector de documento.\n",
    "        Return:\n",
    "            score (float) : El scoring individual (para el campo field_type) del par (q,d):\n",
    "        \"\"\"\n",
    "        ### BEGIN YOUR CODE (FIXME)\n",
    "        score = 0\n",
    "        \n",
    "        # Obtener vectores de consulta y documento\n",
    "        query_vec = self.get_query_vector(q)\n",
    "        doc_vec = self.get_doc_vector(q, d)\n",
    "        \n",
    "        # Obtener el vector del campo específico\n",
    "        field_vec = doc_vec[field_type]\n",
    "        \n",
    "        # Calcular producto escalar: sumar query_vec[term] * field_vec[term] para cada término\n",
    "        for term in query_vec:\n",
    "            if term in field_vec:\n",
    "                score += query_vec[term] * field_vec[term]\n",
    "        \n",
    "        ### END YOUR CODE (FIXME)\n",
    "        return score\n",
    "\n",
    "    def get_net_score(self, q, d):\n",
    "        \"\"\" Cálculo del scoring global (neto), usando los cinco pesos:\n",
    "        Args:\n",
    "            q (Query) : La consulta.\n",
    "            d (Document) : El documento.\n",
    "        Return:\n",
    "            score (float) : El scoring global (neto, sumando todos los campos) del par (q,d):\n",
    "        \"\"\"\n",
    "        ### BEGIN YOUR CODE (FIXME)\n",
    "        score = 0\n",
    "        \n",
    "        # Para cada campo, calcular su scoring individual y multiplicarlo por su peso\n",
    "        for field_type in [\"url\", \"title\", \"headers\", \"anchors\", \"body_hits\"]:\n",
    "            field_score = self.get_sim_score(q, d, field_type)\n",
    "            score += self.weights[field_type] * field_score\n",
    "        \n",
    "        ### END YOUR CODE (FIXME)\n",
    "        return score\n",
    "\n",
    "    ## Normalización\n",
    "    def normalize_doc_vec(self, q, d, doc_vec):\n",
    "        \"\"\" Normalización del vector de documento:\n",
    "        Damos una normalización uniforme basada en la longitud del documento, tal\n",
    "        y como se discutió en el item \"Normalización\" del anterior apartado.\n",
    "        Es decir, dividimos cada componente del vector de documento por\n",
    "        (longitud_del_cuerpo_del_documento + factor_de_suavizado).\n",
    "        \n",
    "        Args:\n",
    "            q (Query) : La consulta.\n",
    "            d (Document) : El documento.\n",
    "            doc_vec (dict) : El vector de documento.\n",
    "        Return:\n",
    "            doc_vec (dict) : El vector de documento tras la normalización.\n",
    "        \"\"\"\n",
    "        ### BEGIN YOUR CODE (FIXME)\n",
    "        # Calcular el factor de normalización\n",
    "        norm_factor = d.body_length + self.smoothing_body_length\n",
    "        \n",
    "        # Normalizar cada campo dividiendo por el factor de normalización\n",
    "        for field_type in doc_vec:\n",
    "            for term in doc_vec[field_type]:\n",
    "                doc_vec[field_type][term] = doc_vec[field_type][term] / norm_factor\n",
    "        \n",
    "        ### END YOUR CODE (FIXME)\n",
    "        # print(d.body_length, self.smoothing_body_length)\n",
    "\n",
    "        return doc_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt-aTjjm97C8"
   },
   "source": [
    "He aquí una primera prueba sencilla de _scoring_ de un par ($q$,$d$) usando esta similaridad del coseno, en particular usando el esquema SMART _ddd.qqq_ = _nnn.bnn_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MiSsb3iXu8Q",
    "outputId": "e2287b08-916f-4d0e-fc8f-ecb9801646f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector consulta:  Counter({'stanford': 1, 'aoerc': 1, 'pool': 1, 'hours': 1}) \n",
      "\n",
      "Vector de documento original:\n",
      " {'url': Counter({'events': 1, 'stanford': 1, 'edu': 1, '2014': 1, 'february': 1, '18': 1}), 'title': Counter({'events': 1, 'at': 1, 'stanford': 1, 'tuesday': 1, 'february': 1, '18': 1, '2014': 1}), 'headers': Counter({'stanford': 5, 'university': 1, 'event': 1, 'calendar': 1, 'teaching': 1, 'sex': 1, 'at': 1, 'rodin': 1, 'the': 1, 'complete': 1, 'collection': 1, 'rec': 1, 'trx': 1, 'suspension': 1, 'training': 1, 'memorial': 1, 'church': 1, 'open': 1, 'visiting': 1, 'hours': 1, 'alternative': 1, 'transportation': 1, 'counseling': 1, 'tm': 1, '3': 1, 'hour': 1, 'univ': 1, 'shc': 1, 'employees': 1, 'retirees': 1, 'family': 1, 'members': 1}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 10, 'aoerc': 7, 'pool': 1})} \n",
      "\n",
      "---\n",
      "Scoring campo url: 1\n",
      "Scoring campo title: 1\n",
      "Scoring campo headers: 6\n",
      "Scoring campo anchors: 0\n",
      "Scoring campo body_hits: 18\n",
      "\n",
      "Scoring neto: 12.5\n"
     ]
    }
   ],
   "source": [
    "q = Query(\"stanford aoerc pool hours\")\n",
    "d = query_dict[q]['http://events.stanford.edu/2014/February/18/']\n",
    "doc_weight_scheme = {\"tf\": 'n', \"df\": 'n', \"norm\": None}\n",
    "query_weight_scheme = {\"tf\": 'b', \"df\": 'n', \"norm\": None}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector consulta: ', cs.get_query_vector(q), '\\n')\n",
    "print('Vector de documento original:\\n', cs.get_doc_vector(q, d), '\\n')\n",
    "print(\"---\")\n",
    "print(\"Scoring campo url:\", cs.get_sim_score(q,d,\"url\"))\n",
    "print(\"Scoring campo title:\", cs.get_sim_score(q,d,\"title\"))\n",
    "print(\"Scoring campo headers:\", cs.get_sim_score(q,d,\"headers\"))\n",
    "print(\"Scoring campo anchors:\", cs.get_sim_score(q,d,\"anchors\"))\n",
    "print(\"Scoring campo body_hits:\", cs.get_sim_score(q,d,\"body_hits\"))\n",
    "print(\"\\nScoring neto:\", cs.get_net_score(q,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida tendría que ser la siguiente:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vector consulta:  Counter({'stanford': 1, 'aoerc': 1, 'pool': 1, 'hours': 1}) \n",
    "\n",
    "Vector de documento original:\n",
    " {'url': Counter({'events': 1, 'stanford': 1, 'edu': 1, '2014': 1, 'february': 1, '18': 1}), 'title': Counter({'events': 1, 'at': 1, 'stanford': 1, 'tuesday': 1, 'february': 1, '18': 1, '2014': 1}), 'headers': Counter({'stanford': 5, 'university': 1, 'event': 1, 'calendar': 1, 'teaching': 1, 'sex': 1, 'at': 1, 'rodin': 1, 'the': 1, 'complete': 1, 'collection': 1, 'rec': 1, 'trx': 1, 'suspension': 1, 'training': 1, 'memorial': 1, 'church': 1, 'open': 1, 'visiting': 1, 'hours': 1, 'alternative': 1, 'transportation': 1, 'counseling': 1, 'tm': 1, '3': 1, 'hour': 1, 'univ': 1, 'shc': 1, 'employees': 1, 'retirees': 1, 'family': 1, 'members': 1}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 10, 'aoerc': 7, 'pool': 1})} \n",
    "\n",
    "---\n",
    "Scoring campo url: 1\n",
    "Scoring campo title: 1\n",
    "Scoring campo headers: 6\n",
    "Scoring campo anchors: 0\n",
    "Scoring campo body_hits: 18\n",
    "\n",
    "Scoring neto: 12.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTEKmPiOAfRf"
   },
   "source": [
    "Y he aquí, para el mismo par ($q$,$d$), algunos posibles vectores alternativos, obtenidos usando diferentes variantes SMART, tanto para la consulta $q$ como para el documento $d$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99aWF9shXu8R",
    "outputId": "c296936e-d36d-47de-e6f1-85c01aa6f575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector consulta original:  Counter({'stanford': 1, 'aoerc': 1, 'pool': 1, 'hours': 1}) \n",
      "\n",
      "Vector consulta IDF:  Counter({'aoerc': 11.502865028055611, 'pool': 5.633568114921836, 'hours': 2.9662614431195498, 'stanford': 0.3295747967117297}) \n",
      "\n",
      "Vector de documento original:\n",
      " {'url': Counter({'events': 1, 'stanford': 1, 'edu': 1, '2014': 1, 'february': 1, '18': 1}), 'title': Counter({'events': 1, 'at': 1, 'stanford': 1, 'tuesday': 1, 'february': 1, '18': 1, '2014': 1}), 'headers': Counter({'stanford': 5, 'university': 1, 'event': 1, 'calendar': 1, 'teaching': 1, 'sex': 1, 'at': 1, 'rodin': 1, 'the': 1, 'complete': 1, 'collection': 1, 'rec': 1, 'trx': 1, 'suspension': 1, 'training': 1, 'memorial': 1, 'church': 1, 'open': 1, 'visiting': 1, 'hours': 1, 'alternative': 1, 'transportation': 1, 'counseling': 1, 'tm': 1, '3': 1, 'hour': 1, 'univ': 1, 'shc': 1, 'employees': 1, 'retirees': 1, 'family': 1, 'members': 1}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 10, 'aoerc': 7, 'pool': 1})} \n",
      "\n",
      "-----\n",
      "Vector de documento normalizado:\n",
      " {'url': Counter({'events': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'edu': 0.0006752194463200541, '2014': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541}), 'title': Counter({'events': 0.0006752194463200541, 'at': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'tuesday': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541, '2014': 0.0006752194463200541}), 'headers': Counter({'stanford': 0.00337609723160027, 'university': 0.0006752194463200541, 'event': 0.0006752194463200541, 'calendar': 0.0006752194463200541, 'teaching': 0.0006752194463200541, 'sex': 0.0006752194463200541, 'at': 0.0006752194463200541, 'rodin': 0.0006752194463200541, 'the': 0.0006752194463200541, 'complete': 0.0006752194463200541, 'collection': 0.0006752194463200541, 'rec': 0.0006752194463200541, 'trx': 0.0006752194463200541, 'suspension': 0.0006752194463200541, 'training': 0.0006752194463200541, 'memorial': 0.0006752194463200541, 'church': 0.0006752194463200541, 'open': 0.0006752194463200541, 'visiting': 0.0006752194463200541, 'hours': 0.0006752194463200541, 'alternative': 0.0006752194463200541, 'transportation': 0.0006752194463200541, 'counseling': 0.0006752194463200541, 'tm': 0.0006752194463200541, '3': 0.0006752194463200541, 'hour': 0.0006752194463200541, 'univ': 0.0006752194463200541, 'shc': 0.0006752194463200541, 'employees': 0.0006752194463200541, 'retirees': 0.0006752194463200541, 'family': 0.0006752194463200541, 'members': 0.0006752194463200541}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 0.00675219446320054, 'aoerc': 0.004726536124240378, 'pool': 0.0006752194463200541})} \n",
      "\n",
      "-----\n",
      "Vector de documento con escalado logarítmico de tf:\n",
      " {'url': Counter({'events': 1.0, 'stanford': 1.0, 'edu': 1.0, '2014': 1.0, 'february': 1.0, '18': 1.0}), 'title': Counter({'events': 1.0, 'at': 1.0, 'stanford': 1.0, 'tuesday': 1.0, 'february': 1.0, '18': 1.0, '2014': 1.0}), 'headers': Counter({'stanford': 2.6094379124341005, 'university': 1.0, 'event': 1.0, 'calendar': 1.0, 'teaching': 1.0, 'sex': 1.0, 'at': 1.0, 'rodin': 1.0, 'the': 1.0, 'complete': 1.0, 'collection': 1.0, 'rec': 1.0, 'trx': 1.0, 'suspension': 1.0, 'training': 1.0, 'memorial': 1.0, 'church': 1.0, 'open': 1.0, 'visiting': 1.0, 'hours': 1.0, 'alternative': 1.0, 'transportation': 1.0, 'counseling': 1.0, 'tm': 1.0, '3': 1.0, 'hour': 1.0, 'univ': 1.0, 'shc': 1.0, 'employees': 1.0, 'retirees': 1.0, 'family': 1.0, 'members': 1.0}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 3.302585092994046, 'aoerc': 2.9459101490553135, 'pool': 1.0})} \n",
      "\n",
      "-----\n",
      "Vector de documento con escalado logarítmico y normalizado:\n",
      " {'url': Counter({'events': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'edu': 0.0006752194463200541, '2014': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541}), 'title': Counter({'events': 0.0006752194463200541, 'at': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'tuesday': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541, '2014': 0.0006752194463200541}), 'headers': Counter({'stanford': 0.001761943222440311, 'university': 0.0006752194463200541, 'event': 0.0006752194463200541, 'calendar': 0.0006752194463200541, 'teaching': 0.0006752194463200541, 'sex': 0.0006752194463200541, 'at': 0.0006752194463200541, 'rodin': 0.0006752194463200541, 'the': 0.0006752194463200541, 'complete': 0.0006752194463200541, 'collection': 0.0006752194463200541, 'rec': 0.0006752194463200541, 'trx': 0.0006752194463200541, 'suspension': 0.0006752194463200541, 'training': 0.0006752194463200541, 'memorial': 0.0006752194463200541, 'church': 0.0006752194463200541, 'open': 0.0006752194463200541, 'visiting': 0.0006752194463200541, 'hours': 0.0006752194463200541, 'alternative': 0.0006752194463200541, 'transportation': 0.0006752194463200541, 'counseling': 0.0006752194463200541, 'tm': 0.0006752194463200541, '3': 0.0006752194463200541, 'hour': 0.0006752194463200541, 'univ': 0.0006752194463200541, 'shc': 0.0006752194463200541, 'employees': 0.0006752194463200541, 'retirees': 0.0006752194463200541, 'family': 0.0006752194463200541, 'members': 0.0006752194463200541}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 0.002229969677916304, 'aoerc': 0.0019891358197537566, 'pool': 0.0006752194463200541})} \n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "q = Query(\"stanford aoerc pool hours\")\n",
    "d = query_dict[q]['http://events.stanford.edu/2014/February/18/']\n",
    "\n",
    "query_weight_scheme, doc_weight_scheme = None, None\n",
    "\n",
    "query_weight_scheme = {\"tf\": 'b', \"df\": 'n', \"norm\": None}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector consulta original: ', cs.get_query_vector(q), '\\n')\n",
    "\n",
    "query_weight_scheme = {\"tf\": 'b', \"df\": 't', \"norm\": None}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector consulta IDF: ', cs.get_query_vector(q), '\\n')\n",
    "\n",
    "doc_weight_scheme = {\"tf\": 'n', \"df\": 'n', \"norm\": None}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector de documento original:\\n', cs.get_doc_vector(q, d), '\\n')\n",
    "print(\"-----\")\n",
    "\n",
    "doc_weight_scheme = {\"tf\": 'n', \"df\": 'n', \"norm\": \"default\"}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector de documento normalizado:\\n', cs.get_doc_vector(q, d), '\\n')\n",
    "print(\"-----\")\n",
    "\n",
    "doc_weight_scheme = {\"tf\": 'l', \"df\": 'n', \"norm\": None}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector de documento con escalado logarítmico de tf:\\n', cs.get_doc_vector(q, d), '\\n')\n",
    "print(\"-----\")\n",
    "\n",
    "doc_weight_scheme = {\"tf\": 'l', \"df\": 'n', \"norm\": \"default\"}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector de documento con escalado logarítmico y normalizado:\\n', cs.get_doc_vector(q, d), '\\n')\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida debería ser la siguiente:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vector consulta original:  Counter({'stanford': 1, 'aoerc': 1, 'pool': 1, 'hours': 1}) \n",
    "\n",
    "Vector consulta IDF:  Counter({'aoerc': 4.995630807762446, 'pool': 2.446627545736658, 'hours': 1.2882309766291968, 'stanford': 0.14313251558629017}) \n",
    "\n",
    "Vector de documento original:\n",
    " {'url': Counter({'events': 1, 'stanford': 1, 'edu': 1, '2014': 1, 'february': 1, '18': 1}), 'title': Counter({'events': 1, 'at': 1, 'stanford': 1, 'tuesday': 1, 'february': 1, '18': 1, '2014': 1}), 'headers': Counter({'stanford': 5, 'university': 1, 'event': 1, 'calendar': 1, 'teaching': 1, 'sex': 1, 'at': 1, 'rodin': 1, 'the': 1, 'complete': 1, 'collection': 1, 'rec': 1, 'trx': 1, 'suspension': 1, 'training': 1, 'memorial': 1, 'church': 1, 'open': 1, 'visiting': 1, 'hours': 1, 'alternative': 1, 'transportation': 1, 'counseling': 1, 'tm': 1, '3': 1, 'hour': 1, 'univ': 1, 'shc': 1, 'employees': 1, 'retirees': 1, 'family': 1, 'members': 1}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 10, 'aoerc': 7, 'pool': 1})} \n",
    "\n",
    "-----\n",
    "Vector de documento normalizado:\n",
    " {'url': Counter({'events': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'edu': 0.0006752194463200541, '2014': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541}), 'title': Counter({'events': 0.0006752194463200541, 'at': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'tuesday': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541, '2014': 0.0006752194463200541}), 'headers': Counter({'stanford': 0.00337609723160027, 'university': 0.0006752194463200541, 'event': 0.0006752194463200541, 'calendar': 0.0006752194463200541, 'teaching': 0.0006752194463200541, 'sex': 0.0006752194463200541, 'at': 0.0006752194463200541, 'rodin': 0.0006752194463200541, 'the': 0.0006752194463200541, 'complete': 0.0006752194463200541, 'collection': 0.0006752194463200541, 'rec': 0.0006752194463200541, 'trx': 0.0006752194463200541, 'suspension': 0.0006752194463200541, 'training': 0.0006752194463200541, 'memorial': 0.0006752194463200541, 'church': 0.0006752194463200541, 'open': 0.0006752194463200541, 'visiting': 0.0006752194463200541, 'hours': 0.0006752194463200541, 'alternative': 0.0006752194463200541, 'transportation': 0.0006752194463200541, 'counseling': 0.0006752194463200541, 'tm': 0.0006752194463200541, '3': 0.0006752194463200541, 'hour': 0.0006752194463200541, 'univ': 0.0006752194463200541, 'shc': 0.0006752194463200541, 'employees': 0.0006752194463200541, 'retirees': 0.0006752194463200541, 'family': 0.0006752194463200541, 'members': 0.0006752194463200541}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 0.00675219446320054, 'aoerc': 0.004726536124240378, 'pool': 0.0006752194463200541})} \n",
    "\n",
    "-----\n",
    "Vector de documento con escalado logarítmico de tf:\n",
    " {'url': Counter({'events': 1.0, 'stanford': 1.0, 'edu': 1.0, '2014': 1.0, 'february': 1.0, '18': 1.0}), 'title': Counter({'events': 1.0, 'at': 1.0, 'stanford': 1.0, 'tuesday': 1.0, 'february': 1.0, '18': 1.0, '2014': 1.0}), 'headers': Counter({'stanford': 2.6094379124341005, 'university': 1.0, 'event': 1.0, 'calendar': 1.0, 'teaching': 1.0, 'sex': 1.0, 'at': 1.0, 'rodin': 1.0, 'the': 1.0, 'complete': 1.0, 'collection': 1.0, 'rec': 1.0, 'trx': 1.0, 'suspension': 1.0, 'training': 1.0, 'memorial': 1.0, 'church': 1.0, 'open': 1.0, 'visiting': 1.0, 'hours': 1.0, 'alternative': 1.0, 'transportation': 1.0, 'counseling': 1.0, 'tm': 1.0, '3': 1.0, 'hour': 1.0, 'univ': 1.0, 'shc': 1.0, 'employees': 1.0, 'retirees': 1.0, 'family': 1.0, 'members': 1.0}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 3.302585092994046, 'aoerc': 2.9459101490553135, 'pool': 1.0})} \n",
    "\n",
    "-----\n",
    "Vector de documento con escalado logarítmico y normalizado:\n",
    " {'url': Counter({'events': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'edu': 0.0006752194463200541, '2014': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541}), 'title': Counter({'events': 0.0006752194463200541, 'at': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'tuesday': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541, '2014': 0.0006752194463200541}), 'headers': Counter({'stanford': 0.001761943222440311, 'university': 0.0006752194463200541, 'event': 0.0006752194463200541, 'calendar': 0.0006752194463200541, 'teaching': 0.0006752194463200541, 'sex': 0.0006752194463200541, 'at': 0.0006752194463200541, 'rodin': 0.0006752194463200541, 'the': 0.0006752194463200541, 'complete': 0.0006752194463200541, 'collection': 0.0006752194463200541, 'rec': 0.0006752194463200541, 'trx': 0.0006752194463200541, 'suspension': 0.0006752194463200541, 'training': 0.0006752194463200541, 'memorial': 0.0006752194463200541, 'church': 0.0006752194463200541, 'open': 0.0006752194463200541, 'visiting': 0.0006752194463200541, 'hours': 0.0006752194463200541, 'alternative': 0.0006752194463200541, 'transportation': 0.0006752194463200541, 'counseling': 0.0006752194463200541, 'tm': 0.0006752194463200541, '3': 0.0006752194463200541, 'hour': 0.0006752194463200541, 'univ': 0.0006752194463200541, 'shc': 0.0006752194463200541, 'employees': 0.0006752194463200541, 'retirees': 0.0006752194463200541, 'family': 0.0006752194463200541, 'members': 0.0006752194463200541}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 0.002229969677916304, 'aoerc': 0.0019891358197537566, 'pool': 0.0006752194463200541})} \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "RI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
