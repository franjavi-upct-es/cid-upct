{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hsV88l89O24"
   },
   "source": [
    "# Función de _ranking_ 1: Similaridad del coseno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_b6g67dI9O24"
   },
   "source": [
    "Mas allá del _scoring_ _baseline_ (un tanto _naive_) anterior, la primera función de _ranking_ más elaborada que aplicaremos consistirá en una variante clásica de la similitud coseno (con la norma L1). Se trata esencialmente de construir el vector del documento y el vector de la consulta para luego tomar el producto escalar como resultado.\n",
    "En realidad, es exactamente lo mismo que hemos hecho ya para el simple conteo de términos anterior (suponiendo que el vector consulta era siempre un vector binario con 1 en los términos contenidos en la consulta, y 0 en el resto). Ahora, sin embargo, en lugar de tomar simplemente los conteos de términos (tanto en la consulta como en el documento), podrían considerarse varias alternativas para calcular el peso (=componente) de cada término, decidiendo:\n",
    "\n",
    "1. Cómo se calcula exactamente la frecuencia de cada término.\n",
    "2. Cómo se realiza la ponderación por frecuencia de documento de cada término.\n",
    "3. La estrategia de normalización seguida.\n",
    "\n",
    "De nuevo, la figura 6.15 de la página 128 del libro de Manning ([enlace](http://nlp.stanford.edu/IR-book/pdf/06vect.pdf)) nos recuerda todas las posibles alternativas para ello, según la notación SMART.\n",
    "\n",
    "En lo que sigue discutiremos las opciones para ambos vectores por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeJBuqVgXu8P"
   },
   "source": [
    "## Vectores de consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLSmX-K49O24"
   },
   "source": [
    "* **Frecuencia del término** (_tf_):\n",
    "Las frecuencias crudas pueden computarse de forma sencilla a partir de los términos de la consulta. Deberían corresponderse, en la mayoría de los casos, con un simple 1 para cada término que apareciese en la consulta, equivalente a la opción _\"boolean\"_ (pero no necesariamente, ya que algún término podría aparecer repetido). Dicha frecuencia cruda podría, si se desease, ser escalada sublinealmente (usando el logaritmo). En todo caso, en este notebook mantendremos el enfoque simple del conteo natural de términos, muy similar al vector booleano, dado que la inmensa mayoría de las consultas del _dataset_ no contienen términos repetidos.\n",
    "\n",
    "* **Frecuencia del documento** (_df_):\n",
    "Cada uno de los términos en el vector de la consulta deberá entonces ser pesado (=multiplicado) usando el valor de IDF correspondiente para cada término. Usaremos, como ya se comentó antes en este mismo notebook, el IDF computado a partir del corpus de la práctica 1. Recuérdese que, para el caso de palabras que no apareciesen en dicho corpus, se usará la técnica del suavizado Laplaciano (es decir, simplemente sumar 1 en el numerador y en el denominador; esto equivale esencialmente a asumir la existencia de un hipotético documento _\"dummy\"_ que contiene todos los posibles términos)\n",
    "\n",
    "* **Normalización** (_norm_):\n",
    "En ningún caso será necesario normalizar el vector de consulta, ya que cualquier posible normalización se aplicaría por igual al cruzarlo con todos los correspondientes documentos resultado, obteniéndose un simple escalado uniforme de los valores de _scoring_, lo que obviamente no influiría en absoluto en el correspondiente _ranking_ de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0gv0n8SXu8Q"
   },
   "source": [
    "## Vectores de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXjTFreN9O24"
   },
   "source": [
    "* **Frecuencia del término** (_tf_):\n",
    "Al igual que con el vector de consulta, podremos utilizar directamente las frecuencias crudas, o, alternativamente, aplicar algún tipo de escalado sublineal. En particular, el escalado sublineal típico es $tf_i = 1 + log(rs_i)$ si $rs_i > 0$, o simplemente $0$ en caso contrario. Así, por ejemplo, para el anterior vector _tf_ del campo **body** del documento _d_, el vector resultante sería $[\\text{1+log(10)  1+log(7)  1+log(1)  0}]^T$ (de nuevo, puede encontrarse más información sobre el escalado sublineal del término _tf_ en la página 126, sección 6.4.1 del [libro de Manning](http://nlp.stanford.edu/IR-book/pdf/06vect.pdf)).\n",
    "\n",
    "* **Frecuencia del documento** (_df_):\n",
    "No utilizaremos ningún tipo de frecuencia del documento en el vector de documento. En lugar de ello, se incorporará este peso únicamente en el vector de consulta, como se describía en el apartado anterior.\n",
    "\n",
    "* **Normalización** (_norm_):\n",
    "En este caso, no podemos usar la normalización del coseno, dado que nuestros archivos de entrenamiento no proporcionan acceso al contenido del documento en sí, sino solo un resumen de campos. Por lo tanto, no sabemos ni qué otros términos aparecen, ni el recuento de los mismos, en el campo **body**. En lugar de ello, por tanto, utilizaremos la normalización de longitud. Además, dado que puede haber enormes discrepancias entre las longitudes de los diferentes campos, dividimos todos los campos por el mismo factor de normalización, la propia longitud del campo **body**. Dado, además, el hecho de que algunos documentos aparecen con una longitud de 0, una buena estrategia es, de nuevo, agregar un valor (p.e. 500), a la longitud del cuerpo de cada documento. El valor concreto a utilizar, además, puede ser también utilizado para experimentar con ésta u otras estrategias de suavizado, y observar su posible influencia en los resultados de _ranking_ obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6rDDMYUXu8Q"
   },
   "source": [
    "## Pesado relativo de los diferentes campos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4P5hJ8kYXu8Q"
   },
   "source": [
    "Dado un documento $d$ y una consulta $q$, si $qv_q$ es el vector resultante de la consulta y $tf_{d,u}$, $tf_{d,t}$, $tf_{d,b}$, $tf_{d,h}$ y $tf_{d,a}$ son los vectores resultantes para cada uno de los campos **url**, **title**, **body**, **header** and **anchor**, respectivamente, definimos el _scoring_ global neto como (nótese que el símbolo $\\cdot$ se usa en la siguiente expresión tanto para el producto escalar entre vectores como para el producto de un escalar por un vector):\n",
    "\n",
    "$$qv_q \\cdot (c_u \\cdot tf_{d,u} + c_t \\cdot tf_{d,t} + c_b \\cdot tf_{d,b} + c_h \\cdot tf_{d,h} + c_a \\cdot tf_{d,a})$$\n",
    "\n",
    "Donde $c_u$, $c_t$, $c_b$, $c_h$ y $c_a$ son los pesos dados a los campos **url**, **title**, **body**, **header** y **anchor**, respectivamente.\n",
    "\n",
    "Por supuesto, para usar la expresión anterior necesitamos determinar de una forma sensata los pesos para cada uno de estos cinco campos. En este sentido, trataremos de escogerlos de forma que la función NDCG de evaluación (que describiremos más adelante) obtenga un valor lo más optimizado posible cuando sea aplicada al conjunto de test completo. Usaremos el conjunto de _training_ para intentar derivar dicho valor óptimo de los cinco parámetros mencionados, para luego evaluar su rendimiento en el conjunto de _test_. En una primera instancia, lo intentaremos hacer manualmente, intentando razonar simplemente sobre la importancia relativa de los diferentes pesos. Al final del notebook sustituiremos esta suerte de \"razonamiento manual\" por una śencilla técnica de _machine learning_.\n",
    "\n",
    "Nótese que el valor absoluto de dichos pesos no importará, sólo la relación (ratio) entre ellos (valores relativos), dado que si multiplicamos todos los pesos por la misma constante, el _scoring_ final quedará simplemente multiplicado por dicha constante para todos los documentos por igual, lo que obviamente no afectará en absoluto a la ordenación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O25xXnvz3aCC"
   },
   "source": [
    "### Esquema de _weighting_ inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x2v0V6v9O24"
   },
   "source": [
    "Proporcionamos aquí un esquema de pesado por defecto de partida, que puede después variarse para intentar mejorar el rendimiento (medido con NDGC). Nótese que:\n",
    "* En estos primeros pesos por defecto se asigna una importancia del peso de la URL 100 veces superior a la del resto de pesos, a los que, por otro lado, se da un peso equivalente.\n",
    "* Se añade al conjunto de parámetros ajustables un parámetro de suavizado de la longitud del documento (`smoothing_body_length`), término que podrá ser modificado para influir en la función de _scoring_ final. Dicho término será simplemente sumado a la longitud original de cada documento (con lo que, en todo caso, y como se comentó anteriormente, se evitará siempre la posible división por cero para documentos en los cuales la longitud indicada en el documento del dataset de entrada sea cero). Se deduce, pues, que dar un valor cada vez mayor para este parámetro implicará una influencia progresivamente menor del campo `body_length` original de cada documento particular, ya que el correspondiente factor de influencia de la longitud tenderá con ello a homogeneizarse más para todos los documentos, al disminuir progresivamente el peso relativo del valor inicial de `body_length` en la suma total del denominador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "e46XW4OH9O26"
   },
   "outputs": [],
   "source": [
    "params_cosine = {\n",
    "    \"url_weight\" : 10,\n",
    "    \"title_weight\": 0.1,\n",
    "    \"body_hits_weight\" : 0.1,\n",
    "    \"header_weight\" : 0.1,\n",
    "    \"anchor_weight\" : 0.1,\n",
    "    \"smoothing_body_length\" : 500,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7NxyuAB3j46"
   },
   "source": [
    "## Clase _CosineSimilarityScorer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53E1MUCo3yab"
   },
   "source": [
    "He aquí la definición de una clase para realizar un _scoring_ basado en la similaridad del coseno (basada en la clase `AbstractScorer` definida anteriormente, y reimplementando los métodos adecuados):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtG8AVtv9O27"
   },
   "outputs": [],
   "source": [
    "class CosineSimilarityScorer(AbstractScorer):\n",
    "\n",
    "    def __init__(self, idf, query_dict, params, query_weight_scheme=None, doc_weight_scheme=None):\n",
    "        # Inicializamos clase base \"AbstractScorer\", ...\n",
    "        super().__init__(idf, query_weight_scheme=query_weight_scheme, doc_weight_scheme=doc_weight_scheme)\n",
    "        self.query_dict = query_dict\n",
    "        # ... y añadimos los parámetros necesarios (5 pesos de los 5 campos + factor suavizado longitud):\n",
    "        try:\n",
    "            self.smoothing_body_length = params[\"smoothing_body_length\"]\n",
    "        except:\n",
    "            self.smoothing_body_length = 0\n",
    "        self.weights = {\"url\": params[\"url_weight\"], \"title\": params[\"title_weight\"],\n",
    "                        \"headers\": params[\"header_weight\"], \"anchors\": params[\"anchor_weight\"],\n",
    "                        \"body_hits\": params[\"body_hits_weight\"]}\n",
    "\n",
    "    def get_query_vector(self, q):\n",
    "        \"\"\" Usando los vectores de conteo crudos de la clase base, aplica diferentes variantes\n",
    "            SMART para obtener el correspondiente vector numéricos de consulta modificado.\n",
    "        Args:\n",
    "            q (Query): Query(\"Una consulta determinada\")\n",
    "        Returns:\n",
    "            query_vec (dict): El vector resultado.\n",
    "        \"\"\"\n",
    "        # Método de conteo de la clase base:\n",
    "        query_vec = super().get_query_vector(q)\n",
    "\n",
    "        # Frecuencia de documento (implementadas las variantes n, b, y t SMART):\n",
    "        if self.query_weight_scheme[\"tf\"] == \"b\":   # Vector query_vec booleano:\n",
    "            ### BEGIN YOUR CODE (FIXME)\n",
    "           \n",
    "            ### END YOUR CODE (FIXME)\n",
    "        if self.query_weight_scheme[\"df\"] == \"n\":     # No se modifica query_vec:\n",
    "            pass\n",
    "        elif self.query_weight_scheme[\"df\"] == \"t\":   # Modificación IDF de query_vec:\n",
    "            ### BEGIN YOUR CODE (FIXME)\n",
    "            \n",
    "\n",
    "            ### END YOUR CODE (FIXME)\n",
    "        return query_vec\n",
    "\n",
    "    def get_doc_vector(self, q, d):\n",
    "        \"\"\" Usando los vectores de conteo crudos de la clase base, aplica diferentes variantes\n",
    "            SMART para obtener los correspondientes vectores numéricos de documento modificados.\n",
    "        Args:\n",
    "        q (Query) : Query(\"Una consulta\")\n",
    "        d (Document) : Query(\"Una consulta\")[\"Un URL\"]\n",
    "        Returns:\n",
    "        doc_vec (dict) : Vectores numéricos modificados, de nuevo con esquema (tipo_de_campo -> (término -> conteo))\n",
    "                    Ejemplo: \"{'url':   {'stanford': 0.13, 'aoerc': 0, 'pool': 0, 'hours': 0},\n",
    "                               'title': {'stanford': 0.11, 'aoerc': 0, 'pool': 0, 'hours': 0},\n",
    "                               ...\n",
    "                               }\"\n",
    "        \"\"\"\n",
    "        # Método de conteo de la clase base:\n",
    "        doc_vec = super().get_doc_vector(q, d)\n",
    "\n",
    "        # Frecuencia de término (implementadas las variantes n y l SMART):\n",
    "        if self.doc_weight_scheme[\"tf\"] == \"n\":   # No se modifica doc_vec:\n",
    "            pass\n",
    "        elif self.doc_weight_scheme[\"tf\"] == \"l\": # Modificación logarítmica (sublineal) de doc_vec\n",
    "            ### BEGIN YOUR CODE (FIXME)\n",
    "            \n",
    "            ### END YOUR CODE (FIXME)\n",
    "        # Normalización:\n",
    "        if self.doc_weight_scheme['norm'] == \"default\":\n",
    "            doc_vec = self.normalize_doc_vec(q, d, doc_vec)\n",
    "\n",
    "        return doc_vec\n",
    "\n",
    "    def get_sim_score(self, q, d, field_type):\n",
    "        \"\"\" Cálculo del scoring para un campo individual:\n",
    "        Args:\n",
    "            q (Query) : La consulta.\n",
    "            d (Document) : El documento.\n",
    "            field_type (str) : El campo del que se usará el vector de documento.\n",
    "        Return:\n",
    "            score (float) : El scoring individual (para el campo field_type) del par (q,d):\n",
    "        \"\"\"\n",
    "        ### BEGIN YOUR CODE (FIXME)\n",
    "\n",
    "        ### END YOUR CODE (FIXME)\n",
    "        return score\n",
    "\n",
    "    def get_net_score(self, q, d):\n",
    "        \"\"\" Cálculo del scoring global (neto), usando los cinco pesos:\n",
    "        Args:\n",
    "            q (Query) : La consulta.\n",
    "            d (Document) : El documento.\n",
    "        Return:\n",
    "            score (float) : El scoring global (neto, sumando todos los campos) del par (q,d):\n",
    "        \"\"\"\n",
    "        ### BEGIN YOUR CODE (FIXME)\n",
    "\n",
    "        ### END YOUR CODE (FIXME)\n",
    "        return score\n",
    "\n",
    "    ## Normalización\n",
    "    def normalize_doc_vec(self, q, d, doc_vec):\n",
    "        \"\"\" Normalización del vector de documento:\n",
    "        Damos una normalización uniforme basada en la longitud del documento, tal\n",
    "        y como se discutió en el item \"Normalización\" del anterior apartado.\n",
    "        Es decir, dividimos cada componente del vector de documento por\n",
    "        (longitud_del_cuerpo_del_documento + factor_de_suavizado).\n",
    "        \n",
    "        Args:\n",
    "            q (Query) : La consulta.\n",
    "            d (Document) : El documento.\n",
    "            doc_vec (dict) : El vector de documento.\n",
    "        Return:\n",
    "            doc_vec (dict) : El vector de documento tras la normalización.\n",
    "        \"\"\"\n",
    "        ### BEGIN YOUR CODE (FIXME)\n",
    "\n",
    "        ### END YOUR CODE (FIXME)\n",
    "        # print(d.body_length, self.smoothing_body_length)\n",
    "\n",
    "        return doc_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt-aTjjm97C8"
   },
   "source": [
    "He aquí una primera prueba sencilla de _scoring_ de un par ($q$,$d$) usando esta similaridad del coseno, en particular usando el esquema SMART _ddd.qqq_ = _nnn.bnn_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MiSsb3iXu8Q",
    "outputId": "e2287b08-916f-4d0e-fc8f-ecb9801646f2"
   },
   "outputs": [],
   "source": [
    "q = Query(\"stanford aoerc pool hours\")\n",
    "d = query_dict[q]['http://events.stanford.edu/2014/February/18/']\n",
    "doc_weight_scheme = {\"tf\": 'n', \"df\": 'n', \"norm\": None}\n",
    "query_weight_scheme = {\"tf\": 'b', \"df\": 'n', \"norm\": None}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector consulta: ', cs.get_query_vector(q), '\\n')\n",
    "print('Vector de documento original:\\n', cs.get_doc_vector(q, d), '\\n')\n",
    "print(\"---\")\n",
    "print(\"Scoring campo url:\", cs.get_sim_score(q,d,\"url\"))\n",
    "print(\"Scoring campo title:\", cs.get_sim_score(q,d,\"title\"))\n",
    "print(\"Scoring campo headers:\", cs.get_sim_score(q,d,\"headers\"))\n",
    "print(\"Scoring campo anchors:\", cs.get_sim_score(q,d,\"anchors\"))\n",
    "print(\"Scoring campo body_hits:\", cs.get_sim_score(q,d,\"body_hits\"))\n",
    "print(\"\\nScoring neto:\", cs.get_net_score(q,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida tendría que ser la siguiente:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vector consulta:  Counter({'stanford': 1, 'aoerc': 1, 'pool': 1, 'hours': 1}) \n",
    "\n",
    "Vector de documento original:\n",
    " {'url': Counter({'events': 1, 'stanford': 1, 'edu': 1, '2014': 1, 'february': 1, '18': 1}), 'title': Counter({'events': 1, 'at': 1, 'stanford': 1, 'tuesday': 1, 'february': 1, '18': 1, '2014': 1}), 'headers': Counter({'stanford': 5, 'university': 1, 'event': 1, 'calendar': 1, 'teaching': 1, 'sex': 1, 'at': 1, 'rodin': 1, 'the': 1, 'complete': 1, 'collection': 1, 'rec': 1, 'trx': 1, 'suspension': 1, 'training': 1, 'memorial': 1, 'church': 1, 'open': 1, 'visiting': 1, 'hours': 1, 'alternative': 1, 'transportation': 1, 'counseling': 1, 'tm': 1, '3': 1, 'hour': 1, 'univ': 1, 'shc': 1, 'employees': 1, 'retirees': 1, 'family': 1, 'members': 1}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 10, 'aoerc': 7, 'pool': 1})} \n",
    "\n",
    "---\n",
    "Scoring campo url: 1\n",
    "Scoring campo title: 1\n",
    "Scoring campo headers: 6\n",
    "Scoring campo anchors: 0\n",
    "Scoring campo body_hits: 18\n",
    "\n",
    "Scoring neto: 12.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTEKmPiOAfRf"
   },
   "source": [
    "Y he aquí, para el mismo par ($q$,$d$), algunos posibles vectores alternativos, obtenidos usando diferentes variantes SMART, tanto para la consulta $q$ como para el documento $d$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99aWF9shXu8R",
    "outputId": "c296936e-d36d-47de-e6f1-85c01aa6f575"
   },
   "outputs": [],
   "source": [
    "q = Query(\"stanford aoerc pool hours\")\n",
    "d = query_dict[q]['http://events.stanford.edu/2014/February/18/']\n",
    "\n",
    "query_weight_scheme, doc_weight_scheme = None, None\n",
    "\n",
    "query_weight_scheme = {\"tf\": 'b', \"df\": 'n', \"norm\": None}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector consulta original: ', cs.get_query_vector(q), '\\n')\n",
    "\n",
    "query_weight_scheme = {\"tf\": 'b', \"df\": 't', \"norm\": None}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector consulta IDF: ', cs.get_query_vector(q), '\\n')\n",
    "\n",
    "doc_weight_scheme = {\"tf\": 'n', \"df\": 'n', \"norm\": None}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector de documento original:\\n', cs.get_doc_vector(q, d), '\\n')\n",
    "print(\"-----\")\n",
    "\n",
    "doc_weight_scheme = {\"tf\": 'n', \"df\": 'n', \"norm\": \"default\"}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector de documento normalizado:\\n', cs.get_doc_vector(q, d), '\\n')\n",
    "print(\"-----\")\n",
    "\n",
    "doc_weight_scheme = {\"tf\": 'l', \"df\": 'n', \"norm\": None}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector de documento con escalado logarítmico de tf:\\n', cs.get_doc_vector(q, d), '\\n')\n",
    "print(\"-----\")\n",
    "\n",
    "doc_weight_scheme = {\"tf\": 'l', \"df\": 'n', \"norm\": \"default\"}\n",
    "cs = CosineSimilarityScorer(theIDF, query_dict, params_cosine, query_weight_scheme, doc_weight_scheme)\n",
    "print('Vector de documento con escalado logarítmico y normalizado:\\n', cs.get_doc_vector(q, d), '\\n')\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida debería ser la siguiente:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vector consulta original:  Counter({'stanford': 1, 'aoerc': 1, 'pool': 1, 'hours': 1}) \n",
    "\n",
    "Vector consulta IDF:  Counter({'aoerc': 4.995630807762446, 'pool': 2.446627545736658, 'hours': 1.2882309766291968, 'stanford': 0.14313251558629017}) \n",
    "\n",
    "Vector de documento original:\n",
    " {'url': Counter({'events': 1, 'stanford': 1, 'edu': 1, '2014': 1, 'february': 1, '18': 1}), 'title': Counter({'events': 1, 'at': 1, 'stanford': 1, 'tuesday': 1, 'february': 1, '18': 1, '2014': 1}), 'headers': Counter({'stanford': 5, 'university': 1, 'event': 1, 'calendar': 1, 'teaching': 1, 'sex': 1, 'at': 1, 'rodin': 1, 'the': 1, 'complete': 1, 'collection': 1, 'rec': 1, 'trx': 1, 'suspension': 1, 'training': 1, 'memorial': 1, 'church': 1, 'open': 1, 'visiting': 1, 'hours': 1, 'alternative': 1, 'transportation': 1, 'counseling': 1, 'tm': 1, '3': 1, 'hour': 1, 'univ': 1, 'shc': 1, 'employees': 1, 'retirees': 1, 'family': 1, 'members': 1}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 10, 'aoerc': 7, 'pool': 1})} \n",
    "\n",
    "-----\n",
    "Vector de documento normalizado:\n",
    " {'url': Counter({'events': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'edu': 0.0006752194463200541, '2014': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541}), 'title': Counter({'events': 0.0006752194463200541, 'at': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'tuesday': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541, '2014': 0.0006752194463200541}), 'headers': Counter({'stanford': 0.00337609723160027, 'university': 0.0006752194463200541, 'event': 0.0006752194463200541, 'calendar': 0.0006752194463200541, 'teaching': 0.0006752194463200541, 'sex': 0.0006752194463200541, 'at': 0.0006752194463200541, 'rodin': 0.0006752194463200541, 'the': 0.0006752194463200541, 'complete': 0.0006752194463200541, 'collection': 0.0006752194463200541, 'rec': 0.0006752194463200541, 'trx': 0.0006752194463200541, 'suspension': 0.0006752194463200541, 'training': 0.0006752194463200541, 'memorial': 0.0006752194463200541, 'church': 0.0006752194463200541, 'open': 0.0006752194463200541, 'visiting': 0.0006752194463200541, 'hours': 0.0006752194463200541, 'alternative': 0.0006752194463200541, 'transportation': 0.0006752194463200541, 'counseling': 0.0006752194463200541, 'tm': 0.0006752194463200541, '3': 0.0006752194463200541, 'hour': 0.0006752194463200541, 'univ': 0.0006752194463200541, 'shc': 0.0006752194463200541, 'employees': 0.0006752194463200541, 'retirees': 0.0006752194463200541, 'family': 0.0006752194463200541, 'members': 0.0006752194463200541}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 0.00675219446320054, 'aoerc': 0.004726536124240378, 'pool': 0.0006752194463200541})} \n",
    "\n",
    "-----\n",
    "Vector de documento con escalado logarítmico de tf:\n",
    " {'url': Counter({'events': 1.0, 'stanford': 1.0, 'edu': 1.0, '2014': 1.0, 'february': 1.0, '18': 1.0}), 'title': Counter({'events': 1.0, 'at': 1.0, 'stanford': 1.0, 'tuesday': 1.0, 'february': 1.0, '18': 1.0, '2014': 1.0}), 'headers': Counter({'stanford': 2.6094379124341005, 'university': 1.0, 'event': 1.0, 'calendar': 1.0, 'teaching': 1.0, 'sex': 1.0, 'at': 1.0, 'rodin': 1.0, 'the': 1.0, 'complete': 1.0, 'collection': 1.0, 'rec': 1.0, 'trx': 1.0, 'suspension': 1.0, 'training': 1.0, 'memorial': 1.0, 'church': 1.0, 'open': 1.0, 'visiting': 1.0, 'hours': 1.0, 'alternative': 1.0, 'transportation': 1.0, 'counseling': 1.0, 'tm': 1.0, '3': 1.0, 'hour': 1.0, 'univ': 1.0, 'shc': 1.0, 'employees': 1.0, 'retirees': 1.0, 'family': 1.0, 'members': 1.0}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 3.302585092994046, 'aoerc': 2.9459101490553135, 'pool': 1.0})} \n",
    "\n",
    "-----\n",
    "Vector de documento con escalado logarítmico y normalizado:\n",
    " {'url': Counter({'events': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'edu': 0.0006752194463200541, '2014': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541}), 'title': Counter({'events': 0.0006752194463200541, 'at': 0.0006752194463200541, 'stanford': 0.0006752194463200541, 'tuesday': 0.0006752194463200541, 'february': 0.0006752194463200541, '18': 0.0006752194463200541, '2014': 0.0006752194463200541}), 'headers': Counter({'stanford': 0.001761943222440311, 'university': 0.0006752194463200541, 'event': 0.0006752194463200541, 'calendar': 0.0006752194463200541, 'teaching': 0.0006752194463200541, 'sex': 0.0006752194463200541, 'at': 0.0006752194463200541, 'rodin': 0.0006752194463200541, 'the': 0.0006752194463200541, 'complete': 0.0006752194463200541, 'collection': 0.0006752194463200541, 'rec': 0.0006752194463200541, 'trx': 0.0006752194463200541, 'suspension': 0.0006752194463200541, 'training': 0.0006752194463200541, 'memorial': 0.0006752194463200541, 'church': 0.0006752194463200541, 'open': 0.0006752194463200541, 'visiting': 0.0006752194463200541, 'hours': 0.0006752194463200541, 'alternative': 0.0006752194463200541, 'transportation': 0.0006752194463200541, 'counseling': 0.0006752194463200541, 'tm': 0.0006752194463200541, '3': 0.0006752194463200541, 'hour': 0.0006752194463200541, 'univ': 0.0006752194463200541, 'shc': 0.0006752194463200541, 'employees': 0.0006752194463200541, 'retirees': 0.0006752194463200541, 'family': 0.0006752194463200541, 'members': 0.0006752194463200541}), 'anchors': Counter(), 'body_hits': Counter({'stanford': 0.002229969677916304, 'aoerc': 0.0019891358197537566, 'pool': 0.0006752194463200541})} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
