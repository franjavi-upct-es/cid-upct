---
title: "Procesos Estocásticos y Series Temporales"
subtitle: "Entregable Práctica 4 y 5 (Modelo A)"
author: "Francisco Javier Mercader Martínez"
output: 
  pdf_document:
    latex_engine: xelatex
geometry: margin=1.5cm, a4paper
header-includes:
- \renewcommand{\and}{\\}
- \usepackage{fvextra}
- \usepackage{hyperref}
- \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines, commandchars=\\\{\}}
---

# Problema 1

En el fichero **ARIMA_modelo_A.txt**, se ecnuentran los datos horarios correspondientes a la concentración de un gas en una zona salvaje. Responder a los siguientes apartados:

```{r}
library(forecast)
library(tseries)
library(tidyverse)
```

1) Obtener, de forma manual y explicando cada paso, un modelo ARIMA como generador de la serie en estudio (no hay que realizar predicciones, pero sí incluir la validación del modelo).

```{r}
datos <- read.csv2("ARIMA_modelo_A.txt", header = FALSE, dec = ".")
datos.ts <- ts(datos$V1, frequency = 1)
ts.plot(datos.ts)
```

- La serie presenta estacionalidad (hay un patrón periódico ascendente)

```{r}
datos_estacionaria <- diff(datos.ts, differences = 1)
ts.plot(datos_estacionaria)
```

```{r}
par(mfrow = c(1, 2))
Acf(datos_estacionaria, main = "Correlograma Simple (ACF)")
Pacf(datos_estacionaria, main = "Correlograma Parcial (PACF)")
```

En el correlograma simple observamos un decaimiento muy lento, tenemos correlaciones hasta retardo 10 más o menos, por otro lado, tenemos que en el correlograma parcial observamos una única correlación significativa.

Al observar un decaimiento tan lento en el correlograma simple, no vamos a poder extraer mucha información modelizando la parte de medias móviles pero al observar el correlograma es posible poder proponer un modelo $AR(1)$

Por lo tanto, vamos a proponer este modelo inicial (con estos datos diferenciados) $ARMA(p=1)$, y en función de la interpretación de los $p$-valores y de la validación de los residuos plantearemos otros modelos o nos quedaremos con este.

```{r}
pvalores <- function(modelo) {
  # Extract coefficients
  coefs <- coef(modelo)
  # Extract standard errores
  se <- sqrt(diag(vcov(modelo)))
  # Calculate the t-values
  t_values <- coefs / se
  # Calculate the p-values
  p_values <- 2 * (1 - pnorm(abs(t_values)))
  # Create a data frame with coefficients, standard errors, t-values, and p-values
  results_pvalues <- data.frame(
    Coefficients = coefs,
    Std_Errors = se,
    T_values = t_values,
    P_values = p_values
  )
  print(results_pvalues)
}
```

```{r}
# Primer modelo propuesto
arima.model100 <- Arima(datos_estacionaria, c(1, 0, 0))
arima.model100
pvalores(arima.model100)
```

Observamos que el `intercept` del modelo puede ser obviado y el modelo reducido ya que tiene el $p$-valor mayor a 0.05.

Propongamos un modelo sin tener en cuenta el `intercept`:

```{r}
arima.model_without_mean <- Arima(datos_estacionaria, c(1, 0, 0), include.mean = FALSE)
arima.model_without_mean
pvalores(arima.model_without_mean)
```

Propongamos ahora otro modelo modelizando también la parte de medias móviles con un orden $q=2$ y observemos si podemos mejorar nuestro modelo:

```{r}
arima.model102 <- Arima(datos_estacionaria, c(1, 0, 2))
arima.model102
pvalores(arima.model102)
```

Observando los $p$-valores de los modelos planteados, se puede obviar el uso de `intercept` y modelizar la parte de medias móviles ya que su $p$-valor es mayor que 0.05 y eso indica que el modelo es reducible.

Modelo final escogido:

```{r}
arima.modelo_final <- Arima(datos_estacionaria, c(1, 0, 0), include.mean = FALSE)
```

Pasemos a validar el modelo

El modelo ARIMA ajustado será válido si se cumplen las hipótesis:

1. Normalidad de los residuos.
2. Homocedasticidad: residuos con varianza constante.
3. Independencia de los residuos.

```{r}
shapiro.test(arima.modelo_final$residuals)
```

No podemos garantizar que los residuos siguen una normal.

```{r}
plot(arima.modelo_final$fitted, arima.modelo_final$residuals)
```

Podemos observar que se cumple la hipótesis de homocedasticidad, es decir, los residuos presentan una varianza constante ya que muestran una distribución homogénea.

```{r}
par(mfrow = c(1, 2))
Acf(arima.modelo_final$residuals, main = "Correlograma Simple (ACF)")
Pacf(arima.modelo_final$residuals, main = "Correlograma Parcial (PACF)")
```

Observando la ACF y PACF de los residuos, hay una correlación significativa, podemos suponer una muy pequeña dependencia en los residuos.

Los residuos del modelo no pasan las hipótesis de normalidad ni de independencia por lo que el modelo no puede ser valido.

2) Obtener el modelo ARIMA de forma automática con una función de **`R`**. Indicar cuál sería la expresión del modelo ARIMA resultante y determinar los intervalos de predicción al 95% para las siguientes 2 horas (no hay que representar las predicciones gráficamente).

```{r}
auto_model <- auto.arima(datos.ts)
summary(auto_model)
```

La obtención automática del modelo nos indica que el modelo correcto para modelizar nuestra serie en estudio sería un $ARIMA(1,1,0)$, el mismo que planteamos nosotros manualmente pero teniendo en cuenta la deriva, se planteó un $AR(1)$ con los datos diferenciados, que a la hora de trabajar con la serie en estudio es un $ARIMA(1,1,0)$.

Expresión del modelo resultante:

$$
(1-0.8048377)X_t=\varepsilon_t
$$

Predicciones para las 2 siguientes horas.

```{r}
pred <- forecast(auto_model, h = 2, level = 0.95)
pred$mean
```

# Problema 2

En el fichero **Consumo_Electrico_modelo_A.csv**, se encuentran los datos horarios del consumo eléctrico (en kW) de los habitantes de una población (datos simulados), entre el 15/05/2009 y el 20/06/2009. También se muestran los registros de Temperatura ambiente (en ºKelvin), humedad relativa y la variable indicadora de festividad "Festivo".

**El objetivo es modelizar la serie de consumo eléctrico horario usando como predictores Temperatura, Humedad, Festivo, así como predictores que representen la tendencia y estacionalidad de la serie (si fueran necesarios).** Responder a las siguientes cuestiones:

```{r}
datos <- read.csv2("Consumo_Electrico_modelo_A.csv", header = TRUE, sep = ";")
sum(is.na(datos))
summary(datos)
```

1) Representa la serie de Consumo en un gráfico temporal. ¿Cómo es la tendencia? ¿La serie presenta estacionalidad? ¿Cuál sería el periodo?

```{r}
ts.plot(datos$Consumo)
```

No presenta una tendencia ya que la media se mantiene constante a lo largo de la serie observada pero si se observa una componente estacional, al ser datos horarios, la serie presenta estacionalidad diaria y semanal, es decir, el periodo de la diaria sería $L=24$ y el periodo de la semanal sería $L=168$

2) Divide los datos en entrenamiento y test, dejando para test sólo los días 19 y 20 de junio.

```{r}
inicio_test <- which(datos$Fecha == "19/06/2009")
indices_train <- 1:(inicio_test - 1)
indices_test <- inicio_test:nrow(datos)
datos_train <- datos[indices_train, ]
datos_test <- datos[indices_test, ]

consumo.ts <- ts(datos$Consumo, start = c(1, 1), frequency = 24)
consumo.ts_train <- window(consumo.ts, end = c(35, 24))
consumo.ts_test <- window(consumo.ts, start = c(36, 1))
```

3) Con los \underline{datos de entrenamiento}, ajusta un modelo regresión lineal múltiple (RLM) para la serie de Consumo **usando como predictores Temperatura, Humedad, Festivo y variables dummy para la estacionalidad diaria (no usar tendencia)**. Indicar el coeficiente de regresión obtenido para la variable "Festivo" e interpretarlo. ¿Se está teniendo en cuenta la estacionalidad semanal?

```{r}
# Eliminamos la variable Fecha y Consumo del dataframe para poder construir el modelo mediante las varaibles restantes.
p1 <- datos |>
  select(-Fecha, -Consumo)

p1.train <- p1[indices_train, ]
p1.test <- p1[indices_test, ]

p1.train_matrix <- as.matrix(p1.train)

modelo_season <- tslm(consumo.ts_train ~ season + p1.train_matrix)
modelo_season
```

4) Analiza si los residuos que resultan del apartado (3) son \underline{independientes}. Justifica si te parece adecuado el modelo planteado en el apartado (3) y qué plantearías en este escenario.

```{r}
ts.plot(modelo_season$residuals)

par(mfrow = c(1, 2))
Acf(modelo_season$residuals, main = "Correlograma Simple (ACF)")
Pacf(modelo_season$residuals, main = "Correlograma Parcial (PACF)")
```

```{r}
shapiro.test(modelo_season$residuals)
plot(modelo_season$residuals, modelo_season$fitted)
```

Se puede observar que los residuos superan la hipótesis de normalidad y la de homocedasticidad por poco pero se puede observar que no tienen un comportamiento como el que tendría un ruido blanco gaussiano y , además, si interpretamos los correlogramas normal y parcial de estos residuos, podemos observar cierta correlación entre ellos, es decir, que no son Independientes. Esto se puede estar dando porque no se está captando toda la información de la serie objetivo y esta información se ha ido a los residuos.

Para corregir esto podemos llegar a plantear realizar una Regresión Dinámica para así modelizar los residuos con un modelo ARIMA y poder explicar la información restante no explicada por los regresores previamente empleados.

5) Con el modelo resultante del apartado (3), realiza las predicciones de la \underline{zona test} (19 y 20 de junio). ¿Cuál es la predicción puntual de consumo eléctrico para el 19 junio a las 6h? ¿Podemos decir que el consumo en esa hora será superior a 2000 kW con un 90%? ¿Se trata de predicciones ex-ante o ex-post?

```{r}
pred_season <- forecast(modelo_season, newdata = p1.test, level = 0.9)
pred_season
```

Predicción puntual cosumo del 19 de junio a las 6h: 2773.677 kW por lo que podemos asegurar que el consumo será superior a 2000 kW.

Estamos realizando predicciones ex-post porque no estamos prediciendo los valores de los regresores sino que utilizamos los valores reales de estos, una sola fuente de incertidumbre ya que solamente tenemos que buscar predecir el consumo para los 2 siguientes días, sin embargo, este tipo de predicción no es del todo realista ya que estamos suponiendo que se pueden predecir los regresores de manera perfecta.

6) Calcula el RMSE, que resulta en la zona de entrenamiento y el RMSE en la zona test.

```{r}
RMSE_train <- sqrt(mean((consumo.ts_train - modelo_season$fitted.values)^2))
RMSE_test <- sqrt(mean((consumo.ts_test - pred_season$mean)^2))
cat("RMSE training:", RMSE_train, "\nRMSE test:", RMSE_test)
```

**Ahora vamos a construir un modelo de regresión dinámica para la serie Consumo**

7) Con los \underline{datos de entrenamiento}, ajusta un modelo de **regresión dinámica** (de froma automática) para la serie de Consumo **usando como predictores la Temperatura, Festivo, Humedad y series de Fourier (con K=6) para la estacionalidad diaria.** ¿Qué modelo ARIMA se obtiene para los residuos del modelo RLM? ¿Contiene parte estacional? En caso afirmativo, explica a qué puede deberse.

```{r}
p1.train_fourier <- data.frame(p1.train, fourier(consumo.ts_train, K = 6))
p1.train_fourier_matrix <- as.matrix(p1.train_fourier)

dyreg_fourier <- auto.arima(consumo.ts_train, xreg = p1.train_fourier_matrix)
summary(dyreg_fourier)
```

Se obtiene un modelo ARIMA(3,0,2)(0,0,1) para modelizar los residuos, sería un modelo SARIMA por lo que los residuos contienen información sobre la estacionalidad, esto se debe a que deberíamos de incrementar el valor de K de los términos de Fourier para poder captar y estimar toda la información de la estacionalidad.

8) Con el modelo resultante del apartado (7), analiza la independencia de los residuos y realiza las predicciones de la \underline{zona test} (19 y 20 de junio). ¿Cuál es la predicción puntual de consumo eléctrico para el 19 de junio a las 6h?

```{r}
p1.test_fourier <- data.frame(p1.test, fourier(consumo.ts_test, K = 6))
p1.test_fourier_matrix <- as.matrix(p1.test_fourier)

pred_reg_dinamica <- forecast(dyreg_fourier, xreg = p1.test_fourier_matrix)
pred_reg_dinamica
```

Predicción para el 19 de junio a las 6h: 3086.477 kW.

9) Representa conjuntamente, para la zona test, los datos reales (en negro), las predicciones obtenidas con el modelo RLM (en verde) y las predicciones obtenidas con el modelo de regresión dinámica (en rojo).

```{r}
ts.plot(consumo.ts_test, pred_season$mean, pred_reg_dinamica$mean,
  col = c("black", "green", "red"),
  lwd = 2
)
```

10) Si se pretende analizar la mejora del modelo de regresión dinámica frente al RLM, ¿te parece adecuado el planteamiento que se ha hecho comparando el modelo del apartado (3) con el del apartado (7)? Justifica tu respuesta argumentando qué harías.

Podemos ver que las predicciones con el modelo de regresión dinámica son mucho mejores porque consiguen modelizar los residuos y se corrigen así mismo por lo que consigue hacer mejores predicciones.
