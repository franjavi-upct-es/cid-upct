{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDidLfcnC9tL"
   },
   "source": [
    "\n",
    "# Práctica 1 - Distancia léxica. Aplicación a la corrección automática.\n",
    "\n",
    "En esta práctica se pretende mostrar algunas librerías para la aplicación de medidas de distancia léxica como Levenshtein y cómo puede aplicarse a la corrección automática de errores \"non real words\" o corrección ortográfica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cs5r6euDFcli"
   },
   "source": [
    "## 1- Calculando distancias de Levenshtein\n",
    "En este apartado vamos a calcular las distancias de Levenshtein de varias palabras y hacer una simple corrección ortográfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 14768,
     "status": "ok",
     "timestamp": 1737445093564,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "RB9YAexWFb9f",
    "outputId": "349eaaf6-9c98-4b42-ce1c-0f019e868739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in /home/codespace/.python/current/lib/python3.12/site-packages (0.26.1)\n",
      "Requirement already satisfied: Levenshtein==0.26.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from python-Levenshtein) (0.26.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from Levenshtein==0.26.1->python-Levenshtein) (3.12.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo distancia de edición para obtener la similitud entre dos cadenas de carácteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1737445145341,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "sUeNWpXBDaSA",
    "outputId": "f4f1eacb-201a-47f0-b562-dbc0fda8a91f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La distancia de Levenshtein entre 'burro' y 'vurro' es: 1\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "\n",
    "# Ejemplo de uso de la distancia de Levenshtein\n",
    "string1 = \"burro\"\n",
    "string2 = \"vurro\"\n",
    "\n",
    "distance = Levenshtein.distance(string1, string2)\n",
    "\n",
    "print(f\"La distancia de Levenshtein entre '{string1}' y '{string2}' es: {distance}\")\n",
    "\n",
    "# Probamos otras palabras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1737389441010,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "SamW8is9G4WG",
    "outputId": "72d392fe-6434-4392-ca50-6b1cdb048e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La distancia de Levenshtein normalizadas entre  'burro' and 'vurro' is: 0.2\n",
      "La distancia de Levenshtein normalizadas entre 'kitten' and 'sitting' is: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "#Podemos calcular la distancia normalizada\n",
    "\n",
    "def normalized_levenshtein(str1, str2):\n",
    "  distance = Levenshtein.distance(str1, str2)\n",
    "  max_len = max(len(str1), len(str2))\n",
    "  if max_len == 0:\n",
    "    return 0\n",
    "  return distance / max_len\n",
    "\n",
    "# Ejemplo de uso\n",
    "string1 = \"burro\"\n",
    "string2 = \"vurro\"\n",
    "\n",
    "normalized_distance = normalized_levenshtein(string1, string2)\n",
    "print(f\"La distancia de Levenshtein normalizadas entre  '{string1}' and '{string2}' is: {normalized_distance}\")\n",
    "\n",
    "# Otro example\n",
    "string3 = \"kitten\"\n",
    "string4 = \"sitting\"\n",
    "normalized_distance = normalized_levenshtein(string3, string4)\n",
    "print(f\"La distancia de Levenshtein normalizadas entre '{string3}' and '{string4}' is: {normalized_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podemos obtener la distancia absoluta(nº operaciones de transformación solamente) y la distancia normalizada(nº operaciones de transformación teniendo en cuenta la longitud de la secuencia de carácteres más grande entre la source-target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1737445169344,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "-PVCdtzAF4pj",
    "outputId": "eaadb642-9654-4d89-d2a3-621e30a46b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabra introducida: pyton\n",
      "Posible corrección: python\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de aplicación a la corrección automática (simple)\n",
    "palabras_correctas = [\"hola\", \"mundo\", \"python\", \"pitón\"]\n",
    "palabra_introducida = \"pyton\"\n",
    "\n",
    "mejor_candidato = \"\"\n",
    "min_distancia = float('inf')\n",
    "\n",
    "for palabra in palabras_correctas:\n",
    "  distancia = Levenshtein.distance(palabra_introducida, palabra)\n",
    "  if distancia < min_distancia:\n",
    "    min_distancia = distancia\n",
    "    mejor_candidato = palabra\n",
    "\n",
    "print(f\"Palabra introducida: {palabra_introducida}\")\n",
    "print(f\"Posible corrección: {mejor_candidato}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NEPtjFsHaR8"
   },
   "source": [
    "## 2. Corrección ortográfica usando algunas librerías\n",
    "En este apartado vamos a ver distintas librerías para la corrección ortográfica que usan distancias léxicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiGjyuI4DJEy"
   },
   "source": [
    "### Creación de los datos a corregir.\n",
    "\n",
    "Se proporcionan dos textos en dos versiones, una sin errores ootográficos y otra en la que se han introducido errores que vamos a intentar corregir mediante el uso de las librerías symspellpy y hunspell. En el segundo texto, algunos de los errores introducidos se corresponden con \"real words\".\n",
    "\n",
    "Los textos se proporcionan en un dataframe de pandas con objeto de ir añadiendo los resultados obtenidos y poder razonar sobre ellos más adelante.\n",
    "\n",
    "Se proporcionan también dos ejemplos de almacenamiento y recupoaración de estos datos en y desde un fichero csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "id": "HPs0-0gJAQva"
   },
   "outputs": [],
   "source": [
    "# Creación de los datos y almacenamiento en fichero:\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "data = pd.DataFrame(\n",
    " {\n",
    "    \"textos_sin_errores\":\n",
    "    [\n",
    "    \" La toma de posesión de Donald Trump\"\n",
    "    \" como presidente de Estados Unidos se llevará\"\n",
    "    \" a cabo el lunes veinte de enero en el Capitolio\"\n",
    "    \" de Washington D.C. Esta ceremonia histórica,\"\n",
    "    \" que se realiza cada cuatro años, tiene en\"\n",
    "    \" su lista de invitados a figuras clave en la\"\n",
    "    \" política mundial, además de empresarios que\"\n",
    "    \" buscan ganarse el favor del nuevo comandante\"\n",
    "    \" en jefe, y celebridades que lo han apoyado y\"\n",
    "    \" que comparten su visión para el futuro de la\"\n",
    "    \" unión americana.\"\n",
    "    ,\n",
    "\n",
    "    \" Cerrar podrá mis ojos la postrera\"\n",
    "    \" sombra, que me llevare el blanco día,\"\n",
    "    \" y podrá desatar esta alma mía\"\n",
    "    \" hora, a su afán ansioso linsojera;\"\n",
    "    \" mas no de esa otra parte en la ribera\"\n",
    "    \" dejará la memoria en donde ardía;\"\n",
    "    \" nadar sabe mi llama la agua fría,\"\n",
    "    \" y perder el respeto a ley severa;\"\n",
    "    \" Alma a quien todo un Dios prisión ha sido,\"\n",
    "    \" venas que humor a tanto fuego han dado,\"\n",
    "    \" médulas que han gloriosamente ardido,\"\n",
    "    \" su cuerpo dejarán, no su cuidado;\"\n",
    "    \" serán ceniza, mas tendrán sentido.\"\n",
    "    \" Polvo serán, mas polvo enamorado.\"\n",
    "    ],\n",
    "\n",
    "  \"textos_con_errores\" :\n",
    "    [\n",
    "    \" La tma de posesión de Donald Trump\"                # toma         -> tma\n",
    "    \" como presdente de Estados Unidos se llevará\"       # presidente   -> presdente\n",
    "    \" a cabo el lunes, veinte de enero en el Capittolio\" # Captitolio   -> Capittolio\n",
    "    \" de Washington D.C. Esta ceremonia hitórrica,\"      # histórica    -> hitórrica\n",
    "    \" que se realiza cada cuatro años, teine en\"         # tiene        -> teine\n",
    "    \" su pista de invitados a figuras clave en la\"       # lista        -> pista\n",
    "    \" política mundial, ademas de empresarios que\"       # además       -> ademas\n",
    "    \" busca ganarse el fvaor del nuevo comandante\"       # favor        -> fvaor\n",
    "    \" en jefe, y selevridades que lo han apoyado y\"      # celebridades -> selevridades\n",
    "    \" que comparten su vission para el futuro de la\"     # visión       -> vission\n",
    "    \" unión americana.\",\n",
    "\n",
    "    \" Cerrar podrá mis hojos la postrera\"          # ojos         -> hojos\n",
    "    \" sombra, que me llevre el blanco día,\"        # llevare      -> llevre\n",
    "    \" y podrá desatar esta alma mía\"\n",
    "    \" hora, a su afán ansioso lisonjera;\"\n",
    "    \" mas no de esa otra parte en la rivrera\"      # rivera        -> rivrera\n",
    "    \" dejará la memorria en donde ardía;\"          # memoria       -> memorria\n",
    "    \" nadar sabe mi llama la agua fría,\"\n",
    "    \" y preder el respeto a ley severa;\"           # perder        -> preder\n",
    "    \" Alma a quien todo un Dios prisión ha sido,\"\n",
    "    \" venas que rumor a tanto fuego han dado,\"     # humor         -> rumor\n",
    "    \" médulas que han glorsamente ardido,\"         # gloriosamente -> glorsamente\n",
    "    \" su cuerpo dejaran, no su cuidado;\"           # dejarán       -> dejaran\n",
    "    \" serán cenisa, mas tendrán sentido.\"          # ceniza        -> cenisa\n",
    "    \" Polvo serán, mas polbu enamorado.\"           # polvo         -> polbu\n",
    "    ]\n",
    " }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgOF8rkKCN-w"
   },
   "source": [
    "Si quiere guardar el dataframe en un csv puede seguir este ejemplo definiendo el path correspondiente a su sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_kjih1-CB97M"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos_sin_errores</th>\n",
       "      <th>textos_con_errores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La toma de posesión de Donald Trump como pres...</td>\n",
       "      <td>La tma de posesión de Donald Trump como presd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cerrar podrá mis ojos la postrera sombra, que...</td>\n",
       "      <td>Cerrar podrá mis hojos la postrera sombra, qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  textos_sin_errores  \\\n",
       "0   La toma de posesión de Donald Trump como pres...   \n",
       "1   Cerrar podrá mis ojos la postrera sombra, que...   \n",
       "\n",
       "                                  textos_con_errores  \n",
       "0   La tma de posesión de Donald Trump como presd...  \n",
       "1   Cerrar podrá mis hojos la postrera sombra, qu...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Almacenamiento de datos en fichero csv\n",
    "data_dir_path = \"Datos\"\n",
    "data_file_path = data_dir_path + \"textos_p1_01.csv\"\n",
    "data.to_csv(data_file_path, index=False, quoting=csv.QUOTE_ALL)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ph016C101YX"
   },
   "source": [
    "Para reconstruir el dataframe a partir de un csv puede seguir este ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1737446155493,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "A8E5r5inaWJe",
    "outputId": "b2779b24-af81-4c4c-be6b-c4cbc09d2102"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos_sin_errores</th>\n",
       "      <th>textos_con_errores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La toma de posesión de Donald Trump como pres...</td>\n",
       "      <td>La tma de posesión de Donald Trump como presd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cerrar podrá mis ojos la postrera sombra, que...</td>\n",
       "      <td>Cerrar podrá mis hojos la postrera sombra, qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  textos_sin_errores  \\\n",
       "0   La toma de posesión de Donald Trump como pres...   \n",
       "1   Cerrar podrá mis ojos la postrera sombra, que...   \n",
       "\n",
       "                                  textos_con_errores  \n",
       "0   La tma de posesión de Donald Trump como presd...  \n",
       "1   Cerrar podrá mis hojos la postrera sombra, qu...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "data_file_path =  data_dir_path + \"textos_p1_01.csv\"\n",
    "datos = pd.read_csv(data_file_path, encoding=\"UTF-8\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rpZB8bPCOQh"
   },
   "source": [
    "2.- Instalación de symspellpy.\n",
    "\n",
    "El primero de los correctores ortográficos que vamos a utilizar es symspellpy (https://symspellpy.readthedocs.io/en/latest/index.html#)\n",
    "\n",
    "symspellpy tiene una API relativamente simple y según sus creadores es muy eficiente tanto en términos de velocidad como de uso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3889,
     "status": "ok",
     "timestamp": 1737445215665,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "sLfaj2fy_tjA",
    "outputId": "443c30d7-432c-4141-b3da-61c3e6ddd4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: symspellpy in /home/codespace/.python/current/lib/python3.12/site-packages (6.7.8)\n",
      "Requirement already satisfied: editdistpy>=0.1.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from symspellpy) (0.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install symspellpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SBltaLL4Iuo"
   },
   "source": [
    "3.- Carga de recursos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 224571,
     "status": "ok",
     "timestamp": 1737445447056,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "Az2Gre1D0HR-",
    "outputId": "ced1ea4d-dd38-4dd8-b67b-08630b05b1c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6030/3946075148.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "# Descargamos algunos recursos para este práctica\n",
    "# !wget --no-check-certificate https://valencia.inf.um.es/valencia-plne/p1.zip\n",
    "# !unzip p1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6W0VhCjEulk"
   },
   "source": [
    "4.- Carga de un diccionario en castellano para symspellpy.\n",
    "\n",
    "symspellpy, como el resto de correctores, necesita diccionarios que utiliza para comprobar la corrección de las palabras. symspellpy utiliza diccionarios de frecuencia en los que cada palabra tiene asociado el número de veces que ha sido contabilizada en una serie de corpora.\n",
    "\n",
    "Las sugerencias que nos va a proporcionar symspellpy van a depender en primer lugar de la distancia léxica entre el te´rmino analizado y los te´rminos que encuentre en el diccionario y en segundo lugar de la frecuancia con la aparecen dichos términos.\n",
    "\n",
    "El diccionario que se proporciona está confeccionado a partir de un diccionario de frecuencia de la Real Academia de la Lengua e incluye los 80000 términos más frecuentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1737450741391,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "kjghXQmh-cHx",
    "outputId": "846ceebf-96e5-4389-9447-952d3ccb857b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de,9999518\n",
      "la,6277560\n",
      "que,4681839\n",
      "el,4569652\n",
      "en,4234281\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "dictionary_file = data_dir_path + \"/CREA_80000.txt\"\n",
    "\n",
    "#dictionary_file =  \"CREA_80000.txt\"\n",
    "\n",
    "# Traza ............................................................\n",
    "f1 = open(dictionary_file, 'r', encoding ='utf-8')\n",
    "for i in range(5):\n",
    "  print(f1.readline(), end = '')\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvxTjBioFenS"
   },
   "source": [
    "5.- Creación de un objeto symspell y carga de diccionario de frecuencias.\n",
    "\n",
    "Se proporciona un ejemplo de creación de objeto con carga de frecuencias en inglés.\n",
    "\n",
    "Symspellpy incorpora entre sus recursos un diccionario de frecuencias de palabras en inglés, que es el que se usa en el ejemplo.\n",
    "\n",
    "Para trabajar en castellano tendrá que cargar el diccionario proporcionado en (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 12673,
     "status": "ok",
     "timestamp": 1737450845012,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "KsrBZEcFDqW0",
    "outputId": "c06d36ee-3424-49c4-e41a-29c8230150ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sym_spell_en  ---> [('the', 23135851162), ('of', 13151942776), ('and', 12997637966), ('to', 12136980858), ('a', 9081174698)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "sym_spell_sp  ---> [('de', 9999518), ('la', 6277560), ('que', 4681839), ('el', 4569652), ('en', 4234281)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "# EJEMPLO. Diccionario de frecuencias en inglés................................\n",
    "\n",
    "sym_spell_en = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "                        \"symspellpy\",\n",
    "                        \"frequency_dictionary_en_82_765.txt\")\n",
    "\n",
    "sym_spell_en.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "# Traza.\n",
    "from itertools import islice\n",
    "print(\"sym_spell_en \", end = \" ---> \" )\n",
    "print(list(islice(sym_spell_en.words.items(), 5)))\n",
    "print(\"------------\"*10)\n",
    "\n",
    "# CASTELLANO ..................................................................\n",
    "\n",
    "# En este caso tendrá que utilizar el diccionario obtenido en (4)\n",
    "# sp_dictionary = \"CREA_80000.txt\"\n",
    "sp_dictionary = data_dir_path + \"/CREA_80000.txt\"\n",
    "\n",
    "sym_spell_sp = SymSpell(max_dictionary_edit_distance=3, prefix_length=7)\n",
    "\n",
    "sym_spell_sp.load_dictionary(sp_dictionary,\n",
    "                             term_index=0,\n",
    "                             count_index=1,\n",
    "                             separator =',')\n",
    "\n",
    "# Traza ......................................................................\n",
    "from itertools import islice\n",
    "print(\"sym_spell_sp \", end = \" ---> \" )\n",
    "print(list(islice(sym_spell_sp.words.items(), 5)))\n",
    "print(\"------------\"*10)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6u1oS3APBag"
   },
   "source": [
    "6.- Preprocesamiento previo a la detección y corrección de errores en palabras individuales.\n",
    "\n",
    "Para facilitar la detección y corrección de errores en palabras individuales vamos a preprocesar los textos.\n",
    "\n",
    "  * Eliminaremos los signos de puntuación con la función remove_punctuation.\n",
    "  * Pasaremos todo a minúsculas.\n",
    "  * Obtendremos las \"palabras\" del texto con la función tokenize.\n",
    "  * Guardaremos en una nueva columna 'pals' las palabras correspondientes al texto con errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1737451111342,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "2UuvcQeoPB2s",
    "outputId": "811e8005-0b26-45d3-96d8-e2542d5a0254"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos_sin_errores</th>\n",
       "      <th>textos_con_errores</th>\n",
       "      <th>pals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La toma de posesión de Donald Trump como pres...</td>\n",
       "      <td>La tma de posesión de Donald Trump como presd...</td>\n",
       "      <td>[la, tma, de, posesión, de, donald, trump, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cerrar podrá mis ojos la postrera sombra, que...</td>\n",
       "      <td>Cerrar podrá mis hojos la postrera sombra, qu...</td>\n",
       "      <td>[cerrar, podrá, mis, hojos, la, postrera, somb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  textos_sin_errores  \\\n",
       "0   La toma de posesión de Donald Trump como pres...   \n",
       "1   Cerrar podrá mis ojos la postrera sombra, que...   \n",
       "\n",
       "                                  textos_con_errores  \\\n",
       "0   La tma de posesión de Donald Trump como presd...   \n",
       "1   Cerrar podrá mis hojos la postrera sombra, qu...   \n",
       "\n",
       "                                                pals  \n",
       "0  [la, tma, de, posesión, de, donald, trump, com...  \n",
       "1  [cerrar, podrá, mis, hojos, la, postrera, somb...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesado, obtención de palabras\n",
    "\n",
    "import string\n",
    "\n",
    "sp_punctuation = string.punctuation + '¿' + '¡'\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in sp_punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "def tolower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "def preprocesado(text):\n",
    "    return tokenize(tolower(remove_punctuation(text)))\n",
    "\n",
    "datos['pals'] = datos['textos_con_errores'].apply(preprocesado)\n",
    "\n",
    "#print(datos)\n",
    "datos.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_tyGPEOG9XK"
   },
   "source": [
    "7.- Encontrar la ortografía más probable para una palabra dada. Función lookup.\n",
    "\n",
    "Este ejercicio se da resuelto y se piden únicamente algunas modificaciones y reflexionar sobre los resultados.\n",
    "\n",
    "Una vez que tenemos las palabras en una columna vamos a pasarles el corrector ortográfico y a imprimir las sugerencias que nos hace el corrector ortógrafico (se muestran sólo las que están a la mínima distancia de edición, Verbosity.CLOSEST).\n",
    "\n",
    "En el primer texto tenemos los sigientes errores:\n",
    "  * toma         -> tma\n",
    "  * presidente   -> presdente\n",
    "  * Capitolio    -> Capittolio\n",
    "  * histórica    -> histórrica\n",
    "  * tiene        -> teine\n",
    "  * además       -> ademas\n",
    "  * favor        -> fvaor\n",
    "  * celebridades -> selevriddades\n",
    "  * visión       -> vission\n",
    "\n",
    "En el segundo texto tenemos los sigientes errores:\n",
    "  * ojos           -> hojos\n",
    "  * llevare        -> llevre\n",
    "  * memoria        -> memorria\n",
    "  * perder         -> preder\n",
    "  * humor          -> rumor\n",
    "  * gloriosamente  -> glorsamente\n",
    "  * dejarán        -> dejaran\n",
    "  * ceniza         -> cenisa\n",
    "  * polvo          -> polbu\n",
    "\n",
    "¿Qué falsos positivos y falsos negativos detecta?\n",
    "Experimente con las palabras del texto con errores, introduzca nuevos errores, recargue los datos y observe los resultados que ofrece el corrector.\n",
    "\n",
    "Cambie Verbosity.CLOSEST por Verbosity.TOP, elimine la condición *if suggestion.distance > 0* y vuelva a ejecutar el código.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 687,
     "status": "error",
     "timestamp": 1738446752368,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "S3HIXVTtIp-A",
    "outputId": "a6082596-5b2f-4460-9d53-4045edbd8f2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tma        ---> tema         1 30398\n",
      "tma        ---> toma         1 15003\n",
      "tma        ---> tía          1 7095\n",
      "tma        ---> ama          1 3530\n",
      "tma        ---> ma           1 809\n",
      "tma        ---> ta           1 536\n",
      "tma        ---> tm           1 252\n",
      "tma        ---> tam          1 244\n",
      "tma        ---> tia          1 213\n",
      "tma        ---> ema          1 176\n",
      "tma        ---> tea          1 158\n",
      "tma        ---> twa          1 140\n",
      "tma        ---> uma          1 115\n",
      "tma        ---> pma          1 110\n",
      "tma        ---> toa          1 107\n",
      "tma        ---> tra          1 49\n",
      "presdente  ---> presidente   1 91350\n",
      "presdente  ---> presente     1 24211\n",
      "presdente  ---> presiente    1 178\n",
      "capittolio ---> capitolio    1 333\n",
      "hitórrica  ---> histórica    2 7815\n",
      "teine      ---> tiene        1 147274\n",
      "teine      ---> peine        1 328\n",
      "teine      ---> teide        1 140\n",
      "teine      ---> heine        1 83\n",
      "teine      ---> reine        1 76\n",
      "fvaor      ---> favor        1 21818\n",
      "selevridades ---> celebridades   2 160\n",
      "vission    ---> vision       1 92\n",
      "vission    ---> mission      1 53\n",
      "------------------------------------------------------------\n",
      "hojos      ---> ojos         1 42371\n",
      "hojos      ---> hijos        1 24995\n",
      "hojos      ---> hojas        1 9453\n",
      "hojos      ---> rojos        1 3134\n",
      "hojos      ---> hoyos        1 921\n",
      "hojos      ---> cojos        1 89\n",
      "llevre     ---> lleve        1 2250\n",
      "lisonjera  ---> pionera      3 406\n",
      "lisonjera  ---> litosfera    3 262\n",
      "lisonjera  ---> misionera    3 214\n",
      "lisonjera  ---> lissner      3 115\n",
      "lisonjera  ---> limonero     3 95\n",
      "lisonjera  ---> lisonjas     3 53\n",
      "rivrera    ---> rivera       1 3651\n",
      "rivrera    ---> riviera      1 121\n",
      "memorria   ---> memoria      1 17083\n",
      "preder     ---> perder       1 11890\n",
      "preder     ---> prever       1 1333\n",
      "preder     ---> prender      1 417\n",
      "glorsamente ---> gloriosamente   2 78\n",
      "cenisa     ---> ceniza       1 966\n",
      "polbu      ---> polvo        2 6592\n",
      "polbu      ---> pollo        2 2993\n",
      "polbu      ---> polo         2 2726\n",
      "polbu      ---> polos        2 948\n",
      "polbu      ---> palau        2 866\n",
      "polbu      ---> poli         2 798\n",
      "polbu      ---> polar        2 788\n",
      "polbu      ---> polen        2 585\n",
      "polbu      ---> pombo        2 475\n",
      "polbu      ---> pol          2 466\n",
      "polbu      ---> polla        2 246\n",
      "polbu      ---> pola         2 210\n",
      "polbu      ---> polis        2 208\n",
      "polbu      ---> pou          2 140\n",
      "polbu      ---> polio        2 139\n",
      "polbu      ---> polea        2 126\n",
      "polbu      ---> poble        2 113\n",
      "polbu      ---> polay        2 105\n",
      "polbu      ---> pobló        2 94\n",
      "polbu      ---> poleo        2 82\n",
      "polbu      ---> poll         2 75\n",
      "polbu      ---> pole         2 71\n",
      "polbu      ---> polka        2 64\n",
      "polbu      ---> pobla        2 61\n",
      "polbu      ---> pobo         2 58\n",
      "polbu      ---> polke        2 53\n",
      "------------------------------------------------------------\n",
      "\n",
      "Con Verbosity. TOP ----> \n",
      "\n",
      "la         ---> la           0 6277560\n",
      "tma        ---> tema         1 30398\n",
      "de         ---> de           0 9999518\n",
      "posesión   ---> posesión     0 4236\n",
      "de         ---> de           0 9999518\n",
      "donald     ---> donald       0 667\n",
      "trump      ---> trump        0 62\n",
      "como       ---> como         0 773465\n",
      "presdente  ---> presidente   1 91350\n",
      "de         ---> de           0 9999518\n",
      "estados    ---> estados      0 49814\n",
      "unidos     ---> unidos       0 39806\n",
      "se         ---> se           0 2022514\n",
      "llevará    ---> llevará      0 2811\n",
      "a          ---> a            0 3260939\n",
      "cabo       ---> cabo         0 25125\n",
      "el         ---> el           0 4569652\n",
      "lunes      ---> lunes        0 12951\n",
      "veinte     ---> veinte       0 12600\n",
      "de         ---> de           0 9999518\n",
      "enero      ---> enero        0 16929\n",
      "en         ---> en           0 4234281\n",
      "el         ---> el           0 4569652\n",
      "capittolio ---> capitolio    1 333\n",
      "de         ---> de           0 9999518\n",
      "washington ---> washington   0 9419\n",
      "dc         ---> dc           0 2118\n",
      "esta       ---> esta         0 238841\n",
      "ceremonia  ---> ceremonia    0 4973\n",
      "hitórrica  ---> histórica    2 7815\n",
      "que        ---> que          0 4681839\n",
      "se         ---> se           0 2022514\n",
      "realiza    ---> realiza      0 8602\n",
      "cada       ---> cada         0 124558\n",
      "cuatro     ---> cuatro       0 56570\n",
      "años       ---> años         0 203027\n",
      "teine      ---> tiene        1 147274\n",
      "en         ---> en           0 4234281\n",
      "su         ---> su           0 1103617\n",
      "pista      ---> pista        0 5784\n",
      "de         ---> de           0 9999518\n",
      "invitados  ---> invitados    0 4482\n",
      "a          ---> a            0 3260939\n",
      "figuras    ---> figuras      0 8702\n",
      "clave      ---> clave        0 9321\n",
      "en         ---> en           0 4234281\n",
      "la         ---> la           0 6277560\n",
      "política   ---> política     0 73464\n",
      "mundial    ---> mundial      0 24963\n",
      "ademas     ---> ademas       0 78\n",
      "de         ---> de           0 9999518\n",
      "empresarios ---> empresarios   0 9208\n",
      "que        ---> que          0 4681839\n",
      "busca      ---> busca        0 15280\n",
      "ganarse    ---> ganarse      0 1059\n",
      "el         ---> el           0 4569652\n",
      "fvaor      ---> favor        1 21818\n",
      "del        ---> del          0 1857225\n",
      "nuevo      ---> nuevo        0 77262\n",
      "comandante ---> comandante   0 5946\n",
      "en         ---> en           0 4234281\n",
      "jefe       ---> jefe         0 25526\n",
      "y          ---> y            0 4180279\n",
      "selevridades ---> celebridades   2 160\n",
      "que        ---> que          0 4681839\n",
      "lo         ---> lo           0 866955\n",
      "han        ---> han          0 169718\n",
      "apoyado    ---> apoyado      0 2488\n",
      "y          ---> y            0 4180279\n",
      "que        ---> que          0 4681839\n",
      "comparten  ---> comparten    0 1779\n",
      "su         ---> su           0 1103617\n",
      "vission    ---> vision       1 92\n",
      "para       ---> para         0 1062152\n",
      "el         ---> el           0 4569652\n",
      "futuro     ---> futuro       0 26989\n",
      "de         ---> de           0 9999518\n",
      "la         ---> la           0 6277560\n",
      "unión      ---> unión        0 21933\n",
      "americana  ---> americana    0 4383\n",
      "------------------------------------------------------------\n",
      "cerrar     ---> cerrar       0 5440\n",
      "podrá      ---> podrá        0 15804\n",
      "mis        ---> mis          0 43564\n",
      "hojos      ---> ojos         1 42371\n",
      "la         ---> la           0 6277560\n",
      "postrera   ---> postrera     0 211\n",
      "sombra     ---> sombra       0 8792\n",
      "que        ---> que          0 4681839\n",
      "me         ---> me           0 374368\n",
      "llevre     ---> lleve        1 2250\n",
      "el         ---> el           0 4569652\n",
      "blanco     ---> blanco       0 21035\n",
      "día        ---> día          0 110921\n",
      "y          ---> y            0 4180279\n",
      "podrá      ---> podrá        0 15804\n",
      "desatar    ---> desatar      0 305\n",
      "esta       ---> esta         0 238841\n",
      "alma       ---> alma         0 13357\n",
      "mía        ---> mía          0 6087\n",
      "hora       ---> hora         0 40581\n",
      "a          ---> a            0 3260939\n",
      "su         ---> su           0 1103617\n",
      "afán       ---> afán         0 3479\n",
      "ansioso    ---> ansioso      0 667\n",
      "lisonjera  ---> pionera      3 406\n",
      "mas        ---> mas          0 8538\n",
      "no         ---> no           0 1465503\n",
      "de         ---> de           0 9999518\n",
      "esa        ---> esa          0 115377\n",
      "otra       ---> otra         0 113982\n",
      "parte      ---> parte        0 148750\n",
      "en         ---> en           0 4234281\n",
      "la         ---> la           0 6277560\n",
      "rivrera    ---> rivera       1 3651\n",
      "dejará     ---> dejará       0 1745\n",
      "la         ---> la           0 6277560\n",
      "memorria   ---> memoria      1 17083\n",
      "en         ---> en           0 4234281\n",
      "donde      ---> donde        0 132077\n",
      "ardía      ---> ardía        0 393\n",
      "nadar      ---> nadar        0 873\n",
      "sabe       ---> sabe         0 31358\n",
      "mi         ---> mi           0 186360\n",
      "llama      ---> llama        0 14903\n",
      "la         ---> la           0 6277560\n",
      "agua       ---> agua         0 54702\n",
      "fría       ---> fría         0 6068\n",
      "y          ---> y            0 4180279\n",
      "preder     ---> perder       1 11890\n",
      "el         ---> el           0 4569652\n",
      "respeto    ---> respeto      0 11285\n",
      "a          ---> a            0 3260939\n",
      "ley        ---> ley          0 48945\n",
      "severa     ---> severa       0 1574\n",
      "alma       ---> alma         0 13357\n",
      "a          ---> a            0 3260939\n",
      "quien      ---> quien        0 82555\n",
      "todo       ---> todo         0 247340\n",
      "un         ---> un           0 1659827\n",
      "dios       ---> dios         0 32373\n",
      "prisión    ---> prisión      0 7854\n",
      "ha         ---> ha           0 380339\n",
      "sido       ---> sido         0 107352\n",
      "venas      ---> venas        0 1485\n",
      "que        ---> que          0 4681839\n",
      "rumor      ---> rumor        0 2417\n",
      "a          ---> a            0 3260939\n",
      "tanto      ---> tanto        0 110679\n",
      "fuego      ---> fuego        0 16685\n",
      "han        ---> han          0 169718\n",
      "dado       ---> dado         0 29292\n",
      "médulas    ---> médulas      0 88\n",
      "que        ---> que          0 4681839\n",
      "han        ---> han          0 169718\n",
      "glorsamente ---> gloriosamente   2 78\n",
      "ardido     ---> ardido       0 69\n",
      "su         ---> su           0 1103617\n",
      "cuerpo     ---> cuerpo       0 44470\n",
      "dejaran    ---> dejaran      0 680\n",
      "no         ---> no           0 1465503\n",
      "su         ---> su           0 1103617\n",
      "cuidado    ---> cuidado      0 10089\n",
      "serán      ---> serán        0 17529\n",
      "cenisa     ---> ceniza       1 966\n",
      "mas        ---> mas          0 8538\n",
      "tendrán    ---> tendrán      0 6730\n",
      "sentido    ---> sentido      0 47559\n",
      "polvo      ---> polvo        0 6592\n",
      "serán      ---> serán        0 17529\n",
      "mas        ---> mas          0 8538\n",
      "polbu      ---> polvo        2 6592\n",
      "enamorado  ---> enamorado    0 2308\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_sugerencias (termino, distancia = 3):\n",
    "  sugs = sym_spell_sp.lookup(termino,\n",
    "                             Verbosity.CLOSEST, max_edit_distance=distancia)\n",
    "  for suggestion in sugs:\n",
    "    if suggestion.distance > 0:\n",
    "       print('{:10}'.format(termino), end = \" ---> \")\n",
    "       print('{:10}'.format(suggestion.term),\n",
    "             '{:3}'.format(suggestion.distance), suggestion.count)\n",
    "\n",
    "for palabras in datos['pals']:\n",
    "  for palabra in palabras:\n",
    "    print_sugerencias(palabra)\n",
    "  print(\"------------\"*5)\n",
    "\n",
    "# .....................................................................\n",
    "print()\n",
    "print(\"Con Verbosity. TOP ----> \")\n",
    "print()\n",
    "def print_sugerencias (termino, distancia = 3):\n",
    "  sugs = sym_spell_sp.lookup(termino,\n",
    "                             Verbosity.TOP, max_edit_distance=distancia)\n",
    "  for suggestion in sugs:\n",
    "       print('{:10}'.format(termino), end = \" ---> \")\n",
    "       print('{:10}'.format(suggestion.term),\n",
    "             '{:3}'.format(suggestion.distance), suggestion.count)\n",
    "\n",
    "for palabras in datos['pals']:\n",
    "  for palabra in palabras:\n",
    "    print_sugerencias(palabra)\n",
    "  print(\"------------\"*5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbA4zQsNHjX3"
   },
   "source": [
    "8.- Vamos a añadir ahora tres columnas al frame de pandas:\n",
    "\n",
    " - Una con todas las palabras sugeridas por symspellpy (texto completo dividido en palabras): 'pals_symspellpy'. Para ello use la sugerencia más probable en lookup (Verbosity.TOP)\n",
    " - otra sólo con las palabras corregidas por symspellpy: 'corr_symspellpy'\n",
    " - y una más 'text_symspellpy' con el texto resultante de utilizar las palabras sugeridas por symspellpy (las de la columna 'pals_symspellpy).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1737453099832,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "2oIF_733IEzk",
    "outputId": "e47a9f27-e9eb-4041-98b7-ff9fcc30e8bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "la tema de posesión de donald trump como presidente de estados unidos se llevará a cabo el lunes veinte de enero en el capitolio de washington dc esta ceremonia histórica que se realiza cada cuatro años tiene en su pista de invitados a figuras clave en la política mundial ademas de empresarios que busca ganarse el favor del nuevo comandante en jefe y celebridades que lo han apoyado y que comparten su vision para el futuro de la unión americana\n",
      "\n",
      "cerrar podrá mis ojos la postrera sombra que me lleve el blanco día y podrá desatar esta alma mía hora a su afán ansioso pionera mas no de esa otra parte en la rivera dejará la memoria en donde ardía nadar sabe mi llama la agua fría y perder el respeto a ley severa alma a quien todo un dios prisión ha sido venas que rumor a tanto fuego han dado médulas que han gloriosamente ardido su cuerpo dejaran no su cuidado serán ceniza mas tendrán sentido polvo serán mas polvo enamorado\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos_sin_errores</th>\n",
       "      <th>textos_con_errores</th>\n",
       "      <th>pals</th>\n",
       "      <th>pals_simspellpy</th>\n",
       "      <th>corr_simspellpy</th>\n",
       "      <th>text_simspellpy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La toma de posesión de Donald Trump como pres...</td>\n",
       "      <td>La tma de posesión de Donald Trump como presd...</td>\n",
       "      <td>[la, tma, de, posesión, de, donald, trump, com...</td>\n",
       "      <td>[la, tema, de, posesión, de, donald, trump, co...</td>\n",
       "      <td>[tema, presidente, capitolio, histórica, tiene...</td>\n",
       "      <td>la tema de posesión de donald trump como presi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cerrar podrá mis ojos la postrera sombra, que...</td>\n",
       "      <td>Cerrar podrá mis hojos la postrera sombra, qu...</td>\n",
       "      <td>[cerrar, podrá, mis, hojos, la, postrera, somb...</td>\n",
       "      <td>[cerrar, podrá, mis, ojos, la, postrera, sombr...</td>\n",
       "      <td>[ojos, lleve, pionera, rivera, memoria, perder...</td>\n",
       "      <td>cerrar podrá mis ojos la postrera sombra que m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  textos_sin_errores  \\\n",
       "0   La toma de posesión de Donald Trump como pres...   \n",
       "1   Cerrar podrá mis ojos la postrera sombra, que...   \n",
       "\n",
       "                                  textos_con_errores  \\\n",
       "0   La tma de posesión de Donald Trump como presd...   \n",
       "1   Cerrar podrá mis hojos la postrera sombra, qu...   \n",
       "\n",
       "                                                pals  \\\n",
       "0  [la, tma, de, posesión, de, donald, trump, com...   \n",
       "1  [cerrar, podrá, mis, hojos, la, postrera, somb...   \n",
       "\n",
       "                                     pals_simspellpy  \\\n",
       "0  [la, tema, de, posesión, de, donald, trump, co...   \n",
       "1  [cerrar, podrá, mis, ojos, la, postrera, sombr...   \n",
       "\n",
       "                                     corr_simspellpy  \\\n",
       "0  [tema, presidente, capitolio, histórica, tiene...   \n",
       "1  [ojos, lleve, pionera, rivera, memoria, perder...   \n",
       "\n",
       "                                     text_simspellpy  \n",
       "0  la tema de posesión de donald trump como presi...  \n",
       "1  cerrar podrá mis ojos la postrera sombra que m...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sugerencias (lista_terminos):\n",
    "  l = [sym_spell_sp.lookup(termino,\n",
    "                             Verbosity.TOP, max_edit_distance=3)[0].term\n",
    "       for termino in lista_terminos]\n",
    "  return l\n",
    "\n",
    "def get_cambiadas (l_original, l_cambiada):\n",
    "  l = [termino_cambiada\n",
    "         for termino_original, termino_cambiada in zip(l_original, l_cambiada)\n",
    "            if termino_original != termino_cambiada]\n",
    "  return l\n",
    "\n",
    "datos['pals_simspellpy'] = datos['pals'].apply(get_sugerencias)\n",
    "datos['corr_simspellpy'] = datos.apply(lambda x:\n",
    "                                          get_cambiadas(x['pals'],\n",
    "                                                        x['pals_simspellpy']),\n",
    "                                                        axis=1)\n",
    "datos['text_simspellpy'] = datos['pals_simspellpy'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "print()\n",
    "print(datos['text_simspellpy'][0])\n",
    "print()\n",
    "print(datos['text_simspellpy'][1])\n",
    "print(\"----------\"*10)\n",
    "datos.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnCjf3xGH8CQ"
   },
   "source": [
    "9.- Adición de palabras al diccionario.\n",
    "\n",
    "Si observamos los resultados del ejercicio anterior vemos que en el diccionario no se encuentran las palabras 'lisonjera' ni 'llevare', que son palabras correctas que no se hayan incluidas en el diccionario de frecuencias proporcionado.\n",
    "\n",
    "Utilice la función create_dictionary_entry para añadirlas.\n",
    "\n",
    "Una vez añadidas vuelva a ejecutar el código del punto 7. ¿Cómo utiliza lookup las palabras añadidas?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1737446318145,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "6p0p6J1_mRRY",
    "outputId": "0e137a8e-e5e6-426c-dc2a-7617e2be0a19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_spell_sp.create_dictionary_entry(\"lisonjera\", 1)\n",
    "sym_spell_sp.create_dictionary_entry(\"llevare\", 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yFAAzwZI_Pz"
   },
   "source": [
    "10.- Uso de la función lookup_compound para corrección de errores ortográficos en oraciones o en bloques de texto.\n",
    "\n",
    "En los ejemplos y ejercicios vistos hasta ahora hemos considerado palabras individuales. Esta es una visión muy restringida de la corrección ortográfica ya que, por un lado, los errores implican a menudo a varias palabras y, por otro, hay errores que sólo pueden detectarse si disponemos de información sobre el contexto en el que se producen. En este ejercicio vamos a ver una parte de la funcionalidad de symspellpy ofrece para estos casos.\n",
    "\n",
    "La función lookup_compound corrige tres tipos de errores en oraciones:\n",
    "\n",
    "  - Espacio que insertado por error en una palabra correcta genera dos términos incorrectos.\n",
    "  - Espacio omitido por error entre dos palabras correctas que genera un término incorrecto\n",
    "  - Múltiples términos de entrada independientes con errores ortográficos.\n",
    "\n",
    "Averigüe qué tipo de información contextual utiliza lookup_compound. Pruebe con las oraciones de abajo y con otras diferentes que estime oportunas y razone acerca del rendimiento de lookup compound y sobre los factores que pueden influir en el mismo.\n",
    "\n",
    "*correjir ortografia enespañol correc tamente*\n",
    "\n",
    "*La toma deposesión de Donald Trump como presdente de Estados Unidos se llevará a cabo el lunes, dos de enero en el Capi tolio*\n",
    "    \n",
    "*Alma a quien todo un Dios prisión ha sido, benas que rumor a tanto fuego han dado, médula que han gloriosa mente ardido, su cuerpo dejarán, nosu cuidado*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1737452037876,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "Us6S_7lCjPBo",
    "outputId": "50770f90-5bbd-4894-d61b-bea3c210a201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correjir ortografia enespañol correc tamente \n",
      "Suggestions ---> \n",
      "corregir ortografía e español correctamente\n",
      "------------------------------------------------\n",
      "La toma deposesión de Donald Trump como presdente de Estados Unidosse llevará a cabo el lunes, dos de enero en el Capi tolio\n",
      "Suggestions ---> \n",
      "la toma desposesión de donald trump como presidente de estados unido se llevará a cabo el lunes dos de enero en el capitolio\n",
      "------------------------------------------------\n",
      "La sombra que me llevre el blanco día, alma dequien todo un Dios prisiónhasido, venas quehumor a tanto fuego, médulasque han gloriosa mente ardido,su cuerpo dejarán, no sucuidado\n",
      "Suggestions ---> \n",
      "la sombra que me lleve el blanco día alma d quien todo un dios prisión asido venas que humor a tanto fuego médula que han gloriosa mente ardido su cuerpo dejarán no s cuidado\n",
      "------------------------------------------------\n",
      "La asginatura de prosesamiento de lenguajenatural escrito haze trabajar y aprehnder perfectam ente procesamiengo de teexto\n",
      "Suggestions ---> \n",
      "la asignatura de procesamiento de lenguaje natural escrito hace trabajar y aprender perfectamente procesamiento de texto\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_terms = [\n",
    "    \"correjir ortografia enespañol correc tamente \",\n",
    "    \"La toma deposesión de Donald Trump como presdente de Estados Unidos\" \\\n",
    "    \"se llevará a cabo el lunes, dos de enero en el Capi tolio\",\n",
    "    \"La sombra que me llevre el blanco día, alma dequien todo un Dios prisión\" \\\n",
    "    \"hasido, venas quehumor a tanto fuego, médulasque han gloriosa mente ardido,\" \\\n",
    "    \"su cuerpo dejarán, no sucuidado\",\n",
    "    \"La asginatura de prosesamiento de lenguajenatural escrito haze trabajar\" \\\n",
    "    \" y aprehnder perfectam ente procesamiengo de teexto\"\n",
    "    ]\n",
    "\n",
    "for input_term in input_terms:\n",
    "  print(input_term)\n",
    "  print(\"Suggestions ---> \")\n",
    "  suggestions = sym_spell_sp.lookup_compound(input_term, max_edit_distance=2)\n",
    "  for suggestion in suggestions:\n",
    "    print(suggestion.term)\n",
    "  print(\"---\"*16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qp_zH2YzJ1kt"
   },
   "source": [
    "11.- Segmentación de textos\n",
    "\n",
    "Symspellpy es capaz de segmentar textos en los que no hay separación entre las palabras mediante la función word_segmentation.\n",
    "\n",
    "Averigüe qué tipo de información contextual utiliza word_segementation. Pruebe con las oraciones de abajo y con otras diferentes que estime oportunas y razone acerca del rendimiento de word_segmentation y sobre los factores que pueden influir en el mismo.\n",
    "\n",
    "*divideestaoraciónenpalabrasindividuales*\n",
    "\n",
    "*correjirortografiaenespañolcorrectamente*\n",
    "\n",
    "*corregirortografíaenespañolcorrectamente*\n",
    "\n",
    "*LatomadeposesióndeDonaldTrumpcomopresdentedeEstadosUnidos*\n",
    "\n",
    "*AlmaaquientodounDiosprisiónhasidovenasquehumorafuegohandado*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4139,
     "status": "ok",
     "timestamp": 1737452081787,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "be1Y6a0UjU_W",
    "outputId": "6dd3ac0f-f63f-4db1-e559-0d61c80fdadd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divideestaoraciónenpalabrasindividuales\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented Sentence: divide esta oración en palabras individuales\n",
      "Sum of Edit Distances: 5\n",
      "Sum of Log Probabilities: -45.438651416742104\n",
      "------------------------------------------------\n",
      "correjirortografiaenespañolcorrectamente\n",
      "Segmented Sentence: corregir ortografía en español correctamente\n",
      "Sum of Edit Distances: 6\n",
      "Sum of Log Probabilities: -39.59758634502835\n",
      "------------------------------------------------\n",
      "corregirortografíaenespañolcorrectamente\n",
      "Segmented Sentence: corregir ortografía en español correctamente\n",
      "Sum of Edit Distances: 4\n",
      "Sum of Log Probabilities: -39.59758634502835\n",
      "------------------------------------------------\n",
      "LatomadeposesióndeDonaldTrumpcomopresdentedeEstadosUnidos\n",
      "Segmented Sentence: La toma desposesión de Donald Trump como presidente de Estados Unidos\n",
      "Sum of Edit Distances: 12\n",
      "Sum of Log Probabilities: -80.69939991087726\n",
      "------------------------------------------------\n",
      "AlmaaquientodounDiosprisiónhasidovenasquehumorafuegohandado\n",
      "Segmented Sentence: Alma quien todo unidos prisión habido venas que humor fuego mandado\n",
      "Sum of Edit Distances: 15\n",
      "Sum of Log Probabilities: -84.47454198142808\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_terms = [\"divideestaoraciónenpalabrasindividuales\",\n",
    "               \"correjirortografiaenespañolcorrectamente\",\n",
    "               \"corregirortografíaenespañolcorrectamente\",\n",
    "               \"LatomadeposesióndeDonaldTrumpcomopresdentedeEstadosUnidos\",\n",
    "               \"AlmaaquientodounDiosprisiónhasidovenasquehumorafuegohandado\"\n",
    "              ]\n",
    "for input_term in input_terms:\n",
    "  print(input_term)\n",
    "  result= sym_spell_sp.word_segmentation(input_term)\n",
    "  print(f\"Segmented Sentence: {result.corrected_string}\")\n",
    "  print(f\"Sum of Edit Distances: {result.distance_sum}\")\n",
    "  print(f\"Sum of Log Probabilities: {result.log_prob_sum}\")\n",
    "  print(\"---\"*16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arsSAdRhJLIT"
   },
   "source": [
    "12.- Generación y uso de un diccionario a partir de un corpus.\n",
    "\n",
    "En el siguiente ejemplo vamos a generar un diccionario a partir de un corpus de recetas de cocina.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 168078,
     "status": "ok",
     "timestamp": 1737452284503,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "aWG3DvDLKH8W",
    "outputId": "5ded39df-e8b1-4c33-ae24-84fd8cafe1df"
   },
   "outputs": [],
   "source": [
    "# Descargamos un corpus de recetas de cocina\n",
    "# !wget --no-check-certificate https://valencia.inf.um.es/valencia-plne/corpusRecetasv3.tgz\n",
    "# !tar -xzf corpusRecetasv3.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25828,
     "status": "ok",
     "timestamp": 1737390075782,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "d51sWCZcJPav",
    "outputId": "94f0baf9-6551-4058-ac63-9f5ab4d0ff92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diccionario guardado en ./symspell_corpusRecetas_dictionary.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "\n",
    "corpus_folder = \"./corpusRecetasv3\"\n",
    "dictionary_path = \"./symspell_corpusRecetas_dictionary.txt\"\n",
    "\n",
    "# Creamos un diccionario a partir del corpus descargado\n",
    "symspell = SymSpell(max_dictionary_edit_distance=3, prefix_length=7)\n",
    "# Leer todos los archivos de texto en la carpeta\n",
    "for file_name in os.listdir(corpus_folder):\n",
    "  if file_name.endswith(\".txt\"):\n",
    "    file_path = os.path.join(corpus_folder, file_name)\n",
    "    symspell.create_dictionary(file_path)\n",
    "\n",
    "# Guardar el diccionario generado manualmente\n",
    "with open(dictionary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "  for key, count in symspell.words.items():\n",
    "    f.write(f\"{key} {count}\\n\")\n",
    "print(f\"Diccionario guardado en {dictionary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4ANlcUuMcT1",
    "outputId": "e6fbb1bb-99de-4f05-f848-53d5a123df8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruebas con la palabra: 'cane'\n",
      "Corrección sugerida: carne, Distancia: 1, Frecuencia: 15867\n",
      "Corrección sugerida: cake, Distancia: 1, Frecuencia: 714\n",
      "Corrección sugerida: cabe, Distancia: 1, Frecuencia: 257\n",
      "Corrección sugerida: cae, Distancia: 1, Frecuencia: 56\n",
      "Corrección sugerida: cine, Distancia: 1, Frecuencia: 36\n",
      "Corrección sugerida: caen, Distancia: 1, Frecuencia: 12\n",
      "Corrección sugerida: gane, Distancia: 1, Frecuencia: 8\n",
      "Corrección sugerida: pane, Distancia: 1, Frecuencia: 5\n",
      "Corrección sugerida: cafe, Distancia: 1, Frecuencia: 5\n",
      "Corrección sugerida: cone, Distancia: 1, Frecuencia: 2\n",
      "Corrección sugerida: can, Distancia: 1, Frecuencia: 2\n",
      "Corrección sugerida: canse, Distancia: 1, Frecuencia: 1\n",
      "Corrección sugerida: lane, Distancia: 1, Frecuencia: 1\n",
      "Corrección sugerida: crne, Distancia: 1, Frecuencia: 1\n",
      "Corrección sugerida: care, Distancia: 1, Frecuencia: 1\n",
      "Corrección sugerida: cale, Distancia: 1, Frecuencia: 1\n",
      "Corrección sugerida: case, Distancia: 1, Frecuencia: 1\n",
      "Corrección sugerida: cano, Distancia: 1, Frecuencia: 1\n",
      "Pruebas con la palabra: 'pallo'\n",
      "Corrección sugerida: pollo, Distancia: 1, Frecuencia: 17927\n",
      "Corrección sugerida: tallo, Distancia: 1, Frecuencia: 463\n",
      "Corrección sugerida: gallo, Distancia: 1, Frecuencia: 271\n",
      "Corrección sugerida: palo, Distancia: 1, Frecuencia: 207\n",
      "Corrección sugerida: paleo, Distancia: 1, Frecuencia: 131\n",
      "Corrección sugerida: pablo, Distancia: 1, Frecuencia: 21\n",
      "Corrección sugerida: paolo, Distancia: 1, Frecuencia: 5\n",
      "Corrección sugerida: callo, Distancia: 1, Frecuencia: 4\n",
      "Corrección sugerida: palmo, Distancia: 1, Frecuencia: 3\n",
      "Corrección sugerida: fallo, Distancia: 1, Frecuencia: 2\n",
      "Corrección sugerida: pillo, Distancia: 1, Frecuencia: 2\n",
      "Corrección sugerida: palto, Distancia: 1, Frecuencia: 2\n",
      "Corrección sugerida: allo, Distancia: 1, Frecuencia: 1\n",
      "Corrección sugerida: rallo, Distancia: 1, Frecuencia: 1\n",
      "Corrección sugerida: palio, Distancia: 1, Frecuencia: 1\n",
      "Corrección sugerida: palle, Distancia: 1, Frecuencia: 1\n",
      "Pruebas con la palabra: 'espageti'\n",
      "Corrección sugerida: espagueti, Distancia: 1, Frecuencia: 159\n"
     ]
    }
   ],
   "source": [
    "max_edit_distance = 3\n",
    "#Creamos un diccionario y lo cargamos\n",
    "symspell_corpus = SymSpell(max_dictionary_edit_distance= max_edit_distance, prefix_length=7)\n",
    "symspell_corpus.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "# Pruebas\n",
    "test_words = [\"cane\", \"pallo\", \"espageti\"]\n",
    "for word in test_words:\n",
    "    suggestions = symspell_corpus.lookup(word, Verbosity.CLOSEST, max_edit_distance)\n",
    "    print(f\"Pruebas con la palabra: '{word}'\")\n",
    "    if suggestions:\n",
    "        for suggestion in suggestions:\n",
    "            print(f\"Corrección sugerida: {suggestion.term}, Distancia: {suggestion.distance}, Frecuencia: {suggestion.count}\")\n",
    "    else:\n",
    "        print(\"No se encontraron correcciones sugeridas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4yYr1YjMvl_"
   },
   "source": [
    "12.- Corrección de errores con Hunspell.\n",
    "\n",
    "symspellpy es sólo una de las librerías de corrección ortográfica que tenemos a nuestra disposición. En los siguientes ejercicios vamos a trabajar con la librería hunspell (https://hunspell.github.io/).\n",
    "\n",
    "En este ejercicio vamos a:\n",
    "  - Instalar humspell y cargar diccionarios en español.\n",
    "  - Trabajar sobre la columna 'pals'para ver que correcciones nos sugiere en los textos proporcionados (como ya se ha hecho con symspellpy).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5608,
     "status": "ok",
     "timestamp": 1737452601033,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "rUI_sxpdyOoj",
    "outputId": "4e414c7e-cabf-48c9-baba-a7ef11b98918"
   },
   "outputs": [],
   "source": [
    "# !sudo apt-get install libhunspell-dev\n",
    "# !pip install hunspell\n",
    "\n",
    "# paths a los diccionarios de hunspell\n",
    "# dic_path = \"./Spanish.dic\"\n",
    "# aff_path = \"./Spanish.aff\"\n",
    "\n",
    "dic_path = data_dir_path + \"/Spanish.dic\"\n",
    "aff_path = data_dir_path + \"/Spanish.aff\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMC4pYevNJBf"
   },
   "source": [
    "13.- Creación de un objeto HunSpell para obtener las correcciones sugeridas.\n",
    "\n",
    "  - Cremoas objeto HunSpell suministrándole los dicccionarios en español.\n",
    "  - Aplicamos el método suggest sobre la columna 'pals' para ver que correcciones nos sugiere en los textos proporcionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1598,
     "status": "ok",
     "timestamp": 1737452739991,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "XN3r0ssUzZmM",
    "outputId": "6e825109-7119-47bf-a6fb-f240aa5f69b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tma: correccion sugerida --->   ta\n",
      "tma: posibilidades       ---> ['ta', 'tema', 'toma', 'tima', 'ama', 'tea', 'toa', 'tía', 'ritma']\n",
      "------------------------------------------------------------\n",
      "donald: correccion sugerida --->   donad\n",
      "donald: posibilidades       ---> ['donad', 'donala', 'donalo', 'McDonald', 'baldona', 'hondonal', 'algodonal']\n",
      "------------------------------------------------------------\n",
      "trump: correccion sugerida --->   trumao\n",
      "trump: posibilidades       ---> ['trumao']\n",
      "------------------------------------------------------------\n",
      "presdente: correccion sugerida --->   presente\n",
      "presdente: posibilidades       ---> ['presente', 'presidente', 'presiente', 'precedente', 'presidenta', 'presciente', 'presentate']\n",
      "------------------------------------------------------------\n",
      "llevará: correccion sugerida --->   llevara\n",
      "llevará: posibilidades       ---> ['llevara', 'llevará', 'llevar', 'levará', 'llevarán', 'llevarás', 'llevare', 'elevará', 'llenará', 'llegará', 'llevaré', 'lle vará', 'lle-vará']\n",
      "------------------------------------------------------------\n",
      "a: correccion sugerida --->   ea\n",
      "a: posibilidades       ---> ['ea', 'ar', 'ra', 'as', 'ca', 'ta', 'al', 'la', 'ad', 'da', 'ap', 'fa', 'av', 'va', 'ah']\n",
      "------------------------------------------------------------\n",
      "capittolio: correccion sugerida --->   capitolio\n",
      "capittolio: posibilidades       ---> ['capitolio', 'capitalino']\n",
      "------------------------------------------------------------\n",
      "washington: correccion sugerida --->   Washington\n",
      "washington: posibilidades       ---> ['Washington', 'washingtoniano']\n",
      "------------------------------------------------------------\n",
      "dc: correccion sugerida --->   d\n",
      "dc: posibilidades       ---> ['d', 'da', 'de', 'do', 'oc', 'di', 'dí', 'dé', 'CD']\n",
      "------------------------------------------------------------\n",
      "hitórrica: correccion sugerida --->   histórica\n",
      "hitórrica: posibilidades       ---> ['histórica']\n",
      "------------------------------------------------------------\n",
      "años: correccion sugerida --->   anos\n",
      "años: posibilidades       ---> ['anos', 'años', 'año', 'ños', 'raños', 'caños', 'daños', 'maños', 'paños', 'baños', 'Baños', 'aros', 'amos', 'azos', 'ajos']\n",
      "------------------------------------------------------------\n",
      "teine: correccion sugerida --->   tiene\n",
      "teine: posibilidades       ---> ['tiene', 'reine', 'trine', 'terne', 'peine', 'inerte']\n",
      "------------------------------------------------------------\n",
      "a: correccion sugerida --->   ea\n",
      "a: posibilidades       ---> ['ea', 'ar', 'ra', 'as', 'ca', 'ta', 'al', 'la', 'ad', 'da', 'ap', 'fa', 'av', 'va', 'ah']\n",
      "------------------------------------------------------------\n",
      "fvaor: correccion sugerida --->   favor\n",
      "fvaor: posibilidades       ---> ['favor']\n",
      "------------------------------------------------------------\n",
      "y: correccion sugerida --->   u\n",
      "y: posibilidades       ---> ['u', 'ya', 'ay', 'ye', 'yo', 'uy', 'a', 'e', 'o', 'i', 'd', 'ó', 'R', 'O', 'I']\n",
      "------------------------------------------------------------\n",
      "selevridades: correccion sugerida --->   severidades\n",
      "selevridades: posibilidades       ---> ['severidades', 'selectividades', 'celeridades', 'celebridades']\n",
      "------------------------------------------------------------\n",
      "y: correccion sugerida --->   u\n",
      "y: posibilidades       ---> ['u', 'ya', 'ay', 'ye', 'yo', 'uy', 'a', 'e', 'o', 'i', 'd', 'ó', 'R', 'O', 'I']\n",
      "------------------------------------------------------------\n",
      "vission: correccion sugerida --->   visiona\n",
      "vission: posibilidades       ---> ['visiona']\n",
      "------------------------------------------------------------\n",
      "hojos: correccion sugerida --->   hijos\n",
      "hojos: posibilidades       ---> ['hijos', 'ojos', 'hojosa', 'hojoso', 'hojas', 'aojos', 'rojos', 'cojos', 'hotos', 'tojos', 'mojos', 'hobos', 'hoyos', 'hojudos']\n",
      "------------------------------------------------------------\n",
      "llevre: correccion sugerida --->   lleve\n",
      "llevre: posibilidades       ---> ['lleve', 'llevare', 'releve', 'revele']\n",
      "------------------------------------------------------------\n",
      "y: correccion sugerida --->   u\n",
      "y: posibilidades       ---> ['u', 'ya', 'ay', 'ye', 'yo', 'uy', 'a', 'e', 'o', 'i', 'd', 'ó', 'R', 'O', 'I']\n",
      "------------------------------------------------------------\n",
      "mía: correccion sugerida --->   miá\n",
      "mía: posibilidades       ---> ['miá', 'mía', 'nía', 'mí', 'mían', 'mías', 'muía', 'míe', 'mea', 'ría', 'mío', 'moa', 'oía', 'mín', 'sía']\n",
      "------------------------------------------------------------\n",
      "a: correccion sugerida --->   ea\n",
      "a: posibilidades       ---> ['ea', 'ar', 'ra', 'as', 'ca', 'ta', 'al', 'la', 'ad', 'da', 'ap', 'fa', 'av', 'va', 'ah']\n",
      "------------------------------------------------------------\n",
      "rivrera: correccion sugerida --->   rivera\n",
      "rivrera: posibilidades       ---> ['rivera', 'riera']\n",
      "------------------------------------------------------------\n",
      "dejará: correccion sugerida --->   dejara\n",
      "dejará: posibilidades       ---> ['dejara', 'dejará', 'jedará', 'dejar', 'dejarán', 'dejarás', 'dejare', 'cejará', 'tejará', 'depará', 'vejará', 'dejaré']\n",
      "------------------------------------------------------------\n",
      "memorria: correccion sugerida --->   memoria\n",
      "memorria: posibilidades       ---> ['memoria', 'memoriza', 'memoriosa', 'memorismo', 'memora']\n",
      "------------------------------------------------------------\n",
      "y: correccion sugerida --->   u\n",
      "y: posibilidades       ---> ['u', 'ya', 'ay', 'ye', 'yo', 'uy', 'a', 'e', 'o', 'i', 'd', 'ó', 'R', 'O', 'I']\n",
      "------------------------------------------------------------\n",
      "preder: correccion sugerida --->   perder\n",
      "preder: posibilidades       ---> ['perder', 'prender', 'predar', 'prever', 'preceder', 'precede', 'proceder', 'depreda']\n",
      "------------------------------------------------------------\n",
      "a: correccion sugerida --->   ea\n",
      "a: posibilidades       ---> ['ea', 'ar', 'ra', 'as', 'ca', 'ta', 'al', 'la', 'ad', 'da', 'ap', 'fa', 'av', 'va', 'ah']\n",
      "------------------------------------------------------------\n",
      "a: correccion sugerida --->   ea\n",
      "a: posibilidades       ---> ['ea', 'ar', 'ra', 'as', 'ca', 'ta', 'al', 'la', 'ad', 'da', 'ap', 'fa', 'av', 'va', 'ah']\n",
      "------------------------------------------------------------\n",
      "a: correccion sugerida --->   ea\n",
      "a: posibilidades       ---> ['ea', 'ar', 'ra', 'as', 'ca', 'ta', 'al', 'la', 'ad', 'da', 'ap', 'fa', 'av', 'va', 'ah']\n",
      "------------------------------------------------------------\n",
      "glorsamente: correccion sugerida --->   gloriosamente\n",
      "glorsamente: posibilidades       ---> ['gloriosamente', 'llorosamente', 'golosamente', 'orgullosamente']\n",
      "------------------------------------------------------------\n",
      "cenisa: correccion sugerida --->   cenias\n",
      "cenisa: posibilidades       ---> ['cenias', 'cenia', 'censa', 'ceniza', 'cenizosa']\n",
      "------------------------------------------------------------\n",
      "polbu: correccion sugerida --->   pol bu\n",
      "polbu: posibilidades       ---> ['pol bu', 'pol-bu', 'poluto']\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import hunspell\n",
    "dic = hunspell.HunSpell(dic_path, aff_path)\n",
    "\n",
    "for palabras in datos['pals']:\n",
    "  for palabra in palabras:\n",
    "    candidatos = dic.suggest(palabra)\n",
    "    if palabra != candidatos[0]:\n",
    "       print(palabra, end = \": correccion sugerida --->   \")\n",
    "       print(candidatos[0])\n",
    "       print(palabra, end = \": posibilidades       ---> \")\n",
    "       print(candidatos)\n",
    "       print(\"------------\"*5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jAlLF52NmND"
   },
   "source": [
    "14.- Adición de columnas a datos con los resultados de aplicar HunSpell a las palabras de los textos.\n",
    "\n",
    "Vamos a añadir tres columnas al frame de pandas análogas a las que ya creamos con simspellpy (ejercicio 8):\n",
    "\n",
    "- Una columna con todas las palabras sugeridas por pyspellchecker (texto completo dividido en palabras): 'pals_hunspell'. Para ello, como en el ejercicio anterior, usaremos el método suggest(word).\n",
    "- Otra columna sólo con las palabras corregidas por HunSpell: 'corr_hunspell'.\n",
    "- Y una columna más, 'text_hunspell', con el texto resultante de utilizar las palabras sugeridas por HunSpel (las que hemos puesto en 'pals_hunspell).\n",
    "\n",
    "Podrá observar que los resultados son diferentes según el corrector utilizado. Esto puede deberse a muchos factores, aunque en nuestro caso hay uno muy evidente: se han utilizado diccionarios diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2660,
     "status": "ok",
     "timestamp": 1737453150904,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "BEiTSxfL0-AP",
    "outputId": "488b93bb-34ea-4d9c-b56a-4098f86ff294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "la ta de posesión de donad trumao como presente de estados unidos se llevara ea cabo el lunes veinte de enero en el capitolio de Washington d esta ceremonia histórica que se realiza cada cuatro anos tiene en su pista de invitados ea figuras clave en la política mundial ademas de empresarios que busca ganarse el favor del nuevo comandante en jefe u severidades que lo han apoyado u que comparten su visiona para el futuro de la unión americana\n",
      "\n",
      "cerrar podrá mis hijos la postrera sombra que me lleve el blanco día u podrá desatar esta alma miá hora ea su afán ansioso lisonjera mas no de esa otra parte en la rivera dejara la memoria en donde ardía nadar sabe mi llama la agua fría u perder el respeto ea ley severa alma ea quien todo un dios prisión ha sido venas que rumor ea tanto fuego han dado médulas que han gloriosamente ardido su cuerpo dejaran no su cuidado serán cenias mas tendrán sentido polvo serán mas pol bu enamorado\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos_sin_errores</th>\n",
       "      <th>textos_con_errores</th>\n",
       "      <th>pals</th>\n",
       "      <th>pals_simspellpy</th>\n",
       "      <th>corr_simspellpy</th>\n",
       "      <th>text_simspellpy</th>\n",
       "      <th>pals_hunsspell</th>\n",
       "      <th>corr_hunsspell</th>\n",
       "      <th>text_hunsspell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La toma de posesión de Donald Trump como pres...</td>\n",
       "      <td>La tma de posesión de Donald Trump como presd...</td>\n",
       "      <td>[la, tma, de, posesión, de, donald, trump, com...</td>\n",
       "      <td>[la, tema, de, posesión, de, donald, trump, co...</td>\n",
       "      <td>[tema, presidente, capitolio, histórica, tiene...</td>\n",
       "      <td>la tema de posesión de donald trump como presi...</td>\n",
       "      <td>[la, ta, de, posesión, de, donad, trumao, como...</td>\n",
       "      <td>[ta, donad, trumao, presente, llevara, ea, cap...</td>\n",
       "      <td>la ta de posesión de donad trumao como present...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cerrar podrá mis ojos la postrera sombra, que...</td>\n",
       "      <td>Cerrar podrá mis hojos la postrera sombra, qu...</td>\n",
       "      <td>[cerrar, podrá, mis, hojos, la, postrera, somb...</td>\n",
       "      <td>[cerrar, podrá, mis, ojos, la, postrera, sombr...</td>\n",
       "      <td>[ojos, lleve, pionera, rivera, memoria, perder...</td>\n",
       "      <td>cerrar podrá mis ojos la postrera sombra que m...</td>\n",
       "      <td>[cerrar, podrá, mis, hijos, la, postrera, somb...</td>\n",
       "      <td>[hijos, lleve, u, miá, ea, rivera, dejara, mem...</td>\n",
       "      <td>cerrar podrá mis hijos la postrera sombra que ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  textos_sin_errores  \\\n",
       "0   La toma de posesión de Donald Trump como pres...   \n",
       "1   Cerrar podrá mis ojos la postrera sombra, que...   \n",
       "\n",
       "                                  textos_con_errores  \\\n",
       "0   La tma de posesión de Donald Trump como presd...   \n",
       "1   Cerrar podrá mis hojos la postrera sombra, qu...   \n",
       "\n",
       "                                                pals  \\\n",
       "0  [la, tma, de, posesión, de, donald, trump, com...   \n",
       "1  [cerrar, podrá, mis, hojos, la, postrera, somb...   \n",
       "\n",
       "                                     pals_simspellpy  \\\n",
       "0  [la, tema, de, posesión, de, donald, trump, co...   \n",
       "1  [cerrar, podrá, mis, ojos, la, postrera, sombr...   \n",
       "\n",
       "                                     corr_simspellpy  \\\n",
       "0  [tema, presidente, capitolio, histórica, tiene...   \n",
       "1  [ojos, lleve, pionera, rivera, memoria, perder...   \n",
       "\n",
       "                                     text_simspellpy  \\\n",
       "0  la tema de posesión de donald trump como presi...   \n",
       "1  cerrar podrá mis ojos la postrera sombra que m...   \n",
       "\n",
       "                                      pals_hunsspell  \\\n",
       "0  [la, ta, de, posesión, de, donad, trumao, como...   \n",
       "1  [cerrar, podrá, mis, hijos, la, postrera, somb...   \n",
       "\n",
       "                                      corr_hunsspell  \\\n",
       "0  [ta, donad, trumao, presente, llevara, ea, cap...   \n",
       "1  [hijos, lleve, u, miá, ea, rivera, dejara, mem...   \n",
       "\n",
       "                                      text_hunsspell  \n",
       "0  la ta de posesión de donad trumao como present...  \n",
       "1  cerrar podrá mis hijos la postrera sombra que ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sugerencias_hunsspell (lista_terminos):\n",
    "  l = [dic.suggest(termino)[0]\n",
    "               if dic.suggest(termino)[0] is not None\n",
    "               else termino for termino in lista_terminos]\n",
    "  return l\n",
    "\n",
    "\n",
    "def get_cambiadas_hunsspell (l_original, l_cambiada):\n",
    "  l = [termino_cambiada\n",
    "         for termino_original, termino_cambiada in zip(l_original, l_cambiada)\n",
    "            if termino_original != termino_cambiada]\n",
    "  return l\n",
    "\n",
    "datos['pals_hunsspell'] = datos['pals'].apply(get_sugerencias_hunsspell)\n",
    "datos['corr_hunsspell'] = datos.apply(lambda x:\n",
    "                                          get_cambiadas_hunsspell(x['pals'],\n",
    "                                                        x['pals_hunsspell']),\n",
    "                                                        axis=1)\n",
    "\n",
    "datos['text_hunsspell'] = datos['pals_hunsspell'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "print()\n",
    "print(datos['text_hunsspell'][0])\n",
    "print()\n",
    "print(datos['text_hunsspell'][1])\n",
    "print(\"----------\"*10)\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNrrEngiNxd9"
   },
   "source": [
    "15.- Finalmente, vamos a visualizar cómo quedan los textos con las correciones hechas con ambos correctores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737453664326,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "_ZYAw5Hc1XdB",
    "outputId": "979c5dbc-2848-4b5b-aad3-775173d5d42c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto sin errores ---->   La toma de posesión de Donald Trump como presidente de Estados Unidos se llevará a cabo el lunes veinte de enero en el Capitolio de Washington D.C. Esta ceremonia histórica, que se realiza cada cuatro años, tiene en su lista de invitados a figuras clave en la política mundial, además de empresarios que buscan ganarse el favor del nuevo comandante en jefe, y celebridades que lo han apoyado y que comparten su visión para el futuro de la unión americana.\n",
      "Texto con errores ---->   La tma de posesión de Donald Trump como presdente de Estados Unidos se llevará a cabo el lunes, veinte de enero en el Capittolio de Washington D.C. Esta ceremonia hitórrica, que se realiza cada cuatro años, teine en su pista de invitados a figuras clave en la política mundial, ademas de empresarios que busca ganarse el fvaor del nuevo comandante en jefe, y selevridades que lo han apoyado y que comparten su vission para el futuro de la unión americana.\n",
      "Texto symspellpy  ---->  la tema de posesión de donald trump como presidente de estados unidos se llevará a cabo el lunes veinte de enero en el capitolio de washington dc esta ceremonia histórica que se realiza cada cuatro años tiene en su pista de invitados a figuras clave en la política mundial ademas de empresarios que busca ganarse el favor del nuevo comandante en jefe y celebridades que lo han apoyado y que comparten su vision para el futuro de la unión americana\n",
      "Texto hunspell    ---->  la ta de posesión de donad trumao como presente de estados unidos se llevara ea cabo el lunes veinte de enero en el capitolio de Washington d esta ceremonia histórica que se realiza cada cuatro anos tiene en su pista de invitados ea figuras clave en la política mundial ademas de empresarios que busca ganarse el favor del nuevo comandante en jefe u severidades que lo han apoyado u que comparten su visiona para el futuro de la unión americana\n",
      "\n",
      "------------------------------------------------------------\n",
      "Texto sin errores ---->   Cerrar podrá mis ojos la postrera sombra, que me llevare el blanco día, y podrá desatar esta alma mía hora, a su afán ansioso linsojera; mas no de esa otra parte en la ribera dejará la memoria en donde ardía; nadar sabe mi llama la agua fría, y perder el respeto a ley severa; Alma a quien todo un Dios prisión ha sido, venas que humor a tanto fuego han dado, médulas que han gloriosamente ardido, su cuerpo dejarán, no su cuidado; serán ceniza, mas tendrán sentido. Polvo serán, mas polvo enamorado.\n",
      "Texto con errores ---->   Cerrar podrá mis hojos la postrera sombra, que me llevre el blanco día, y podrá desatar esta alma mía hora, a su afán ansioso lisonjera; mas no de esa otra parte en la rivrera dejará la memorria en donde ardía; nadar sabe mi llama la agua fría, y preder el respeto a ley severa; Alma a quien todo un Dios prisión ha sido, venas que rumor a tanto fuego han dado, médulas que han glorsamente ardido, su cuerpo dejaran, no su cuidado; serán cenisa, mas tendrán sentido. Polvo serán, mas polbu enamorado.\n",
      "Texto symspellpy  ---->  cerrar podrá mis ojos la postrera sombra que me lleve el blanco día y podrá desatar esta alma mía hora a su afán ansioso pionera mas no de esa otra parte en la rivera dejará la memoria en donde ardía nadar sabe mi llama la agua fría y perder el respeto a ley severa alma a quien todo un dios prisión ha sido venas que rumor a tanto fuego han dado médulas que han gloriosamente ardido su cuerpo dejaran no su cuidado serán ceniza mas tendrán sentido polvo serán mas polvo enamorado\n",
      "Texto hunspell    ---->  cerrar podrá mis hijos la postrera sombra que me lleve el blanco día u podrá desatar esta alma miá hora ea su afán ansioso lisonjera mas no de esa otra parte en la rivera dejara la memoria en donde ardía nadar sabe mi llama la agua fría u perder el respeto ea ley severa alma ea quien todo un dios prisión ha sido venas que rumor ea tanto fuego han dado médulas que han gloriosamente ardido su cuerpo dejaran no su cuidado serán cenias mas tendrán sentido polvo serán mas pol bu enamorado\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for row in datos.itertuples():\n",
    "  print(\"Texto sin errores ----> \", end = \" \")\n",
    "  print(datos['textos_sin_errores'][row.Index])\n",
    "  print(\"Texto con errores ----> \", end = \" \")\n",
    "  print(datos['textos_con_errores'][row.Index])\n",
    "  print(\"Texto symspellpy  ----> \", end = \" \")\n",
    "  print(datos['text_simspellpy'][row.Index])\n",
    "  print(\"Texto hunspell    ----> \", end = \" \")\n",
    "  print(datos['text_hunsspell'][row.Index])\n",
    "  print()\n",
    "  print(\"------------\"*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTmBAoOXOrug"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "vtRLK5FD1lw1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "id": "ij2cHWi1AYMT"
   },
   "outputs": [],
   "source": [
    "# Guardar en fichero ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "hrohUb57Io0I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "rHj0bfTXBddh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1eYT26299XC2i9zEPpge6MAiVQDzX4CuS",
     "timestamp": 1737388923924
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
