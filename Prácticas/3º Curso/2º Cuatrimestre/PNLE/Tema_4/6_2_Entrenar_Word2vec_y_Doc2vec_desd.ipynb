{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrajzBdoGAki"
      },
      "source": [
        "# Sesión 6 - Entrenar Word2vec y Doc2Vec desde 0\n",
        "\n",
        "En este notebook vamos a ver cómo se entrena un modelo sencillo de word2vec eligiendo las dimensiones de los vectores.\n",
        "\n",
        "Además, se creará un modelo de Doc2Vec a partir de un conjunto de documentos y se verá cómo se puede obtener las similitudes entre documentos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aWLFpiTGDgWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d11e1bf3-7c2a-42f1-e389-5b2a35981864",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "# Instalamos gensim si no lo tenemos instalado\n",
        "!pip3 install -U gensim\n",
        "# Esto es por si no está ya instalado\n",
        "!pip3 install -U pandas\n",
        "!pip3 install -U nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXwlp73V7Ttp"
      },
      "source": [
        "# Apartado 1.1 Descargamos un corpus de prueba\n",
        "\n",
        "Vamos a probar con un corpus de noticias que se encuentra en la URL https://valencia.inf.um.es/valencia-tgine/corpusNoticias.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kWO6w9RLzzRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea3be00-d44d-4ee2-a4e0-75663716b06f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-20 21:21:44--  https://valencia.inf.um.es/valencia-plne/corpusNoticias.zip\n",
            "Resolving valencia.inf.um.es (valencia.inf.um.es)... 155.54.204.133\n",
            "Connecting to valencia.inf.um.es (valencia.inf.um.es)|155.54.204.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4170052 (4.0M) [application/zip]\n",
            "Saving to: ‘corpusNoticias.zip.2’\n",
            "\n",
            "corpusNoticias.zip. 100%[===================>]   3.98M  4.38MB/s    in 0.9s    \n",
            "\n",
            "2025-03-20 21:21:45 (4.38 MB/s) - ‘corpusNoticias.zip.2’ saved [4170052/4170052]\n",
            "\n",
            "replace corpusNoticias/00005112614397266846.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "# Descargamos un corpus de noticias que he creado\n",
        "!wget --no-check-certificate https://valencia.inf.um.es/valencia-plne/corpusNoticias.zip\n",
        "!unzip corpusNoticias.zip > extract.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap0DBy7V7e-4"
      },
      "source": [
        "Leemos todos lo ficheros y los metemos en una variable *texts*\n",
        "\n",
        "Tened en cuenta que la codificación de caracteres en estos ficheros es UTF-8. Esto depende del contenido de las web a descargar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7YShf3_zDZNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "12ded0ec-cf58-4fc3-923b-dd069e2ee98a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El cambio de ley que permitirá trabajar a los estudiantes extranjeros: \"Yo sobrevivía con 400 euros\n",
            "Laura Rosero, inmigrante colombiana de 25 años, se trasladó a vivir a Madrid hace tres años para realizar un Máster en Cine. La joven había estudiado Comunicación Social y Periodismo en su país y, dado que su intención era trabajar en la producción de películas y cortos, pensó que mudarse a España sería un atajo para acceder al mercado laboral y obtener una mejor «calidad de vida». Nada más lejos de la realidad, porque cuando se instaló en la capital, aunque estaba cómoda y veía cómo gracias al esfuerzo académico había logrado mudarse a Europa, no tardó en darse cuenta de que no podía mantenerse por sí sola. «El visado de estudiante no me permitía trabajar con oportunidades más allá de un contrato en prácticas, así que sobrevivía con 400 euros de beca», explica. La joven describe ese año de máster como una época «difícil» y reconoce que, con ese presupuesto, «no le llegaba para vivir». «Recuerdo que mis compañeros decían de salir a tomar unas copas y a mí solo me sobraban 40 euros al mes para gastármelo en ocio, un importe que cualquiera sabe que en una noche se te va en seguida». De modo que, la mayoría de las veces, Laura renunciaba a las invitaciones de sus amigos y se quedaba en su piso de Puerta del Ángel. Esta dificultad de los inmigrantes estudiantes para trabajar en suelo español desaparecerá a partir del próximo martes con la entrada en vigor de una reforma en la Ley de Extranjería. La modificación del reglamento permitirá a los más de 50.000 estudiantes extranjeros que residen en España compaginar el estudio con el trabajo siempre y cuando éste no supere las 30 horas semanales y sea compatible con la formación, lo que facilitará que puedan hacer frente a sus propios gastos sin ayuda ajena. Entre sus novedades, la ley incluye renovaciones en los arraigos, que son los modos de obtener permiso de residencia temporal en España. Los cambios en el arraigo laboral, en el arraigo social y en el arraigo por formación tendrán la intención de acabar con la «desprotección de muchas personas que llevan viviendo mucho tiempo en España y que siguen en una situación de vulnerabilidad laboral», manifestó hace unos días el ministro de Inclusión, José Luis Escrivá, cuando fue preguntado por la reforma. Por arraigo laboral, podrán obtener una autorización de residencia temporal los extranjeros que se encuentren en situación irregular y acrediten la permanencia continuada en España durante un mínimo de dos años, siempre que carezcan de antecedentes penales en España y en su país de origen o en el país o países en que haya residido durante los últimos cinco años. Deben además demostrar que han trabajado como mínimo una jornada de 30 horas semanales durante seis meses o de 15 horas semanales durante 12 meses. Mercado de trabajo El decreto ha levantado dudas sobre el efecto llamada que pueda generar su puesta en marcha, una teoría que el ministro de Inclusión, José Luis Escrivá ha negado que pueda ocurrir, según ha declarado en una reciente entrevista en El País. «Hay numerosos estudios que a lo largo del tiempo han demostrado que los cambios legales en los procesos de migración regular e irregular no parecen ser un foco determinante» para animar a las personas a emigrar, dijo. Y, en cuanto a la regularización de los sin papeles, consideró como «errónea» la tesis de que este decreto vaya a suponer la «sustitución de trabajadores» nacionales por extranjeros ya que apuntó, lo que hay son «déficits en el mercado de trabajo que dificultan el crecimiento general de la economía». En el caso de España la inmigración supone una parte fundamental de la población. Los datos del padrón del último año reflejan que la llegada de extranjeros mantiene el crecimiento poblacional. En 2021, el número de extranjeros aumentó en 49.612 personas hasta sumar un total de 5.417.883 a 1 de enero de 2022. El incremento se debió, en gran parte a un saldo migratorio positivo de 153.094 personas. La población de nacionalidad española se redujo en 15.502 personas. «A mí me hubiese ayudado a prosperar», dice Laura sobre la nueva reforma, que le habría permitido estudiar y trabajar a la vez. «Me habría sido de gran ayuda».\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Iron Maiden anuncia tres conciertos en España para 2023: fechas y venta de entradas\n",
            "El grupo británico Iron Maiden ha anunciado las fechas de su gira mundial The Future Past Tour 2023, que incluirá tres conciertos en España. La banda de heavy metal tocará en Barcelona, Murcia y Bilbao, según ha desvelado la promotora Madness Live este jueves en un comunicado. Así, los conciertos de Iron Maiden en España serán el 18 de julio de 2023 en el Palau Sant Jordi de Barcelona; el 20 de julio, en el Estadio Enrique Roca de Murcia; y el 22 de julio en el Bizkaia Arena de Bilbao. El comunicado detalla que la banda presentará así su \"viaje en el tiempo hacia el Japón feudal\" que refleja en su último disco, Senjutsu\" (2021). Entradas para los conciertos de Iron Maiden Las entradas para los conciertos de Iron Maiden saldrán a la venta la próxima semana en la web de Madnesslive.es. El miércoles, 2 de noviembre, habrá una preventa de entradas para el Fan Club a partir de las 10:00 horas. Mientras que la venta general de entradas se abrirá un día después, el jueves 3 de noviembre a las 10:00 horas. En cuanto a los precios de las entradas de Iron Maiden, estos irán desde los 65 euros más gastos de gestión, según detallan en la propia web de Madness Live. Asimismo, indican que solo se podrán comprar un máximo de cuatro entradas por usuario en preventa y de seis entradas por usuario en venta general.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Diego Rico, jugador de la Real Sociedad, denuncia que lleva meses sufriendo acoso en las redes\n",
            "El futbolista de la Real Sociedad Diego Rico ha denunciado en su cuenta de Instagram que lleva \"meses\" sufriendo acoso a través de redes sociales. Así, ha colgado un comunicado en el que asegura que ha sufrido \"difamaciones\" y ataques personales tanto a él como a su familia y su entorno. \"Acoso en definitiva, a través de diversas redes sociales\", sentencia. Tal es la situación vivida que asegura que ya ha puesto lo sucedido en manos de las fuerzas de seguridad y ha aprovechado el comunicado para agradecer a la Ertzaintza el trato recibido. \"Con la ayuda de mis allegados he intentado poner freno a esto y ahora, una vezo logrado el objetivo no queriendo desviar la atención de mi profesión, he denunciado estos hechos ante las autoridades competentes\". En el comunicado publicado Rico insiste en que \"nadie es merecedor de ser acosado a través de cuentas falsas que se crean expresamente con el motivo de hacer daño\". Además, asegura haber sufrido \"acusaciones falsas muy graves\" que \"no podía permitir más\".\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "my_path = \"corpusNoticias/\"\n",
        "texts = []\n",
        "for fn in listdir(my_path):\n",
        "  f = open(my_path+fn, encoding = \"utf-8\")\n",
        "  file_content = f.read()\n",
        "  texts.append(file_content)\n",
        "  f.close()\n",
        "\n",
        "# Comprobar que se ha leído bien:\n",
        "for text in texts[:3]:\n",
        "  print(text)\n",
        "  print(\"----------\"*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayP_P-SdgnYq",
        "tags": []
      },
      "source": [
        "# Apartado 1.2 Entrenamos un modelo word2vec a partir del corpus\n",
        "\n",
        "Aquí vamos a entrenar un modelo word2vec con la librería GENSIM. Como Tokenizer se utilizará el word_tokenize de NLTK, pero se podría usar cualquier otro tokenizador."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J--eYc8h3H8v",
        "outputId": "45bfb14c-26ad-46bc-f9e5-dc521bd9b130"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nltk\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click (from nltk)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting joblib (from nltk)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tqdm (from nltk)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "Successfully installed click-8.1.8 joblib-1.4.2 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VYOCayluhnw7"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import numpy\n",
        "import pandas\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec,KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "import re\n",
        "import unicodedata\n",
        "from tqdm import tqdm\n",
        "import gensim\n",
        "import multiprocessing\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FM6EVMswuu9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fcab474-0d3c-4038-ad07-48e3cbf05ba1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "['el', 'cambio', 'de', 'ley', 'que', 'permitirá', 'trabajar', 'a', 'los', 'estudiantes', 'extranjeros', ':', '``', 'yo', 'sobrevivía', 'con', '400', 'euros', 'laura', 'rosero', ',', 'inmigrante', 'colombiana', 'de', '25', 'años', ',', 'se', 'trasladó', 'a', 'vivir', 'a', 'madrid', 'hace', 'tres', 'años', 'para', 'realizar', 'un', 'máster', 'en', 'cine', '.', 'la', 'joven', 'había', 'estudiado', 'comunicación', 'social', 'y', 'periodismo', 'en', 'su', 'país', 'y', ',', 'dado', 'que', 'su', 'intención', 'era', 'trabajar', 'en', 'la', 'producción', 'de', 'películas', 'y', 'cortos', ',', 'pensó', 'que', 'mudarse', 'a', 'españa', 'sería', 'un', 'atajo', 'para', 'acceder', 'al', 'mercado', 'laboral', 'y', 'obtener', 'una', 'mejor', '«', 'calidad', 'de', 'vida', '»', '.', 'nada', 'más', 'lejos', 'de', 'la', 'realidad', ',', 'porque', 'cuando', 'se', 'instaló', 'en', 'la', 'capital', ',', 'aunque', 'estaba', 'cómoda', 'y', 'veía', 'cómo', 'gracias', 'al', 'esfuerzo', 'académico', 'había', 'logrado', 'mudarse', 'a', 'europa', ',', 'no', 'tardó', 'en', 'darse', 'cuenta', 'de', 'que', 'no', 'podía', 'mantenerse', 'por', 'sí', 'sola', '.', '«', 'el', 'visado', 'de', 'estudiante', 'no', 'me', 'permitía', 'trabajar', 'con', 'oportunidades', 'más', 'allá', 'de', 'un', 'contrato', 'en', 'prácticas', ',', 'así', 'que', 'sobrevivía', 'con', '400', 'euros', 'de', 'beca', '»', ',', 'explica', '.', 'la', 'joven', 'describe', 'ese', 'año', 'de', 'máster', 'como', 'una', 'época', '«', 'difícil', '»', 'y', 'reconoce', 'que', ',', 'con', 'ese', 'presupuesto', ',', '«', 'no', 'le', 'llegaba', 'para', 'vivir', '»', '.', '«', 'recuerdo', 'que', 'mis', 'compañeros', 'decían', 'de', 'salir', 'a', 'tomar', 'unas', 'copas', 'y', 'a', 'mí', 'solo', 'me', 'sobraban', '40', 'euros', 'al', 'mes', 'para', 'gastármelo', 'en', 'ocio', ',', 'un', 'importe', 'que', 'cualquiera', 'sabe', 'que', 'en', 'una', 'noche', 'se', 'te', 'va', 'en', 'seguida', '»', '.', 'de', 'modo', 'que', ',', 'la', 'mayoría', 'de', 'las', 'veces', ',', 'laura', 'renunciaba', 'a', 'las', 'invitaciones', 'de', 'sus', 'amigos', 'y', 'se', 'quedaba', 'en', 'su', 'piso', 'de', 'puerta', 'del', 'ángel', '.', 'esta', 'dificultad', 'de', 'los', 'inmigrantes', 'estudiantes', 'para', 'trabajar', 'en', 'suelo', 'español', 'desaparecerá', 'a', 'partir', 'del', 'próximo', 'martes', 'con', 'la', 'entrada', 'en', 'vigor', 'de', 'una', 'reforma', 'en', 'la', 'ley', 'de', 'extranjería', '.', 'la', 'modificación', 'del', 'reglamento', 'permitirá', 'a', 'los', 'más', 'de', '50.000', 'estudiantes', 'extranjeros', 'que', 'residen', 'en', 'españa', 'compaginar', 'el', 'estudio', 'con', 'el', 'trabajo', 'siempre', 'y', 'cuando', 'éste', 'no', 'supere', 'las', '30', 'horas', 'semanales', 'y', 'sea', 'compatible', 'con', 'la', 'formación', ',', 'lo', 'que', 'facilitará', 'que', 'puedan', 'hacer', 'frente', 'a', 'sus', 'propios', 'gastos', 'sin', 'ayuda', 'ajena', '.', 'entre', 'sus', 'novedades', ',', 'la', 'ley', 'incluye', 'renovaciones', 'en', 'los', 'arraigos', ',', 'que', 'son', 'los', 'modos', 'de', 'obtener', 'permiso', 'de', 'residencia', 'temporal', 'en', 'españa', '.', 'los', 'cambios', 'en', 'el', 'arraigo', 'laboral', ',', 'en', 'el', 'arraigo', 'social', 'y', 'en', 'el', 'arraigo', 'por', 'formación', 'tendrán', 'la', 'intención', 'de', 'acabar', 'con', 'la', '«', 'desprotección', 'de', 'muchas', 'personas', 'que', 'llevan', 'viviendo', 'mucho', 'tiempo', 'en', 'españa', 'y', 'que', 'siguen', 'en', 'una', 'situación', 'de', 'vulnerabilidad', 'laboral', '»', ',', 'manifestó', 'hace', 'unos', 'días', 'el', 'ministro', 'de', 'inclusión', ',', 'josé', 'luis', 'escrivá', ',', 'cuando', 'fue', 'preguntado', 'por', 'la', 'reforma', '.', 'por', 'arraigo', 'laboral', ',', 'podrán', 'obtener', 'una', 'autorización', 'de', 'residencia', 'temporal', 'los', 'extranjeros', 'que', 'se', 'encuentren', 'en', 'situación', 'irregular', 'y', 'acrediten', 'la', 'permanencia', 'continuada', 'en', 'españa', 'durante', 'un', 'mínimo', 'de', 'dos', 'años', ',', 'siempre', 'que', 'carezcan', 'de', 'antecedentes', 'penales', 'en', 'españa', 'y', 'en', 'su', 'país', 'de', 'origen', 'o', 'en', 'el', 'país', 'o', 'países', 'en', 'que', 'haya', 'residido', 'durante', 'los', 'últimos', 'cinco', 'años', '.', 'deben', 'además', 'demostrar', 'que', 'han', 'trabajado', 'como', 'mínimo', 'una', 'jornada', 'de', '30', 'horas', 'semanales', 'durante', 'seis', 'meses', 'o', 'de', '15', 'horas', 'semanales', 'durante', '12', 'meses', '.', 'mercado', 'de', 'trabajo', 'el', 'decreto', 'ha', 'levantado', 'dudas', 'sobre', 'el', 'efecto', 'llamada', 'que', 'pueda', 'generar', 'su', 'puesta', 'en', 'marcha', ',', 'una', 'teoría', 'que', 'el', 'ministro', 'de', 'inclusión', ',', 'josé', 'luis', 'escrivá', 'ha', 'negado', 'que', 'pueda', 'ocurrir', ',', 'según', 'ha', 'declarado', 'en', 'una', 'reciente', 'entrevista', 'en', 'el', 'país', '.', '«', 'hay', 'numerosos', 'estudios', 'que', 'a', 'lo', 'largo', 'del', 'tiempo', 'han', 'demostrado', 'que', 'los', 'cambios', 'legales', 'en', 'los', 'procesos', 'de', 'migración', 'regular', 'e', 'irregular', 'no', 'parecen', 'ser', 'un', 'foco', 'determinante', '»', 'para', 'animar', 'a', 'las', 'personas', 'a', 'emigrar', ',', 'dijo', '.', 'y', ',', 'en', 'cuanto', 'a', 'la', 'regularización', 'de', 'los', 'sin', 'papeles', ',', 'consideró', 'como', '«', 'errónea', '»', 'la', 'tesis', 'de', 'que', 'este', 'decreto', 'vaya', 'a', 'suponer', 'la', '«', 'sustitución', 'de', 'trabajadores', '»', 'nacionales', 'por', 'extranjeros', 'ya', 'que', 'apuntó', ',', 'lo', 'que', 'hay', 'son', '«', 'déficits', 'en', 'el', 'mercado', 'de', 'trabajo', 'que', 'dificultan', 'el', 'crecimiento', 'general', 'de', 'la', 'economía', '»', '.', 'en', 'el', 'caso', 'de', 'españa', 'la', 'inmigración', 'supone', 'una', 'parte', 'fundamental', 'de', 'la', 'población', '.', 'los', 'datos', 'del', 'padrón', 'del', 'último', 'año', 'reflejan', 'que', 'la', 'llegada', 'de', 'extranjeros', 'mantiene', 'el', 'crecimiento', 'poblacional', '.', 'en', '2021', ',', 'el', 'número', 'de', 'extranjeros', 'aumentó', 'en', '49.612', 'personas', 'hasta', 'sumar', 'un', 'total', 'de', '5.417.883', 'a', '1', 'de', 'enero', 'de', '2022.', 'el', 'incremento', 'se', 'debió', ',', 'en', 'gran', 'parte', 'a', 'un', 'saldo', 'migratorio', 'positivo', 'de', '153.094', 'personas', '.', 'la', 'población', 'de', 'nacionalidad', 'española', 'se', 'redujo', 'en', '15.502', 'personas', '.', '«', 'a', 'mí', 'me', 'hubiese', 'ayudado', 'a', 'prosperar', '»', ',', 'dice', 'laura', 'sobre', 'la', 'nueva', 'reforma', ',', 'que', 'le', 'habría', 'permitido', 'estudiar', 'y', 'trabajar', 'a', 'la', 'vez', '.', '«', 'me', 'habría', 'sido', 'de', 'gran', 'ayuda', '»', '.']\n",
            "----------------------------------------------------------------------------------------------------\n",
            "['iron', 'maiden', 'anuncia', 'tres', 'conciertos', 'en', 'españa', 'para', '2023', ':', 'fechas', 'y', 'venta', 'de', 'entradas', 'el', 'grupo', 'británico', 'iron', 'maiden', 'ha', 'anunciado', 'las', 'fechas', 'de', 'su', 'gira', 'mundial', 'the', 'future', 'past', 'tour', '2023', ',', 'que', 'incluirá', 'tres', 'conciertos', 'en', 'españa', '.', 'la', 'banda', 'de', 'heavy', 'metal', 'tocará', 'en', 'barcelona', ',', 'murcia', 'y', 'bilbao', ',', 'según', 'ha', 'desvelado', 'la', 'promotora', 'madness', 'live', 'este', 'jueves', 'en', 'un', 'comunicado', '.', 'así', ',', 'los', 'conciertos', 'de', 'iron', 'maiden', 'en', 'españa', 'serán', 'el', '18', 'de', 'julio', 'de', '2023', 'en', 'el', 'palau', 'sant', 'jordi', 'de', 'barcelona', ';', 'el', '20', 'de', 'julio', ',', 'en', 'el', 'estadio', 'enrique', 'roca', 'de', 'murcia', ';', 'y', 'el', '22', 'de', 'julio', 'en', 'el', 'bizkaia', 'arena', 'de', 'bilbao', '.', 'el', 'comunicado', 'detalla', 'que', 'la', 'banda', 'presentará', 'así', 'su', '``', 'viaje', 'en', 'el', 'tiempo', 'hacia', 'el', 'japón', 'feudal', \"''\", 'que', 'refleja', 'en', 'su', 'último', 'disco', ',', 'senjutsu', \"''\", '(', '2021', ')', '.', 'entradas', 'para', 'los', 'conciertos', 'de', 'iron', 'maiden', 'las', 'entradas', 'para', 'los', 'conciertos', 'de', 'iron', 'maiden', 'saldrán', 'a', 'la', 'venta', 'la', 'próxima', 'semana', 'en', 'la', 'web', 'de', 'madnesslive.es', '.', 'el', 'miércoles', ',', '2', 'de', 'noviembre', ',', 'habrá', 'una', 'preventa', 'de', 'entradas', 'para', 'el', 'fan', 'club', 'a', 'partir', 'de', 'las', '10:00', 'horas', '.', 'mientras', 'que', 'la', 'venta', 'general', 'de', 'entradas', 'se', 'abrirá', 'un', 'día', 'después', ',', 'el', 'jueves', '3', 'de', 'noviembre', 'a', 'las', '10:00', 'horas', '.', 'en', 'cuanto', 'a', 'los', 'precios', 'de', 'las', 'entradas', 'de', 'iron', 'maiden', ',', 'estos', 'irán', 'desde', 'los', '65', 'euros', 'más', 'gastos', 'de', 'gestión', ',', 'según', 'detallan', 'en', 'la', 'propia', 'web', 'de', 'madness', 'live', '.', 'asimismo', ',', 'indican', 'que', 'solo', 'se', 'podrán', 'comprar', 'un', 'máximo', 'de', 'cuatro', 'entradas', 'por', 'usuario', 'en', 'preventa', 'y', 'de', 'seis', 'entradas', 'por', 'usuario', 'en', 'venta', 'general', '.']\n",
            "----------------------------------------------------------------------------------------------------\n",
            "['diego', 'rico', ',', 'jugador', 'de', 'la', 'real', 'sociedad', ',', 'denuncia', 'que', 'lleva', 'meses', 'sufriendo', 'acoso', 'en', 'las', 'redes', 'el', 'futbolista', 'de', 'la', 'real', 'sociedad', 'diego', 'rico', 'ha', 'denunciado', 'en', 'su', 'cuenta', 'de', 'instagram', 'que', 'lleva', '``', 'meses', \"''\", 'sufriendo', 'acoso', 'a', 'través', 'de', 'redes', 'sociales', '.', 'así', ',', 'ha', 'colgado', 'un', 'comunicado', 'en', 'el', 'que', 'asegura', 'que', 'ha', 'sufrido', '``', 'difamaciones', \"''\", 'y', 'ataques', 'personales', 'tanto', 'a', 'él', 'como', 'a', 'su', 'familia', 'y', 'su', 'entorno', '.', '``', 'acoso', 'en', 'definitiva', ',', 'a', 'través', 'de', 'diversas', 'redes', 'sociales', \"''\", ',', 'sentencia', '.', 'tal', 'es', 'la', 'situación', 'vivida', 'que', 'asegura', 'que', 'ya', 'ha', 'puesto', 'lo', 'sucedido', 'en', 'manos', 'de', 'las', 'fuerzas', 'de', 'seguridad', 'y', 'ha', 'aprovechado', 'el', 'comunicado', 'para', 'agradecer', 'a', 'la', 'ertzaintza', 'el', 'trato', 'recibido', '.', '``', 'con', 'la', 'ayuda', 'de', 'mis', 'allegados', 'he', 'intentado', 'poner', 'freno', 'a', 'esto', 'y', 'ahora', ',', 'una', 'vezo', 'logrado', 'el', 'objetivo', 'no', 'queriendo', 'desviar', 'la', 'atención', 'de', 'mi', 'profesión', ',', 'he', 'denunciado', 'estos', 'hechos', 'ante', 'las', 'autoridades', 'competentes', \"''\", '.', 'en', 'el', 'comunicado', 'publicado', 'rico', 'insiste', 'en', 'que', '``', 'nadie', 'es', 'merecedor', 'de', 'ser', 'acosado', 'a', 'través', 'de', 'cuentas', 'falsas', 'que', 'se', 'crean', 'expresamente', 'con', 'el', 'motivo', 'de', 'hacer', 'daño', \"''\", '.', 'además', ',', 'asegura', 'haber', 'sufrido', '``', 'acusaciones', 'falsas', 'muy', 'graves', \"''\", 'que', '``', 'no', 'podía', 'permitir', 'más', \"''\", '.']\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Procesamos todos los textos y le aplicamos el word_tokenize de NLTK\n",
        "nltk.download('punkt_tab')\n",
        "train_texts=[]\n",
        "for text in texts:\n",
        "     train_texts.append(word_tokenize(text.lower()))\n",
        "\n",
        "# Comprobar tokenización:\n",
        "print()\n",
        "print()\n",
        "for t in train_texts[:3]:\n",
        "  print(t)\n",
        "  print(\"----------\"*10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nXcj2gSJjKBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b22300-1c79-45d8-8719-589a5526c6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=65286, vector_size=100, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "# define training data\n",
        "# train model\n",
        "# se puede entrenar el modelo con distintos parámetros como el tamaño del vector,\n",
        "# tamaño de la ventana, las veces que debe aparecer una palabra, etc.\n",
        "model = Word2Vec(train_texts, vector_size=100, window=10, min_count=1, workers=10)\n",
        "# summarize the loaded model\n",
        "print(model)\n",
        "# save model\n",
        "model.save('model.bin')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Mgj_UBgG90GZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6081a94-a997-4d28-8fde-630e8112d134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.54966843  0.0875638   0.49173936  0.31768817  0.60506946 -1.3478377\n",
            "  0.44486743  1.3436048  -0.22349086 -1.2903141   0.18226402 -0.63643825\n",
            " -0.20991665 -0.10744024  0.21418516 -0.33001572  1.280824   -0.6162934\n",
            "  0.27269593 -0.6326234   0.848064    0.95154965  0.7661901  -0.5198638\n",
            "  0.11636665 -0.91778165 -0.6305624   0.5948861   0.05202897  0.23123802\n",
            "  1.1733158  -0.72866476 -0.00409259  0.26516086  0.43973595  0.36105534\n",
            "  0.1902662   0.08324517  0.844308   -0.03544473  0.5116959  -0.2893432\n",
            " -0.11126821  0.01203209 -0.03792691  1.171641   -0.21934138  0.2378036\n",
            "  0.4355185   0.21893078 -0.29556614 -0.04398661  0.14149816 -0.9219015\n",
            "  0.06030832  1.4807315   0.09648234  0.23586525  0.85574925  0.2006561\n",
            " -0.6391146  -0.34830517  0.26138386  0.10251787 -0.38559857  0.9993626\n",
            "  0.7503709   0.09393875 -1.4534297   0.5084284  -0.2581475   0.11072753\n",
            "  1.4035052   0.10173576 -0.26802996 -0.2895834   0.70822775 -0.33866778\n",
            " -0.9215679   0.92181545 -1.0497291  -0.4286957   0.9014103   1.5455356\n",
            " -0.08711688 -0.48286414 -0.4214867  -0.20667174  0.96826184  0.20953166\n",
            "  0.99164915 -0.28412503  0.94627136 -0.5634814   0.8432515   0.21145186\n",
            " -0.1730661  -0.04924663  0.20830375  0.02235414]\n"
          ]
        }
      ],
      "source": [
        "# Cargamos el modelo guardado\n",
        "new_model = Word2Vec.load('model.bin')\n",
        "\n",
        "# Probamos el nuevo modelo\n",
        "# Imprimimos el vector de la palabra 'energía'\n",
        "print(model.wv['energía'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MOZqC1A3y9HB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1c5502-1c70-417d-c3b7-15184b5ef354"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9616275"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Probamos similitudes\n",
        "new_model.wv.similarity(\"coronavirus\", \"covid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5ZPaD_Fvc2ZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f067ce-29a4-48c2-8df8-3e92ea7eba17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('coronavirus', 0.9616276025772095), ('covid-19', 0.9595453143119812), ('inmunización', 0.897813618183136), ('contagio', 0.8871909976005554), ('vacunación', 0.8726752996444702), ('pfizer', 0.8726686239242554), ('astrazeneca', 0.8609094023704529), ('casos', 0.8549132347106934), ('sars-cov-2', 0.8539988398551941), ('pacientes', 0.851979672908783)]\n",
            "[('producción', 0.9278727173805237), ('eficiencia', 0.9064045548439026), ('inversión', 0.9029995799064636), ('capacidad', 0.9011706709861755), ('electricidad', 0.9000114798545837), ('consecución', 0.8928479552268982), ('mejora', 0.8907243609428406), ('emisiones', 0.8906304836273193), ('carbono', 0.8856784701347351), ('reducir', 0.8841058015823364)]\n"
          ]
        }
      ],
      "source": [
        "# Probamos en listar alguna de las palabras más similares\n",
        "# Imprimimos las palabras más similares a 'covid'\n",
        "palabra = 'covid'\n",
        "print(new_model.wv.most_similar(palabra))\n",
        "\n",
        "# Imprimimos las palabras más similares a 'energía'\n",
        "palabra = 'energía'\n",
        "print(new_model.wv.most_similar(palabra))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EBffwV47-DbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e876d30-8e41-4bf2-db0e-09931db2d8f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('pública', 0.8515499234199524), ('medidas', 0.8274768590927124), ('seguridad', 0.8245885968208313), ('cavaleri', 0.8233178853988647), ('administración', 0.8051121234893799), ('sanidad', 0.803527295589447), ('prevención', 0.7982622981071472), ('ema', 0.797874391078949), ('consejerías', 0.7913883328437805), ('educación', 0.7817356586456299)]\n",
            "[('proactivos', 0.8448898196220398), ('política', 0.8444766998291016), ('importancia', 0.8441581130027771), ('cuestión', 0.839758574962616), ('voluntad', 0.8394683003425598), ('convivencia', 0.8384665250778198), ('democracia', 0.8341692090034485), ('opinión', 0.8326576948165894), ('estrategia', 0.8308067917823792), ('tomar', 0.8279587030410767)]\n"
          ]
        }
      ],
      "source": [
        "# Probamos alguna analogía\n",
        "# Covid es a Vacunas lo que Salud es a ...\n",
        "print(new_model.wv.most_similar(positive=[\"salud\", \"vacunas\"], negative=[\"covid\"], topn=10))\n",
        "\n",
        "# Covid es a Vacunas lo que Guerra es a ...\n",
        "print(new_model.wv.most_similar(positive=[\"guerra\", \"vacunas\"], negative=[\"covid\"], topn=10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CZuk9ucac2ZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbac0598-a696-498a-b245-f73c1289bdd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('coronavirus', 0.9616276025772095), ('covid-19', 0.9595453143119812), ('inmunización', 0.897813618183136), ('contagio', 0.8871909976005554), ('vacunación', 0.8726752996444702), ('pfizer', 0.8726686239242554), ('astrazeneca', 0.8609094023704529), ('casos', 0.8549132347106934), ('sars-cov-2', 0.8539988398551941), ('pacientes', 0.851979672908783)]\n",
            "[('particular', 0.8929041028022766), ('rusia', 0.8905982971191406), ('bruselas', 0.8880709409713745), ('ciudadanía', 0.8839694857597351), ('guerra', 0.8834167122840881), ('violencia', 0.8809518814086914), ('invasión', 0.8753531575202942), ('personal', 0.8731408715248108), ('conflictos', 0.8684223890304565), ('urgente', 0.8645603656768799)]\n"
          ]
        }
      ],
      "source": [
        "# Probamos a mostrar términos similares\n",
        "# Imprimimos las palabras más similares a 'covid'\n",
        "palabra = 'covid'\n",
        "print(new_model.wv.most_similar(palabra))\n",
        "\n",
        "# Imprimimos las palabras más similares a 'ucrania'\n",
        "palabra = 'ucrania'\n",
        "print(new_model.wv.most_similar(palabra))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mca-aFsZIaoH"
      },
      "source": [
        "# Apartado 1.3 Entrenamos un Doc2Vec con los mismos textos\n",
        "\n",
        "El Doc2Vec se puede ver como un tipo de sentence embeddings que traduce todo el texto a un vector de unas dimensiones determinadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yZ8Su_gJIcn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6caf9540-a010-4376-8112-56f17ba916eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "TaggedDocument<['el', 'cambio', 'de', 'ley', 'que', 'permitirá', 'trabajar', 'a', 'los', 'estudiantes', 'extranjeros', ':', '``', 'yo', 'sobrevivía', 'con', '400', 'euros', 'laura', 'rosero', ',', 'inmigrante', 'colombiana', 'de', '25', 'años', ',', 'se', 'trasladó', 'a', 'vivir', 'a', 'madrid', 'hace', 'tres', 'años', 'para', 'realizar', 'un', 'máster', 'en', 'cine', '.', 'la', 'joven', 'había', 'estudiado', 'comunicación', 'social', 'y', 'periodismo', 'en', 'su', 'país', 'y', ',', 'dado', 'que', 'su', 'intención', 'era', 'trabajar', 'en', 'la', 'producción', 'de', 'películas', 'y', 'cortos', ',', 'pensó', 'que', 'mudarse', 'a', 'españa', 'sería', 'un', 'atajo', 'para', 'acceder', 'al', 'mercado', 'laboral', 'y', 'obtener', 'una', 'mejor', '«', 'calidad', 'de', 'vida', '»', '.', 'nada', 'más', 'lejos', 'de', 'la', 'realidad', ',', 'porque', 'cuando', 'se', 'instaló', 'en', 'la', 'capital', ',', 'aunque', 'estaba', 'cómoda', 'y', 'veía', 'cómo', 'gracias', 'al', 'esfuerzo', 'académico', 'había', 'logrado', 'mudarse', 'a', 'europa', ',', 'no', 'tardó', 'en', 'darse', 'cuenta', 'de', 'que', 'no', 'podía', 'mantenerse', 'por', 'sí', 'sola', '.', '«', 'el', 'visado', 'de', 'estudiante', 'no', 'me', 'permitía', 'trabajar', 'con', 'oportunidades', 'más', 'allá', 'de', 'un', 'contrato', 'en', 'prácticas', ',', 'así', 'que', 'sobrevivía', 'con', '400', 'euros', 'de', 'beca', '»', ',', 'explica', '.', 'la', 'joven', 'describe', 'ese', 'año', 'de', 'máster', 'como', 'una', 'época', '«', 'difícil', '»', 'y', 'reconoce', 'que', ',', 'con', 'ese', 'presupuesto', ',', '«', 'no', 'le', 'llegaba', 'para', 'vivir', '»', '.', '«', 'recuerdo', 'que', 'mis', 'compañeros', 'decían', 'de', 'salir', 'a', 'tomar', 'unas', 'copas', 'y', 'a', 'mí', 'solo', 'me', 'sobraban', '40', 'euros', 'al', 'mes', 'para', 'gastármelo', 'en', 'ocio', ',', 'un', 'importe', 'que', 'cualquiera', 'sabe', 'que', 'en', 'una', 'noche', 'se', 'te', 'va', 'en', 'seguida', '»', '.', 'de', 'modo', 'que', ',', 'la', 'mayoría', 'de', 'las', 'veces', ',', 'laura', 'renunciaba', 'a', 'las', 'invitaciones', 'de', 'sus', 'amigos', 'y', 'se', 'quedaba', 'en', 'su', 'piso', 'de', 'puerta', 'del', 'ángel', '.', 'esta', 'dificultad', 'de', 'los', 'inmigrantes', 'estudiantes', 'para', 'trabajar', 'en', 'suelo', 'español', 'desaparecerá', 'a', 'partir', 'del', 'próximo', 'martes', 'con', 'la', 'entrada', 'en', 'vigor', 'de', 'una', 'reforma', 'en', 'la', 'ley', 'de', 'extranjería', '.', 'la', 'modificación', 'del', 'reglamento', 'permitirá', 'a', 'los', 'más', 'de', '50.000', 'estudiantes', 'extranjeros', 'que', 'residen', 'en', 'españa', 'compaginar', 'el', 'estudio', 'con', 'el', 'trabajo', 'siempre', 'y', 'cuando', 'éste', 'no', 'supere', 'las', '30', 'horas', 'semanales', 'y', 'sea', 'compatible', 'con', 'la', 'formación', ',', 'lo', 'que', 'facilitará', 'que', 'puedan', 'hacer', 'frente', 'a', 'sus', 'propios', 'gastos', 'sin', 'ayuda', 'ajena', '.', 'entre', 'sus', 'novedades', ',', 'la', 'ley', 'incluye', 'renovaciones', 'en', 'los', 'arraigos', ',', 'que', 'son', 'los', 'modos', 'de', 'obtener', 'permiso', 'de', 'residencia', 'temporal', 'en', 'españa', '.', 'los', 'cambios', 'en', 'el', 'arraigo', 'laboral', ',', 'en', 'el', 'arraigo', 'social', 'y', 'en', 'el', 'arraigo', 'por', 'formación', 'tendrán', 'la', 'intención', 'de', 'acabar', 'con', 'la', '«', 'desprotección', 'de', 'muchas', 'personas', 'que', 'llevan', 'viviendo', 'mucho', 'tiempo', 'en', 'españa', 'y', 'que', 'siguen', 'en', 'una', 'situación', 'de', 'vulnerabilidad', 'laboral', '»', ',', 'manifestó', 'hace', 'unos', 'días', 'el', 'ministro', 'de', 'inclusión', ',', 'josé', 'luis', 'escrivá', ',', 'cuando', 'fue', 'preguntado', 'por', 'la', 'reforma', '.', 'por', 'arraigo', 'laboral', ',', 'podrán', 'obtener', 'una', 'autorización', 'de', 'residencia', 'temporal', 'los', 'extranjeros', 'que', 'se', 'encuentren', 'en', 'situación', 'irregular', 'y', 'acrediten', 'la', 'permanencia', 'continuada', 'en', 'españa', 'durante', 'un', 'mínimo', 'de', 'dos', 'años', ',', 'siempre', 'que', 'carezcan', 'de', 'antecedentes', 'penales', 'en', 'españa', 'y', 'en', 'su', 'país', 'de', 'origen', 'o', 'en', 'el', 'país', 'o', 'países', 'en', 'que', 'haya', 'residido', 'durante', 'los', 'últimos', 'cinco', 'años', '.', 'deben', 'además', 'demostrar', 'que', 'han', 'trabajado', 'como', 'mínimo', 'una', 'jornada', 'de', '30', 'horas', 'semanales', 'durante', 'seis', 'meses', 'o', 'de', '15', 'horas', 'semanales', 'durante', '12', 'meses', '.', 'mercado', 'de', 'trabajo', 'el', 'decreto', 'ha', 'levantado', 'dudas', 'sobre', 'el', 'efecto', 'llamada', 'que', 'pueda', 'generar', 'su', 'puesta', 'en', 'marcha', ',', 'una', 'teoría', 'que', 'el', 'ministro', 'de', 'inclusión', ',', 'josé', 'luis', 'escrivá', 'ha', 'negado', 'que', 'pueda', 'ocurrir', ',', 'según', 'ha', 'declarado', 'en', 'una', 'reciente', 'entrevista', 'en', 'el', 'país', '.', '«', 'hay', 'numerosos', 'estudios', 'que', 'a', 'lo', 'largo', 'del', 'tiempo', 'han', 'demostrado', 'que', 'los', 'cambios', 'legales', 'en', 'los', 'procesos', 'de', 'migración', 'regular', 'e', 'irregular', 'no', 'parecen', 'ser', 'un', 'foco', 'determinante', '»', 'para', 'animar', 'a', 'las', 'personas', 'a', 'emigrar', ',', 'dijo', '.', 'y', ',', 'en', 'cuanto', 'a', 'la', 'regularización', 'de', 'los', 'sin', 'papeles', ',', 'consideró', 'como', '«', 'errónea', '»', 'la', 'tesis', 'de', 'que', 'este', 'decreto', 'vaya', 'a', 'suponer', 'la', '«', 'sustitución', 'de', 'trabajadores', '»', 'nacionales', 'por', 'extranjeros', 'ya', 'que', 'apuntó', ',', 'lo', 'que', 'hay', 'son', '«', 'déficits', 'en', 'el', 'mercado', 'de', 'trabajo', 'que', 'dificultan', 'el', 'crecimiento', 'general', 'de', 'la', 'economía', '»', '.', 'en', 'el', 'caso', 'de', 'españa', 'la', 'inmigración', 'supone', 'una', 'parte', 'fundamental', 'de', 'la', 'población', '.', 'los', 'datos', 'del', 'padrón', 'del', 'último', 'año', 'reflejan', 'que', 'la', 'llegada', 'de', 'extranjeros', 'mantiene', 'el', 'crecimiento', 'poblacional', '.', 'en', '2021', ',', 'el', 'número', 'de', 'extranjeros', 'aumentó', 'en', '49.612', 'personas', 'hasta', 'sumar', 'un', 'total', 'de', '5.417.883', 'a', '1', 'de', 'enero', 'de', '2022.', 'el', 'incremento', 'se', 'debió', ',', 'en', 'gran', 'parte', 'a', 'un', 'saldo', 'migratorio', 'positivo', 'de', '153.094', 'personas', '.', 'la', 'población', 'de', 'nacionalidad', 'española', 'se', 'redujo', 'en', '15.502', 'personas', '.', '«', 'a', 'mí', 'me', 'hubiese', 'ayudado', 'a', 'prosperar', '»', ',', 'dice', 'laura', 'sobre', 'la', 'nueva', 'reforma', ',', 'que', 'le', 'habría', 'permitido', 'estudiar', 'y', 'trabajar', 'a', 'la', 'vez', '.', '«', 'me', 'habría', 'sido', 'de', 'gran', 'ayuda', '»', '.'], ['0']>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "TaggedDocument<['iron', 'maiden', 'anuncia', 'tres', 'conciertos', 'en', 'españa', 'para', '2023', ':', 'fechas', 'y', 'venta', 'de', 'entradas', 'el', 'grupo', 'británico', 'iron', 'maiden', 'ha', 'anunciado', 'las', 'fechas', 'de', 'su', 'gira', 'mundial', 'the', 'future', 'past', 'tour', '2023', ',', 'que', 'incluirá', 'tres', 'conciertos', 'en', 'españa', '.', 'la', 'banda', 'de', 'heavy', 'metal', 'tocará', 'en', 'barcelona', ',', 'murcia', 'y', 'bilbao', ',', 'según', 'ha', 'desvelado', 'la', 'promotora', 'madness', 'live', 'este', 'jueves', 'en', 'un', 'comunicado', '.', 'así', ',', 'los', 'conciertos', 'de', 'iron', 'maiden', 'en', 'españa', 'serán', 'el', '18', 'de', 'julio', 'de', '2023', 'en', 'el', 'palau', 'sant', 'jordi', 'de', 'barcelona', ';', 'el', '20', 'de', 'julio', ',', 'en', 'el', 'estadio', 'enrique', 'roca', 'de', 'murcia', ';', 'y', 'el', '22', 'de', 'julio', 'en', 'el', 'bizkaia', 'arena', 'de', 'bilbao', '.', 'el', 'comunicado', 'detalla', 'que', 'la', 'banda', 'presentará', 'así', 'su', '``', 'viaje', 'en', 'el', 'tiempo', 'hacia', 'el', 'japón', 'feudal', \"''\", 'que', 'refleja', 'en', 'su', 'último', 'disco', ',', 'senjutsu', \"''\", '(', '2021', ')', '.', 'entradas', 'para', 'los', 'conciertos', 'de', 'iron', 'maiden', 'las', 'entradas', 'para', 'los', 'conciertos', 'de', 'iron', 'maiden', 'saldrán', 'a', 'la', 'venta', 'la', 'próxima', 'semana', 'en', 'la', 'web', 'de', 'madnesslive.es', '.', 'el', 'miércoles', ',', '2', 'de', 'noviembre', ',', 'habrá', 'una', 'preventa', 'de', 'entradas', 'para', 'el', 'fan', 'club', 'a', 'partir', 'de', 'las', '10:00', 'horas', '.', 'mientras', 'que', 'la', 'venta', 'general', 'de', 'entradas', 'se', 'abrirá', 'un', 'día', 'después', ',', 'el', 'jueves', '3', 'de', 'noviembre', 'a', 'las', '10:00', 'horas', '.', 'en', 'cuanto', 'a', 'los', 'precios', 'de', 'las', 'entradas', 'de', 'iron', 'maiden', ',', 'estos', 'irán', 'desde', 'los', '65', 'euros', 'más', 'gastos', 'de', 'gestión', ',', 'según', 'detallan', 'en', 'la', 'propia', 'web', 'de', 'madness', 'live', '.', 'asimismo', ',', 'indican', 'que', 'solo', 'se', 'podrán', 'comprar', 'un', 'máximo', 'de', 'cuatro', 'entradas', 'por', 'usuario', 'en', 'preventa', 'y', 'de', 'seis', 'entradas', 'por', 'usuario', 'en', 'venta', 'general', '.'], ['1']>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "TaggedDocument<['diego', 'rico', ',', 'jugador', 'de', 'la', 'real', 'sociedad', ',', 'denuncia', 'que', 'lleva', 'meses', 'sufriendo', 'acoso', 'en', 'las', 'redes', 'el', 'futbolista', 'de', 'la', 'real', 'sociedad', 'diego', 'rico', 'ha', 'denunciado', 'en', 'su', 'cuenta', 'de', 'instagram', 'que', 'lleva', '``', 'meses', \"''\", 'sufriendo', 'acoso', 'a', 'través', 'de', 'redes', 'sociales', '.', 'así', ',', 'ha', 'colgado', 'un', 'comunicado', 'en', 'el', 'que', 'asegura', 'que', 'ha', 'sufrido', '``', 'difamaciones', \"''\", 'y', 'ataques', 'personales', 'tanto', 'a', 'él', 'como', 'a', 'su', 'familia', 'y', 'su', 'entorno', '.', '``', 'acoso', 'en', 'definitiva', ',', 'a', 'través', 'de', 'diversas', 'redes', 'sociales', \"''\", ',', 'sentencia', '.', 'tal', 'es', 'la', 'situación', 'vivida', 'que', 'asegura', 'que', 'ya', 'ha', 'puesto', 'lo', 'sucedido', 'en', 'manos', 'de', 'las', 'fuerzas', 'de', 'seguridad', 'y', 'ha', 'aprovechado', 'el', 'comunicado', 'para', 'agradecer', 'a', 'la', 'ertzaintza', 'el', 'trato', 'recibido', '.', '``', 'con', 'la', 'ayuda', 'de', 'mis', 'allegados', 'he', 'intentado', 'poner', 'freno', 'a', 'esto', 'y', 'ahora', ',', 'una', 'vezo', 'logrado', 'el', 'objetivo', 'no', 'queriendo', 'desviar', 'la', 'atención', 'de', 'mi', 'profesión', ',', 'he', 'denunciado', 'estos', 'hechos', 'ante', 'las', 'autoridades', 'competentes', \"''\", '.', 'en', 'el', 'comunicado', 'publicado', 'rico', 'insiste', 'en', 'que', '``', 'nadie', 'es', 'merecedor', 'de', 'ser', 'acosado', 'a', 'través', 'de', 'cuentas', 'falsas', 'que', 'se', 'crean', 'expresamente', 'con', 'el', 'motivo', 'de', 'hacer', 'daño', \"''\", '.', 'además', ',', 'asegura', 'haber', 'sufrido', '``', 'acusaciones', 'falsas', 'muy', 'graves', \"''\", 'que', '``', 'no', 'podía', 'permitir', 'más', \"''\", '.'], ['2']>\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Import all the dependencies\n",
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "#Necestiamos crear un TaggedDocument para cada uno de los textos indicando un índice de cada texto\n",
        "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(train_texts)]\n",
        "\n",
        "# Comprobar tokenización:\n",
        "print()\n",
        "print()\n",
        "for td in tagged_data[:3]:\n",
        "  print(td)\n",
        "  print(\"----------\"*10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "su6HsyG7I-UH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1207457-1af2-496a-ba01-5b3578dd6558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved\n"
          ]
        }
      ],
      "source": [
        "# Definimos los parámetros de entrenamiento y entrenamos\n",
        "max_epochs = 5\n",
        "vec_size = 100\n",
        "alpha = 0.025\n",
        "\n",
        "doc2vec_model = Doc2Vec(vector_size=vec_size,\n",
        "                alpha=alpha,\n",
        "                min_alpha=0.00025,\n",
        "                min_count=1,\n",
        "                dm = 1,\n",
        "                epochs = max_epochs)\n",
        "\n",
        "doc2vec_model.build_vocab(tagged_data)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    doc2vec_model.train(tagged_data,\n",
        "                total_examples=doc2vec_model.corpus_count,\n",
        "                epochs=doc2vec_model.epochs)\n",
        "    # decrease the learning rate\n",
        "    doc2vec_model.alpha -= 0.0002\n",
        "    # fix the learning rate, no decay\n",
        "    doc2vec_model.min_alpha = model.alpha\n",
        "\n",
        "doc2vec_model.save(\"d2v.model\")\n",
        "print(\"Model Saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1gBkCLWVJahE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b330558-dd26-4cd9-bc05-45f67661d957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('1058', 0.6124743819236755), ('1422', 0.6007329821586609), ('861', 0.5957950353622437), ('1509', 0.593778669834137), ('1054', 0.590646505355835)]\n",
            "--------------------------\n",
            "Rafa Nadal se retira de la Copa Laver por \"motivos personales\"\n",
            "Rafa Nadal se ha retirado de la Copa Laver, en la que el viernes disputó junto a Roger Federer el partido de dobles, el último de la carrera del suizo, por \"motivos personales\", confirmó la organización del torneo. Según apuntan algunas fuentes, el campeón de 22 majors volará a Mallorca para acompañar a su mujer, con la que espera su primer hijo. En la rueda de prensa posterior a su derrota del viernes ante Jack Sock y Francis Tiafoe, Nadal admitió que no se encontraba en absoluto en su mejor momento. \"No estoy bien. No voy a jugar. Tengo un conflicto interno bastante importante y ahora mismo no os puedo contestar, se me hace difícil. Cuando terminen todos estos momentos de emoción volveré a mi habitación y veré qué es lo que realmente tengo que hacer\", explicó el español. Además, reconoció que había vivido \"semanas difíciles\", con situaciones \"un poco más complicadas de lo habitual en casa\". \"He tenido que lidiar con una presión diferente a la que estás acostumbrado en la vida profesional\", apuntó, haciendo hincapié en las horas de sueño y el estrés. \"Un cúmulo de desgracias\" Probablemente, Nadal no hubiese viajado a Londres si Federer no le hubiera pedido formar el dobles con él en su despedida, donde finalmente cayeron contra la pareja estadounidense (4-6, 7-6 (2), 11-9) tras algo más de dos horas. Durante este partido, el último campeón del Open de Australia y Roland Garros mostró un nivel por debajo de lo acostumbrado. Las molestias físicas, recurrentes durante sus últimas temporadas, han mermado su rendimiento desde que alzó su decimocuarta Copa de los Mosqueteros en París. \"En Roland Garros pensé que quizás fuera mi último torneo y desde ahí todo ha salido muy mal, porque me rompí el abdominal en Wimbledon y Nueva York\", relató Nadal. \"Ha sido un cúmulo de desgracias importantes\", subrayó. Cameron Norrie, campeón del Masters de Indian Wells en 2021, ocupará el sitio de Nadal en el equipo capitaneado por Bjorn Borg. Sin embargo, el británico no pudo cumplir con las expectativas y perdió este sábado en su estreno ante el estadounidense Taylor Fritz (6-1, 4-6, 10-8). De momento, a falta de seis partidos, la igualdad es máxima entre Europa y Resto del Mundo (4-4).\n",
            "Similitud: 0.6124743819236755\n",
            "--------------------------\n",
            "Rafa Nadal, un regreso con posible premio en Cincinnati\n",
            "Será en Cincinnati, una vez aplazado el regreso previsto en Canadá. Esta vez sí está de vuelta Rafael Nadal, que compite de nuevo tras superar plenamente la lesión abdominal que le impidió disputar las semifinales en Wimbledon. El plan no varía demasiado con respecto a sus previsiones. La idea era disputar un torneo antes del comienzo del Abierto de Estados Unidos, el día 29. Ganador en Ohio en 2013, el español no juega este torneo desde hace cuatro años. La tarde del pasado 7 de julio, en vísperas del partido que le debía enfrentar a Nick Kyrgios en la penúltima ronda de Wimbledon, Nadal convocó una rueda de prensa para comunicar que no estaba en condiciones de afrontarlo. El día anterior había sacado adelante el encuentro frente a Taylor Fritz pese a sufrir el desgarro en el comienzo, pero jugar de nuevo con la lesión debilitaba mucho sus opciones, además de poder comprometer el resto de la temporada. En un año nuevamente condicionado por las lesiones, el español presenta una excelente cuenta de resultados. Ha ganado tantos títulos como el que más, tras imponerse en el Abierto de Australia, en Roland Garros, en el ATP 500 de Acapulco y en el ATP 250 de Melbourne, y se encuentra invicto en los majors. Éxitos y padeceres Escribir sobre Nadal en los últimos tiempos, diríase que casi a lo largo de toda su carrera, es hacerlo a través de un relato simultáneo de sus éxitos y sus padeceres, más aún desde que reapareciesen los daños ocasionados por la lesión crónica en el pie izquierdo que logró sofocar tras jugar infiltrado durante las dos semanas de Roland Garros. La secuencia de 2022, dejando a un lado el acertado rodaje en el torneo previo, comienza con el impresionante triunfo en el Abierto de Australia tras levantar una final muy adversa ante Daniil Medvedev, para conquistar su vigesimoprimer grande y quedarse solo en las alturas en la lucha que mantiene con Novak Djokovic y Roger Federer, éste último, lejos de las canchas desde hace más de un año, casi descabalgado ya de la carrera Ha ganado 35 partidos, con sólo tres derrotas: ante Fritz, en la final de Indian Wells, que jugó con una fisura por estrés en el tercer arco del costal izquierdo producida contra Carlos Alcaraz, en las semifinales de ese mismo torneo; frente a Alcaraz, en los cuartos de final del Mutua Madrid Open, torneo donde reapareció tras quedarse cinco semanas en el arcén como consecuencia de los daños acaecidos en el desierto californiano; y contra Denis Shapovalov, en octavos de Roma, debilitado por el síndrome de Müller-Weiss, esa enfermedad degenerativa en el escafoides del pie izquierdo. Ya con 36 años y cerca de su primera paternidad, Nadal sigue bregando con el entusiasmo de su adolescencia, aún con serios empeños por cumplir. El más importante, sabido es, se encuentra en el ahora mano a mano con Djokovic por terminar con más títulos del Grand Slam, litigio en el que cuenta con un título de ventaja después de que el serbio estrechase las distancias al ganar por sexta vez en Wimbledon. Otros desafíos le salen al paso casi sin pretenderlo, como consecuencia de sus magníficos resultados y de las debilidades de sus oponentes. El manacorense tiene ante sí en Cincinnati la posibilidad de encaramarse nuevamente al número 1 del mundo y convertirse en el segundo jugador más veterano que luce el mejor dorsal después de que Federer lo hiciese con 36 años y 320 días el 24 de julio de 2018. Para lograrlo, necesita ganar el torneo y que Medvedev, todavía primero en el escalafón no llegue a cuartos de final. Primera cumbre, hace 14 años Nadal, que hizo cumbre por primera vez el 18 de agosto de 2008, ha estado 209 semanas como número 1, las 13 últimas entre el 4 de noviembre de 2019 y el 3 de febrero de 2020. Como reconocía el propio Medvedev antes del inicio de la gira norteamericana de pista rápida, lo lógico es que Nadal salga de ella en lo más alto. No en vano, además de la amenaza a la que habrá de hacer frente en Cincinnati, en el Abierto de Estados Unidos el ruso defenderá 2.000 puntos como vigente campeón, mientras que su más firme perseguidor parte de cero, dado que hace un año se encontraba lesionado y no disputó ningún torneo en la segunda parte de la temporada. Medvedev tiene 6.885 puntos; Zverev, segundo y aún sin fecha para su reaparición tras romperse los ligamentos del tobillo derecho en las semifinales de Roland Garros, ante Nadal, 6.760; y el español, tercero, 5.620. Nadal debutará este miércoles ante Borna Coric y podría encontrarse con Felix Auger-Aliassime en cuartos y con Alcaraz en semifinales.\n",
            "Similitud: 0.6007329821586609\n",
            "--------------------------\n",
            "Carlos Alcaraz, de Nueva York a la Historia: todos los récords que le acompañan\n",
            "En su frenético despegue a la élite, Carlos Alcaraz ha atravesado la historia. La conquista del US Open convierte al tenista murciano en el número uno del mundo más joven que ha visto el circuito ATP. Alcaraz graba su nombre junto a otros genios precoces, y coge sitio en la historia del tenis español. El número uno más precoz Carlos Alcaraz será desde este lunes el número uno del mundo más joven de la historia del circuito ATP. El murciano alcanzará la cima del tenis masculino con 19 años, cuatro meses y ocho días, superando el récord de precocidad que el australiano Lleyton Hewitt estableció en noviembre de 2001 (20 años, ocho meses y 26 días). Para entender mejor lo fulminante que ha sido este ascenso vale otro dato: Alcaraz tenía de margen hasta finales de enero de 2024 para lograr este récord. El murciano decía en la previa que había soñado con este momento desde que era pequeño, quizá sin caer en la cuenta de que no ha pasado tanto tiempo. Si consigue retenerlo hasta final de temporada, superará también el récord de Hewitt en aquel 2001. El 'grande' más joven desde Nadal Con su victoria en el US Open, Carlos Alcaraz se convierte también en el jugador más joven en conquistar un título de Grand Slam del circuito masculino... Desde Rafa Nadal en 2005. El manacorí subió por primera vez al trono de Roland Garros dos días después de haber cumplido los 19 años. En este apartado, quedaban demasiado lejos los récords de precocidad que lograron en los ochenta Michael Chang, Boris Becker o Mats Wilander, leyendas que conquistaron su primer grande antes de cumplir los 18 años. El US Open más bisoño desde Sampras En la lista de estrellas precoces, Alcaraz es el segundo ganador más joven del US Open, solo superado por Pete Sampras. El californiano ganó el primero de sus cinco títulos con 19 años y 28 días. Fue en la final de 1990, el primer duelo en un gran escenario de su inolvidable rivalidad con Andre Agassi. Sampras fue el penúltimo estadounidense en ganar el US Open masculino. Su quinta corona llegó en 2002, un año antes que Andy Roddick. Desde entonces, una sequía que la próxima temporada alcanzará las dos décadas. Frances Tiafoe era una de las mejores bazas de los últimos tiempos, pero cayó ante Alcaraz en semifinales. 12º español con un título de Grand Slam Carlos Alcaraz es el duodécimo español en ganar un torneo de Grand Slam, el noveno en hacerlo en categoría masculina. En esa lista que presiden los 22 grandes de Rafa Nadal figuran también Manolo Santana, Arantxa Sánchez Vicario (4), Sergi Bruguera, Garbiñe Muguruza (2), y hasta seis tenistas que ganaron uno. Fueron Andrés Gimeno, Manolo Orantes, Conchita Martínez, Carlos Moyá, Albert Costa y el mentor de Alcaraz, Juan Carlos Ferrero. Con el US Open del murciano, el balance total queda en 41 títulos de Grand Slam para el tenis español. Repartido por torneos: 26 en Roland Garros, 8 en el US Open, 5 en Wimbledon y 2 en el Open de Australia. 6º español número uno del mundo Carlos Alcaraz es el sexto tenista español en alcanzar el número uno del mundo, y el cuarto en lograrlo en categoría masculina. Aquí el dominio de Rafa Nadal es todavía más contundente: el mallorquín ha estado en lo más alto del ranking durante 209 semanas, y ha cerrado ahí la temporada en cinco ocasiones (2008, 2010, 2013, 2017, 2019). Alcaraz tiene la oportunidad de ser el segundo español de la historia en cerrar una campaña en ese puesto de honor. Los otros tenistas españoles que alcanzaron lo más alto fueron Juan Carlos Ferrero (ocho semanas) y Carlos Moyá (2) en ATP, y Arantxa Sánchez Vicario (12) y Garbiñe Muguruza (4) en WTA.\n",
            "Similitud: 0.5957950353622437\n",
            "--------------------------\n",
            "Rafa Nadal, un regreso con posible premio en Cincinnati\n",
            "Será en Cincinnati, una vez aplazado el regreso previsto en Canadá. Esta vez sí está de vuelta Rafael Nadal, que compite de nuevo tras superar plenamente la lesión abdominal que le impidió disputar las semifinales en Wimbledon. El plan no varía demasiado con respecto a sus previsiones. La idea era disputar un torneo antes del comienzo del Abierto de Estados Unidos, el día 29. Ganador en Ohio en 2013, el español no juega este torneo desde hace cuatro años. La tarde del pasado 7 de julio, en vísperas del partido que le debía enfrentar a Nick Kyrgios en la penúltima ronda de Wimbledon, Nadal convocó una rueda de prensa para comunicar que no estaba en condiciones de afrontarlo. El día anterior había sacado adelante el encuentro frente a Taylor Fritz pese a sufrir el desgarro en el comienzo, pero jugar de nuevo con la lesión debilitaba mucho sus opciones, además de poder comprometer el resto de la temporada. En un año nuevamente condicionado por las lesiones, el español presenta una excelente cuenta de resultados. Ha ganado tantos títulos como el que más, tras imponerse en el Abierto de Australia, en Roland Garros, en el ATP 500 de Acapulco y en el ATP 250 de Melbourne, y se encuentra invicto en los majors. Éxitos y padeceres Escribir sobre Nadal en los últimos tiempos, diríase que casi a lo largo de toda su carrera, es hacerlo a través de un relato simultáneo de sus éxitos y sus padeceres, más aún desde que reapareciesen los daños ocasionados por la lesión crónica en el pie izquierdo que logró sofocar tras jugar infiltrado durante las dos semanas de Roland Garros. La secuencia de 2022, dejando a un lado el acertado rodaje en el torneo previo, comienza con el impresionante triunfo en el Abierto de Australia tras levantar una final muy adversa ante Daniil Medvedev, para conquistar su vigesimoprimer grande y quedarse solo en las alturas en la lucha que mantiene con Novak Djokovic y Roger Federer, éste último, lejos de las canchas desde hace más de un año, casi descabalgado ya de la carrera Ha ganado 35 partidos, con sólo tres derrotas: ante Fritz, en la final de Indian Wells, que jugó con una fisura por estrés en el tercer arco del costal izquierdo producida contra Carlos Alcaraz, en las semifinales de ese mismo torneo; frente a Alcaraz, en los cuartos de final del Mutua Madrid Open, torneo donde reapareció tras quedarse cinco semanas en el arcén como consecuencia de los daños acaecidos en el desierto californiano; y contra Denis Shapovalov, en octavos de Roma, debilitado por el síndrome de Müller-Weiss, esa enfermedad degenerativa en el escafoides del pie izquierdo. Ya con 36 años y cerca de su primera paternidad, Nadal sigue bregando con el entusiasmo de su adolescencia, aún con serios empeños por cumplir. El más importante, sabido es, se encuentra en el ahora mano a mano con Djokovic por terminar con más títulos del Grand Slam, litigio en el que cuenta con un título de ventaja después de que el serbio estrechase las distancias al ganar por sexta vez en Wimbledon. Otros desafíos le salen al paso casi sin pretenderlo, como consecuencia de sus magníficos resultados y de las debilidades de sus oponentes. El manacorense tiene ante sí en Cincinnati la posibilidad de encaramarse nuevamente al número 1 del mundo y convertirse en el segundo jugador más veterano que luce el mejor dorsal después de que Federer lo hiciese con 36 años y 320 días el 24 de julio de 2018. Para lograrlo, necesita ganar el torneo y que Medvedev, todavía primero en el escalafón no llegue a cuartos de final. Primera cumbre, hace 14 años Nadal, que hizo cumbre por primera vez el 18 de agosto de 2008, ha estado 209 semanas como número 1, las 13 últimas entre el 4 de noviembre de 2019 y el 3 de febrero de 2020. Como reconocía el propio Medvedev antes del inicio de la gira norteamericana de pista rápida, lo lógico es que Nadal salga de ella en lo más alto. No en vano, además de la amenaza a la que habrá de hacer frente en Cincinnati, en el Abierto de Estados Unidos el ruso defenderá 2.000 puntos como vigente campeón, mientras que su más firme perseguidor parte de cero, dado que hace un año se encontraba lesionado y no disputó ningún torneo en la segunda parte de la temporada. Medvedev tiene 6.885 puntos; Zverev, segundo y aún sin fecha para su reaparición tras romperse los ligamentos del tobillo derecho en las semifinales de Roland Garros, ante Nadal, 6.760; y el español, tercero, 5.620. Nadal debutará este miércoles ante Borna Coric y podría encontrarse con Felix Auger-Aliassime en cuartos y con Alcaraz en semifinales.\n",
            "Similitud: 0.593778669834137\n",
            "--------------------------\n",
            "Federer en el arcén, Nadal en la enfermería y Djokovic en el diván\n",
            "Una semana después de cumplir 40 años, Roger Federer anunció que se someterá a su tercera operación de rodilla en los últimos 18 meses y estará un largo tiempo ausente de las pistas. No por esperado, una vez que había renunciado a los Juegos Olímpicos y venía manifestando su inquietud por cómo marchaban las cosas después del grave percance físico que sólo le ha permitido disputar 13 partidos esta temporada, el mensaje no pierde un ápice de su impacto. Estamos ante el prólogo del adiós del ganador de 20 títulos del Grand Slam. Federer tratará de recuperarse lo mejor posible, con las limitaciones propias de su edad, para organizar una despedida acorde con la extraordinaria tarjeta adquirida a lo largo de más de dos décadas jugando al tenis como nadie lo hizo jamás. Más allá de los compromisos publicitarios adquiridos, no quiere que quede como su último partido la derrota sufrida en cuartos de final de Wimbledon ante el polaco Hubert Hurkacz: 6-3, 7-6 (4) y 6-0. Tras su reciente efeméride, que celebró en Ibiza acompañado de su mujer y sus cuatro hijos, Federer concedió algunas entrevistas a medios de su país. En ellas asume con naturalidad que el final está cerca. Dice que cuando deje caer la hoja roja le gustaría ver florecer los árboles de cerezo en Tokio, volver a esquiar y aprender a tocar el saxofón. Su figura se observa ya sólo a la luz de su inmenso legado. \"En el pasado solía mirar a la gente de 40 y me resultaban muy viejos; ahora, de repente, yo también soy uno de ellos\", comentó. La lesión crónica de Nadal Federer desaparece sine die mientras Nadal se enfrenta a momentos inciertos por la lesión en el escafoides del pie izquierdo. Sólo ha disputado dos partidos desde que perdió con Djokovic en las semifinales de Roland Garros y su baja en Toronto y Cincinnati abre bastantes dudas con respecto a su participación en el Abierto de Estados Unidos, que comienza el día 30. No se trata de un percance menor, sino de la dolencia crónica que estuvo a punto de comprometer su carrera profesional hace más de tres lustros. El caso de Nadal no es comparable al de Federer. A los 35, y después de una temporada en la que, aunque sin la autoridad de antaño, ha vuelto a mostrarse competitivo, en particular sobre arcilla, posee mejores argumentos para pelear en esa carrera por sumar el vigesimoprimer major, ya convertida en un cuerpo a cuerpo con Djokovic. El serbio, que sigue siendo favorito para cuadrar en Nueva York los cuatro grandes en un año y subirse así al 21, no ha mantenido el paso marcial con el que caminó hasta alzar la copa en París. Su desafortunado paso por los Juegos le resta crédito. Zverev ganó el oro en Tokio. Medvedev venció en Toronto. El domingo tendremos campeón en Cincinnati. Asoma un US Open abierto.\n",
            "Similitud: 0.590646505355835\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Doc2Vec\n",
        "\n",
        "doc2vec_model= Doc2Vec.load(\"d2v.model\")\n",
        "# Probamos a encontrar textos similares a uno dado\n",
        "query_text = \"nadal\"\n",
        "test_data = word_tokenize(query_text)\n",
        "v1 = doc2vec_model.infer_vector(test_data)\n",
        "\n",
        "# Encontramos los documentos más similares\n",
        "similar_doc = doc2vec_model.dv.most_similar(v1)\n",
        "\n",
        "# Imprimimos los 5 documentos más similares\n",
        "top5_similar_doc = similar_doc[:5]\n",
        "print(top5_similar_doc)\n",
        "for doc in top5_similar_doc:\n",
        "  print(\"--------------------------\")\n",
        "  print(texts[int(doc[0])])\n",
        "  print('Similitud:',doc[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ahora sacar el vector de una frase de ejemplo con el método ```infer_vector``` del modelo Doc2Vec"
      ],
      "metadata": {
        "id": "1dcyz2xqeh9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frase = \"Las vacunas son una muy buena solución para el COVID\"\n",
        "vector = doc2vec_model.infer_vector(word_tokenize(frase))\n",
        "print(vector)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKL1gXOrehd-",
        "outputId": "bab0884c-6e79-4952-d238-c191abb27242"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.09300517  0.13779175 -0.08150215  0.11505105 -0.11832687 -0.03355703\n",
            " -0.03556609  0.21398129 -0.17638782  0.07347623 -0.06622016 -0.03756933\n",
            " -0.11138067  0.12688838  0.13176124 -0.04352955  0.11552393  0.02075611\n",
            " -0.10841041 -0.09238128  0.05245872  0.04062342  0.12578683  0.06922287\n",
            " -0.03091728  0.11775588 -0.15422659 -0.08668992 -0.1423299  -0.16109878\n",
            "  0.14400291  0.05284026  0.15638171  0.02689828  0.02614942 -0.05249069\n",
            "  0.00832978 -0.03303083 -0.01849047 -0.09177777  0.16557693  0.10032246\n",
            " -0.09673145 -0.21017034  0.05269767 -0.0019765  -0.09246822  0.00804257\n",
            "  0.11234571  0.01009793 -0.05100893 -0.07525957 -0.09857091 -0.10605402\n",
            " -0.10660521  0.01688475 -0.00601662  0.02395856 -0.23491445  0.01607885\n",
            "  0.19299448  0.15672156 -0.03395867 -0.07131705 -0.00132948  0.1830033\n",
            " -0.01740997  0.09517356 -0.09897375  0.01730702 -0.03537436 -0.00852644\n",
            "  0.09021304 -0.00680741  0.03315742  0.03579649  0.02518085 -0.03657433\n",
            "  0.00530994 -0.04579997 -0.02677135  0.00473733 -0.03164658  0.15841435\n",
            " -0.06462967  0.01620157 -0.14028563 -0.04716049  0.05091672  0.09372695\n",
            "  0.02427538  0.15220827 -0.10992981 -0.03599865 -0.09472499  0.03038993\n",
            "  0.03636982 -0.2201121   0.12264208  0.01571758]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio a resolver\n",
        "\n",
        "### 1.- Con el nuevo Doc2Vec entrenado para generar sentence embeddings probar cómo funciona la clasificación de los sentence embeddings del conjunto de entrenamiento `dataset_train.csv`y de `dataset_test`.\n",
        "\n",
        "(Si no sabe cómo empezar, veáse apartado 1.8 de práctica 6_1_Word_embeddings ...)"
      ],
      "metadata": {
        "id": "JRUTN8Ayd3k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargamos los datasets en español que hemos usado en otras prácticas\n",
        "!wget -c --no-check-certificate https://valencia.inf.um.es/valencia-plne/dataset_train.csv\n",
        "!wget -c --no-check-certificate https://valencia.inf.um.es/valencia-plne/dataset_test.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7fg2Hq5fgLn",
        "outputId": "fe29fc62-3e0a-4c6e-b0a2-149c4da79f56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-20 21:25:06--  https://valencia.inf.um.es/valencia-plne/dataset_train.csv\n",
            "Resolving valencia.inf.um.es (valencia.inf.um.es)... 155.54.204.133\n",
            "Connecting to valencia.inf.um.es (valencia.inf.um.es)|155.54.204.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1367959 (1.3M) [text/csv]\n",
            "Saving to: ‘dataset_train.csv’\n",
            "\n",
            "dataset_train.csv   100%[===================>]   1.30M  1.88MB/s    in 0.7s    \n",
            "\n",
            "2025-03-20 21:25:07 (1.88 MB/s) - ‘dataset_train.csv’ saved [1367959/1367959]\n",
            "\n",
            "--2025-03-20 21:25:07--  https://valencia.inf.um.es/valencia-plne/dataset_test.csv\n",
            "Resolving valencia.inf.um.es (valencia.inf.um.es)... 155.54.204.133\n",
            "Connecting to valencia.inf.um.es (valencia.inf.um.es)|155.54.204.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 584195 (571K) [text/csv]\n",
            "Saving to: ‘dataset_test.csv’\n",
            "\n",
            "dataset_test.csv    100%[===================>] 570.50K   875KB/s    in 0.7s    \n",
            "\n",
            "2025-03-20 21:25:08 (875 KB/s) - ‘dataset_test.csv’ saved [584195/584195]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "\n",
        "df_train = pandas.read_csv(\"dataset_train.csv\",encoding=\"UTF-8\")\n",
        "df_test = pandas.read_csv(\"dataset_test.csv\",encoding=\"UTF-8\")\n",
        "\n",
        "# Ponemos en lower_case los dos conjuntos de tweets\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "df_train['tweet'] = df_train['tweet'].str.lower()\n",
        "df_test['tweet'] = df_test['tweet'].str.lower()\n",
        "\n",
        "# Generamos los embeddings para los tweets de entrenamiento y prueba\n",
        "train_embeddings = [doc2vec_model.infer_vector(word_tokenize(tweet)) for tweet in df_train['tweet']]\n",
        "test_embeddings = [doc2vec_model.infer_vector(word_tokenize(tweet)) for tweet in df_test['tweet']]\n",
        "\n",
        "# Entrenams un clasificador SVM con los embeddings generados\n",
        "clf = LinearSVC(random_state=0, tol=1e-5)\n",
        "clf.fit(train_embeddings, df_train['label'])\n",
        "\n",
        "# Realizamos predicciones en el conjunto de prueba\n",
        "predict = clf.predict(test_embeddings)\n",
        "\n",
        "# Calculamos y mostramos el rendimiento del modelo\n",
        "accuracy = np.mean(predict == df_test['label'])\n",
        "print(f\"Accuracy = {accuracy:.4f}\")\n",
        "print(\"\\nReporte de clasificación:\\n\")\n",
        "print(classification_report(df_test['label'], predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXHCnXfxe7y_",
        "outputId": "c47efbb1-0255-4276-ba21-804a4278e9f7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.7438\n",
            "\n",
            "Reporte de clasificación:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.67      0.37      0.47       561\n",
            "    positive       0.76      0.92      0.83      1227\n",
            "\n",
            "    accuracy                           0.74      1788\n",
            "   macro avg       0.71      0.64      0.65      1788\n",
            "weighted avg       0.73      0.74      0.72      1788\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.- Entrena ahora otro Doc2Vec ampliando las dimensiones y compara los resultados."
      ],
      "metadata": {
        "id": "0Fxof55ZB1Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero preparamos los datos para el nuevo entrenamiento\n",
        "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str]) for i, doc in enumerate(texts)]\n",
        "\n",
        "#Entrenamos el nuevo Doc2Vec con 300 dimensiones\n",
        "\n",
        "# Definimos los parámetros de entrenamiento y entrenamos\n",
        "max_epochs = 10\n",
        "vec_size = 200\n",
        "alpha = 0.025\n",
        "\n",
        "doc2vec_model = Doc2Vec(vector_size=vec_size,\n",
        "                        alpha=alpha,\n",
        "                        min_alpha=0.00025,\n",
        "                        min_count=1,\n",
        "                        dm = 1,\n",
        "                        epochs = max_epochs)\n",
        "\n",
        "doc2vec_model.build_vocab(tagged_data)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print(f\"Época {epoch+1}\")\n",
        "    doc2vec_model.train(tagged_data,\n",
        "                        total_examples=doc2vec_model.corpus_count,\n",
        "                        epochs=doc2vec_model.epochs)\n",
        "    # Reducimos la tasa de aprendizaje\n",
        "    doc2vec_model.alpha -= 0.0002\n",
        "    # Fijamos la tasa de aprendizaje, sin decaimiento\n",
        "    doc2vec_model.min_alpha = doc2vec_model.alpha\n",
        "\n",
        "# Guardamos el nuevo modelo entrenado\n",
        "doc2vec_model.save(\"d2v_300d.model\")\n",
        "print(\"Hecho ✅\")\n",
        "\n",
        "# Generamos nuevos embeddins para los conjuntos de entrenamiento y prueba\n",
        "train_embeddings = [doc2vec_model.infer_vector(word_tokenize(tweet)) for tweet in df_train['tweet']]\n",
        "test_embeddings = [doc2vec_model.infer_vector(word_tokenize(tweet)) for tweet in df_test['tweet']]\n",
        "\n",
        "# Entrenamos un clasificador SVM con los nuevos embeddins\n",
        "clf_300d = LinearSVC(random_state=0, tol=1e-5)\n",
        "clf_300d.fit(train_embeddings, df_train['label'])\n",
        "\n",
        "# Realizamos predicciones en el conjunto de prueba\n",
        "predict_300d = clf_300d.predict(test_embeddings)\n",
        "\n",
        "# Calculamos y mostramos el rendimiento del modelo\n",
        "accuracy = np.mean(predict_300d == df_test['label'])\n",
        "print(f\"Accuracy = {accuracy:.4f}\")\n",
        "print(\"\\nReporte de clasificación:\\n\")\n",
        "print(classification_report(df_test['label'], predict_300d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAd02BrzgBbA",
        "outputId": "e0c813b7-8c65-474f-88e1-7864d0d675cd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 2\n",
            "Época 3\n",
            "Época 4\n",
            "Época 5\n",
            "Época 6\n",
            "Época 7\n",
            "Época 8\n",
            "Época 9\n",
            "Época 10\n",
            "Hecho ✅\n",
            "Accuracy = 0.7416\n",
            "\n",
            "Reporte de clasificación:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.64      0.40      0.49       561\n",
            "    positive       0.77      0.90      0.83      1227\n",
            "\n",
            "    accuracy                           0.74      1788\n",
            "   macro avg       0.70      0.65      0.66      1788\n",
            "weighted avg       0.73      0.74      0.72      1788\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ha habido una leve empeoramiento en la precisión del modelo después de ampliar las dimensiones:\n",
        "\n",
        "- Primero modelo: `accuracy=0.7438`\n",
        "- Nuevo modelo: `accuracy=0.7416`"
      ],
      "metadata": {
        "id": "N-TL-EmSiBQl"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}