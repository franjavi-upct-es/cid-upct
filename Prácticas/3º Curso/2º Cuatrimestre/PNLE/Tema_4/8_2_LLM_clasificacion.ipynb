{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a6a6d8519bb44dba34e3d43bf4a7faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6becaa43ddb94b82bbb72769ba365915",
              "IPY_MODEL_d6db8f09d13c4c2eb46f216aa2036155",
              "IPY_MODEL_fb647838514c42b0a92bf617405ce7d1"
            ],
            "layout": "IPY_MODEL_0d45cdaa799f46b3a56c2045832b0d3c"
          }
        },
        "6becaa43ddb94b82bbb72769ba365915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a0ef1730eea40db9a8c534ae0bd0d70",
            "placeholder": "​",
            "style": "IPY_MODEL_2b26bc7afbcf432bbf8a32b6d73f3533",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d6db8f09d13c4c2eb46f216aa2036155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea1b8f3f8aa4afcbf7a3d4f490a192e",
            "max": 1156999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_641cef3075e24782a5c7fcfe43e7e00f",
            "value": 1156999
          }
        },
        "fb647838514c42b0a92bf617405ce7d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3681e3817844aebf0f98454e5b0428",
            "placeholder": "​",
            "style": "IPY_MODEL_e444ad6528d846cfa633cb46ef6ac1b0",
            "value": " 1.16M/1.16M [00:00&lt;00:00, 9.29MB/s]"
          }
        },
        "0d45cdaa799f46b3a56c2045832b0d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a0ef1730eea40db9a8c534ae0bd0d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b26bc7afbcf432bbf8a32b6d73f3533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ea1b8f3f8aa4afcbf7a3d4f490a192e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641cef3075e24782a5c7fcfe43e7e00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a3681e3817844aebf0f98454e5b0428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e444ad6528d846cfa633cb46ef6ac1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bdde0e507564796ad8b59ac6fa9c41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6339e01a0764594b7587ff4d7c1fe56",
              "IPY_MODEL_593693757dca46afa5f10a6b677d0dbe",
              "IPY_MODEL_3f60a27a2752432d8024d3896340a204"
            ],
            "layout": "IPY_MODEL_c246b8eafc57493491b146c1a088a686"
          }
        },
        "d6339e01a0764594b7587ff4d7c1fe56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77dea793df5848029d7761abd65ff3e9",
            "placeholder": "​",
            "style": "IPY_MODEL_8f2a8a4f801347a388a1768694e0135f",
            "value": "tokenizer.model: 100%"
          }
        },
        "593693757dca46afa5f10a6b677d0dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8970e56985f34ae2961d638594fcc543",
            "max": 4689074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23dc13edf3c94376a1e076d01f3ac258",
            "value": 4689074
          }
        },
        "3f60a27a2752432d8024d3896340a204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16720b592afe4628aa44d07e1c11a492",
            "placeholder": "​",
            "style": "IPY_MODEL_4945ab7f118d4ee89a48f9ed48adbafc",
            "value": " 4.69M/4.69M [00:00&lt;00:00, 56.0MB/s]"
          }
        },
        "c246b8eafc57493491b146c1a088a686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77dea793df5848029d7761abd65ff3e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2a8a4f801347a388a1768694e0135f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8970e56985f34ae2961d638594fcc543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23dc13edf3c94376a1e076d01f3ac258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16720b592afe4628aa44d07e1c11a492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4945ab7f118d4ee89a48f9ed48adbafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4654e191920450a9e024e757658fdb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e531bd7f29f14371ae5a3edc13b60184",
              "IPY_MODEL_8d423945bd5b4932986b7d490cbf138b",
              "IPY_MODEL_def67ef4d8944a1a9093b1887aa37601"
            ],
            "layout": "IPY_MODEL_731f46a1b231441a9fc4a100cc47831f"
          }
        },
        "e531bd7f29f14371ae5a3edc13b60184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f4646c84c2f4b74baeaa2d2461ab032",
            "placeholder": "​",
            "style": "IPY_MODEL_3b1f7774f3424f6f94b2245d020fb8ac",
            "value": "tokenizer.json: 100%"
          }
        },
        "8d423945bd5b4932986b7d490cbf138b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28ea924bb61844a38c021f8e203867c4",
            "max": 33384568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_467b4085bf0a4f65b5efe4c3132f8020",
            "value": 33384568
          }
        },
        "def67ef4d8944a1a9093b1887aa37601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88f528cfd8fc4dcebc25903dfeb287fc",
            "placeholder": "​",
            "style": "IPY_MODEL_5b44bee6ecf143668e4d5e400bb0c7b3",
            "value": " 33.4M/33.4M [00:00&lt;00:00, 133MB/s]"
          }
        },
        "731f46a1b231441a9fc4a100cc47831f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f4646c84c2f4b74baeaa2d2461ab032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b1f7774f3424f6f94b2245d020fb8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28ea924bb61844a38c021f8e203867c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "467b4085bf0a4f65b5efe4c3132f8020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88f528cfd8fc4dcebc25903dfeb287fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b44bee6ecf143668e4d5e400bb0c7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b97cea2894b4480489bcba2f634c7488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb8ea3c81f504605b954a8e16256e6e4",
              "IPY_MODEL_44fd1921b7fd4b3ab87764f9edac9e53",
              "IPY_MODEL_eb666f5176394f0c89ea40719063a159"
            ],
            "layout": "IPY_MODEL_8de36e678c7b40ec9cc1552e7b68cbe5"
          }
        },
        "bb8ea3c81f504605b954a8e16256e6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_702eec5607704da885009832cbccc1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_182dd452e5ec4fc7a0d133ce77693ec7",
            "value": "added_tokens.json: 100%"
          }
        },
        "44fd1921b7fd4b3ab87764f9edac9e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40e73b5102454d4ca058f7e69b487318",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d8eb408ea784a7d87ab0ec83b080961",
            "value": 35
          }
        },
        "eb666f5176394f0c89ea40719063a159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df449836efd4f41bdeb760638f41cf3",
            "placeholder": "​",
            "style": "IPY_MODEL_08aa4c3477be4ab1b3a775dcfb71c60d",
            "value": " 35.0/35.0 [00:00&lt;00:00, 1.74kB/s]"
          }
        },
        "8de36e678c7b40ec9cc1552e7b68cbe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "702eec5607704da885009832cbccc1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "182dd452e5ec4fc7a0d133ce77693ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40e73b5102454d4ca058f7e69b487318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d8eb408ea784a7d87ab0ec83b080961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4df449836efd4f41bdeb760638f41cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08aa4c3477be4ab1b3a775dcfb71c60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73a80ee583d4418a997444973f7df5f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d153167cb12640738a40e31f9bff2627",
              "IPY_MODEL_500ad76a27f54470a14a30d8c2f6f64d",
              "IPY_MODEL_9a42af923fc240519e586a394fa324fa"
            ],
            "layout": "IPY_MODEL_a3567df176f344f299af3e3288557060"
          }
        },
        "d153167cb12640738a40e31f9bff2627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_395dfc2a11e34fea8c760b5c5908157e",
            "placeholder": "​",
            "style": "IPY_MODEL_e166dd98b6194d35abef240a3a105b37",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "500ad76a27f54470a14a30d8c2f6f64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f243e9fc7d54ef0b8088be1fe6113bd",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfd19a7352474dcb926a5facb7334c95",
            "value": 662
          }
        },
        "9a42af923fc240519e586a394fa324fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd61cf1980fa4732b788d83ba94b31f9",
            "placeholder": "​",
            "style": "IPY_MODEL_638191116f924d33982ba4a0563d8443",
            "value": " 662/662 [00:00&lt;00:00, 55.2kB/s]"
          }
        },
        "a3567df176f344f299af3e3288557060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "395dfc2a11e34fea8c760b5c5908157e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e166dd98b6194d35abef240a3a105b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f243e9fc7d54ef0b8088be1fe6113bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfd19a7352474dcb926a5facb7334c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd61cf1980fa4732b788d83ba94b31f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "638191116f924d33982ba4a0563d8443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "447438488e5c437884bcbb9d049e7f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_921d15bf42344c7ea500d8cfa6327e1b",
              "IPY_MODEL_581ee2dccf2941539916ec67a04e6755",
              "IPY_MODEL_1ead169da8154ee3836c15cb347dd6ed"
            ],
            "layout": "IPY_MODEL_7d2c525a2e7949698bbb82fe5cd9c3a8"
          }
        },
        "921d15bf42344c7ea500d8cfa6327e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92396b112ed437fbf4697c679998329",
            "placeholder": "​",
            "style": "IPY_MODEL_f2ddf6eda5b84c17af6b4b01c50e9436",
            "value": "config.json: 100%"
          }
        },
        "581ee2dccf2941539916ec67a04e6755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_882aaaf630384e2aadfed07e6c72e9b5",
            "max": 899,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52b3fe5c73e04efab05c14bb658ed734",
            "value": 899
          }
        },
        "1ead169da8154ee3836c15cb347dd6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e133fb8e73b4e7c86f17311652f2acc",
            "placeholder": "​",
            "style": "IPY_MODEL_04f7aaf278cc4fff8eca61555fded871",
            "value": " 899/899 [00:00&lt;00:00, 2.02kB/s]"
          }
        },
        "7d2c525a2e7949698bbb82fe5cd9c3a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92396b112ed437fbf4697c679998329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ddf6eda5b84c17af6b4b01c50e9436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "882aaaf630384e2aadfed07e6c72e9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b3fe5c73e04efab05c14bb658ed734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e133fb8e73b4e7c86f17311652f2acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04f7aaf278cc4fff8eca61555fded871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8199cb600c3d4ea99414feaba5c06906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cba249c1e1d4225845d19c79f004669",
              "IPY_MODEL_622eba335f38482ab0dca460744d10bb",
              "IPY_MODEL_c6beed4e1e624a57aea556a08a283ef5"
            ],
            "layout": "IPY_MODEL_866cfdfeffde4a5d828e01903d9f8e02"
          }
        },
        "2cba249c1e1d4225845d19c79f004669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45df5ad542f4417db73690493ca3349b",
            "placeholder": "​",
            "style": "IPY_MODEL_1c1bcaa3b8e9477bac1e2af9a65c9550",
            "value": "model.safetensors: 100%"
          }
        },
        "622eba335f38482ab0dca460744d10bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd3f5f769223454c98b277eef45aecd3",
            "max": 1999811208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdd8f2dfeed34219ae896a433273bab0",
            "value": 1999811208
          }
        },
        "c6beed4e1e624a57aea556a08a283ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_569ef554e24a4634a0df016b6e064b86",
            "placeholder": "​",
            "style": "IPY_MODEL_317c540cad054a6fa0447a09a6989944",
            "value": " 2.00G/2.00G [00:32&lt;00:00, 134MB/s]"
          }
        },
        "866cfdfeffde4a5d828e01903d9f8e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45df5ad542f4417db73690493ca3349b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1bcaa3b8e9477bac1e2af9a65c9550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd3f5f769223454c98b277eef45aecd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd8f2dfeed34219ae896a433273bab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "569ef554e24a4634a0df016b6e064b86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317c540cad054a6fa0447a09a6989944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31f28e840967439e933d355b091ed427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcb686ee12c847f1ad8ebbb075533eca",
              "IPY_MODEL_ed3f0029480b40eabe8b2517a20fc40a",
              "IPY_MODEL_c5b3eb7993c243368515f873f47df05a"
            ],
            "layout": "IPY_MODEL_b7b45b382bed405d84da19bc4670fd38"
          }
        },
        "fcb686ee12c847f1ad8ebbb075533eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b8c67cda7d34a85b8a340dad40bb61c",
            "placeholder": "​",
            "style": "IPY_MODEL_22e4fbc6997e4d3f8580afde3ecd8389",
            "value": "generation_config.json: 100%"
          }
        },
        "ed3f0029480b40eabe8b2517a20fc40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37f81f95470a47dcb3f500439b0b98ea",
            "max": 215,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97b3dd63418b472b8f205b4ad21ac424",
            "value": 215
          }
        },
        "c5b3eb7993c243368515f873f47df05a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644314512adf4f239762039a93cfce90",
            "placeholder": "​",
            "style": "IPY_MODEL_96fbe1b2ad15420889c204deb3f3fe05",
            "value": " 215/215 [00:00&lt;00:00, 9.01kB/s]"
          }
        },
        "b7b45b382bed405d84da19bc4670fd38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b8c67cda7d34a85b8a340dad40bb61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e4fbc6997e4d3f8580afde3ecd8389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37f81f95470a47dcb3f500439b0b98ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97b3dd63418b472b8f205b4ad21ac424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "644314512adf4f239762039a93cfce90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96fbe1b2ad15420889c204deb3f3fe05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sesión 8 - Demostración de la capacidad In-Context Learning de los LLMs para clasificación de textos\n",
        "\n",
        "En el boletín anterior hemos visto cómo los LLMs pueden realizar una tarea de resumen de texto sin necesidad de haber sido entrenados específicamente para ello gracias al **In-Context Learning**. En este boletín vamos a generalizar este enfoque para realizar diferentes tareas de clasificación de textos.\n",
        "\n",
        "Para ello, vamos a utilizar unos modelos que han sido entrenados en tareas de Natural Language Inference (NLI), que se adaptan especialmente bien a través de las diferentes técnicas de In-Context Learning a un amplio rango de nuevas tareas.\n",
        "\n",
        "Con todo ello, en esta sesión:\n",
        "1. Instalamos las librerías necesaria y descargamos tanto los modelos a utilizar como los conjuntos de datos sobre los que trabajar.\n",
        "\n",
        "2. Utilizamos Zero-Shot learning:\n",
        "   - Para realizar diversas tareas de clasificación de textos, (1) a través del pipeline de la librería transformers y (2) de forma manual.\n",
        "   - Para realizar análisis de sentimientos.\n",
        "   - ídem con plantillas.\n",
        "\n",
        "3. Utilizamos Few-Shot learning:\n",
        "   - Para realizar diversas tareas de clasificación de textos, (1) a través del pipeline de la librería transformers y (2) de forma manual.\n",
        "   - Para experimentar con diferentes números de ejemplos en el prompt.\n",
        "\n",
        "4. Utilizamos Chain of thouht:\n",
        "   - Para realizar diversas tareas de clasificación de textos, (1) a través del pipeline de la librería transformers y (2) de forma manual.\n",
        "   - Para RESOLVER UN EJERCICIO de clasificación de texto con el dataset proporcionado.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EBI88_u6nxxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero, instalaremos las librerias necesarias y descargamos el dataset_test que se usará más adelante.."
      ],
      "metadata": {
        "id": "aJ1D1hE2kmrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos las librerías necesarias\n",
        "!pip install transformers huggingface_hub bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENu_zpw7e_a6",
        "outputId": "819b8655-30c8-43f0-cb24-200bd5e0f8fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsFb69O_neOX",
        "outputId": "e3c2eb59-b4cc-4282-fc2e-3be0252276dd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-09 15:43:18--  https://valencia.inf.um.es/valencia-plne/dataset_test.csv\n",
            "Resolving valencia.inf.um.es (valencia.inf.um.es)... 155.54.204.133\n",
            "Connecting to valencia.inf.um.es (valencia.inf.um.es)|155.54.204.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Descarga desde repositorio UMU\n",
        "!wget -c --no-check-certificate https://valencia.inf.um.es/valencia-plne/dataset_test.csv\n",
        "data_dir_path = \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga en local:\n",
        "# Ejecutar solo para accesos desde drive\n",
        "from google.colab import drive\n",
        "g_drive_path = \"/content/drive\"\n",
        "drive.mount(g_drive_path)\n",
        "\n",
        "# Directorio Drive Domus\n",
        "# data_dir_path = \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29sWDGLZfHPP",
        "outputId": "032184fd-3ff2-4864-9b71-be36c8f0ee85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apartado 1 - Zero-Shot Learning\n"
      ],
      "metadata": {
        "id": "WIECFB85q09g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzamos explorando **la forma más sencilla** de In-Context Learning: el **Zero-Shot Learning**. En esta estrategia, usamos un modelo para resolver una tarea sin proporcionarle ejemplos previos, en el prompt le damos únicamente una lista de instrucciones con las que el modelo generará una respuesta basándose en el conocimiento adquirido durante su entrenamiento previo."
      ],
      "metadata": {
        "id": "_r9IBaz8IiA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apartado 1.1 - Zero-Shot Learning mediante pipeline"
      ],
      "metadata": {
        "id": "8vYUFD6rnIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzaremos usando un `pipeline` de la `librería Transformers` de Hugging Face. Los pipelines permiten crear modelos para tareas específicas con solo unas líneas de código.\n",
        "\n",
        "En el pipeline especificaremos la tarea que vamos a realizar, en este caso, Zero-Shot Classification, y el modelo pre-entrenado que vamos a utlizar. Para Zero-Shot-Classification existen modelos válidos optimizados listados en:\n",
        "- https://huggingface.co/models?other=zero-shot-classification\n",
        "- https://huggingface.co/models?language=es&other=zero-shot-classification&sort=trending (español y multilingües)"
      ],
      "metadata": {
        "id": "2SSIkHQ9IlUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La mayoría de los modelos usados para zero-shot classification han sido entrenados en tareas de **Natural Language Inference (NLI)**. En este tipo de tareas, el modelo recibe dos textos:\n",
        "\n",
        "- **Premisa**: un hecho o situación dada.\n",
        "- **Hipótesis**: una afirmación cuya veracidad debe evaluar el modelo en función de la premisa.\n",
        "\n",
        "El objetivo del modelo es clasificar la relación entre ambos textos en una de las siguientes categorías:\n",
        "\n",
        "- **Entailment (Implicación)**: Dada la premisa, se infiere que la hipótesis es verdadera.\n",
        "- **Neutral**: Dada la premisa, la hipótesis podría ser verdadera.\n",
        "- **Contradiction (Contradicción)**: La hipótesis contradice la premisa. Es imposible que dada la premisa la hipotesis sea cierta.\n",
        "\n",
        "Por ejemplo:\n",
        "- Premisa: El hombre está preparando la cena.\n",
        "- Hipótesis: El hombre esta cocinando.\n",
        "- Clasificación esperada: Entailment, ya que si el hombre esta preparando la cena se puede inferir que está cocinando (no al revés, ya que de que esté cocinando no se sigue necesariamente que esté preparando la cena, la clasificación esperada sería neutral).\n",
        "\n",
        "No obstante, en los modelos estadísticos las cosas no son tan claras, porque no se utiliza inferencia lógica formal y por tanto los términos de premisa, hipótesis e inferencia no se usan de la misma manera que en la lógica formal simbólica. Los modelos de lenguaje estadísticos (como los basados en transformers) aprenden patrones de co-ocurrencia y relaciones semánticas implícitas y a partir de ellos calculan la probabilidad de que entre dos textos haya implicación, contradicción o neutralidad.\n",
        "\n",
        "Para una explicación más detallada sobre inferencia en lenguaje natural, puedes consultar [este recurso](https://nlpprogress.com/english/natural_language_inference.html)."
      ],
      "metadata": {
        "id": "TGAV3ljdptha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos el pipeline de la librería transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "# Definimos el path al modelo que vamos a usar\n",
        "model_path = 'MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7'\n",
        "\n",
        "# Creamos el clasificador, definiendo la tarea ZSC (Zero-Shot-Classification)\n",
        "classifier = pipeline('zero-shot-classification', model = model_path)\n",
        "\n",
        "# Al crear el pipeline se puede indicar, opcionalmente, el parámetro device\n",
        "# para hacer uso de la GPU (device = 0 si solo se dispone de una GPU).\n",
        "# El modelo solo se va a utilizar para inferencia, donde el uso de una GPU\n",
        "# no es tan necesario como en el fine-tuning."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORq97t4toM8X",
        "outputId": "12780124-bd72-44b1-f136-8192af019456"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez configurado el pipeline, podemos utilizar el modelo para **clasificar textos en función de una lista de etiquetas predefinidas**.\n",
        "\n",
        "El **resultado** devuelto por el modelo serán las **probabilidades asociadas a cada posible etiqueta**. Si trabajamos en un escenario de clasificación exclusiva (cada texto solo pertenece a una categoría), la suma de las probilidades debe ser 1 (100%). También podemos usar el modelo en modo multi-etiqueta, lo que permite asignar varias categorías a un mismo texto.\n",
        "\n",
        "Internamente, el pipeline transforma esta tarea en un problema de NLI. El modelo, en lugar de tratar el problema como una clasificación, evalúa en qué medida (probabilidad) cada etiqueta se relaciona con el texto de entrada (entailment, neutral, contradiction). En los ejemplos que siguen estaremos interesadso en la probabilidad que el modelo otorga a 'entailment'."
      ],
      "metadata": {
        "id": "grCrJ8kGomiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con todo ello, usaremos el pipeline para los siguientes tipos de clasificación:\n",
        "\n",
        "- **Detección de tópicos**: Identificar de qué trata un texto.\n",
        "- **Análisis de emociones**: Determinar la emoción expresada en el mensaje.\n",
        "- **Detección de intención**: Inferir la intención del usuario en un mensaje.\n",
        "\n",
        "Cada una de estas tareas se resolverá pasando un texto y una lista de etiquetas al modelo, que asignará probabilidades a cada una de ellas."
      ],
      "metadata": {
        "id": "z6_GPg9Ew2fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_tasks = [\n",
        "    {\n",
        "        'title': 'clasificación de opiniones',\n",
        "        'text': 'El servicio en este restaurante fue increíble, definitivamente volveré.',\n",
        "        'labels': ['positivo', 'negativo', 'neutral']\n",
        "    },\n",
        "    {\n",
        "        'title': 'análisis de emociones',\n",
        "        'text': 'No puedo creer que me haya pasado esto. Todo es un desastre',\n",
        "        'labels': ['alegría', 'disgusto', 'ira', 'miedo', 'otro', 'sorpresa', 'tristeza']\n",
        "    },\n",
        "    {\n",
        "        'title': 'detección de intención',\n",
        "        'text': 'Quiero devolver un producto porque llegó dañado',\n",
        "        'labels': ['elogio', 'pregunta', 'queja', 'solicitud']\n",
        "    }\n",
        "]\n",
        "\n",
        "# Más ejemplos\n",
        "# No me ha gustado nada la atención recibida por los camareros.\n",
        "# Qué suerte tengo, me ha tocado la loteria contigo.\n",
        "# ¿Es normal que mi frigorífico me de la corriente cuando lo intento abrir?"
      ],
      "metadata": {
        "id": "7_ZJ8JYKoDxt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerias necesarias\n",
        "import json\n",
        "\n",
        "# Esta variable almacenará la respuesta del modelo\n",
        "response = []\n",
        "\n",
        "# Para cada tarea definida\n",
        "for task in labeled_tasks:\n",
        "\n",
        "  # Obtenemos la respuesta del modelo\n",
        "  scores = classifier(task['text'], task['labels'])\n",
        "\n",
        "  # Guardamos la respuesta obtenida\n",
        "  response.append({\n",
        "     'task': task['title'],\n",
        "     'text': task['text'],\n",
        "     'scores': dict(zip(scores['labels'], scores['scores']))\n",
        "  })\n",
        "\n",
        "# Mostramos la respuesta del modelo\n",
        "print(json.dumps(response, indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtbRAz2ToELn",
        "outputId": "b0bca1e9-92e6-479c-d30e-55b4cee6af41"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"task\": \"clasificación de opiniones\",\n",
            "        \"text\": \"El servicio en este restaurante fue increíble, definitivamente volveré.\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.8544603586196899,\n",
            "            \"neutral\": 0.134955033659935,\n",
            "            \"negativo\": 0.01058459933847189\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"task\": \"análisis de emociones\",\n",
            "        \"text\": \"No puedo creer que me haya pasado esto. Todo es un desastre\",\n",
            "        \"scores\": {\n",
            "            \"disgusto\": 0.3257310688495636,\n",
            "            \"tristeza\": 0.2903386354446411,\n",
            "            \"sorpresa\": 0.14868924021720886,\n",
            "            \"miedo\": 0.09137936681509018,\n",
            "            \"ira\": 0.07350143045186996,\n",
            "            \"otro\": 0.04553481191396713,\n",
            "            \"alegría\": 0.024825429543852806\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"task\": \"detección de intención\",\n",
            "        \"text\": \"Quiero devolver un producto porque llegó dañado\",\n",
            "        \"scores\": {\n",
            "            \"solicitud\": 0.7473142147064209,\n",
            "            \"pregunta\": 0.1655227541923523,\n",
            "            \"queja\": 0.08159509301185608,\n",
            "            \"elogio\": 0.005567928310483694\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observación: Modelos que requieren un token:\n",
        "\n",
        "Algunos modelos requieren la autenticación o la aceptación de ciertos términos y condiciones antes de poder usarlos. Para que el modelo reconozca que se dispone de los permisos necesarios al iniciar el pipeline hay que utilizar un token de autenticación de Hugging Face.\n",
        "\n",
        "Por ejemplo:\n",
        "```\n",
        "new_pipe = pipeline('zero-shot-classification', token = my_auth_token, model = model_that_requires_token_path)\n",
        "```\n",
        "\n",
        "Una vez registrado en HUgging Face, los tokens de autenticación se generan en [esta página](https://huggingface.co/settings/tokens). Este token permite verificar si se han aceptado los términos del modelo o si se necesita solicitar acceso.\n",
        "\n",
        "Por ejemplo, puedes repetir el ejercicio anterior utilizando Gemma de Google con el modelo:\n",
        "```\n",
        "model_that_requires_token_path = 'google/gemma-2-2b-it'\n",
        "```\n",
        "Pero recuerda que para ello habrá que registrarse/iniciar sesión en Hugging Face y aceptar los términos y condiciones del modelo para obtener el permiso de utilización del mismo. Una vez obtenido este permiso, habrá que generar un token y  añadirlo como parámetro para crear el pipeline."
      ],
      "metadata": {
        "id": "q5FXJWlny1Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apartado 1.2 - Zero-Shot Learning de forma manual"
      ],
      "metadata": {
        "id": "CfkeC-UfyGcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta subsección veremos cómo aplicar Zero-Shot Learning sin depender del pipeline de transformers, lo que nos dará mayor flexibilidad y control sobre el proceso.\n",
        "\n",
        "El flujo general consiste en los siguientes pasos:\n",
        "\n",
        "1.   Carga del modelo de clasificación y de su tokenizador (usaremos un modelo previamente entrenado en NLI).\n",
        "2.   Tokenización y procesamiento del texto con el modelo para convertirlo en una representación numérica que el modelo pueda interpretar.\n",
        "3.   Predicción: se aplica la función softmax para calcular la probabilidad de pertenencia del texto a cada una de las etiquetas.\n",
        "4.   Evaluación: se calcula la probabilidad de que la premisa (texto) implique la hipótesis (cada una de las etiquetas), lo que nos permitirá clasificar correctamente el texto."
      ],
      "metadata": {
        "id": "duOQiSScIrlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerias necesarias\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Definimos el path al modelo que vamos a usar (el mismo que antes)\n",
        "model_path = 'MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7'\n",
        "\n",
        "# Cargamos el tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Cargamos el modelo,\n",
        "# recordad que este modelo ha sido preentenado para la tarea de NLI\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Esta variable almacenará la respuesta del modelo\n",
        "response = []"
      ],
      "metadata": {
        "id": "VjBM22Qi4-I4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j-sEGxLUtDTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definimos una función para reutilizar el mismo código con diferentes formulaciones de la hipótesis."
      ],
      "metadata": {
        "id": "YIr3OT1gtFH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entailment_logits(labeled_tasks = labeled_tasks,\n",
        "                          hypothesis_template = 'El texto trata sobre ',\n",
        "                          model = model,\n",
        "                          tokenizer = tokenizer):\n",
        "\n",
        "  response = []\n",
        "\n",
        "  # Para cada tarea definida\n",
        "  for task in labeled_tasks:\n",
        "\n",
        "     # Transformamos los textos en formato de premisa e hipótesis\n",
        "     premises = [task['text']] * len(task['labels'])\n",
        "     hypotheses = [f\"{hypothesis_template}{label}.\" for label in task['labels']]\n",
        "\n",
        "     # Tokenizamos tanto las premisas como las hipótesis\n",
        "     inputs = tokenizer(premises, hypotheses,\n",
        "                     return_tensors = \"pt\", padding = True, truncation = True)\n",
        "\n",
        "     # Pasamos las premisas e hipótesis tokenizadas al modelo\n",
        "     outputs = model(**inputs)\n",
        "\n",
        "     # Obtenemos los logits del modelo\n",
        "     # Estos son los valores de la última capa de nuestro modelo, es decir,\n",
        "     # las probabilidades de entailment, neutral y contradiction\n",
        "     logits = outputs.logits\n",
        "\n",
        "     # Sin embargo, esto son valores en crudo.\n",
        "     # Vamos a usar softmax para normalizarlos, haciendo que su suma sea 1\n",
        "     # (probabilidades excluyentes)\n",
        "     probs = torch.softmax(logits, dim = 1)\n",
        "\n",
        "     # Al estar trabajando en NLI, la salida del modelo incluye varias columnas,\n",
        "     # como entailment, neutral y contradiction.\n",
        "     # Nos interesa quedarnos con la columna que contenga la clase \"entailment\",\n",
        "     # es decir, la columna que indica la probabilidad de que la premisa (texto)\n",
        "     # implique la hipotesis (cada etiqueta).\n",
        "     # No todos los modelos lo almacenan en la misma columna.\n",
        "     # Esto puede consultarse en la documentación del modelo en Hugging Face\n",
        "     entailment_probs = probs[:, 0]\n",
        "\n",
        "     # Normalizamos las probabilidades obtenidas con get_label_logits\n",
        "     # Este paso es necesario para que la suma del entailment de todas las\n",
        "     # etiquetas sea 1\n",
        "     normalized_probs = entailment_probs / entailment_probs.sum()\n",
        "\n",
        "     # Asociamos cada etiqueta con su probabilidad\n",
        "     label_probs = {label: prob.item() for label, prob\n",
        "                                          in zip(task['labels'],\n",
        "                                                 normalized_probs)}\n",
        "\n",
        "     # Ordenamos la salida de mayor a menor según la probabilidad\n",
        "     label_probs = dict(sorted(label_probs.items(),\n",
        "                              key = lambda item: item[1],\n",
        "                              reverse = True))\n",
        "\n",
        "     # Guardamos la respuesta obtenida\n",
        "     response.append({\n",
        "            'task': task['title'],\n",
        "            'text': task['text'],\n",
        "            'scores': label_probs\n",
        "    })\n",
        "  return response\n",
        "\n"
      ],
      "metadata": {
        "id": "3Z4BBWWn5SMo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vemos qué salida produce el modelo para cada una de las tareas.\n",
        "\n",
        "Observe que la forma en qué se formula la hipótesis (parámetro hypothesis_template) afecta directamente al resultado final. Vamos a probar con dos formatos de hipótesis y a comparar los resultados (pueden probar con otras fórmulas):\n",
        "\n",
        "```\n",
        "El texto trata sobre {label}.\n",
        "```\n",
        "\n",
        "```\n",
        "El texto es de {label}.\n",
        "```"
      ],
      "metadata": {
        "id": "WvbByYHt0WoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_entailment_logits(hypothesis_template = 'El texto trata sobre ')\n",
        "print(json.dumps(response, indent = 4, sort_keys = False, ensure_ascii = False))\n",
        "print(\"-------------------------------------\"*3)\n",
        "response = get_entailment_logits(hypothesis_template = 'El texto es de ')\n",
        "print(json.dumps(response, indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "23-XGNChz-B3",
        "outputId": "05f53208-3c66-49b0-e193-1bf0386780e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"task\": \"clasificación de opiniones\",\n",
            "        \"text\": \"El servicio en este restaurante fue increíble, definitivamente volveré.\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.5861138701438904,\n",
            "            \"neutral\": 0.29765430092811584,\n",
            "            \"negativo\": 0.11623183637857437\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"task\": \"análisis de emociones\",\n",
            "        \"text\": \"No puedo creer que me haya pasado esto. Todo es un desastre\",\n",
            "        \"scores\": {\n",
            "            \"sorpresa\": 0.37130987644195557,\n",
            "            \"disgusto\": 0.29799437522888184,\n",
            "            \"otro\": 0.28879478573799133,\n",
            "            \"tristeza\": 0.020510932430624962,\n",
            "            \"ira\": 0.013441214337944984,\n",
            "            \"miedo\": 0.007135125808417797,\n",
            "            \"alegría\": 0.0008136545075103641\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"task\": \"detección de intención\",\n",
            "        \"text\": \"Quiero devolver un producto porque llegó dañado\",\n",
            "        \"scores\": {\n",
            "            \"pregunta\": 0.38689514994621277,\n",
            "            \"solicitud\": 0.37523195147514343,\n",
            "            \"queja\": 0.23672913014888763,\n",
            "            \"elogio\": 0.0011437325738370419\n",
            "        }\n",
            "    }\n",
            "]\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "[\n",
            "    {\n",
            "        \"task\": \"clasificación de opiniones\",\n",
            "        \"text\": \"El servicio en este restaurante fue increíble, definitivamente volveré.\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.5104537606239319,\n",
            "            \"neutral\": 0.46727126836776733,\n",
            "            \"negativo\": 0.02227499894797802\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"task\": \"análisis de emociones\",\n",
            "        \"text\": \"No puedo creer que me haya pasado esto. Todo es un desastre\",\n",
            "        \"scores\": {\n",
            "            \"disgusto\": 0.34431061148643494,\n",
            "            \"sorpresa\": 0.3274167776107788,\n",
            "            \"tristeza\": 0.14462582767009735,\n",
            "            \"ira\": 0.10123954713344574,\n",
            "            \"miedo\": 0.0426257848739624,\n",
            "            \"alegría\": 0.026983091607689857,\n",
            "            \"otro\": 0.01279840711504221\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"task\": \"detección de intención\",\n",
            "        \"text\": \"Quiero devolver un producto porque llegó dañado\",\n",
            "        \"scores\": {\n",
            "            \"solicitud\": 0.5300973057746887,\n",
            "            \"pregunta\": 0.3727163076400757,\n",
            "            \"queja\": 0.09420802444219589,\n",
            "            \"elogio\": 0.0029784066136926413\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a comparar los resultados para la primera tarea de las dos transformaciones:"
      ],
      "metadata": {
        "id": "9HAKbAPE7LdX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apartado 1.3 - Análisis de sentimientos mediante Zero-Shot Learning\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8fYAnshaq_eJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasta ahora hemos explorado Zero-Shot Classification en diversas tareas generales.\n",
        "\n",
        "En esta subsección, nos centraremos en analizar cómo se comporta el modelo específicamente para la tarea de análisis de sentimientos. Es importante tener en cuenta que el modelo no ha sido entrenado directamente para esta tarea ni ha sido sometido a ningún fine-tuning, por lo que evaluaremos su rendimiento en un contexto completamente nuevo para él."
      ],
      "metadata": {
        "id": "ucajdw7sIump"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un par de textos\n",
        "sentiment_sentences = [\n",
        "  \"Esta película me pareció maravillosa\",\n",
        "  \"La película me pareció muy mala\",\n",
        "  \"Viendo esa película me aburrí como una ostra\"\n",
        "]\n",
        "\n",
        "# Definimos las posibles etiquetas\n",
        "sentiment_labels = ['neutral', 'negativo', 'positivo']"
      ],
      "metadata": {
        "id": "hkW4WtGmqJ7u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta variable almacenará la respuesta del modelo\n",
        "response = []\n",
        "\n",
        "# Para cada texto a clasificar\n",
        "for sentence in sentiment_sentences:\n",
        "\n",
        "  # Obtenemos la respuesta del modelo\n",
        "  scores = classifier(sentence, sentiment_labels)\n",
        "\n",
        "  # Guardamos la respuesta obtenida\n",
        "  response.append({\n",
        "     'text': sentence,\n",
        "     'scores': dict(zip(scores['labels'], scores['scores']))\n",
        "  })\n",
        "\n",
        "# Mostramos la respuesta del modelo\n",
        "print(json.dumps(response, indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I-zusxR_N7W",
        "outputId": "71630b51-6bd5-4c5e-a919-de02131db918",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"Esta película me pareció maravillosa\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.9540171027183533,\n",
            "            \"neutral\": 0.039515502750873566,\n",
            "            \"negativo\": 0.006467350292950869\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"La película me pareció muy mala\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.9580336809158325,\n",
            "            \"neutral\": 0.03393789753317833,\n",
            "            \"positivo\": 0.008028417825698853\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"Viendo esa película me aburrí como una ostra\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.8699044585227966,\n",
            "            \"neutral\": 0.08870945125818253,\n",
            "            \"positivo\": 0.04138613119721413\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También podemos hacer un análisis de sentimientos solamente positivo y negativo como era el caso del dataset de tuits de la pandemia que hemos utilizado en prácticas anteriores \"dataset_test.csv\" que ya hemos descargado en la primera celda."
      ],
      "metadata": {
        "id": "d_QEPZRH_2qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerias necesarias\n",
        "import pandas as pd\n",
        "\n",
        "# Leemos los datos descargados (correspondientes a un conjunto de tweets recopilados durante la pandemia)\n",
        "data = pd.read_csv(data_dir_path + \"dataset_test.csv\",encoding=\"UTF-8\")\n",
        "data.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ofiZ6LA3Y2ed",
        "outputId": "af973cff-587d-436a-959f-7700e18f1f22",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               twitter_id   twitter_created_at  \\\n",
              "1783  1259620549594095618  2020-05-11 03:05:16   \n",
              "1784  1262709390890749952  2020-05-19 15:39:13   \n",
              "1785  1260914933182726144  2020-05-14 16:48:41   \n",
              "1786  1264152028244213761  2020-05-23 15:11:44   \n",
              "1787  1247511128445456384  2020-04-07 15:06:45   \n",
              "\n",
              "                                                  tweet  \\\n",
              "1783  la calle ruge contra pedro sánchez. brutal cac...   \n",
              "1784  el gobierno sopesa volver a pedir 15 días de #...   \n",
              "1785  a mal tiempo, buena cara. y los productos más ...   \n",
              "1786  no ganaréis con cacerolas lo que las urnas vot...   \n",
              "1787  ? #españa #covidー19 . ⏩ @interiorgob, detenido...   \n",
              "\n",
              "                                   corpus            user  agreement  votes  \\\n",
              "1783  Estado de alarma nacional (oficial)     demorganica        100      1   \n",
              "1784  Estado de alarma nacional (oficial)  lavozdegalicia        100      1   \n",
              "1785  Estado de alarma nacional (oficial)      frutasmaxi        100      1   \n",
              "1786  Estado de alarma nacional (oficial)        becurios        100      1   \n",
              "1787  Estado de alarma nacional (oficial)      ElCadisimo        100      1   \n",
              "\n",
              "      score     label __split  \n",
              "1783     -1  negative    test  \n",
              "1784     -1  negative   train  \n",
              "1785      1  positive    test  \n",
              "1786     -1  negative   train  \n",
              "1787     -1  negative   train  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35944712-b9d5-4e28-bd7e-2ecac513965c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>twitter_id</th>\n",
              "      <th>twitter_created_at</th>\n",
              "      <th>tweet</th>\n",
              "      <th>corpus</th>\n",
              "      <th>user</th>\n",
              "      <th>agreement</th>\n",
              "      <th>votes</th>\n",
              "      <th>score</th>\n",
              "      <th>label</th>\n",
              "      <th>__split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1783</th>\n",
              "      <td>1259620549594095618</td>\n",
              "      <td>2020-05-11 03:05:16</td>\n",
              "      <td>la calle ruge contra pedro sánchez. brutal cac...</td>\n",
              "      <td>Estado de alarma nacional (oficial)</td>\n",
              "      <td>demorganica</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>1262709390890749952</td>\n",
              "      <td>2020-05-19 15:39:13</td>\n",
              "      <td>el gobierno sopesa volver a pedir 15 días de #...</td>\n",
              "      <td>Estado de alarma nacional (oficial)</td>\n",
              "      <td>lavozdegalicia</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1785</th>\n",
              "      <td>1260914933182726144</td>\n",
              "      <td>2020-05-14 16:48:41</td>\n",
              "      <td>a mal tiempo, buena cara. y los productos más ...</td>\n",
              "      <td>Estado de alarma nacional (oficial)</td>\n",
              "      <td>frutasmaxi</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1786</th>\n",
              "      <td>1264152028244213761</td>\n",
              "      <td>2020-05-23 15:11:44</td>\n",
              "      <td>no ganaréis con cacerolas lo que las urnas vot...</td>\n",
              "      <td>Estado de alarma nacional (oficial)</td>\n",
              "      <td>becurios</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1787</th>\n",
              "      <td>1247511128445456384</td>\n",
              "      <td>2020-04-07 15:06:45</td>\n",
              "      <td>? #españa #covidー19 . ⏩ @interiorgob, detenido...</td>\n",
              "      <td>Estado de alarma nacional (oficial)</td>\n",
              "      <td>ElCadisimo</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35944712-b9d5-4e28-bd7e-2ecac513965c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35944712-b9d5-4e28-bd7e-2ecac513965c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35944712-b9d5-4e28-bd7e-2ecac513965c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c848bcd2-a931-46ab-97cf-dc7d07fc3fa4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c848bcd2-a931-46ab-97cf-dc7d07fc3fa4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c848bcd2-a931-46ab-97cf-dc7d07fc3fa4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutamos el zero shot learning para algunos de los tuits y observamos el resultado."
      ],
      "metadata": {
        "id": "tFFJifiagjw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta variable almacenará la respuesta del modelo\n",
        "response = []\n",
        "\n",
        "# Definimos que las etiquetas de este dataset solamente son dos\n",
        "sentiment_test_labels = ['positivo', 'negativo']\n",
        "\n",
        "# Obtenemos unos pocos tweets\n",
        "tweets_to_classify = data.head()['tweet']\n",
        "\n",
        "# Para cada tweet a clasificar\n",
        "for sentence in tweets_to_classify:\n",
        "\n",
        "  # Obtenemos la respuesta del modelo\n",
        "  scores = classifier(sentence, sentiment_test_labels)\n",
        "\n",
        "  # Guardamos la respuesta obtenida\n",
        "  response.append({\n",
        "     'text': sentence,\n",
        "     'scores': dict(zip(scores['labels'], scores['scores']))\n",
        "  })\n",
        "\n",
        "# Mostramos la respuesta del modelo\n",
        "print(json.dumps(response, indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY-w6HsP_5w7",
        "outputId": "b63314d1-af60-4faf-bd6f-7d14eff90ca9",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"hoy me ha tocado samu y hemos tenido 4 avisos de pacientes con sospecha de covid. al terminar uno de ellos y hacer la desinfección los vecinos nos aplaudieron. parece una tontería, pero el equipo se vino arriba. #gracias #quedateencasa\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.8452410101890564,\n",
            "            \"positivo\": 0.1547590047121048\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"buenisimos dias!!! que seria la vida sin un toque de locura??? feliz semana a tod@s!!! #undiamasundiamenos #yomequedoencasa #unpocodelocura #estavidatedevuelveloquetuledas #acuerdatedevivir #seguimosadelante…\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.6119665503501892,\n",
            "            \"negativo\": 0.3880334198474884\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"bryan adams back to you vía @albertovegalocutor @kissfm_es (#meencanta!! gracias por #lamúsica y por la compañía de #tuvoz, alberto... y por tu alegría. one kissssssssssssssssssssss #quédateencasa #stayathome\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.9378734827041626,\n",
            "            \"negativo\": 0.06212650239467621\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"esta #semanasanta2020 no pero queda mucho año todavía para disfrutar... #guadalajarateespera #quedateencasa #volveremosaviajar #lamaletarural #nosalgandecasa gracias @hacemosguada @celestinogutirr @asoturguada @ehtguada @sierranortegu\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.7622244358062744,\n",
            "            \"negativo\": 0.23777557909488678\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"??está activado el #estadodealarma . ⛔️no son vacaciones ⛔️. . la pasada semana en #servicioshumanitarios agentes acudían al centro de salud a recoger el parte de baja de una vecina imposibilitada para hacerlo físicamente. #covidー19. #quédateencasa\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.7766955494880676,\n",
            "            \"positivo\": 0.22330449521541595\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apartado 1.4 - Otras estrategías de prompting para Zero-Shot Learning\n"
      ],
      "metadata": {
        "id": "CYpIvLsk-iEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta subsección, exploraremos un enfoque alternativo para aplicar ZSL mediante *prompt engineering*, manteniendo la idea de NLI.\n",
        "\n",
        "Por ejemplo, en una tarea de análisis de emociones, podemos comprobar si el texto proporcionado por el usuario se relaciona con una premisa predefinida.\n",
        "\n",
        "Una forma de estructurar este tipo de prompt es utilizando plantillas específicas. Por ejemplo, en un análisis de emociones, podríamos emplear la siguiente plantilla:\n",
        "```\n",
        "Dime si {} es un texto [positivo|negativo|neutro]\n",
        "```\n",
        "\n",
        "De esta manera, el modelo debe determinar a qué emoción se refiere el texto proporcionado. Por defecto, si no especificamos una plantilla personalizada, el modelo utilizará una estructura más genérica como:\n",
        "```\n",
        "Este es un ejemplo de {} [positivo|negativo|neutro]\n",
        "```"
      ],
      "metadata": {
        "id": "OVGoSbOQI18K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un conjunto de premisas sencillo con su respectiva emoción\n",
        "premises = {\n",
        "    'positivo': 'Dime si {} es un texto positivo.',\n",
        "    'negativo': 'Dime si {} es un texto negativo.',\n",
        "    'neutro': 'Dime si {} es un texto neutro.'\n",
        "}\n",
        "\n",
        "# Definimos las etiquetas que le asignaremos a cada posibilidad\n",
        "hypotheses_labels = ['sí', 'no']\n",
        "\n",
        "# Esta variable almacenará la respuesta del modelo\n",
        "response = []\n",
        "\n",
        "# Para cada tweet a clasificar\n",
        "for tweet in tweets_to_classify:\n",
        "\n",
        "  # Para cada premisa junto a su respectiva emoción\n",
        "  for emotion, premise in premises.items():\n",
        "\n",
        "    # Obtenemos la respuesta del modelo, indicando la plantilla a usar\n",
        "    scores = classifier(tweet, hypotheses_labels, hypothesis_template = premise)\n",
        "\n",
        "    # Guardamos la respuesta obtenida\n",
        "    response.append({\n",
        "      'text': tweet,\n",
        "      'emotion': emotion,\n",
        "      'scores': dict(zip(scores['labels'], scores['scores']))\n",
        "    })\n",
        "\n",
        "# Mostramos la respuesta del modelo para el primer tweet\n",
        "print(json.dumps(response[0:3], indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtVXjkses38w",
        "outputId": "8d8c79d6-9202-4ef7-ebab-86bcb5659b3b",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"hoy me ha tocado samu y hemos tenido 4 avisos de pacientes con sospecha de covid. al terminar uno de ellos y hacer la desinfección los vecinos nos aplaudieron. parece una tontería, pero el equipo se vino arriba. #gracias #quedateencasa\",\n",
            "        \"emotion\": \"positivo\",\n",
            "        \"scores\": {\n",
            "            \"no\": 0.7142413258552551,\n",
            "            \"sí\": 0.2857586741447449\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"hoy me ha tocado samu y hemos tenido 4 avisos de pacientes con sospecha de covid. al terminar uno de ellos y hacer la desinfección los vecinos nos aplaudieron. parece una tontería, pero el equipo se vino arriba. #gracias #quedateencasa\",\n",
            "        \"emotion\": \"negativo\",\n",
            "        \"scores\": {\n",
            "            \"no\": 0.67364102602005,\n",
            "            \"sí\": 0.32635894417762756\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"hoy me ha tocado samu y hemos tenido 4 avisos de pacientes con sospecha de covid. al terminar uno de ellos y hacer la desinfección los vecinos nos aplaudieron. parece una tontería, pero el equipo se vino arriba. #gracias #quedateencasa\",\n",
            "        \"emotion\": \"neutro\",\n",
            "        \"scores\": {\n",
            "            \"sí\": 0.5619259476661682,\n",
            "            \"no\": 0.4380740225315094\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apartado 2 - Few-shot learning\n",
        "\n"
      ],
      "metadata": {
        "id": "y2lb_eHqZswA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seguimos con otra forma de realizar In-Context Learning: el **Few-Shot Learning**. En esta estrategia, incluimos en el prompt algunos ejemplos para guiar al modelo en la tarea específica. Estos ejemplos ayudan al modelo a entender mejor el patrón de la tarea, generando como consecuencia una respuesta más precisa."
      ],
      "metadata": {
        "id": "0KcOrrv0I4Dz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apartado 2.1 - Few-Shot Learning mediante pipeline"
      ],
      "metadata": {
        "id": "8xgcCCHsEnol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a crear un nuevo clasificador para aplicar esta técnica utilizando un pipeline de Hugginface. En el pipeline seguiremos identificando la tarea como `zero-shot-classification` (son las convenciones de la librería).\n",
        "\n",
        "La diferencia estará en el uso del modelo, específicamente en la estructura y el contenido del prompt: mientras que en Zero-Shot solo proporcionábamos instrucciones, en Few-Shot incluimos ejemplos para guiar al modelo."
      ],
      "metadata": {
        "id": "c4gbSSHVI8tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos el pipeline de la librería transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "# Definimos el modelo que vamos a usar\n",
        "model_path = 'MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7'\n",
        "\n",
        "# Creamos el clasificador, definiendo la tarea ZSC (Zero-Shot-Classification)\n",
        "classifier = pipeline('zero-shot-classification', model = model_path)\n",
        "\n",
        "# Al crear el pipeline se puede indicar, opcionalmente, el parámetro device\n",
        "# para hacer uso de la GPU (device = 0 si solo tienes una GPU).\n",
        "# El modelo solo se va a utilizar para inferencia, donde el uso de una GPU\n",
        "# no es tan necesario como en el fine-tuning."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-DLpFr5FL1t",
        "outputId": "25e728c1-becc-4240-86bf-1afc364e1e20"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, vamos a ajustar nuestro prompt para incorporar algunos ejemplos que ayuden al modelo a entender cómo abordar la tarea antes de aplicar la clasificación.\n",
        "\n",
        "Vamos a resolver la tarea de clasificación de sentimientos."
      ],
      "metadata": {
        "id": "LQzuGGehFVQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un par de ejemplos para incluirlos en el prompt\n",
        "# Los ejemplos deben estar relacionados con la tarea a resolver\n",
        "few_shot_examples = \"\"\"\n",
        "Ejemplo 1: Desde la semana pasada no me lo pasaba tan bien -> positivo\n",
        "Ejemplo 2: A tí la película te gustó, pero a mí no -> neutro\n",
        "Ejemplo 3: No recomiendo este lugar, fue una experiencia horrible -> negativo\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"{few_shot_examples}\\nTexto: AQUI IRÍA EL TEXTO A CLASIFICAR\\n->\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrQYynhJZsTY",
        "outputId": "065cafc8-4101-4348-d68c-1a49037234fc",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ejemplo 1: Desde la semana pasada no me lo pasaba tan bien -> positivo\n",
            "Ejemplo 2: A tí la película te gustó, pero a mí no -> neutro\n",
            "Ejemplo 3: No recomiendo este lugar, fue una experiencia horrible -> negativo\n",
            "\n",
            "Texto: AQUI IRÍA EL TEXTO A CLASIFICAR\n",
            "->\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedemos a clasificar un par de textos mediante Few-Shot Learning:"
      ],
      "metadata": {
        "id": "9nhRcXrzLona"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un par de textos\n",
        "sentiment_sentences = [\n",
        "  \"Esta película me pareció maravillosa\",\n",
        "  \"La película me pareció muy mala\",\n",
        "  \"Viendo esa película me aburrí como una ostra\"\n",
        "]\n",
        "\n",
        "# Definimos las etiquetas a clasificar\n",
        "sentiment_labels = [\"positivo\", \"negativo\", \"neutro\"]\n",
        "\n",
        "# Esta variable almacenará la respuesta del modelo\n",
        "response = []\n",
        "\n",
        "# Para cada texto a clasificar\n",
        "for sentence in sentiment_sentences:\n",
        "\n",
        "  # Creamos el prompt incluyendo los ejemplos\n",
        "  prompt = f\"{few_shot_examples}\\nTexto: {sentence}\\n->\"\n",
        "\n",
        "  # Obtenemos la respuesta del modelo\n",
        "  scores = classifier(prompt, sentiment_labels)\n",
        "\n",
        "  # Guardamos la respuesta obtenida\n",
        "  response.append({\n",
        "     'text': sentence,\n",
        "     'scores': dict(zip(scores['labels'], scores['scores']))\n",
        "  })\n",
        "\n",
        "# Mostramos la respuesta del modelo para el primer tweet\n",
        "print(json.dumps(response, indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouj5QGeWLFsX",
        "outputId": "81bb9c3e-5bcf-4004-80f0-97df94c51ad8",
        "collapsed": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"Esta película me pareció maravillosa\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.9271534085273743,\n",
            "            \"negativo\": 0.04307776689529419,\n",
            "            \"neutro\": 0.029768794775009155\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"La película me pareció muy mala\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.7044071555137634,\n",
            "            \"positivo\": 0.18568246066570282,\n",
            "            \"neutro\": 0.10991037636995316\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"Viendo esa película me aburrí como una ostra\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.5896128416061401,\n",
            "            \"negativo\": 0.35761716961860657,\n",
            "            \"neutro\": 0.052770037204027176\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apartado 2.2 - Few-Shot Learning de forma manual"
      ],
      "metadata": {
        "id": "33DnR19FJDm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta subsección veremos cómo aplicar Few-Shot Learning sin depender del pipeline de transformers, lo que nos dará mayor flexibilidad y control sobre el proceso.\n",
        "\n",
        "Al igual que antes, el flujo general consiste en los siguientes pasos:\n",
        "\n",
        "1.   Cargar el modelo de clasificación y su tokenizador.\n",
        "2.   Tokenizar el texto y procesarlo con el modelo.\n",
        "3.   Predicción.\n",
        "4.   Evaluación."
      ],
      "metadata": {
        "id": "nxpE2uyuJOWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos las etiquetas a clasificar\n",
        "sentiment_labels = [\"positivo\", \"negativo\", \"neutro\"]\n",
        "\n",
        "# Textos a clasificar\n",
        "sentiment_sentences = [\n",
        "  \"Esta película me pareció maravillosa\",\n",
        "  \"La película me pareció muy mala\",\n",
        "  \"Viendo esa película me aburrí como una ostra\"\n",
        "]\n",
        "\n",
        "# Definimos un par de ejemplos para incluirlos en el prompt\n",
        "# Los ejemplos deben estar relacionados con la tarea a resolver\n",
        "few_shot_examples = \"\"\"\n",
        "Ejemplo 1: Desde la semana pasada no me lo pasaba tan bien -> positivo\n",
        "Ejemplo 2: A tí la película te gustó, pero a mí no -> neutro\n",
        "Ejemplo 3: No recomiendo este lugar, fue una experiencia horrible -> negativo\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yqe1Q3KCN2jH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerias necesarias\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Definimos el modelo que vamos a usar\n",
        "model_path = 'MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7'\n",
        "\n",
        "# Cargamos el tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Cargamos el modelo, recordad que este modelo ha sido preentenado para la tarea de NLI\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Esta variable almacenará la respuesta del modelo\n",
        "response = []\n",
        "\n",
        "# Para cada texto a clasificar\n",
        "for premise in sentiment_sentences:\n",
        "\n",
        "  # Concatenamos los ejemplos con el texto de entrada\n",
        "  prompt = f\"{few_shot_examples}\\nTexto: {premise}\\n->\"\n",
        "\n",
        "  # Transformamos los textos en formato de premisa e hipótesis\n",
        "  premise_prompts = [prompt] * len(sentiment_labels)\n",
        "  hypotheses = [label for label in sentiment_labels]\n",
        "\n",
        "  # Tokenizamos tanto las premisas como las hipótesis\n",
        "  inputs = tokenizer(premise_prompts, hypotheses, return_tensors = \"pt\", padding = True, truncation = True)\n",
        "\n",
        "  # Pasamos las premisas e hipótesis tokenizadas al modelo\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "  # Obtenemos los logits del modelo\n",
        "  # Estos son los valores de la última capa de nuestro modelo, es decir,\n",
        "  # las probabilidades de entailment, neutral y contradiction\n",
        "  logits = outputs.logits\n",
        "\n",
        "  # Sin embargo, esto son valores en crudo\n",
        "  # Vamos a usar softmax para normalizarlos,\n",
        "  # haciendo que su suma sea 1 (probabilidades excluyentes)\n",
        "  probs = torch.softmax(logits, dim = 1)\n",
        "\n",
        "  # Al estar trabajando en NLI, la salida del modelo incluye varias columnas,\n",
        "  # como entailment, neutral y contradiction\n",
        "  # Nos interesa quedarnos con la columna que contenga la clase \"entailment\",\n",
        "  # es decir, la columna que indica la probabilidad de que la premisa (texto)\n",
        "  # implique la hipotesis (cada etiqueta).\n",
        "  # No todos los modelos lo almacenan en la misma columna.\n",
        "  # Esto puede consultarse en la documentación del modelo en Hugging Face\n",
        "  entailment_probs = probs[:, 0]\n",
        "\n",
        "  # Vamos a realizar un paso adicional para normalizar las probabilidades\n",
        "  # Este paso es necesario para que la suma del entailment de todas las etiquetas sea 1\n",
        "  normalized_probs = entailment_probs / entailment_probs.sum()\n",
        "\n",
        "  # Asociamos cada etiqueta con su probabilidad\n",
        "  label_probs = {label: prob.item() for label, prob in zip(sentiment_labels, normalized_probs)}\n",
        "\n",
        "  # Ordenamos la salida de mayor a menor según la probabilidad\n",
        "  label_probs = dict(sorted(label_probs.items(), key = lambda item: item[1], reverse = True))\n",
        "\n",
        "  # Guardamos la respuesta obtenida\n",
        "  response.append({\n",
        "     'text': premise,\n",
        "     'scores': label_probs\n",
        "  })\n",
        "\n",
        "# Mostramos la respuesta del modelo\n",
        "print(json.dumps(response, indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP8wF6cKMWFH",
        "outputId": "18927c59-d823-4e13-f035-88ee7f273d14",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"Esta película me pareció maravillosa\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.9696201086044312,\n",
            "            \"neutro\": 0.017630496993660927,\n",
            "            \"negativo\": 0.012749424204230309\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"La película me pareció muy mala\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.9505153298377991,\n",
            "            \"neutro\": 0.036793969571590424,\n",
            "            \"positivo\": 0.012690737843513489\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"Viendo esa película me aburrí como una ostra\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.7935903668403625,\n",
            "            \"neutro\": 0.10997354984283447,\n",
            "            \"positivo\": 0.09643608331680298\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apartado 2.3 - La importancia del número de ejemplos para el Few-Shot Learning"
      ],
      "metadata": {
        "id": "zjSojdSkJHrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uno de los factores más importantes que influye en el rendimiento de un modelo en el contexto del Few-Shot Learning es el **número de ejemplos** proporcionados en el prompt.\n",
        "\n",
        "La cantidad de ejemplos, también conocida como *shots*, tiene un **impacto directo en la precisión y la robustez** de las predicciones del modelo."
      ],
      "metadata": {
        "id": "8zAqnvPkU6zu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Few-Shot Learning con un número reducido de ejemplos"
      ],
      "metadata": {
        "id": "X7I7uQXDVQCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando se utilizan **pocos ejemplos**, el modelo debe confiar en **patrones generales** y en su **capacidad de generalización** para hacer predicciones correctas.\n",
        "\n",
        "Sin embargo, el uso de un número de ejemplos muy limitado puede llevar a que el modelo no tenga suficiente información para entender correctamente la tarea a resolver y, por lo tanto, generar predicciones menos precisas."
      ],
      "metadata": {
        "id": "E2KRPbRNVUL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a definir una función que realice la clasificación de un par de textos mediante Few-Shot Learning dados unos ejemplos.\n",
        "\n",
        "Esta función nos permitirá tener un codigo más limpio.\n"
      ],
      "metadata": {
        "id": "sxeh7Ay3W1q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot_classification(few_shot_examples):\n",
        "\n",
        "  # Definimos un par de textos\n",
        "  sentiment_sentences = [\n",
        "    \"Esta película me pareció maravillosa, la volvería a ver mil veces\",\n",
        "    \"La película me ha parecido horrible, no tiene sentido ninguno\",\n",
        "    \"Viendo esa película me aburrí como una ostra, casi me quedo durmiendo\"\n",
        "  ]\n",
        "\n",
        "  # Definimos las etiquetas a clasificar\n",
        "  sentiment_labels = [\"positivo\", \"negativo\", \"neutro\"]\n",
        "\n",
        "  # Esta variable almacenará la respuesta del modelo\n",
        "  response = []\n",
        "\n",
        "  # Para cada texto a clasificar\n",
        "  for sentence in sentiment_sentences:\n",
        "\n",
        "    # Creamos el prompt incluyendo los ejemplos\n",
        "    prompt = f\"{few_shot_examples}\\nTexto: {sentence}\\n->\"\n",
        "\n",
        "    # Obtenemos la respuesta del modelo\n",
        "    scores = classifier(prompt, sentiment_labels)\n",
        "\n",
        "    # Guardamos la respuesta obtenida\n",
        "    response.append({\n",
        "      'text': sentence,\n",
        "      'scores': dict(zip(scores['labels'], scores['scores']))\n",
        "    })\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "EwxnxwCnWnlg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver como se comporta el modelo si solo le damos **un ejemplo**:"
      ],
      "metadata": {
        "id": "SIHqGVPHXZgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un par de ejemplos para incluirlos en el prompt\n",
        "few_shot_examples = \"\"\"\n",
        "Ejemplo 1: Nunca me lo había pasado tan bien en el cine -> positivo\n",
        "\"\"\"\n",
        "\n",
        "# Mostramos la respuesta del modelo para el primer tweet\n",
        "print(json.dumps(few_shot_classification(few_shot_examples), indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPNB9YrTUzwD",
        "outputId": "810ce7db-340f-4198-c089-a70768d0d295",
        "collapsed": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"Esta película me pareció maravillosa, la volvería a ver mil veces\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.9945264458656311,\n",
            "            \"neutro\": 0.003248434979468584,\n",
            "            \"negativo\": 0.0022251533810049295\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"La película me ha parecido horrible, no tiene sentido ninguno\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.9180679321289062,\n",
            "            \"neutro\": 0.04705479368567467,\n",
            "            \"negativo\": 0.034877240657806396\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"Viendo esa película me aburrí como una ostra, casi me quedo durmiendo\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.9897716045379639,\n",
            "            \"neutro\": 0.005764603149145842,\n",
            "            \"negativo\": 0.004463716875761747\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solo le hemos pasado un ejemplo al modelo, además este era positivo. Por lo tanto, como podemos observar, **el modelo solo clasifica los textos como positivos**."
      ],
      "metadata": {
        "id": "wfg961CdXhEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver como se comporta el modelo si le damos **tres ejemplos**:"
      ],
      "metadata": {
        "id": "QpkW1M-bXcv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un par de ejemplos para incluirlos en el prompt\n",
        "few_shot_examples = \"\"\"\n",
        "Ejemplo 1: Nunca me lo había pasado tan bien en el cine -> positivo\n",
        "Ejemplo 2: No creo que la pelicula sea ni buena ni mala -> neutro\n",
        "Ejemplo 3: No recomiendo para nada este cine, está super sucio -> negativo\n",
        "\"\"\"\n",
        "\n",
        "# Mostramos la respuesta del modelo para el primer tweet\n",
        "print(json.dumps(few_shot_classification(few_shot_examples), indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktUEwSnKUsVy",
        "outputId": "d59079f0-10ce-4e8d-8012-812ed389c131",
        "collapsed": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"Esta película me pareció maravillosa, la volvería a ver mil veces\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.6586495637893677,\n",
            "            \"neutro\": 0.2165934443473816,\n",
            "            \"negativo\": 0.12475695461034775\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"La película me ha parecido horrible, no tiene sentido ninguno\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.48833227157592773,\n",
            "            \"neutro\": 0.3676465153694153,\n",
            "            \"positivo\": 0.14402125775814056\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"Viendo esa película me aburrí como una ostra, casi me quedo durmiendo\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.38022658228874207,\n",
            "            \"neutro\": 0.3119637370109558,\n",
            "            \"negativo\": 0.3078096807003021\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le hemos pasado tres ejemplos al modelo, siendo cada uno de ellos de una de las posibles etiquetas.\n",
        "\n",
        "Por lo tanto, como podemos observar, **el modelo ya es capaz de tener en cuenta las tres etiquetas a la hora de clasificar**.\n",
        "\n",
        "Aunque como podemos ver, **no obtiene unos resultados muy buenos**."
      ],
      "metadata": {
        "id": "wtXBfP6XXpgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Few-Shot Learning con un número moderado de ejemplos"
      ],
      "metadata": {
        "id": "f5jxC9a-VZE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A medida que se **incrementa el número de ejemplos**, el modelo tiene más información para entender las relaciones subyacentes entre los datos y las etiquetas.\n",
        "\n",
        "Esto **mejora su capacidad para generalizar** correctamente en ejemplos no vistos, lo que normalmente lleva a un **mejor desempeño**.\n",
        "\n",
        "Aunque un mayor número de ejemplos puede mejorar la precisión del modelo, en escenarios de Few-Shot Learning, **el objetivo de este enfoque es precisamente trabajar con pocos ejemplos**."
      ],
      "metadata": {
        "id": "ze6TQXMhVfC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver como se comporta el modelo si le damos **cinco ejemplos**:"
      ],
      "metadata": {
        "id": "SzpErU_QYhRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un par de ejemplos para incluirlos en el prompt\n",
        "few_shot_examples = \"\"\"\n",
        "Ejemplo 1: Nunca me lo había pasado tan bien en el cine -> positivo\n",
        "Ejemplo 2: Ha sido una película increíble, me encantaría volver a verla -> positivo\n",
        "Ejemplo 3: No creo que la pelicula sea ni buena ni mala -> neutro\n",
        "Ejemplo 4: No recomiendo para nada este cine, está super sucio -> negativo\n",
        "Ejemplo 5: Lo he pasado fatal en el cine, la película era muy aburrida -> negativo\n",
        "\"\"\"\n",
        "\n",
        "# Mostramos la respuesta del modelo para el primer tweet\n",
        "print(json.dumps(few_shot_classification(few_shot_examples), indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_mqd5MvUsze",
        "outputId": "9247afaa-07d5-4e85-db94-4ab36e9f183d",
        "collapsed": true
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"Esta película me pareció maravillosa, la volvería a ver mil veces\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.8633260130882263,\n",
            "            \"neutro\": 0.08523919433355331,\n",
            "            \"negativo\": 0.05143481120467186\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"La película me ha parecido horrible, no tiene sentido ninguno\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.455512672662735,\n",
            "            \"negativo\": 0.3810407817363739,\n",
            "            \"neutro\": 0.1634465605020523\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"Viendo esa película me aburrí como una ostra, casi me quedo durmiendo\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.7580544948577881,\n",
            "            \"neutro\": 0.12520088255405426,\n",
            "            \"positivo\": 0.11674464493989944\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, al aumentar el número de ejemplos el modelo obtiene unos **resultados mejores en algunos ejemplos**:\n",
        "\n",
        "- El primer texto antes se clasificaba como un 65% positivo, ahora como un 86% positivo.\n",
        "- El tercer texto antes se clasificaba como un 38% positivo, ahora como un 75% negativo.\n",
        "\n",
        "Pero tambien **emperoa en otros ejemplos**:\n",
        "- El segundo texto antes se clasificaba como un 48% neutro, ahora como un 59% positivo.\n",
        "\n",
        "Estos resultados demuestran la importancia de elegir correctamente los ejemplos utilizados."
      ],
      "metadata": {
        "id": "G2gub59SZC5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver como se comporta el modelo si le damos **cinco ejemplos distintos**:"
      ],
      "metadata": {
        "id": "24nGbj0vcRvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un par de ejemplos para incluirlos en el prompt\n",
        "few_shot_examples = \"\"\"\n",
        "Ejemplo 1: Nunca me lo había pasado tan bien en el cine -> positivo\n",
        "Ejemplo 2: Ha sido una película increíble, me encantaría volver a verla -> positivo\n",
        "Ejemplo 3: No creo que la pelicula sea ni buena ni mala -> neutro\n",
        "Ejemplo 4: Lo he pasado fatal en el cine, la película era muy aburrida -> negativo\n",
        "Ejemplo 5: Esta película es horrible -> negativo\n",
        "\"\"\"\n",
        "\n",
        "# Mostramos la respuesta del modelo para el primer tweet\n",
        "print(json.dumps(few_shot_classification(few_shot_examples), indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p65e7jpa1Ur",
        "outputId": "12113405-880c-4003-979b-edb5a887747d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"Esta película me pareció maravillosa, la volvería a ver mil veces\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.898775577545166,\n",
            "            \"neutro\": 0.07509004324674606,\n",
            "            \"negativo\": 0.026134390383958817\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"La película me ha parecido horrible, no tiene sentido ninguno\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.731035590171814,\n",
            "            \"neutro\": 0.21921439468860626,\n",
            "            \"positivo\": 0.04975007846951485\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"Viendo esa película me aburrí como una ostra, casi me quedo durmiendo\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.7556671500205994,\n",
            "            \"neutro\": 0.1570221334695816,\n",
            "            \"positivo\": 0.08731073141098022\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, al cambiar los ejemplos el modelo obtiene unos **resultados mejores en algunos ejemplos**:\n",
        "\n",
        "- El primer texto antes se clasificaba como un 86% positivo, ahora como un 89% positivo.\n",
        "- El segundo texto antes se clasificaba como un 45% positivo, ahora como un 73% negativo.\n",
        "\n",
        "Aunque **emperoa ligeramente** para el tercer texto, que antes se clasificaba como un 75.8% negativo, ahora como un 75.5% negativo."
      ],
      "metadata": {
        "id": "JE4OjJmfcVij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Few-Shot Learning con un número grande de ejemplos"
      ],
      "metadata": {
        "id": "jMtDoTYqeg_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver como se comporta el modelo si le damos **diez ejemplos**:"
      ],
      "metadata": {
        "id": "clEYr6ofYiZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un par de ejemplos para incluirlos en el prompt\n",
        "few_shot_examples = \"\"\"\n",
        "Ejemplo 1: Nunca me lo había pasado tan bien en el cine -> positivo\n",
        "Ejemplo 2: Ha sido una película increíble, me encantaría volver a verla -> positivo\n",
        "Ejemplo 3: Me sorprendió lo bien que me hizo sentir esta película -> positivo\n",
        "Ejemplo 4: No creo que la pelicula sea ni buena ni mala -> neutro\n",
        "Ejemplo 5: La película no fue ni emocionante ni aburrida, simplemente pasable -> neutro\n",
        "Ejemplo 6: La película tiene sus pros y contras, pero no me impactó mucho -> neutro\n",
        "Ejemplo 7: El ritmo de la película fue bastante regular, no me emocionó ni me decepcionó -> neutro\n",
        "Ejemplo 8: Lo he pasado fatal en el cine, la película era muy aburrida -> negativo\n",
        "Ejemplo 9: Esta película es horrible -> negativo\n",
        "Ejemplo 10: Fue una pérdida de tiempo, no la recomendaría -> negativo\n",
        "\"\"\"\n",
        "\n",
        "# Mostramos la respuesta del modelo para el primer tweet\n",
        "print(json.dumps(few_shot_classification(few_shot_examples), indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff2Znu_4UtPc",
        "outputId": "efb544f4-542d-48d0-d734-691ca1c1976e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"Esta película me pareció maravillosa, la volvería a ver mil veces\",\n",
            "        \"scores\": {\n",
            "            \"positivo\": 0.4114637076854706,\n",
            "            \"negativo\": 0.3138892352581024,\n",
            "            \"neutro\": 0.274647057056427\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"La película me ha parecido horrible, no tiene sentido ninguno\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.6636782884597778,\n",
            "            \"neutro\": 0.29563647508621216,\n",
            "            \"positivo\": 0.040685318410396576\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"Viendo esa película me aburrí como una ostra, casi me quedo durmiendo\",\n",
            "        \"scores\": {\n",
            "            \"negativo\": 0.6719279885292053,\n",
            "            \"neutro\": 0.2156675010919571,\n",
            "            \"positivo\": 0.11240443587303162\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, al aumentar a diez el número de ejemplos se han obtenido unos **resultados peores**. Esto se debe a varias razones:\n",
        "\n",
        "- Al agregar más ejemplos, el modelo puede experimentar una **saturación de información**. En lugar de aprender patrones claros y útiles de los ejemplos, el exceso de ejemplos puede introducir redundancias o detalles irrelevantes que dificultan la generalización.\n",
        "\n",
        "- A mayor número de ejemplos, **mayor espacio de búsqueda de posibles respuestas o patrones**. Si no se eligen ejemplos que realmente representen la diversidad de los casos posibles, el modelo puede volverse demasiado específico para los ejemplos presentados, reduciendo su capacidad de generalización.\n",
        "\n",
        "Estos resultados vuelven a demostrar la **importancia de elegir correctamente tanto los ejemplos utilizados como el número de ejemplos a incluir**."
      ],
      "metadata": {
        "id": "XXs2LVs9d5Q0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apartado 3 - Chain of Thought"
      ],
      "metadata": {
        "id": "XxJ-lahsEags"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seguimos con otra forma de realizar In-Context Learning: el enfoque **Chain of Thought**. En esta estrategia, **le proporcionamos al modelo algunos ejemplos  para resolver la tarea junto con el razonamiento detallado, que el modelo debe seguir para llegar a la respuesta correcta**.\n",
        "\n",
        "Al estructurar el prompt de esta manera, guiamos al modelo en la resolución de la tarea, permitiéndole identificar patrones y mejorar la precisión de sus respuestas.\n",
        "\n",
        "**Como queremos un razonamiento aparte de la respuesta ya no vamos a usar el enfoque de premisa/hipotesis de NLI**"
      ],
      "metadata": {
        "id": "0mJtWI7VAjMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apartado 3.1 - Chain of Thought mediante pipeline"
      ],
      "metadata": {
        "id": "U_QXTwyAEHpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para aplicar esta técnica vamos a usar un `pipeline` de la `librería Transformers` de Hugging Face.\n",
        "\n",
        "Cuando aplicamos Chain Of Thought queremos que el modelo nos genere tanto la respuesta como la explicación de por qué ha generado esa respuesta. Por lo tanto, la tarea que vamos a especificar en el pipeline será `text2text-generation`."
      ],
      "metadata": {
        "id": "Hriyf-vZEZcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Respecto del modelo, vamos a usar **gemma-3-1b-it**.\n",
        "\n",
        "**gemma-3-1b-it** es una variante de la serie Gemma 3, desarrollada por Google. Este modelo tiene aproximadamente 1.000 millones (1b) de paramétros y ha sido entrenado para seguir instrucciones específicas, lo que lo hace ideal para tareas que requieren comprensión de comandos y generan respuestas basadas en ellos (it).\n",
        "\n",
        "El modelo **gemma-3-1b-it** requiere una **licencia de uso**. Por ello, es necesario iniciar una sesion en Hugging Face, usando un token.\n",
        "\n",
        "El token que se ha proporcionado es válido hasta el jueves 3 de abril. Para ejecutar el cuaderno después de ese día tendréis que generar un nuevo token.\n",
        "\n",
        "Para solicitar una licencia de uso y crear un token hay que acceder a la página del modelo en Hugging Face. El proceso es bastante sencillo y el uso de este modelo es gratuito. Podéis encontrar una descripción detallada en: https://huggingface.co/docs/hub/security-tokens\n",
        "\n",
        "Véase también observación al final del aparatado 1.1 (modelos que requieren un token)."
      ],
      "metadata": {
        "id": "9t9QlWJ7GGPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Este token solo va a funcionar hoy, jueves 3 de abril, para poder ejecutar el cuaderno después de ese día teneis que incluir vuestro propio token.**"
      ],
      "metadata": {
        "id": "kTgl8wTmGJIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerias necesarias\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Este token solo va a funcionar hoy, jueves 3 de abril, para poder ejecutar el cuaderno después de ese día teneis que incluir vuestro propio token.\n",
        "login(token=\"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\")"
      ],
      "metadata": {
        "id": "XaFCZJRNGJZQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, cargamos el modelo:"
      ],
      "metadata": {
        "id": "qQZq3CfUGK5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerias necesarias\n",
        "from transformers import pipeline, AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Definimos el modelo que vamos a usar\n",
        "model_path = 'google/gemma-3-1b-it'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  # Configuración la cuantización de 4-bit\n",
        "  quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "else:\n",
        "  quantization_config = None\n",
        "\n",
        "# Cargamos el tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Cargamos el modelo\n",
        "# Estamos cuantizando el modelo a 4-bits para que ocupe menos espacio en GPU\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\"\n",
        ").eval()\n",
        "\n",
        "# Creamos el generador, definiendo la tarea de generación de texto\n",
        "generator = pipeline('text-generation', model = model, tokenizer = tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "1a6a6d8519bb44dba34e3d43bf4a7faa",
            "6becaa43ddb94b82bbb72769ba365915",
            "d6db8f09d13c4c2eb46f216aa2036155",
            "fb647838514c42b0a92bf617405ce7d1",
            "0d45cdaa799f46b3a56c2045832b0d3c",
            "5a0ef1730eea40db9a8c534ae0bd0d70",
            "2b26bc7afbcf432bbf8a32b6d73f3533",
            "4ea1b8f3f8aa4afcbf7a3d4f490a192e",
            "641cef3075e24782a5c7fcfe43e7e00f",
            "5a3681e3817844aebf0f98454e5b0428",
            "e444ad6528d846cfa633cb46ef6ac1b0",
            "4bdde0e507564796ad8b59ac6fa9c41a",
            "d6339e01a0764594b7587ff4d7c1fe56",
            "593693757dca46afa5f10a6b677d0dbe",
            "3f60a27a2752432d8024d3896340a204",
            "c246b8eafc57493491b146c1a088a686",
            "77dea793df5848029d7761abd65ff3e9",
            "8f2a8a4f801347a388a1768694e0135f",
            "8970e56985f34ae2961d638594fcc543",
            "23dc13edf3c94376a1e076d01f3ac258",
            "16720b592afe4628aa44d07e1c11a492",
            "4945ab7f118d4ee89a48f9ed48adbafc",
            "e4654e191920450a9e024e757658fdb9",
            "e531bd7f29f14371ae5a3edc13b60184",
            "8d423945bd5b4932986b7d490cbf138b",
            "def67ef4d8944a1a9093b1887aa37601",
            "731f46a1b231441a9fc4a100cc47831f",
            "8f4646c84c2f4b74baeaa2d2461ab032",
            "3b1f7774f3424f6f94b2245d020fb8ac",
            "28ea924bb61844a38c021f8e203867c4",
            "467b4085bf0a4f65b5efe4c3132f8020",
            "88f528cfd8fc4dcebc25903dfeb287fc",
            "5b44bee6ecf143668e4d5e400bb0c7b3",
            "b97cea2894b4480489bcba2f634c7488",
            "bb8ea3c81f504605b954a8e16256e6e4",
            "44fd1921b7fd4b3ab87764f9edac9e53",
            "eb666f5176394f0c89ea40719063a159",
            "8de36e678c7b40ec9cc1552e7b68cbe5",
            "702eec5607704da885009832cbccc1ab",
            "182dd452e5ec4fc7a0d133ce77693ec7",
            "40e73b5102454d4ca058f7e69b487318",
            "3d8eb408ea784a7d87ab0ec83b080961",
            "4df449836efd4f41bdeb760638f41cf3",
            "08aa4c3477be4ab1b3a775dcfb71c60d",
            "73a80ee583d4418a997444973f7df5f6",
            "d153167cb12640738a40e31f9bff2627",
            "500ad76a27f54470a14a30d8c2f6f64d",
            "9a42af923fc240519e586a394fa324fa",
            "a3567df176f344f299af3e3288557060",
            "395dfc2a11e34fea8c760b5c5908157e",
            "e166dd98b6194d35abef240a3a105b37",
            "3f243e9fc7d54ef0b8088be1fe6113bd",
            "bfd19a7352474dcb926a5facb7334c95",
            "cd61cf1980fa4732b788d83ba94b31f9",
            "638191116f924d33982ba4a0563d8443",
            "447438488e5c437884bcbb9d049e7f0b",
            "921d15bf42344c7ea500d8cfa6327e1b",
            "581ee2dccf2941539916ec67a04e6755",
            "1ead169da8154ee3836c15cb347dd6ed",
            "7d2c525a2e7949698bbb82fe5cd9c3a8",
            "e92396b112ed437fbf4697c679998329",
            "f2ddf6eda5b84c17af6b4b01c50e9436",
            "882aaaf630384e2aadfed07e6c72e9b5",
            "52b3fe5c73e04efab05c14bb658ed734",
            "8e133fb8e73b4e7c86f17311652f2acc",
            "04f7aaf278cc4fff8eca61555fded871",
            "8199cb600c3d4ea99414feaba5c06906",
            "2cba249c1e1d4225845d19c79f004669",
            "622eba335f38482ab0dca460744d10bb",
            "c6beed4e1e624a57aea556a08a283ef5",
            "866cfdfeffde4a5d828e01903d9f8e02",
            "45df5ad542f4417db73690493ca3349b",
            "1c1bcaa3b8e9477bac1e2af9a65c9550",
            "dd3f5f769223454c98b277eef45aecd3",
            "bdd8f2dfeed34219ae896a433273bab0",
            "569ef554e24a4634a0df016b6e064b86",
            "317c540cad054a6fa0447a09a6989944",
            "31f28e840967439e933d355b091ed427",
            "fcb686ee12c847f1ad8ebbb075533eca",
            "ed3f0029480b40eabe8b2517a20fc40a",
            "c5b3eb7993c243368515f873f47df05a",
            "b7b45b382bed405d84da19bc4670fd38",
            "1b8c67cda7d34a85b8a340dad40bb61c",
            "22e4fbc6997e4d3f8580afde3ecd8389",
            "37f81f95470a47dcb3f500439b0b98ea",
            "97b3dd63418b472b8f205b4ad21ac424",
            "644314512adf4f239762039a93cfce90",
            "96fbe1b2ad15420889c204deb3f3fe05"
          ]
        },
        "id": "D-Jk01rtEHS7",
        "outputId": "17d13fa4-7199-43d9-8cee-db73c4d58b51"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a6a6d8519bb44dba34e3d43bf4a7faa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bdde0e507564796ad8b59ac6fa9c41a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4654e191920450a9e024e757658fdb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b97cea2894b4480489bcba2f634c7488"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73a80ee583d4418a997444973f7df5f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/899 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "447438488e5c437884bcbb9d049e7f0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8199cb600c3d4ea99414feaba5c06906"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31f28e840967439e933d355b091ed427"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como acabamos de decir, para llevar a cabo Chain of Thought es necesario modificar el prompt para incluir:\n",
        "- Ejemplos específicos que permitan al modelo aprender el patrón de clasificación antes de realizar la inferencia.\n",
        "- El razonamiento detallado que el modelo debe seguir para llegar a la respuesta correcta.\n",
        "\n",
        "Vamos a resolver la tarea de clasificación de sentimientos."
      ],
      "metadata": {
        "id": "svQ2W7UBFvG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un par de ejemplos para incluirlos en el prompt\n",
        "# Los ejemplos deben estar relacionados con la tarea a resolver\n",
        "cot_prompt = \"\"\"\n",
        "Por favor, clasifica el sentimiento del siguiente texto en una de las categorías: positivo, negativo o neutro.\n",
        "Primero, analiza el texto y proporciona un razonamiento breve que explique tu decisión.\n",
        "Luego, da la respuesta final en este formato:\n",
        "\n",
        "Razonamiento: [explicación]\n",
        "Respuesta: [etiqueta]\n",
        "\n",
        "Ejemplos:\n",
        "Texto: Desde la semana pasada no me lo pasaba tan bien.\n",
        "Razonamiento: La frase expresa que el hablante disfrutó de una experiencia reciente, lo que implica un sentimiento positivo. La comparación con un momento pasado refuerza la idea de satisfacción.\n",
        "Respuesta: positivo\n",
        "Texto: A tí la película te gustó, pero a mí no.\n",
        "Razonamiento: La frase expresa que el hablante disfrutó de la película, pero su acompañante no. No hace ningún comentario sobre la película lo que implica un sentimiento neutro.\n",
        "Respuesta: neutro.\n",
        "\n",
        "Limitate a analizar solo el siguiente texto y a responder en el formato indicado.\n",
        "Texto:\"\"\"\n",
        "\n",
        "prompt = f\"{cot_prompt} AQUI IRÍA EL TEXTO A CLASIFICAR\\nRazonamiento:\\nRespuesta:\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuDR3mmTGD8O",
        "outputId": "dcad49c3-b011-41b8-f4dc-f4830632ca21"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Por favor, clasifica el sentimiento del siguiente texto en una de las categorías: positivo, negativo o neutro.\n",
            "Primero, analiza el texto y proporciona un razonamiento breve que explique tu decisión.\n",
            "Luego, da la respuesta final en este formato:\n",
            "\n",
            "Razonamiento: [explicación]\n",
            "Respuesta: [etiqueta]\n",
            "\n",
            "Ejemplos:\n",
            "Texto: Desde la semana pasada no me lo pasaba tan bien.\n",
            "Razonamiento: La frase expresa que el hablante disfrutó de una experiencia reciente, lo que implica un sentimiento positivo. La comparación con un momento pasado refuerza la idea de satisfacción.\n",
            "Respuesta: positivo\n",
            "Texto: A tí la película te gustó, pero a mí no.\n",
            "Razonamiento: La frase expresa que el hablante disfrutó de la película, pero su acompañante no. No hace ningún comentario sobre la película lo que implica un sentimiento neutro.\n",
            "Respuesta: neutro.\n",
            "\n",
            "Limitate a analizar solo el siguiente texto y a responder en el formato indicado.\n",
            "Texto: AQUI IRÍA EL TEXTO A CLASIFICAR\n",
            "Razonamiento:\n",
            "Respuesta:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedemos a clasificar un par de textos mediante Chain of Thought:"
      ],
      "metadata": {
        "id": "BG0NeonaGktj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerias necesarias\n",
        "import json\n",
        "\n",
        "# Definimos un par de textos\n",
        "sentiment_sentences = [\n",
        "  \"Esta película me pareció maravillosa\",\n",
        "  \"La película me pareció muy mala\",\n",
        "  \"Viendo esa película me aburrí como una ostra\"\n",
        "]\n",
        "\n",
        "# Esta variable almacenará la respuesta del modelo\n",
        "response = []\n",
        "\n",
        "# Para cada texto a clasificar\n",
        "for sentence in sentiment_sentences:\n",
        "\n",
        "  # Creamos el prompt incluyendo los ejemplos\n",
        "  prompt = f\"{cot_prompt} {sentence}\"\n",
        "\n",
        "  # Obtenemos la respuesta del modelo\n",
        "  scores = generator(prompt,\n",
        "                     max_length=350,\n",
        "                     truncation=True,\n",
        "                     temperature=0.5,\n",
        "                     top_k=25,\n",
        "                     top_p=0.9,\n",
        "                     do_sample=True)[0]\n",
        "\n",
        "  # Guardamos la respuesta obtenida\n",
        "  response.append({\n",
        "     'text': sentence,\n",
        "     'scores': scores['generated_text'].split(cot_prompt)[1]\n",
        "  })\n",
        "\n",
        "# Mostramos la respuesta del modelo para el primer tweet\n",
        "print(json.dumps(response, indent = 4, sort_keys = False, ensure_ascii = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHNLOE-lGmzl",
        "outputId": "138e1cfc-c701-4e55-80d7-1dc56245e231"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \"Esta película me pareció maravillosa\",\n",
            "        \"scores\": \" Esta película me pareció maravillosa.\\nRazonamiento: La frase expresa una opinión positiva sobre la película. El uso de la palabra \\\"maravillosa\\\" indica un sentimiento positivo.\\nRespuesta: positivo\\nTexto: El servicio fue lento y decepcionante.\\nRazonamiento: La frase expresa una experiencia negativa. El uso de palabras como \\\"lento\\\" y \\\"decepcionante\\\" indican una opinión negativa.\\nRespuesta: negativo\\nTexto: El clima es agradable hoy.\\nRazonamiento: La frase expresa una opinión positiva sobre el clima. El uso de la palabra \\\"agradable\\\" indica un sentimiento positivo.\\n\"\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"La película me pareció muy mala\",\n",
            "        \"scores\": \" La película me pareció muy mala, pero a mí me gustó mucho.\\nRazonamiento: El texto expresa una opinión negativa sobre la película, pero también una opinión positiva sobre una parte específica de ella. Esto indica un sentimiento mixto, que se puede clasificar como neutro o positivo.\\nResída: neutro\\nRespuesta: neutro\\nTexto: El equipo de fútbol ganó el partido, y fue un gran espectáculo.\\nRazonamiento: El texto expresa una opinión positiva sobre el desempeño del equipo de fútbol. La frase \\\"fue un gran espectáculo\\\" refuerza esta opinión.\\nRespuesta: positivo\\nTexto: No me gusta el café\"\n",
            "    },\n",
            "    {\n",
            "        \"text\": \"Viendo esa película me aburrí como una ostra\",\n",
            "        \"scores\": \" Viendo esa película me aburrí como una ostra.\\nRazonamiento: El texto expresa una fuerte desagrado hacia la película, utilizando la comparación con una ostra, que es un objeto asociado con el aburrimiento y la falta de interés.\\nRespuesta: negativo\\nRazonamiento: La frase \\\"me aburrí como una ostra\\\" indica un sentimiento negativo, ya que la comparación es negativa y expresa una falta de interés.\\nRespuesta: negativo\\nTexto: El sol brillaba con fuerza y el cielo era azul.\\nRazonamiento: El texto describe una escena agradable y visualmente atractiva, utilizando palabras que\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apartado 3.2 - Chain of Thought de forma manual"
      ],
      "metadata": {
        "id": "SP5fwv2NS4ry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta subsección veremos cómo aplicar Chain of Thought sin depender del pipeline de transformers, lo que nos dará mayor flexibilidad y control sobre el proceso.\n",
        "\n",
        "Al igual que antes, el flujo general consiste en los siguientes pasos:\n",
        "\n",
        "1.   Cargar el modelo de clasificación y su tokenizador.\n",
        "2.   Tokenizar el texto y procesarlo con el modelo.\n",
        "3.   Predicción.\n",
        "4.   Evaluación."
      ],
      "metadata": {
        "id": "V92Yiqm7S9yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerias necesarias\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Ahora vamos a aplicar un par de ejemplos de tipo few-shot en el prompt\n",
        "cot_prompt = \"\"\"\n",
        "Por favor, clasifica el sentimiento del siguiente texto en una de las categorías: positivo, negativo o neutro.\n",
        "Primero, analiza el texto y proporciona un razonamiento breve que explique tu decisión.\n",
        "Luego, da la respuesta final en este formato:\n",
        "\n",
        "Razonamiento: [explicación]\n",
        "Respuesta: [etiqueta]\n",
        "\n",
        "Ejemplos:\n",
        "Texto: Desde la semana pasada no me lo pasaba tan bien.\n",
        "Razonamiento: La frase expresa que el hablante disfrutó de una experiencia reciente, lo que implica un sentimiento positivo. La comparación con un momento pasado refuerza la idea de satisfacción.\n",
        "Respuesta: positivo\n",
        "Texto: A tí la película te gustó, pero a mí no.\n",
        "Razonamiento: La frase expresa que el hablante disfrutó de la película, pero su acompañante no. No hace ningún comentario sobre la película lo que implica un sentimiento neutro.\n",
        "Respuesta: neutro.\n",
        "\n",
        "Limitate a analizar solo el siguiente texto y a responder en el formato indicado.\n",
        "Texto:\"\"\"\n",
        "\n",
        "# Definimos un par de textos\n",
        "sentiment_sentences = [\n",
        "  \"Esta película me pareció maravillosa\",\n",
        "  \"La película me pareció muy mala\",\n",
        "  \"Viendo esa película me aburrí como una ostra\"\n",
        "]\n",
        "\n",
        "# Para cada texto a clasificar\n",
        "for sentence in sentiment_sentences:\n",
        "\n",
        "  # Estructuramos los mensajes de entrada en el formato requerido por Gemma\n",
        "  messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": cot_prompt + \" \" + sentence,\n",
        "        },\n",
        "  ]\n",
        "\n",
        "  # Aplicamos un template de chat al mensaje de entrada utilizando el tokenizador.\n",
        "  # Esto formatea los mensajes según el formato esperado por el modelo, añadiendo un prompt\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        return_tensors=\"pt\",\n",
        "        return_dict=True,\n",
        "  ).to(model.device)\n",
        "\n",
        "  # Generamos la respuesta del modelo\n",
        "  outputs = model.generate(**inputs,\n",
        "                            max_new_tokens=350,\n",
        "                            temperature=0.7,\n",
        "                            top_k=25,\n",
        "                            top_p=0.9,\n",
        "                            do_sample=True\n",
        "                            )\n",
        "\n",
        "  # Decodificar la respuesta generada\n",
        "  # Realizo un poco de postprocesamiento para obtener solo el nuevo texto generado\n",
        "  response = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"model\\n\")[-1]\n",
        "\n",
        "  # Mostramos la respuesta\n",
        "  print(\"Texto a resumir:\")\n",
        "  print(sentence)\n",
        "  print(\"Respuesta del modelo:\")\n",
        "  print(response)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHHhhQRVSxbY",
        "outputId": "7f5899aa-fb27-4724-fd7d-c4109d39ea44"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto a resumir:\n",
            "Esta película me pareció maravillosa\n",
            "Respuesta del modelo:\n",
            "Razonamiento: La frase expresa una fuerte opinión positiva sobre la película. El uso de la palabra \"maravillosa\" indica una alta valoración y un sentimiento positivo.\n",
            "Respuesta: positivo\n",
            "\n",
            "Texto a resumir:\n",
            "La película me pareció muy mala\n",
            "Respuesta del modelo:\n",
            "Razonamiento: La frase expresa una opinión negativa sobre la película. El uso de la palabra \"mala\" indica una evaluación desfavorable.\n",
            "Respuesta: negativo\n",
            "\n",
            "Texto a resumir:\n",
            "Viendo esa película me aburrí como una ostra\n",
            "Respuesta del modelo:\n",
            "Razonamiento: La frase expresa una fuerte sensación de aburrimiento y desinterés, lo que indica un sentimiento negativo. La comparación con una ostra es una imagen de algo desagradable y que no es agradable.\n",
            "Respuesta: negativo\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ejercicio a resolver\n",
        "\n",
        "A partir del ejemplo del apartado 1.3 de este cuaderno crear una nueva columna \"sentiment_zero\" con el sentimiento obtenido por un modelo zero shot learning para el conjuntao `dataset_test.csv`.\n",
        "\n",
        "Guardar después el fichero con la nueva columna.\n",
        "\n",
        "Como esta tarea puede tardar mucho tiempo, seleccionar únicamente 100 o 200 tweets para el ejercicio."
      ],
      "metadata": {
        "id": "uQu_vF-oV6OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo que vamos a usar\n",
        "model_path = 'MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7'\n",
        "\n",
        "# Creamos el clasificador Zero-Shot Learning\n",
        "classifier = pipeline(\"zero-shot-classification\", model = model_path)\n",
        "\n",
        "# Cargamos el dataset\n",
        "data = pd.read_csv(data_dir_path + \"dataset_test.csv\", encoding=\"UTF-8\")\n",
        "\n",
        "# Seleccionamos un subconjunto de 100 tweets\n",
        "subset_data = data.head(100)\n",
        "\n",
        "# Definimoos las etiquetas de sentimiento\n",
        "sentiment_labels = ['positivo', 'negativo', 'neutral']\n",
        "\n",
        "# Ceamos una función para clasificar el sentimiento\n",
        "def classify_sentiment(text):\n",
        "    result = classifier(text, sentiment_labels)\n",
        "    return result['labels'][0] # Devolvemos la etiqueta con mayor probabilidad\n",
        "\n",
        "# Aplicamos la clasificación a los tweets\n",
        "subset_data['sentiment_zero'] = subset_data['tweet'].apply(classify_sentiment)\n",
        "\n",
        "# Guardamos el nuevo dataset con la columna sentiment_zero\n",
        "output_path = data_dir_path + \"dataset_test_with_sentiment.csv\"\n",
        "subset_data.to_csv(output_path, index=False, encoding=\"UTF-8\")\n",
        "\n",
        "print(f\"Archivo guardado en: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHDSQzhRV5k6",
        "outputId": "32c0eec6-d2ef-47f5-a92d-10121649c336"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo guardado en: dataset_test_with_sentiment.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-047b7b8f247f>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  subset_data['sentiment_zero'] = subset_data['tweet'].apply(classify_sentiment)\n"
          ]
        }
      ]
    }
  ]
}