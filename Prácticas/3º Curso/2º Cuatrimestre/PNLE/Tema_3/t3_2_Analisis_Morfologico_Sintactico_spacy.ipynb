{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKpHNHF9pAnM"
      },
      "source": [
        "# Sesión 3 - Análisis morfológico y sintáctico con spaCy\n",
        "\n",
        "spaCy es otra de las bibliotecas de procesamiento de lenguaje natural más populares y eficientes en Python.\n",
        "\n",
        "spaCy permite el análisis morfológico y etiqeutado gramatical, además de realizar un análisis de dependencias. No realiza análisis de constituyentes como tal.\n",
        "\n",
        "En este cuaderno se muestran algunas de sus funciones para el análisis morfológico y sintáctico en español e inglés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-mn79_2fpAIH",
        "outputId": "2a0cb051-4500-4ff1-e56b-767c2da57ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (2.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (75.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/python/3.12.1/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip3 install spacy\n",
        "# Descargamos el modelo en español e inglés\n",
        "!python -m spacy download es_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bk7YXf-zMhf0"
      },
      "outputs": [],
      "source": [
        "data_dir_path = \"Datos/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K1dVCJVoRF42"
      },
      "outputs": [],
      "source": [
        "#Cargamos el modelo en español y el modelo en inglés\n",
        "import spacy\n",
        "nlp_es = spacy.load(\"es_core_news_sm\")\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZLaRS820xCM"
      },
      "source": [
        "#3.1 Tokenización y análisis morfológico en spaCy\n",
        "\n",
        "A diferencia de Stanza, por defecto spaCy realiza todo el procesamiento de golpe y si queremos quitar algun proceso debemos decirlo de manera explícita.\n",
        "\n",
        "Para este ejemplo desactivaremos la detección de entidades y el análisis sintáctico con el siguiente código\n",
        "\n",
        "```\n",
        "nlp_es.disable_pipes(\"ner\", \"parser\")\n",
        "```\n",
        "A continuación se muestra un ejemplo para mostrar la categoría gramatical, el lema y otras propiedades morfológicas de cada palabra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PSvYTMdYRJ4e",
        "outputId": "5d405408-fad8-4af8-e73b-33950e3404e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frase: Los gatos negros corren rápidamente por el jardín.\n",
            "\n",
            "\n",
            "Análisis Morfológico:\n",
            "Token          POS       Lemma          Morfología\n",
            "============================================================\n",
            "Los            DET       el             Definite=Def|Gender=Masc|Number=Plur|PronType=Art\n",
            "gatos          NOUN      gato           Gender=Masc|Number=Plur\n",
            "negros         ADJ       negro          Gender=Masc|Number=Plur\n",
            "corren         VERB      correr         Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\n",
            "rápidamente    ADV       rápidamente    \n",
            "por            ADP       por            \n",
            "el             DET       el             Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
            "jardín         NOUN      jardín         Gender=Masc|Number=Sing\n",
            ".              PUNCT     .              PunctType=Peri\n",
            "\n",
            "\n",
            "             SPACE     \n",
            "\n",
            "             \n",
            "Frase: Hugo bebe zumo de naranja en la cocina.\n",
            "\n",
            "Análisis Morfológico:\n",
            "Token          POS       Lemma          Morfología\n",
            "============================================================\n",
            "Hugo           PROPN     Hugo           \n",
            "bebe           VERB      beber          Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
            "zumo           ADJ       zumo           Gender=Masc|Number=Sing\n",
            "de             ADP       de             \n",
            "naranja        NOUN      naranja        Gender=Fem|Number=Sing\n",
            "en             ADP       en             \n",
            "la             DET       el             Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
            "cocina         NOUN      cocina         Gender=Fem|Number=Sing\n",
            ".              PUNCT     .              PunctType=Peri\n",
            "\n",
            "              SPACE     \n",
            "              \n"
          ]
        }
      ],
      "source": [
        "# Texto de ejemplo\n",
        "texto_es = \"\"\"Los gatos negros corren rápidamente por el jardín.\n",
        "\n",
        "Hugo bebe zumo de naranja en la cocina.\n",
        "\"\"\"\n",
        "\n",
        "# Procesar el texto con spaCy\n",
        "doc = nlp_es(texto_es)\n",
        "\n",
        "# Imprimir información morfológica\n",
        "\n",
        "for sent in doc.sents:\n",
        "  print(f\"Frase: {sent.text}\")\n",
        "  print(\"Análisis Morfológico:\")\n",
        "  print(f\"{'Token':<15}{'POS':<10}{'Lemma':<15}{'Morfología'}\")\n",
        "  print(\"=\"*60)\n",
        "  for token in sent:\n",
        "    print(f\"{token.text:<15}{token.pos_:<10}{token.lemma_:<15}{token.morph}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Gwxy8aibuy4o",
        "outputId": "cb54409b-7527-475a-bf8b-9a6fa8f5d868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frase: Hugo eats apples in Telefónica's kitchen.\n",
            "\n",
            "\n",
            "Análisis Morfológico:\n",
            "Token          POS       Lemma          Morfología\n",
            "============================================================\n",
            "Hugo           PROPN     Hugo           Number=Sing\n",
            "eats           VERB      eat            Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
            "apples         NOUN      apple          Number=Plur\n",
            "in             ADP       in             \n",
            "Telefónica     PROPN     Telefónica     Number=Sing\n",
            "'s             PART      's             \n",
            "kitchen        NOUN      kitchen        Number=Sing\n",
            ".              PUNCT     .              PunctType=Peri\n",
            "\n",
            "\n",
            "             SPACE     \n",
            "\n",
            "             \n",
            "Frase: Sofía plays football with Emma and Cristina with a red ball in Central Park.\n",
            "\n",
            "\n",
            "Análisis Morfológico:\n",
            "Token          POS       Lemma          Morfología\n",
            "============================================================\n",
            "Sofía          PROPN     Sofía          Number=Sing\n",
            "plays          VERB      play           Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
            "football       NOUN      football       Number=Sing\n",
            "with           ADP       with           \n",
            "Emma           PROPN     Emma           Number=Sing\n",
            "and            CCONJ     and            ConjType=Cmp\n",
            "Cristina       PROPN     Cristina       Number=Sing\n",
            "with           ADP       with           \n",
            "a              DET       a              Definite=Ind|PronType=Art\n",
            "red            ADJ       red            Degree=Pos\n",
            "ball           NOUN      ball           Number=Sing\n",
            "in             ADP       in             \n",
            "Central        PROPN     Central        Number=Sing\n",
            "Park           PROPN     Park           Number=Sing\n",
            ".              PUNCT     .              PunctType=Peri\n",
            "\n",
            "\n",
            "             SPACE     \n",
            "\n",
            "             \n",
            "Frase: Marina's father is 56 years old.\n",
            "\n",
            "\n",
            "Análisis Morfológico:\n",
            "Token          POS       Lemma          Morfología\n",
            "============================================================\n",
            "Marina         PROPN     Marina         Number=Sing\n",
            "'s             PART      's             \n",
            "father         NOUN      father         Number=Sing\n",
            "is             AUX       be             Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
            "56             NUM       56             NumType=Card\n",
            "years          NOUN      year           Number=Plur\n",
            "old            ADJ       old            Degree=Pos\n",
            ".              PUNCT     .              PunctType=Peri\n",
            "\n",
            "\n",
            "             SPACE     \n",
            "\n",
            "             \n",
            "Frase: The Earth revolves around the Sun.\n",
            "\n",
            "\n",
            "Análisis Morfológico:\n",
            "Token          POS       Lemma          Morfología\n",
            "============================================================\n",
            "The            DET       the            Definite=Def|PronType=Art\n",
            "Earth          PROPN     Earth          Number=Sing\n",
            "revolves       VERB      revolve        Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
            "around         ADP       around         \n",
            "the            DET       the            Definite=Def|PronType=Art\n",
            "Sun            PROPN     Sun            Number=Sing\n",
            ".              PUNCT     .              PunctType=Peri\n",
            "\n",
            "\n",
            "             SPACE     \n",
            "\n",
            "             \n",
            "Frase: Jupiter is the biggest planet in the solar system.\n",
            "Análisis Morfológico:\n",
            "Token          POS       Lemma          Morfología\n",
            "============================================================\n",
            "Jupiter        PROPN     Jupiter        Number=Sing\n",
            "is             AUX       be             Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
            "the            DET       the            Definite=Def|PronType=Art\n",
            "biggest        ADJ       big            Degree=Sup\n",
            "planet         NOUN      planet         Number=Sing\n",
            "in             ADP       in             \n",
            "the            DET       the            Definite=Def|PronType=Art\n",
            "solar          ADJ       solar          Degree=Pos\n",
            "system         NOUN      system         Number=Sing\n",
            ".              PUNCT     .              PunctType=Peri\n"
          ]
        }
      ],
      "source": [
        "#Podemos hacer el análisis morfológico en inglés\n",
        "en_text = \"\"\"Hugo eats apples in Telefónica's kitchen.\n",
        "\n",
        "Sofía plays football with Emma and Cristina with a red ball in Central Park.\n",
        "\n",
        "Marina's father is 56 years old.\n",
        "\n",
        "The Earth revolves around the Sun.\n",
        "\n",
        "Jupiter is the biggest planet in the solar system.\"\"\"\n",
        "\n",
        "# Procesar el texto con spaCy\n",
        "doc = nlp_en(en_text)\n",
        "\n",
        "# Imprimir información morfológica\n",
        "\n",
        "for sent in doc.sents:\n",
        "  print(f\"Frase: {sent.text}\")\n",
        "  print(\"Análisis Morfológico:\")\n",
        "  print(f\"{'Token':<15}{'POS':<10}{'Lemma':<15}{'Morfología'}\")\n",
        "  print(\"=\"*60)\n",
        "  for token in sent:\n",
        "    print(f\"{token.text:<15}{token.pos_:<10}{token.lemma_:<15}{token.morph}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbuTNZsGCwWK"
      },
      "source": [
        "#3.2 Sintagmas nominales\n",
        "SpaCy no permite realizar un análisis de constituyentes como tal, pero permite obtener los noun chunks (sintagmas nominales de una frase)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c4NjaWqNTHqA",
        "outputId": "ed324dcd-cb5a-41fb-d0a7-ca5660790b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hugo nsubj eats\n",
            "apples dobj eats\n",
            "Telefónica's kitchen pobj in\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sofía nsubj plays\n",
            "football dobj plays\n",
            "Emma pobj with\n",
            "Cristina conj Emma\n",
            "a red ball pobj with\n",
            "Central Park pobj in\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Marina's father nsubj is\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The Earth nsubj revolves\n",
            "the Sun pobj around\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Jupiter nsubj is\n",
            "the biggest planet attr is\n",
            "the solar system pobj in\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#mostramos los sintagmas nominales\n",
        "import spacy\n",
        "\n",
        "for sent in doc.sents:\n",
        "  for chunk in sent.noun_chunks:\n",
        "    print(chunk.text, chunk.root.dep_,\n",
        "            chunk.root.head.text)\n",
        "  print(\"-\"*100)\n",
        "# nolo hace muy bien"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOTf49TuDXFB"
      },
      "source": [
        "#3.3 Análisis de dependencias en spaCy\n",
        "SpaCy sí permite un análisis de dependencias y también mostrar este análisis de una manera gráfica como se muestra a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3O6xsQV7RueM",
        "outputId": "b4ddec51-9704-4870-b6bc-61325fb43b83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Análisis de Dependencias:\n",
            "Token          Dependencia    Cabeza\n",
            "=============================================\n",
            "El             det            perro\n",
            "perro          nsubj          corre\n",
            "negro          flat           perro\n",
            "corre          ROOT           corre\n",
            "rápidamente    advmod         corre\n",
            "por            case           parque\n",
            "el             det            parque\n",
            "parque         obl            corre\n",
            ".              punct          corre\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# Texto de ejemplo\n",
        "texto = \"El perro negro corre rápidamente por el parque.\"\n",
        "\n",
        "# Procesar el texto\n",
        "doc = nlp_es(texto)\n",
        "\n",
        "# Mostrar dependencias en la consola\n",
        "print(\"Análisis de Dependencias:\")\n",
        "print(f\"{'Token':<15}{'Dependencia':<15}{'Cabeza'}\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "for token in doc:\n",
        "    print(f\"{token.text:<15}{token.dep_:<15}{token.head.text}\")\n",
        "\n",
        "# Mostrar visualización en el navegador\n",
        "#displacy.serve(doc, style=\"dep\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jH-vS98ESAh5",
        "outputId": "5fec88f0-35de-42f2-cc67-b171fd87f7f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frase: Los gatos negros de la prima Irene corren rápidamente por el jardín.\n",
            "\n",
            "\n",
            "Sujeto: gatos\n",
            "Raíz: corren\n",
            "Complementos directo: jardín\n",
            "==================================================\n",
            "Frase: Los mejores amigos de Hugo beben un zumo muy rico de naranja en la cocina.\n",
            "\n",
            "Sujeto: amigos\n",
            "Raíz: beben\n",
            "Complementos directo: zumo\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Texto de ejemplo\n",
        "texto = \"\"\"Los gatos negros de la prima Irene corren rápidamente por el jardín.\n",
        "\n",
        "Los mejores amigos de Hugo beben un zumo muy rico de naranja en la cocina.\n",
        "\"\"\"\n",
        "\n",
        "# Procesar el texto con spaCy\n",
        "doc = nlp_es(texto)\n",
        "\n",
        "# Iterar sobre las oraciones en el documento\n",
        "for sent in doc.sents:\n",
        "    sujeto = \"\"\n",
        "    raiz = \"\"\n",
        "    complementos_directo = \"\"\n",
        "\n",
        "    # Iterar sobre los tokens de la oración\n",
        "    for token in sent:\n",
        "        # Sujeto: Si el token es un sujeto (nsubj)\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            sujeto=token.text\n",
        "\n",
        "        # Raíz: Si el token es la raíz de la oración (ROOT)\n",
        "        if token.dep_ == \"ROOT\":\n",
        "            raiz=token.text\n",
        "\n",
        "        # Complemento directo: Si el token es un complemento directo (dobj)\n",
        "        if token.dep_ == \"obj\":\n",
        "            complementos_directo =token.text\n",
        "\n",
        "    # Almacenar los resultados para cada oración\n",
        "    print(f\"Frase: {sent.text}\")\n",
        "    print(f\"Sujeto: {sujeto}\")\n",
        "    print(f\"Raíz: {raiz}\")\n",
        "    print(f\"Complementos directo: {complementos_directo}\")\n",
        "    print(\"=\" * 50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqnBVvLf4MeV"
      },
      "source": [
        "Como antes podemos crear una función *obtener_sintagma_completo_spacy* para obtener todo el sujeto y todo el complemento directo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wsnNglGiyWr4",
        "outputId": "1457dc2f-f9b0-4b3a-9e46-dc22ffee8f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frase: Los gatos negros de la prima Irene corren rápidamente por el jardín.\n",
            "\n",
            "\n",
            "Sujeto: Los gatos negros de la prima Irene\n",
            "Raíz: corren\n",
            "Complementos directos: por el jardín\n",
            "==================================================\n",
            "Frase: Los mejores amigos de Hugo beben un zumo muy rico de naranja en la cocina.\n",
            "\n",
            "Sujeto: Los mejores amigos de Hugo\n",
            "Raíz: beben\n",
            "Complementos directos: un zumo muy rico de naranja\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "def obtener_sintagma_completo_spacy(sentence, word):\n",
        "  ids= []\n",
        "  sintagma = [word]  # Incluye el núcleo del sintagma\n",
        "  ids.append(word.i)\n",
        "  while(ids): # mientras haya elementos vamos buscando si hay palabras que referencian\n",
        "  # como head a algún id\n",
        "    for w in sentence:\n",
        "      if w.head.i in ids:\n",
        "        if(w.i not in ids):\n",
        "          ids.append(w.i)\n",
        "          sintagma.append(w)\n",
        "        # Sacamos el último elemento\n",
        "    ids.pop(0)\n",
        "  # Combina los elementos del sintagma completo y lo devuelve\n",
        "  return \" \".join(w.text for w in sorted(sintagma, key=lambda x: x.i))\n",
        "\n",
        "  import spacy\n",
        "\n",
        "# Texto de ejemplo\n",
        "texto = \"\"\"Los gatos negros de la prima Irene corren rápidamente por el jardín.\n",
        "\n",
        "Los mejores amigos de Hugo beben un zumo muy rico de naranja en la cocina.\n",
        "\"\"\"\n",
        "\n",
        "# Procesar el texto con spaCy\n",
        "doc = nlp_es(texto)\n",
        "\n",
        "# Iterar sobre las oraciones en el documento\n",
        "for sent in doc.sents:\n",
        "    sujeto = \"\"\n",
        "    raiz = \"\"\n",
        "    complementos_directo = \"\"\n",
        "\n",
        "    # Iterar sobre los tokens de la oración\n",
        "    for token in sent:\n",
        "        # Sujeto: Si el token es un sujeto (nsubj)\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            sujeto= obtener_sintagma_completo_spacy(sent, token)\n",
        "\n",
        "        # Raíz: Si el token es la raíz de la oración (ROOT)\n",
        "        if token.dep_ == \"ROOT\":\n",
        "            raiz= token.text\n",
        "\n",
        "        # Complemento directo: Si el token es un complemento directo (dobj)\n",
        "        if token.dep_ == \"obj\":\n",
        "            complementos_directo = obtener_sintagma_completo_spacy(sent,token)\n",
        "\n",
        "    # Almacenar los resultados para cada oración\n",
        "    print(f\"Frase: {sent.text}\")\n",
        "    print(f\"Sujeto: {sujeto}\")\n",
        "    print(f\"Raíz: {raiz}\")\n",
        "    print(f\"Complementos directos: {complementos_directo}\")\n",
        "    print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBOKGD-YI8-0"
      },
      "source": [
        "# Ejercicio a resolver\n",
        "\n",
        "Cargar el fichero P3_frases.csv y crear nuevas columnas obteniendo los adjetivos, los nombres comunes, verbos y nombres propios usando un análisis morfológico hecho con SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "NOtdoqA4I8XO",
        "outputId": "3ec1c0c2-95bd-4ce2-ad47-55a4a6faae10"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frase</th>\n",
              "      <th>adjetivos</th>\n",
              "      <th>nombres_comunes</th>\n",
              "      <th>verbos</th>\n",
              "      <th>nombres_propios</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La prima de María duerme en el sofá de su casa.</td>\n",
              "      <td>[]</td>\n",
              "      <td>[prima, sofá, casa]</td>\n",
              "      <td>[duerme]</td>\n",
              "      <td>[María]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>La pequeña panadería de la esquina vende pan r...</td>\n",
              "      <td>[pequeña, horneado]</td>\n",
              "      <td>[panadería, esquina, pan]</td>\n",
              "      <td>[vende]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>El hermano mayor de Juan compra una bicicleta ...</td>\n",
              "      <td>[mayor, nueva]</td>\n",
              "      <td>[hermano, bicicleta]</td>\n",
              "      <td>[compra]</td>\n",
              "      <td>[Juan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Los dos perros de mi vecino corren por el jard...</td>\n",
              "      <td>[trasero]</td>\n",
              "      <td>[perros, vecino, jardín]</td>\n",
              "      <td>[corren]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>El amable profesor de ciencias explica los con...</td>\n",
              "      <td>[amable, complejos]</td>\n",
              "      <td>[profesor, ciencias, conceptos]</td>\n",
              "      <td>[explica]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Frase            adjetivos  \\\n",
              "0    La prima de María duerme en el sofá de su casa.                   []   \n",
              "1  La pequeña panadería de la esquina vende pan r...  [pequeña, horneado]   \n",
              "2  El hermano mayor de Juan compra una bicicleta ...       [mayor, nueva]   \n",
              "3  Los dos perros de mi vecino corren por el jard...            [trasero]   \n",
              "4  El amable profesor de ciencias explica los con...  [amable, complejos]   \n",
              "\n",
              "                   nombres_comunes     verbos nombres_propios  \n",
              "0              [prima, sofá, casa]   [duerme]         [María]  \n",
              "1        [panadería, esquina, pan]    [vende]              []  \n",
              "2             [hermano, bicicleta]   [compra]          [Juan]  \n",
              "3         [perros, vecino, jardín]   [corren]              []  \n",
              "4  [profesor, ciencias, conceptos]  [explica]              []  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carga el archivo CSV\n",
        "try:\n",
        "    df = pd.read_csv(data_dir_path + 'P3_frases.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: El archivo 'frases.csv' no se encontró.\")\n",
        "    exit()\n",
        "\n",
        "# Inicializa nuevas columnas en el DataFrame con listas vacías\n",
        "df['adjetivos'] = [[] for _ in range(len(df))]\n",
        "df['nombres_comunes'] = [[] for _ in range(len(df))]\n",
        "df['verbos'] = [[] for _ in range(len(df))]\n",
        "df['nombres_propios'] = [[] for _ in range(len(df))]\n",
        "\n",
        "# Procesa cada frase en el DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    doc = nlp_es(row['Frase'])  # Accede a la columna 'Frase' correctamente\n",
        "    adjetivos = [token.text for token in doc if token.pos_ == 'ADJ']\n",
        "    nombres_comunes = [token.text for token in doc if token.pos_ == 'NOUN']\n",
        "    verbos = [token.text for token in doc if token.pos_ == 'VERB']\n",
        "    nombres_propios = [token.text for token in doc if token.pos_ == 'PROPN']\n",
        "\n",
        "    # Guarda el DataFrame actualizado\n",
        "    df.at[index, 'adjetivos'] = adjetivos\n",
        "    df.at[index, 'nombres_comunes'] = nombres_comunes\n",
        "    df.at[index, 'verbos'] = verbos\n",
        "    df.at[index, 'nombres_propios'] = nombres_propios\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIu8M6An8R3z"
      },
      "source": [
        "## Ejercicio a resolver 2\n",
        "\n",
        "Crea nuevas columnas en el dataframe de las frases en español con el root, el sujeto y el objeto directo de cada frase del dataframe usando spaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "OJAEXves5d8a",
        "outputId": "0c9bcc26-9358-48fd-d9c5-fcfe34697539"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frase</th>\n",
              "      <th>adjetivos</th>\n",
              "      <th>nombres_comunes</th>\n",
              "      <th>verbos</th>\n",
              "      <th>nombres_propios</th>\n",
              "      <th>sujetos</th>\n",
              "      <th>raices</th>\n",
              "      <th>objetos_directos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La prima de María duerme en el sofá de su casa.</td>\n",
              "      <td>[]</td>\n",
              "      <td>[prima, sofá, casa]</td>\n",
              "      <td>[duerme]</td>\n",
              "      <td>[María]</td>\n",
              "      <td>[prima]</td>\n",
              "      <td>[duerme]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>La pequeña panadería de la esquina vende pan r...</td>\n",
              "      <td>[pequeña, horneado]</td>\n",
              "      <td>[panadería, esquina, pan]</td>\n",
              "      <td>[vende]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[panadería]</td>\n",
              "      <td>[vende]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>El hermano mayor de Juan compra una bicicleta ...</td>\n",
              "      <td>[mayor, nueva]</td>\n",
              "      <td>[hermano, bicicleta]</td>\n",
              "      <td>[compra]</td>\n",
              "      <td>[Juan]</td>\n",
              "      <td>[hermano]</td>\n",
              "      <td>[compra]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Los dos perros de mi vecino corren por el jard...</td>\n",
              "      <td>[trasero]</td>\n",
              "      <td>[perros, vecino, jardín]</td>\n",
              "      <td>[corren]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[perros]</td>\n",
              "      <td>[corren]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>El amable profesor de ciencias explica los con...</td>\n",
              "      <td>[amable, complejos]</td>\n",
              "      <td>[profesor, ciencias, conceptos]</td>\n",
              "      <td>[explica]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[amable]</td>\n",
              "      <td>[explica]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Frase            adjetivos  \\\n",
              "0    La prima de María duerme en el sofá de su casa.                   []   \n",
              "1  La pequeña panadería de la esquina vende pan r...  [pequeña, horneado]   \n",
              "2  El hermano mayor de Juan compra una bicicleta ...       [mayor, nueva]   \n",
              "3  Los dos perros de mi vecino corren por el jard...            [trasero]   \n",
              "4  El amable profesor de ciencias explica los con...  [amable, complejos]   \n",
              "\n",
              "                   nombres_comunes     verbos nombres_propios      sujetos  \\\n",
              "0              [prima, sofá, casa]   [duerme]         [María]      [prima]   \n",
              "1        [panadería, esquina, pan]    [vende]              []  [panadería]   \n",
              "2             [hermano, bicicleta]   [compra]          [Juan]    [hermano]   \n",
              "3         [perros, vecino, jardín]   [corren]              []     [perros]   \n",
              "4  [profesor, ciencias, conceptos]  [explica]              []     [amable]   \n",
              "\n",
              "      raices objetos_directos  \n",
              "0   [duerme]               []  \n",
              "1    [vende]               []  \n",
              "2   [compra]               []  \n",
              "3   [corren]               []  \n",
              "4  [explica]               []  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializa nuevas columnas en el DataFrame con listas vacías\n",
        "df['sujetos'] = [[] for _ in range(len(df))]\n",
        "df['raices'] = [[] for _ in range(len(df))]\n",
        "df['objetos_directos'] = [[] for _ in range(len(df))]\n",
        "\n",
        "# Procesa cada frase en el DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    doc = nlp_es(row['Frase'])  # Accede a la columna 'Frase' correctamente\n",
        "    \n",
        "    sujetos = [token.text for token in doc if token.dep_ == 'nsubj']\n",
        "    raices = [token.text for token in doc if token.dep_ == 'ROOT']\n",
        "    objetos_directos = [token.text for token in doc if token.dep_ == 'dobj']\n",
        "\n",
        "    # Guarda el DataFrame actualizado\n",
        "    df.at[index, 'sujetos'] = sujetos\n",
        "    df.at[index, 'raices'] = raices\n",
        "    df.at[index, 'objetos_directos'] = objetos_directos\n",
        "\n",
        "df.head()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
