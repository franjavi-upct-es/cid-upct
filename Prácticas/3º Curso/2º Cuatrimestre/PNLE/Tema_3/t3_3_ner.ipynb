{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKpHNHF9pAnM"
   },
   "source": [
    "# 4- Reconocimiento de entidades con Stanza y Spacy\n",
    "\n",
    "Stanza y spaCy son APIs que proporcionan sevicios de PLN organizados en tuberías o Pipelines. Ya las hemos visto en la práctica anterior\n",
    "\n",
    "Lo primero que haremos será instalar Stanza y spaCy y descargar el modelo en español e inglés. Tened en cuenta que se pueden descargar modelos en distintos idiomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d5db4fa9b871465881870ecbfe78f4a4",
      "9882043ef9f74dd5ba67ce98330f490a",
      "d8daa2aab236415ab8d4a1fc68d00787",
      "da4b7a28246f46b6b5a3757518c70eec",
      "ef3138a2f23d44a592d105ca4ee7094a",
      "f9c3357c4796479fb8558dbcc1e72825",
      "6c214e9c845941fe89fddcf962035abc",
      "11bf85ce528d4d76a7ced23424f6b700",
      "49604e818b604f1796826bc5da17840c",
      "8abf19aeee4c49f3bf4ee18c2cc2e142",
      "676e46753b134fe389723beb3140a530",
      "8c820b22eb0441eb99fc22c56eb241f0",
      "f23847546747431eb73bc3b54f2ced1e",
      "ab884a02956a4a0f8f5c4135050031ac",
      "a18007f0f3c24a7eb07c6ff7828e318b",
      "630718fed76a42e3afba4de31c48addd",
      "da5fbf84805347c6b23c65c0f8bcf5e2",
      "11b45e6a94a94492b88f136b4d2ce5ed",
      "a49c81183a8c49fc9170812b8188afc1",
      "77aaf090918947f6b35bf753a837ca3a",
      "748bac112ba946f984e77a93dee38472",
      "e216e30d248c4e1680ede551715a8b1a",
      "5558e7e2585e41db88c2bc0b5b398326",
      "db86a956dc24456d9980a8312add3cde",
      "d25488745b494f09bdb392bcbe4291a9",
      "1485a2940add4a9fa7b47c4beea7bf15",
      "5d0af031c247433c8580a7bd5f290b4e",
      "1e7d18eac0b54a789a9fadbd5b27d0e0",
      "a958d6fea19e4831b35b6bef5a5a0440",
      "c69b46005c1f4c7984796361f2c17340",
      "f98c7994e6934975967818f3d10f7a07",
      "083917c362f5492089cb4ffa01f58c3a",
      "a8969f2818114c87bffad4ca79d7463f",
      "97520452785942309d95328ea211d65e",
      "a70554b0a70f438ca42ea3b4e699345a",
      "29f7393564ab49beabdf43d1cae9410a",
      "583c1f5462f44cc4bf3be3636073b53d",
      "94a31ef03eb44dc6ba7334e85ad4a9d3",
      "be1064f962574486897f7b81525e0a2d",
      "09251bcb2db744ecb08cd243ca6d5a36",
      "7b4cfaee84d148eea513ac5e2646d7df",
      "0d80e6ea4f8f4f168d9210a13238aba9",
      "24c9ff8da9504c5695fdda04432f21b4",
      "06d02b98aea94b70922b5ddb50fac2fd"
     ]
    },
    "executionInfo": {
     "elapsed": 169493,
     "status": "ok",
     "timestamp": 1740566088735,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "-mn79_2fpAIH",
    "outputId": "253be873-15ad-4f11-e321-8d45cb7000c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.10.1)\n",
      "Requirement already satisfied: emoji in /usr/local/python/3.12.1/lib/python3.12/site-packages (from stanza) (2.14.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from stanza) (2.2.0)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from stanza) (5.29.3)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from stanza) (2.32.3)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from stanza) (3.2.1)\n",
      "Requirement already satisfied: torch>=1.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from stanza) (2.5.1+cpu)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from stanza) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.3.0->stanza) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.3.0->stanza) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.3.0->stanza) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.3.0->stanza) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->stanza) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->stanza) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->stanza) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->stanza) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
      "Requirement already satisfied: spacy in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (2.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (75.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/python/3.12.1/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 159MB/s]                     \n",
      "2025-03-06 11:04:09 INFO: Downloaded file to /home/codespace/stanza_resources/resources.json\n",
      "2025-03-06 11:04:09 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2025-03-06 11:04:10 INFO: File exists: /home/codespace/stanza_resources/es/default.zip\n",
      "2025-03-06 11:04:17 INFO: Finished downloading models and saved to /home/codespace/stanza_resources\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 134MB/s]                     \n",
      "2025-03-06 11:04:17 INFO: Downloaded file to /home/codespace/stanza_resources/resources.json\n",
      "2025-03-06 11:04:17 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-03-06 11:04:23 INFO: File exists: /home/codespace/stanza_resources/en/default.zip\n",
      "2025-03-06 11:04:29 INFO: Finished downloading models and saved to /home/codespace/stanza_resources\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza\n",
    "import stanza\n",
    "\n",
    "!pip install spacy\n",
    "!python3 -m spacy download es_core_news_sm\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "\n",
    "stanza.download('es')\n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHlh-aD9mVi0"
   },
   "source": [
    "## 4.1 Reconocimiento de entidades en español con Stanza\n",
    "\n",
    "La librería Stanza proporciona un modelo de reconocimiento de entidades (**Named entity reconginition - NER**) cuando definimos un pipeline. Para ello hay que poner como proceso *ner*. Para mostrar únicamente las entidades de cada frase que se encuentran en la colección *ents* de *sentence*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867,
     "referenced_widgets": [
      "140be48e1b6a43fc9d7362fedb79009f",
      "5d9da5316bea40febb710b383f500fe6",
      "0cfcdd0b6f054428b42928586d3f35d7",
      "5c7126cac1574f1c84feb03e69f0fd4b",
      "ab245ca420194f68af0322160e605ec9",
      "0d062507bff7463ebaed71e1b6716667",
      "c8f2d66df7494561a957eaef334aabaf",
      "1afc985013b948f6a9245de8942f2673",
      "284063db514d446cb5de92b6c4c3c22d",
      "7f2f3029de3c4f68ace9560d193258d4",
      "d6ab82410102405498fc4f4bb6c29cba"
     ]
    },
    "executionInfo": {
     "elapsed": 15107,
     "status": "ok",
     "timestamp": 1740566109072,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "oJaXD-rbieCi",
    "outputId": "7f4dbc4b-e02b-4155-de50-459f6d0d5dde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 11:04:29 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 138MB/s]                     \n",
      "2025-03-06 11:04:29 INFO: Downloaded file to /home/codespace/stanza_resources/resources.json\n",
      "2025-03-06 11:04:34 INFO: Loading these models for language: es (Spanish):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "| ner       | conll02  |\n",
      "========================\n",
      "\n",
      "2025-03-06 11:04:34 INFO: Using device: cpu\n",
      "2025-03-06 11:04:34 INFO: Loading: tokenize\n",
      "2025-03-06 11:04:34 INFO: Loading: mwt\n",
      "2025-03-06 11:04:34 INFO: Loading: ner\n",
      "2025-03-06 11:04:35 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Hugo Pérez come manzanas en la cocina de Telefónica a las 3:00 de la tarde.\n",
      "Hugo Pérez_PER Telefónica_ORG \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Ayer Sofía jugó al fútbol con Emma y Cristina con una pelota roja en Central Park.\n",
      "Sofía_PER Emma_PER Cristina_PER Central Park_LOC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "El padre de Marina tiene 56 años.\n",
      "Marina_PER \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "La Tierra gira alrededor del Sol.\n",
      "Tierra_MISC Sol_MISC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "El planeta Júpiter es el planeta más grande del Sistema Solar.\n",
      "Júpiter_MISC Sistema Solar_MISC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "El 1 de septiembre George ganó 1 dólar mientras veía Juego de Tronos.\n",
      "George_PER Juego de Tronos_MISC \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Hugo Pérez come manzanas en la cocina de Telefónica a las 3:00 de la tarde.\n",
    "\n",
    "Ayer Sofía jugó al fútbol con Emma y Cristina con una pelota roja en Central Park.\n",
    "\n",
    "El padre de Marina tiene 56 años.\n",
    "\n",
    "La Tierra gira alrededor del Sol.\n",
    "\n",
    "El planeta Júpiter es el planeta más grande del Sistema Solar.\n",
    "\n",
    "El 1 de septiembre George ganó 1 dólar mientras veía Juego de Tronos.\"\"\"\n",
    "\n",
    "pipelineStanza = stanza.Pipeline(lang='es', processors= 'tokenize, mwt, ner')\n",
    "stanzaDoc = pipelineStanza(text)\n",
    "\n",
    "for sentence in stanzaDoc.sentences:\n",
    "  print(\"Frase\")\n",
    "  print(\"=====\"*50)\n",
    "  print(sentence.text)\n",
    "  entidades = \"\"\n",
    "  for ent in sentence.entities:\n",
    "    entidades = entidades + ent.text +\"_\" +ent.type+\" \"\n",
    "  print(entidades+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmXkzyrtzVmf"
   },
   "source": [
    "## 4.2 Reconocimiento de entidades en inglés con Stanza\n",
    "\n",
    "En inglés existen muchos más tipos de entidades que en español como por ejemplo TIME o DATE.\n",
    "\n",
    "Los modelos de NER por idiomas están descritos en esta página.\n",
    "https://stanfordnlp.github.io/stanza/ner_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867,
     "referenced_widgets": [
      "88468521f43d435da532231a4d56b79b",
      "4cc5834a0c1e47779dcc56aa05f2db0a",
      "c931c2392c3f4bf8afa5b80faef010c3",
      "d03882cfec7d42e2b5be6497604b2818",
      "55d52fb05d8943e1976bcb880ee66dec",
      "42640b5adc48448d8957e6123893c01c",
      "005deb67bfd144da88706a06e7a12c38",
      "ee7f9acbb5764b34bda99c0cdee4ddfe",
      "44444ec1b03a439392c70b44f41fa5e3",
      "c23affdb3f1b42a2a78ec04ecd086a02",
      "000b206e18154af295b8b8a8a0ffe857"
     ]
    },
    "executionInfo": {
     "elapsed": 8347,
     "status": "ok",
     "timestamp": 1740566123092,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "gtIa6W2rygrG",
    "outputId": "e41aaf63-e78e-4e90-f474-7695340544cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 11:04:36 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 136MB/s]                     \n",
      "2025-03-06 11:04:36 INFO: Downloaded file to /home/codespace/stanza_resources/resources.json\n",
      "2025-03-06 11:04:36 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2025-03-06 11:04:36 INFO: Using device: cpu\n",
      "2025-03-06 11:04:36 INFO: Loading: tokenize\n",
      "2025-03-06 11:04:36 INFO: Loading: mwt\n",
      "2025-03-06 11:04:36 INFO: Loading: ner\n",
      "2025-03-06 11:04:40 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Hugo Pérez eats apples in the Telefónica kitchen at 3:00 pm.\n",
      "Hugo Pérez_PERSON Telefónica_ORG 3:00 pm_TIME \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Yesterday Sofía played football with Emma and Cristina with a red ball in Central Park.\n",
      "Yesterday_DATE Sofía_PERSON Emma_PERSON Cristina_PERSON Central Park_LOC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Marina's father is 56 years old.\n",
      "Marina's_PERSON 56 years old_DATE \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "The Earth revolves around the Sun.\n",
      "Earth_LOC Sun_LOC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "The planet Jupiter is the largest planet in the Solar System.\n",
      "Jupiter_LOC the Solar System_LOC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "On September 1st George won 1 dollar while watching Game of Thrones.\n",
      "September 1st_DATE George_PERSON 1 dollar_MONEY Game of Thrones_WORK_OF_ART \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_en = \"\"\"Hugo Pérez eats apples in the Telefónica kitchen at 3:00 pm.\n",
    "\n",
    "Yesterday Sofía played football with Emma and Cristina with a red ball in Central Park.\n",
    "\n",
    "Marina's father is 56 years old.\n",
    "\n",
    "The Earth revolves around the Sun.\n",
    "\n",
    "The planet Jupiter is the largest planet in the Solar System.\n",
    "\n",
    "On September 1st George won 1 dollar while watching Game of Thrones.\"\"\"\n",
    "\n",
    "pipelineStanza = stanza.Pipeline(lang='en', processors= 'tokenize, mwt, ner')\n",
    "stanzaDoc = pipelineStanza(text_en)\n",
    "\n",
    "for sentence in stanzaDoc.sentences:\n",
    "  print(\"Frase\")\n",
    "  print(\"=====\"*50)\n",
    "  print(sentence.text)\n",
    "  entidades = \"\"\n",
    "  for ent in sentence.entities:\n",
    "    entidades = entidades + ent.text +\"_\" +ent.type+\" \"\n",
    "  print(entidades+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQ_2Dtbc2VQC"
   },
   "source": [
    "## 4.3 Reconocimiento de entidades en español con spaCy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2047,
     "status": "ok",
     "timestamp": 1740566129123,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "fxVaUouC2ZR_",
    "outputId": "0cdd5dbe-8c0b-49f1-ad1a-f200d9ea14da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Hugo Pérez come manzanas en la cocina de Telefónica a las 3:00 de la tarde.\n",
      "Hugo Pérez_PER Telefónica_LOC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Ayer Sofía jugó al fútbol con Emma y Cristina con una pelota roja en Central Park.\n",
      "Ayer Sofía_PER Emma_PER Cristina_PER Central Park_LOC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "El padre de Marina tiene 56 años.\n",
      "El padre de Marina_MISC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "La Tierra gira alrededor del Sol.\n",
      "La Tierra_LOC Sol_MISC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "El planeta Júpiter es el planeta más grande del Sistema Solar.\n",
      "El planeta Júpiter_MISC Sistema Solar_LOC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "El 1 de septiembre George ganó 1 dólar mientras veía Juego de Tronos.\n",
      "George_PER Juego de Tronos_MISC \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargamos el modelo de lenguaje en español\n",
    "nlp_es = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Procesar el texto con spaCy\n",
    "spaCyDoc = nlp_es(text)\n",
    "\n",
    "for sentence in spaCyDoc.sents:\n",
    "  print(\"Frase\")\n",
    "  print(\"=====\"*50)\n",
    "  print(sentence.text.strip())\n",
    "  entidades = \"\"\n",
    "  for ent in sentence.ents:\n",
    "    entidades = entidades + ent.text +\"_\" +ent.label_+\" \"\n",
    "  print(entidades+\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVx1VxgN3uE1"
   },
   "source": [
    "## 4.4 Reconocimiento de entidades en inglés con spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1740566133828,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "tUieO3hE3tyq",
    "outputId": "1eb56c41-9f7c-49bf-e8a7-4e1b991cd872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Hugo Pérez eats apples in the Telefónica kitchen at 3:00 pm.\n",
      "Hugo Pérez_PERSON Telefónica_PRODUCT 3:00 pm_TIME \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Yesterday Sofía played football with Emma and Cristina with a red ball in Central Park.\n",
      "Yesterday_DATE Sofía_ORG Emma_PERSON Cristina_GPE Central Park_LOC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Marina's father is 56 years old.\n",
      "Marina_LOC 56 years old_DATE \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "The Earth revolves around the Sun.\n",
      "Earth_LOC Sun_LOC \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "The planet Jupiter is the largest planet in the Solar System.\n",
      "Jupiter_LOC the Solar System_ORG \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "On September 1st\n",
      "September 1st_DATE \n",
      "\n",
      "Frase\n",
      "==========================================================================================================================================================================================================================================================\n",
      "George won 1 dollar while watching Game of Thrones.\n",
      "1 dollar_MONEY Thrones_ORG \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargamos el modelo de lenguaje en español\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Procesar el texto con spaCy\n",
    "spaCyDoc_en = nlp_en(text_en)\n",
    "\n",
    "for sentence in spaCyDoc_en.sents:\n",
    "  print(\"Frase\")\n",
    "  print(\"=====\"*50)\n",
    "  print(sentence.text.strip())\n",
    "  entidades = \"\"\n",
    "  for ent in sentence.ents:\n",
    "    entidades = entidades + ent.text +\"_\" +ent.label_+\" \"\n",
    "  print(entidades+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwysugBdXB72"
   },
   "source": [
    "## 4.5 Ejercicio a resolver\n",
    "\n",
    "Cargar el archivo P3_frases.csv y extraer todas las entidades del mismo usando Stanza y spaCy. Las frases del fichero están en español.\n",
    "\n",
    "Guardar todos los resultados en dos columnas. La primera columna serían todas las entidades detectadas con Stanza indicando el tipo de entidad y la segunda columna debe contener todas las entidades detectadas con spaCy indicando también su tipo de entidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733,
     "referenced_widgets": [
      "d3681d59d3d44375a5365734fec69dc5",
      "80d9d43357844e88b28572f009bb28fb",
      "45cbb073803b4fe780f97ce831e83d8c",
      "2b4f25d0f227499aba1c7a4a3f8f7be5",
      "7c714ab98c514f778f540a9dc2a3b1a7",
      "2e5a32ae35f94ac293176e497c200e14",
      "8dee094870fc4f5fa6ea6436caab22df",
      "ef1e8585935342c5a7a50459da0c0b99",
      "a3633eb3ab7a4a04a2c19263f6637d1b",
      "7c950a7dcf484118ad0e2c44f26f9f40",
      "97b08b039c764800b4788fa7314220ee"
     ]
    },
    "executionInfo": {
     "elapsed": 51305,
     "status": "ok",
     "timestamp": 1740569897495,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "ApCBkhH_oXHi",
    "outputId": "0a6c7c22-de6f-43d3-86a9-ae70416f5e01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 153MB/s]                     \n",
      "2025-03-06 11:24:00 INFO: Downloaded file to /home/codespace/stanza_resources/resources.json\n",
      "2025-03-06 11:24:00 INFO: Downloading default packages for language: es (Spanish) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 11:24:02 INFO: File exists: /home/codespace/stanza_resources/es/default.zip\n",
      "2025-03-06 11:24:13 INFO: Finished downloading models and saved to /home/codespace/stanza_resources\n",
      "2025-03-06 11:24:13 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 137MB/s]                     \n",
      "2025-03-06 11:24:13 INFO: Downloaded file to /home/codespace/stanza_resources/resources.json\n",
      "2025-03-06 11:24:13 WARNING: Language es package default expects mwt, which has been added\n",
      "2025-03-06 11:24:14 INFO: Loading these models for language: es (Spanish):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "| ner       | conll02  |\n",
      "========================\n",
      "\n",
      "2025-03-06 11:24:14 INFO: Using device: cpu\n",
      "2025-03-06 11:24:14 INFO: Loading: tokenize\n",
      "2025-03-06 11:24:14 INFO: Loading: mwt\n",
      "2025-03-06 11:24:14 INFO: Loading: ner\n",
      "2025-03-06 11:24:17 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frase</th>\n",
       "      <th>Entidades Stanza</th>\n",
       "      <th>Entidades spaCy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La prima de María duerme en el sofá de su casa.</td>\n",
       "      <td>[(María, PER)]</td>\n",
       "      <td>[(María, PER), (sofá, LOC)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La pequeña panadería de la esquina vende pan r...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El hermano mayor de Juan compra una bicicleta ...</td>\n",
       "      <td>[(Juan, PER)]</td>\n",
       "      <td>[(Juan, PER)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los dos perros de mi vecino corren por el jard...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El amable profesor de ciencias explica los con...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Frase Entidades Stanza  \\\n",
       "0    La prima de María duerme en el sofá de su casa.   [(María, PER)]   \n",
       "1  La pequeña panadería de la esquina vende pan r...               []   \n",
       "2  El hermano mayor de Juan compra una bicicleta ...    [(Juan, PER)]   \n",
       "3  Los dos perros de mi vecino corren por el jard...               []   \n",
       "4  El amable profesor de ciencias explica los con...               []   \n",
       "\n",
       "               Entidades spaCy  \n",
       "0  [(María, PER), (sofá, LOC)]  \n",
       "1                           []  \n",
       "2                [(Juan, PER)]  \n",
       "3                           []  \n",
       "4                           []  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "import spacy\n",
    "import os\n",
    "\n",
    "data_dir_path = os.path.join(os.getcwd(), \"Datos/\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_dir_path + 'P3_frases.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'P3_frases.csv' no se encontró.\")\n",
    "    exit()\n",
    "\n",
    "# Inicializamos Stanza y spaCy\n",
    "stanza.download('es')\n",
    "nlp_stanza = stanza.Pipeline('es', processors='tokenize,ner')\n",
    "nlp_spacy = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Función para extraer entidades con Stanza\n",
    "def extract_entities_stanza(text):\n",
    "    doc = nlp_stanza(text)\n",
    "    entities = [(ent.text, ent.type) for ent in doc.entities]\n",
    "    return entities\n",
    "\n",
    "# Función para extraer entidades con spaCy\n",
    "def extract_entities_spacy(text):\n",
    "    doc = nlp_spacy(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "# Creamos nuevas columnas en el DataFrame para las entidades\n",
    "df['Entidades Stanza'] = df['Frase'].apply(lambda x: extract_entities_stanza(x))\n",
    "df['Entidades spaCy'] = df['Frase'].apply(lambda x: extract_entities_spacy(x))\n",
    "\n",
    "# Mostramos el DataFrame con las nuevas columnas\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
