{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKpHNHF9pAnM"
   },
   "source": [
    "# 4- Reconocimiento de entidades con Stanza y Spacy\n",
    "\n",
    "Stanza y spaCy son APIs que proporcionan sevicios de PLN organizados en tuberías o Pipelines. Ya las hemos visto en la práctica anterior\n",
    "\n",
    "Lo primero que haremos será instalar Stanza y spaCy y descargar el modelo en español e inglés. Tened en cuenta que se pueden descargar modelos en distintos idiomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d5db4fa9b871465881870ecbfe78f4a4",
      "9882043ef9f74dd5ba67ce98330f490a",
      "d8daa2aab236415ab8d4a1fc68d00787",
      "da4b7a28246f46b6b5a3757518c70eec",
      "ef3138a2f23d44a592d105ca4ee7094a",
      "f9c3357c4796479fb8558dbcc1e72825",
      "6c214e9c845941fe89fddcf962035abc",
      "11bf85ce528d4d76a7ced23424f6b700",
      "49604e818b604f1796826bc5da17840c",
      "8abf19aeee4c49f3bf4ee18c2cc2e142",
      "676e46753b134fe389723beb3140a530",
      "8c820b22eb0441eb99fc22c56eb241f0",
      "f23847546747431eb73bc3b54f2ced1e",
      "ab884a02956a4a0f8f5c4135050031ac",
      "a18007f0f3c24a7eb07c6ff7828e318b",
      "630718fed76a42e3afba4de31c48addd",
      "da5fbf84805347c6b23c65c0f8bcf5e2",
      "11b45e6a94a94492b88f136b4d2ce5ed",
      "a49c81183a8c49fc9170812b8188afc1",
      "77aaf090918947f6b35bf753a837ca3a",
      "748bac112ba946f984e77a93dee38472",
      "e216e30d248c4e1680ede551715a8b1a",
      "5558e7e2585e41db88c2bc0b5b398326",
      "db86a956dc24456d9980a8312add3cde",
      "d25488745b494f09bdb392bcbe4291a9",
      "1485a2940add4a9fa7b47c4beea7bf15",
      "5d0af031c247433c8580a7bd5f290b4e",
      "1e7d18eac0b54a789a9fadbd5b27d0e0",
      "a958d6fea19e4831b35b6bef5a5a0440",
      "c69b46005c1f4c7984796361f2c17340",
      "f98c7994e6934975967818f3d10f7a07",
      "083917c362f5492089cb4ffa01f58c3a",
      "a8969f2818114c87bffad4ca79d7463f",
      "97520452785942309d95328ea211d65e",
      "a70554b0a70f438ca42ea3b4e699345a",
      "29f7393564ab49beabdf43d1cae9410a",
      "583c1f5462f44cc4bf3be3636073b53d",
      "94a31ef03eb44dc6ba7334e85ad4a9d3",
      "be1064f962574486897f7b81525e0a2d",
      "09251bcb2db744ecb08cd243ca6d5a36",
      "7b4cfaee84d148eea513ac5e2646d7df",
      "0d80e6ea4f8f4f168d9210a13238aba9",
      "24c9ff8da9504c5695fdda04432f21b4",
      "06d02b98aea94b70922b5ddb50fac2fd"
     ]
    },
    "executionInfo": {
     "elapsed": 169493,
     "status": "ok",
     "timestamp": 1740566088735,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "-mn79_2fpAIH",
    "outputId": "253be873-15ad-4f11-e321-8d45cb7000c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stanza in /var/mobile/Containers/Data/Application/57358D79-36BC-482C-998D-15CAC97E81E9/Library/lib/python3.11/site-packages (0.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.3.tar.gz (1.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 1.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [349 lines of output]\n",
      "      Copied /private/var/mobile/Containers/Data/Application/57358D79-36BC-482C-998D-15CAC97E81E9/tmp/pip-install-vkqsh40s/spacy_8441c715324e4737aaf2f098d7f3e14f/setup.cfg -> /private/var/mobile/Containers/Data/Application/57358D79-36BC-482C-998D-15CAC97E81E9/tmp/pip-install-vkqsh40s/spacy_8441c715324e4737aaf2f098d7f3e14f/spacy/tests/package\n",
      "      Copied /private/var/mobile/Containers/Data/Application/57358D79-36BC-482C-998D-15CAC97E81E9/tmp/pip-install-vkqsh40s/spacy_8441c715324e4737aaf2f098d7f3e14f/pyproject.toml -> /private/var/mobile/Containers/Data/Application/57358D79-36BC-482C-998D-15CAC97E81E9/tmp/pip-install-vkqsh40s/spacy_8441c715324e4737aaf2f098d7f3e14f/spacy/tests/package\n",
      "      Cythonizing sources\n",
      "      Compiling spacy/matcher/levenshtein.pyx because it changed.\n",
      "      Compiling spacy/training/alignment_array.pyx because it changed.\n",
      "      Compiling spacy/training/example.pyx because it changed.\n",
      "      Compiling spacy/parts_of_speech.pyx because it changed.\n",
      "      Compiling spacy/strings.pyx because it changed.\n",
      "      Compiling spacy/lexeme.pyx because it changed.\n",
      "      Compiling spacy/vocab.pyx because it changed.\n",
      "      Compiling spacy/attrs.pyx because it changed.\n",
      "      Compiling spacy/kb/candidate.pyx because it changed.\n",
      "      Compiling spacy/kb/kb.pyx because it changed.\n",
      "      Compiling spacy/kb/kb_in_memory.pyx because it changed.\n",
      "      Compiling spacy/ml/parser_model.pyx because it changed.\n",
      "      Compiling spacy/morphology.pyx because it changed.\n",
      "      Compiling spacy/pipeline/dep_parser.pyx because it changed.\n",
      "      Compiling spacy/pipeline/_edit_tree_internals/edit_trees.pyx because it changed.\n",
      "      Compiling spacy/pipeline/morphologizer.pyx because it changed.\n",
      "      Compiling spacy/pipeline/multitask.pyx because it changed.\n",
      "      Compiling spacy/pipeline/ner.pyx because it changed.\n",
      "      Compiling spacy/pipeline/pipe.pyx because it changed.\n",
      "      Compiling spacy/pipeline/trainable_pipe.pyx because it changed.\n",
      "      Compiling spacy/pipeline/sentencizer.pyx because it changed.\n",
      "      Compiling spacy/pipeline/senter.pyx because it changed.\n",
      "      Compiling spacy/pipeline/tagger.pyx because it changed.\n",
      "      Compiling spacy/pipeline/transition_parser.pyx because it changed.\n",
      "      Compiling spacy/pipeline/_parser_internals/arc_eager.pyx because it changed.\n",
      "      Compiling spacy/pipeline/_parser_internals/ner.pyx because it changed.\n",
      "      Compiling spacy/pipeline/_parser_internals/nonproj.pyx because it changed.\n",
      "      Compiling spacy/pipeline/_parser_internals/_state.pyx because it changed.\n",
      "      Compiling spacy/pipeline/_parser_internals/stateclass.pyx because it changed.\n",
      "      Compiling spacy/pipeline/_parser_internals/transition_system.pyx because it changed.\n",
      "      Compiling spacy/pipeline/_parser_internals/_beam_utils.pyx because it changed.\n",
      "      Compiling spacy/tokenizer.pyx because it changed.\n",
      "      Compiling spacy/training/align.pyx because it changed.\n",
      "      Compiling spacy/training/gold_io.pyx because it changed.\n",
      "      Compiling spacy/tokens/doc.pyx because it changed.\n",
      "      Compiling spacy/tokens/span.pyx because it changed.\n",
      "      Compiling spacy/tokens/token.pyx because it changed.\n",
      "      Compiling spacy/tokens/span_group.pyx because it changed.\n",
      "      Compiling spacy/tokens/graph.pyx because it changed.\n",
      "      Compiling spacy/tokens/morphanalysis.pyx because it changed.\n",
      "      Compiling spacy/tokens/_retokenize.pyx because it changed.\n",
      "      Compiling spacy/matcher/matcher.pyx because it changed.\n",
      "      Compiling spacy/matcher/phrasematcher.pyx because it changed.\n",
      "      Compiling spacy/matcher/dependencymatcher.pyx because it changed.\n",
      "      Compiling spacy/symbols.pyx because it changed.\n",
      "      Compiling spacy/vectors.pyx because it changed.\n",
      "      [ 1/46] Cythonizing spacy/attrs.pyx\n",
      "      [ 2/46] Cythonizing spacy/kb/candidate.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \"\"\"Knowledge-base for entity or concept linking.\"\"\"\n",
      "      \n",
      "      from cymem.cymem cimport Pool\n",
      "      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/kb/kb.pxd:3:0: 'cymem/cymem.pxd' not found\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \"\"\"Knowledge-base for entity or concept linking.\"\"\"\n",
      "      \n",
      "      from cymem.cymem cimport Pool\n",
      "      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/kb/kb.pxd:3:0: 'cymem/cymem/Pool.pxd' not found\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      from cymem.cymem cimport Pool\n",
      "      from libcpp.vector cimport vector\n",
      "      from murmurhash.mrmr cimport hash64\n",
      "      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:3:0: 'murmurhash/mrmr.pxd' not found\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      from cymem.cymem cimport Pool\n",
      "      from libcpp.vector cimport vector\n",
      "      from murmurhash.mrmr cimport hash64\n",
      "      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:3:0: 'murmurhash/mrmr/hash64.pxd' not found\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      from cymem.cymem cimport Pool\n",
      "      from libcpp.vector cimport vector\n",
      "      from murmurhash.mrmr cimport hash64\n",
      "      from preshed.maps cimport PreshMap\n",
      "      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:4:0: 'preshed/maps.pxd' not found\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      from cymem.cymem cimport Pool\n",
      "      from libcpp.vector cimport vector\n",
      "      from murmurhash.mrmr cimport hash64\n",
      "      from preshed.maps cimport PreshMap\n",
      "      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:4:0: 'preshed/maps/PreshMap.pxd' not found\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          unsigned char[8] s\n",
      "          unsigned char* p\n",
      "      \n",
      "      \n",
      "      cdef class StringStore:\n",
      "          cdef Pool mem\n",
      "               ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/strings.pxd:23:9: 'Pool' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "      cdef class StringStore:\n",
      "          cdef Pool mem\n",
      "      \n",
      "          cdef vector[hash_t] keys\n",
      "          cdef public PreshMap _map\n",
      "                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/strings.pxd:26:16: 'PreshMap' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "      cdef class StringStore:\n",
      "          cdef Pool mem\n",
      "      \n",
      "          cdef vector[hash_t] keys\n",
      "          cdef public PreshMap _map\n",
      "                               ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/strings.pxd:26:25: C attribute of type '<error>' cannot be accessed from Python\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          cdef public PreshMap _map\n",
      "      \n",
      "          cdef const Utf8Str* intern_unicode(self, str py_string, bint allow_transient)\n",
      "          cdef const Utf8Str* _intern_utf8(self, char* utf8_string, int length, hash_t* precalculated_hash, bint allow_transient)\n",
      "          cdef vector[hash_t] _transient_keys\n",
      "          cdef Pool _non_temp_mem\n",
      "               ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/strings.pxd:31:9: 'Pool' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      from .structs cimport MorphAnalysisC\n",
      "      from .typedefs cimport attr_t, hash_t\n",
      "      \n",
      "      \n",
      "      cdef class Morphology:\n",
      "          cdef readonly Pool mem\n",
      "                        ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/morphology.pxd:12:18: 'Pool' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      from .structs cimport MorphAnalysisC\n",
      "      from .typedefs cimport attr_t, hash_t\n",
      "      \n",
      "      \n",
      "      cdef class Morphology:\n",
      "          cdef readonly Pool mem\n",
      "                             ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/morphology.pxd:12:23: C attribute of type '<error>' cannot be accessed from Python\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "      \n",
      "      cdef class Morphology:\n",
      "          cdef readonly Pool mem\n",
      "          cdef readonly StringStore strings\n",
      "          cdef PreshMap tags  # Keyed by hash, value is pointer to tag\n",
      "               ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/morphology.pxd:14:9: 'PreshMap' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          bint is_lex\n",
      "          int length\n",
      "      \n",
      "      \n",
      "      cdef class Vocab:\n",
      "          cdef Pool mem\n",
      "               ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:27:9: 'Pool' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          cdef readonly int length\n",
      "          cdef public object _unused_object  # TODO remove in v4, see #9150\n",
      "          cdef public object lex_attr_getters\n",
      "          cdef public object cfg\n",
      "      \n",
      "          cdef const LexemeC* get(self, Pool mem, str string) except NULL\n",
      "                                        ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:39:34: 'Pool' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          cdef public object _unused_object  # TODO remove in v4, see #9150\n",
      "          cdef public object lex_attr_getters\n",
      "          cdef public object cfg\n",
      "      \n",
      "          cdef const LexemeC* get(self, Pool mem, str string) except NULL\n",
      "          cdef const LexemeC* get_by_orth(self, Pool mem, attr_t orth) except NULL\n",
      "                                                ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:40:42: 'Pool' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "          cdef const LexemeC* get(self, Pool mem, str string) except NULL\n",
      "          cdef const LexemeC* get_by_orth(self, Pool mem, attr_t orth) except NULL\n",
      "          cdef const TokenC* make_fused_token(self, substrings) except NULL\n",
      "      \n",
      "          cdef const LexemeC* _new_lexeme(self, Pool mem, str string) except NULL\n",
      "                                                ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:43:42: 'Pool' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          cdef const LexemeC* get_by_orth(self, Pool mem, attr_t orth) except NULL\n",
      "          cdef const TokenC* make_fused_token(self, substrings) except NULL\n",
      "      \n",
      "          cdef const LexemeC* _new_lexeme(self, Pool mem, str string) except NULL\n",
      "          cdef int _add_lex_to_vocab(self, hash_t key, const LexemeC* lex, bint is_transient) except -1\n",
      "          cdef const LexemeC* _new_lexeme(self, Pool mem, str string) except NULL\n",
      "                                                ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:45:42: 'Pool' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "          cdef const LexemeC* _new_lexeme(self, Pool mem, str string) except NULL\n",
      "          cdef int _add_lex_to_vocab(self, hash_t key, const LexemeC* lex, bint is_transient) except -1\n",
      "          cdef const LexemeC* _new_lexeme(self, Pool mem, str string) except NULL\n",
      "      \n",
      "          cdef PreshMap _by_orth\n",
      "               ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:47:9: 'PreshMap' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          cdef const LexemeC* _new_lexeme(self, Pool mem, str string) except NULL\n",
      "          cdef int _add_lex_to_vocab(self, hash_t key, const LexemeC* lex, bint is_transient) except -1\n",
      "          cdef const LexemeC* _new_lexeme(self, Pool mem, str string) except NULL\n",
      "      \n",
      "          cdef PreshMap _by_orth\n",
      "          cdef Pool _non_temp_mem\n",
      "               ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/vocab.pxd:48:9: 'Pool' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "      from ..vocab cimport Vocab\n",
      "      \n",
      "      \n",
      "      cdef class KnowledgeBase:\n",
      "          cdef Pool mem\n",
      "               ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      spacy/kb/kb.pxd:10:9: 'Pool' is not a type identifier\n",
      "      Traceback (most recent call last):\n",
      "        File \"/var/mobile/Containers/Data/Application/57358D79-36BC-482C-998D-15CAC97E81E9/Library/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "          main()\n",
      "        File \"/var/mobile/Containers/Data/Application/57358D79-36BC-482C-998D-15CAC97E81E9/Library/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "          json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"/var/mobile/Containers/Data/Application/57358D79-36BC-482C-998D-15CAC97E81E9/Library/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 175, in prepare_metadata_for_build_wheel\n",
      "          return hook(metadata_directory, config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"/private/var/containers/Bundle/Application/5B7C1DE0-E0FE-4CB9-BE3B-3970ED036C7F/Carnets-sci.app/Library/lib/python3.11/site-packages/setuptools/build_meta.py\", line 366, in prepare_metadata_for_build_wheel\n",
      "          self.run_setup()\n",
      "        File \"/private/var/containers/Bundle/Application/5B7C1DE0-E0FE-4CB9-BE3B-3970ED036C7F/Carnets-sci.app/Library/lib/python3.11/site-packages/setuptools/build_meta.py\", line 311, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 221, in <module>\n",
      "        File \"<string>\", line 208, in setup_package\n",
      "        File \"/private/var/containers/Bundle/Application/5B7C1DE0-E0FE-4CB9-BE3B-3970ED036C7F/Carnets-sci.app/Library/lib/python3.11/site-packages/Cython/Build/Dependencies.py\", line 1134, in cythonize\n",
      "          cythonize_one(*args)\n",
      "        File \"/private/var/containers/Bundle/Application/5B7C1DE0-E0FE-4CB9-BE3B-3970ED036C7F/Carnets-sci.app/Library/lib/python3.11/site-packages/Cython/Build/Dependencies.py\", line 1301, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: spacy/kb/candidate.pyx\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "python3: No module named spacy\n",
      "python3: No module named spacy\n",
      "\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'stanza' has no attribute 'download'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython3 -m spacy download es_core_news_sm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython3 -m spacy download en_core_web_sm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mstanza\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m stanza\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'stanza' has no attribute 'download'"
     ]
    }
   ],
   "source": [
    "!pip install stanza\n",
    "import stanza\n",
    "\n",
    "!pip install spacy\n",
    "!python3 -m spacy download es_core_news_sm\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "\n",
    "stanza.download('es')\n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHlh-aD9mVi0"
   },
   "source": [
    "## 4.1 Reconocimiento de entidades en español con Stanza\n",
    "\n",
    "La librería Stanza proporciona un modelo de reconocimiento de entidades (**Named entity reconginition - NER**) cuando definimos un pipeline. Para ello hay que poner como proceso *ner*. Para mostrar únicamente las entidades de cada frase que se encuentran en la colección *ents* de *sentence*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867,
     "referenced_widgets": [
      "140be48e1b6a43fc9d7362fedb79009f",
      "5d9da5316bea40febb710b383f500fe6",
      "0cfcdd0b6f054428b42928586d3f35d7",
      "5c7126cac1574f1c84feb03e69f0fd4b",
      "ab245ca420194f68af0322160e605ec9",
      "0d062507bff7463ebaed71e1b6716667",
      "c8f2d66df7494561a957eaef334aabaf",
      "1afc985013b948f6a9245de8942f2673",
      "284063db514d446cb5de92b6c4c3c22d",
      "7f2f3029de3c4f68ace9560d193258d4",
      "d6ab82410102405498fc4f4bb6c29cba"
     ]
    },
    "executionInfo": {
     "elapsed": 15107,
     "status": "ok",
     "timestamp": 1740566109072,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "oJaXD-rbieCi",
    "outputId": "7f4dbc4b-e02b-4155-de50-459f6d0d5dde"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Hugo Pérez come manzanas en la cocina de Telefónica a las 3:00 de la tarde.\n",
    "\n",
    "Ayer Sofía jugó al fútbol con Emma y Cristina con una pelota roja en Central Park.\n",
    "\n",
    "El padre de Marina tiene 56 años.\n",
    "\n",
    "La Tierra gira alrededor del Sol.\n",
    "\n",
    "El planeta Júpiter es el planeta más grande del Sistema Solar.\n",
    "\n",
    "El 1 de septiembre George ganó 1 dólar mientras veía Juego de Tronos.\"\"\"\n",
    "\n",
    "pipelineStanza = stanza.Pipeline(lang='es', processors= 'tokenize, mwt, ner')\n",
    "stanzaDoc = pipelineStanza(text)\n",
    "\n",
    "for sentence in stanzaDoc.sentences:\n",
    "  print(\"Frase\")\n",
    "  print(\"=====\"*50)\n",
    "  print(sentence.text)\n",
    "  entidades = \"\"\n",
    "  for ent in sentence.entities:\n",
    "    entidades = entidades + ent.text +\"_\" +ent.type+\" \"\n",
    "  print(entidades+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmXkzyrtzVmf"
   },
   "source": [
    "## 4.2 Reconocimiento de entidades en inglés con Stanza\n",
    "\n",
    "En inglés existen muchos más tipos de entidades que en español como por ejemplo TIME o DATE.\n",
    "\n",
    "Los modelos de NER por idiomas están descritos en esta página.\n",
    "https://stanfordnlp.github.io/stanza/ner_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867,
     "referenced_widgets": [
      "88468521f43d435da532231a4d56b79b",
      "4cc5834a0c1e47779dcc56aa05f2db0a",
      "c931c2392c3f4bf8afa5b80faef010c3",
      "d03882cfec7d42e2b5be6497604b2818",
      "55d52fb05d8943e1976bcb880ee66dec",
      "42640b5adc48448d8957e6123893c01c",
      "005deb67bfd144da88706a06e7a12c38",
      "ee7f9acbb5764b34bda99c0cdee4ddfe",
      "44444ec1b03a439392c70b44f41fa5e3",
      "c23affdb3f1b42a2a78ec04ecd086a02",
      "000b206e18154af295b8b8a8a0ffe857"
     ]
    },
    "executionInfo": {
     "elapsed": 8347,
     "status": "ok",
     "timestamp": 1740566123092,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "gtIa6W2rygrG",
    "outputId": "e41aaf63-e78e-4e90-f474-7695340544cb"
   },
   "outputs": [],
   "source": [
    "text_en = \"\"\"Hugo Pérez eats apples in the Telefónica kitchen at 3:00 pm.\n",
    "\n",
    "Yesterday Sofía played football with Emma and Cristina with a red ball in Central Park.\n",
    "\n",
    "Marina's father is 56 years old.\n",
    "\n",
    "The Earth revolves around the Sun.\n",
    "\n",
    "The planet Jupiter is the largest planet in the Solar System.\n",
    "\n",
    "On September 1st George won 1 dollar while watching Game of Thrones.\"\"\"\n",
    "\n",
    "pipelineStanza = stanza.Pipeline(lang='en', processors= 'tokenize, mwt, ner')\n",
    "stanzaDoc = pipelineStanza(text_en)\n",
    "\n",
    "for sentence in stanzaDoc.sentences:\n",
    "  print(\"Frase\")\n",
    "  print(\"=====\"*50)\n",
    "  print(sentence.text)\n",
    "  entidades = \"\"\n",
    "  for ent in sentence.entities:\n",
    "    entidades = entidades + ent.text +\"_\" +ent.type+\" \"\n",
    "  print(entidades+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQ_2Dtbc2VQC"
   },
   "source": [
    "##4.3 Reconocimiento de entidades en español con spaCy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2047,
     "status": "ok",
     "timestamp": 1740566129123,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "fxVaUouC2ZR_",
    "outputId": "0cdd5dbe-8c0b-49f1-ad1a-f200d9ea14da"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargamos el modelo de lenguaje en español\n",
    "nlp_es = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Procesar el texto con spaCy\n",
    "spaCyDoc = nlp_es(text)\n",
    "\n",
    "for sentence in spaCyDoc.sents:\n",
    "  print(\"Frase\")\n",
    "  print(\"=====\"*50)\n",
    "  print(sentence.text.strip())\n",
    "  entidades = \"\"\n",
    "  for ent in sentence.ents:\n",
    "    entidades = entidades + ent.text +\"_\" +ent.label_+\" \"\n",
    "  print(entidades+\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVx1VxgN3uE1"
   },
   "source": [
    "##4.4 Reconocimiento de entidades en inglés con spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1740566133828,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "tUieO3hE3tyq",
    "outputId": "1eb56c41-9f7c-49bf-e8a7-4e1b991cd872"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargamos el modelo de lenguaje en español\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Procesar el texto con spaCy\n",
    "spaCyDoc_en = nlp_en(text_en)\n",
    "\n",
    "for sentence in spaCyDoc_en.sents:\n",
    "  print(\"Frase\")\n",
    "  print(\"=====\"*50)\n",
    "  print(sentence.text.strip())\n",
    "  entidades = \"\"\n",
    "  for ent in sentence.ents:\n",
    "    entidades = entidades + ent.text +\"_\" +ent.label_+\" \"\n",
    "  print(entidades+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwysugBdXB72"
   },
   "source": [
    "##4.5 Ejercicio a resolver\n",
    "\n",
    "Cargar el archivo P4_frases.csv y extraer todas las entidades del mismo usando Stanza y spaCy. Las frases del fichero están en español.\n",
    "\n",
    "Guardar todos los resultados en dos columnas. La primera columna serían todas las entidades detectadas con Stanza indicando el tipo de entidad y la segunda columna debe contener todas las entidades detectadas con spaCy indicando también su tipo de entidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733,
     "referenced_widgets": [
      "d3681d59d3d44375a5365734fec69dc5",
      "80d9d43357844e88b28572f009bb28fb",
      "45cbb073803b4fe780f97ce831e83d8c",
      "2b4f25d0f227499aba1c7a4a3f8f7be5",
      "7c714ab98c514f778f540a9dc2a3b1a7",
      "2e5a32ae35f94ac293176e497c200e14",
      "8dee094870fc4f5fa6ea6436caab22df",
      "ef1e8585935342c5a7a50459da0c0b99",
      "a3633eb3ab7a4a04a2c19263f6637d1b",
      "7c950a7dcf484118ad0e2c44f26f9f40",
      "97b08b039c764800b4788fa7314220ee"
     ]
    },
    "executionInfo": {
     "elapsed": 51305,
     "status": "ok",
     "timestamp": 1740569897495,
     "user": {
      "displayName": "juan pastor",
      "userId": "09767725131573871922"
     },
     "user_tz": -60
    },
    "id": "ApCBkhH_oXHi",
    "outputId": "0a6c7c22-de6f-43d3-86a9-ae70416f5e01"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "import spacy\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_dir_path + 't3_frases_ner.csv', sep = '\\t', on_bad_lines='skip')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 't3_frases_ner.csv' no se encontró.\")\n",
    "    exit()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
