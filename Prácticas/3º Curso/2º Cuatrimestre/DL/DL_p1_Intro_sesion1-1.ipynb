{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7193a0",
   "metadata": {
    "papermill": {
     "duration": 0.034817,
     "end_time": "2024-09-10T18:50:25.913835",
     "exception": false,
     "start_time": "2024-09-10T18:50:25.879018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "        word-wrap: break-word;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div style=\"display:flex; justify-content:space-around; align-items:center; background-color:#cccccc; padding:5px; border:2px solid #333333;\">\n",
    "    <a href=\"https://estudios.upct.es/grado/5251/inicio\" target=\"_blank\">\n",
    "    <img src=\"https://www.upct.es/contenido/universidad/galeria/identidad-2021/logos/logos-upct/marca-upct/marca-principal/horizontal/azul.png\" alt=\"UPCT\" style=\"height:145px; width:auto;\">\n",
    "    <a href=\"https://www.um.es/web/estudios/grados/ciencia-ingenieria-datos/\" target=\"_blank\">\n",
    "    <img src=\"https://www.um.es/documents/1073494/42130150/LogosimboloUMU-positivo.png\" alt=\"UMU\" style=\"height:200px; width:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30c905",
   "metadata": {
    "papermill": {
     "duration": 0.006835,
     "end_time": "2024-09-10T18:50:25.928004",
     "exception": false,
     "start_time": "2024-09-10T18:50:25.921169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Asignatura: **Deep Learning**\n",
    "\n",
    "## Titulación: **Grado en Ciencia e Ingeniería de Datos**\n",
    "\n",
    "## Práctica 1: Introducción al Deep Learning\n",
    "### **Sesión 1/3: Implementación de modelos de aprendizaje automático**\n",
    "\n",
    "**Autores**: Juan Morales Sánchez, Antonio Martínez Sánchez, José Luís Sancho Gómez y Juan Antonio Botía Blaya\n",
    "\n",
    "___\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "- Familiarización con TensorFlow y Python para *Deep Learning*\n",
    "- Manipulación de datos con tensores\n",
    "- Diseño y configuración de modelos supervisados\n",
    "- Entrenamiento y evaluación de modelos\n",
    "\n",
    "### Contenidos\n",
    "- [Entorno de trabajo](#entorno)\n",
    "- [Marcos para aprendizaje profundo](#librerias)\n",
    "- [Aprendizaje supervisado](#aprendizaje)\n",
    "- [Tensores y manipulación de datos](#tensores)\n",
    "- [La arquitectura de red](#arquitectura)\n",
    "- [Entrenamiento del modelo](#entrenamiento)\n",
    "- [Inferencia o predicciones del modelo](#inferencia)\n",
    "- [Ejercicios](#ejercicios)\n",
    "\n",
    "### Bibliografía\n",
    "- [Deep Learning with Python (segunda edición)](https://www.manning.com/books/deep-learning-with-python-second-edition)\n",
    "- [Dive into Deep Learning](https://d2l.ai/)\n",
    "\n",
    "### Requisitos \n",
    "<a class='anchor' id='requisitos'></a>\n",
    "\n",
    "- [Numpy](https://pypi.org/project/numpy/) (computación numérica)\n",
    "- [Scipy](https://pypi.org/project/scipy/) (computación científica)\n",
    "- [Scikit-learn](https://pypi.org/project/scikit-learn/) (*Machine Learning*)\n",
    "- [Scikit-image](https://pypi.org/project/scikit-image/) (*Image Processing*)\n",
    "- [Matplotlib](https://pypi.org/project/matplotlib/) y [Seaborn](https://pypi.org/project/seaborn/) (visualización de datos)\n",
    "- [Tensorflow](https://www.tensorflow.org/) 2.x que incluye a [Keras](https://www.tensorflow.org/guide/keras) 2.x (*Deep Learning*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849ee22",
   "metadata": {},
   "source": [
    "<div style=\"page-break-before: always;\"></div>\n",
    "\n",
    "<a class='anchor' id='entorno'></a>\n",
    "\n",
    "## Entorno de trabajo\n",
    "\n",
    "Se trabajará con notebooks de [Jupyter](https://jupyter.org/install) con código Python empleando como intérprete la última versión de [Miniconda](https://docs.anaconda.com/miniconda/). A continuación se enumeran los pasos a seguir para configurar un entorno virtual de Python adecuado. \n",
    "\n",
    "### Microconda + Visual Studio Code\n",
    "\n",
    "Para instalar miniconda:\n",
    "1. Accede al [repositorio de miniconda](https://repo.anaconda.com/miniconda/).\n",
    "2. Descarga e instala la última version (*latest*) disponible para tu sistema operativo.\n",
    "\n",
    "Para instalar Visual Studio Code:\n",
    "1. Descarga e instala VS Code desde [su sitio web oficial](https://code.visualstudio.com/download).\n",
    "2. Instala las extensiones de Python y Jupyter desde VS Code.\n",
    "\n",
    "### Configuración del entorno virtual\n",
    "1. Abre un nuevo terminal en tu sistema operativo (Linux, Windows o macOS).\n",
    "\n",
    "2. OPCIÓN 1: Crea un nuevo entorno virtual e instala paquetes desde repositorio de ``conda``:\n",
    "   ```bash\n",
    "   conda create --name dl --channel defaults python=3.9\n",
    "   conda activate dl\n",
    "   conda install numpy scipy scikit-learn scikit-image matplotlib seaborn mrcfile ipykernel tensorflow\n",
    "   ```\n",
    "\n",
    "2. OPCIÓN 2: Crea un nuevo entorno virtual e instala paquetes desde repositorio de ``pip`` (preferible si su equipo dispone de una GPU Nvidia):\n",
    "   ```bash\n",
    "   conda create --name dl --channel defaults python=3.9 pip\n",
    "   conda activate dl\n",
    "   pip install numpy scipy scikit-learn scikit-image matplotlib seaborn mrcfile ipykernel tensorflow[and-cuda]\n",
    "   ```\n",
    "\n",
    "3. Para gestionar el entorno, puedes desactivarlo y opcionalmente eliminarlo:\n",
    "   ```bash \n",
    "   conda deactivate\n",
    "   conda env remove --name dl --all\n",
    "   ```\n",
    "\n",
    "\n",
    "\n",
    "*Nota: Tenga en cuenta que [TensorFlow 2.10](https://www.tensorflow.org/install/pip#windows-native) es la última versión de TensorFlow que admite GPU en Windows nativo. A partir de [TensorFlow 2.11](https://www.tensorflow.org/install/pip#windows-wsl2) para utilizar GPU en Windows es necesario instalar TensorFlow sobre WSL2.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd5f098",
   "metadata": {},
   "source": [
    "<a class='anchor' id='librerias'></a>\n",
    "\n",
    "## Marcos para aprendizaje profundo\n",
    "\n",
    "En la práctica las librerías de código abierto para la construcción y entrenamiento de modelos de aprendizaje profundo resultan ideales para implementar redes neuronales y procesar datos complejos como imágenes y texto.\n",
    "\n",
    "A continuación se resumen en una tabla comparativa las características de las 3 principales iniciativas o marcos de cómputo para *Deep Learning* que cumplen estos requisitos, y que actualmente concentran más de 90% del desarrollo en este campo: [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/) y [JAX](https://github.com/google/jax).\n",
    "\n",
    "| Aspecto            | [JAX](https://github.com/google/jax)                                                                                                                                         | [TensorFlow](https://www.tensorflow.org/)                                                                                                                                              | [PyTorch](https://pytorch.org/)                                                                                                                                          |\n",
    "|--------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Origen**         | Desarrollado por [Google Research](https://research.google/) (inspirado en [Autograd](https://github.com/HIPS/autograd))                                                                                           | Creado y mantenido por [Google Brain](https://ai.google/research/teams/brain/) (incluye componentes como [Keras](https://keras.io), [TFLite](https://www.tensorflow.org/lite), [TensorFlow.js](https://www.tensorflow.org/js), etc.) | Desarrollado por [Meta AI](https://ai.facebook.com/) (anteriormente Facebook), con apoyo de la comunidad de [GitHub](https://github.com/pytorch/pytorch)                                                       |\n",
    "| **Paradigma**      | Estilo funcional: usa transformaciones como [`jit`](https://jax.readthedocs.io/en/latest/jax.html#jax.jit), [`grad`](https://jax.readthedocs.io/en/latest/jax.html#jax.grad), [`vmap`](https://jax.readthedocs.io/en/latest/jax.html#jax.vmap), etc., sobre sintaxis parecida a [NumPy](https://numpy.org/). | Ejecución imperativa por defecto ([Eager Execution](https://www.tensorflow.org/guide/eager)) y optimizaciones basadas en grafos internos (p. ej., [XLA](https://openxla.org/)).                                 | Ejecución imperativa (dinámica), muy similar a la programación en Python nativo.                                                                                                                               |\n",
    "| **Curva de aprendizaje**   | Moderada: sintaxis de [NumPy](https://numpy.org/) es familiar, pero el paradigma funcional (p. ej., `jit`, `vmap`) puede requerir un cambio de mentalidad.                                                            | Bastante accesible gracias a la integración con [Keras](https://keras.io). En casos avanzados, se puede profundizar en niveles de API más bajos (por ej., `tf.*` a bajo nivel).                                               | Normalmente considerada sencilla, útil para prototipado rápido y depuración, gracias a la ejecución imperativa paso a paso.                                                                                   |\n",
    "| **Rendimiento**    | Muy alto en [GPU](https://developer.nvidia.com/cuda-toolkit) y [TPU](https://cloud.google.com/tpu) gracias a la integración con [XLA](https://openxla.org/).                                                                                            | Excelente rendimiento en GPU y TPU; TensorFlow se integra con [XLA](https://openxla.org/) y ofrece muchas optimizaciones para despliegue en producción ([TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving), etc.). | Muy buen rendimiento en GPU ([CUDA](https://developer.nvidia.com/cuda-toolkit)). Soporte limitado para TPU (existen iniciativas de la comunidad, pero no un soporte oficial completo).                          |\n",
    "| **Ventajas**       | - Control granular sobre transformaciones y compilación<br>- Sintaxis similar a [NumPy](https://numpy.org/)<br>- Integración potente en [TPU](https://cloud.google.com/tpu).                                       | - Amplio ecosistema ([Keras](https://keras.io), [TFLite](https://www.tensorflow.org/lite), [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving), [TensorFlow.js](https://www.tensorflow.org/js), etc.)<br>- Respaldo empresarial<br>- Facilidad de despliegue | - Flujo imperativo muy intuitivo<br>- Amplia adopción en investigación (especialmente en visión, NLP, etc.)<br>- Gran cantidad de ejemplos y repositorios de la comunidad                                      |\n",
    "| **Desventajas**    | - Ecosistema más pequeño que PyTorch/TensorFlow<br>- El enfoque funcional no es tan común y puede ser menos intuitivo para principiantes                                                                            | - Puede ser abrumador por la gran cantidad de documentación y APIs<br>- A veces requiere atención a la versión y a la configuración de entornos (GPU/TPU)                                                                       | - No siempre tan optimizado como TensorFlow en escenarios de producción a gran escala<br>- Soporte oficial para TPU inexistente o muy limitado                                                                 |\n",
    "| **Comunidad y recursos**      | En crecimiento, con proyectos recientes en [GitHub](https://github.com/google/jax) y foros especializados, aunque menor que las de TensorFlow/PyTorch.                                                               | Muy grande, con abundantes recursos de aprendizaje (foros, cursos, documentación oficial, etc.).                                                                                       | Muy activa y enfocada en investigación; gran cantidad de *repos* y tutoriales en [GitHub](https://github.com/pytorch).                                                                                       |\n",
    "\n",
    "\n",
    "En conclusión, se puede afirmar que [PyTorch](https://pytorch.org/) y [TensorFlow](https://www.tensorflow.org/) son hoy por hoy los marcos más utilizadas para *Deep Learning* por diferentes motivos, mientras que [JAX](https://github.com/google/jax) se está abriendo paso especialmente en investigación y proyectos que busquen optimizaciones avanzadas mediante XLA.\n",
    "\n",
    "En las prácticas de esta asignatura nos utilizaremos [TensorFlow](https://www.tensorflow.org/), al considerar que el interfaz de integrado de [Keras](https://keras.io) ofrece la alternativa más accesible para un primer contacto con la implmentación de modelos de aprendizaje automático. Y a largo plazo también parece ofrecer una visión más amplia y completa de posibilidades y usos dentro del ámbito académico y profesional. La experiencia adquirida debería permitir una fácil adaptación a otros entornos como [PyTorch](https://pytorch.org/), e incluso una migración e código bastante directa.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505de2b",
   "metadata": {},
   "source": [
    "<a class='anchor' id='aprendizaje'></a>\n",
    "\n",
    "## Aprendizaje supervisado\n",
    "\n",
    "El **aprendizaje supervisado** constituye una categoría del aprendizaje automático en la cual se enseña a un modelo a realizar predicciones o clasificaciones basándose en un conjunto de datos etiquetados. Este tipo de aprendizaje se denomina \"supervisado\" porque el proceso de entrenamiento está guiado por una supervisión explícita a través de etiquetas que indican las respuestas correctas.\n",
    "\n",
    "### Tipos de Aprendizaje Supervisado\n",
    "1. **Regresión**: <a class='anchor' id='regresion'></a>\n",
    "   - El objetivo es predecir valores continuos.\n",
    "   - Ejemplo: Predecir el precio de una vivienda en función de sus características.\n",
    "\n",
    "2. **Clasificación**: <a class='anchor' id='clasificacion'></a>\n",
    "   - El objetivo es asignar categorías a las entradas.\n",
    "   - Ejemplo: Clasificar correos electrónicos como \"spam\" o \"no spam\".\n",
    "\n",
    "### Componentes del aprendizaje supervisado\n",
    "1. **Datos de entrenamiento**: <a class='anchor' id='datos'></a>\n",
    "   - Conjunto de ejemplos que incluyen:\n",
    "     - **Entradas** \\(X\\): Características o variables independientes.\n",
    "     - **Etiquetas** \\(Y\\): Salidas esperadas o variables dependientes (valores conocidos).\n",
    "\n",
    "2. **Modelo**: <a class='anchor' id='modelo'></a>\n",
    "   - Una función  f\\(X\\) que el sistema entrena para aproximar la relación entre X y Y.\n",
    "\n",
    "3. **Coste o pérdida (error)**: <a class='anchor' id='coste'></a>\n",
    "   - Una métrica que evalúa lo bien que las predicciones del modelo coinciden con las etiquetas reales.\n",
    "\n",
    "4. **Optimización**: <a class='anchor' id='optimizacion'></a>\n",
    "   - Proceso de ajuste de los parámetros del modelo para minimizar la pérdida mediante algoritmos como el descenso estocástico de gradiente.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "112d2155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 08:51:06.514648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737708666.529277   27217 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737708666.533731   27217 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-24 08:51:06.550751: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#### Cargando el conjunto de datos MNIST\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434b581",
   "metadata": {},
   "source": [
    "### Atributos clave de un conjunto de datos: rango, dimensiones y tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1272a4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango del tensor del conjunto de entrenamiento:\n",
      " 3\n",
      "Dimensiones del conjunto de entrenamiento [samples x height x width]:\n",
      " (60000, 28, 28)\n",
      "Número de etiquetas del conjunto de entrenamiento:\n",
      " 60000\n",
      "Tipo del conjunto de entrenamiento:\n",
      " <class 'numpy.ndarray'> uint8\n",
      "Tipo de las etiquetas de entrenamiento:\n",
      " <class 'numpy.ndarray'> uint8\n",
      "Rango dinánico de valores del conjunto de entrenamiento:\n",
      " [np.uint8(0), np.uint8(255)]\n",
      "Valores de las etiquetas de entrenamiento:\n",
      " [0 1 2 3 4 5 6 7 8 9]\n",
      "Rango del tensor del conjunto de test:\n",
      " 3\n",
      "Dimensiones del conjunto de test [samples x height x width]:\n",
      " (10000, 28, 28)\n",
      "Número de etiquetas del conjunto de test:\n",
      " 10000\n",
      "Tipo del conjunto de test:\n",
      " <class 'numpy.ndarray'> uint8\n",
      "Tipo de las etiquetas de test:\n",
      " <class 'numpy.ndarray'> uint8\n",
      "Rango dinánico de valores del conjunto de entrenamiento:\n",
      " [np.uint8(0), np.uint8(255)]\n",
      "Valores de las etiquetas de entrenamiento:\n",
      " [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(\"Rango del tensor del conjunto de entrenamiento:\\n\", train_images.ndim)\n",
    "print(\"Dimensiones del conjunto de entrenamiento [samples x height x width]:\\n\", train_images.shape)\n",
    "print(\"Número de etiquetas del conjunto de entrenamiento:\\n\", len(train_labels))\n",
    "print(\"Tipo del conjunto de entrenamiento:\\n\", type(train_images), train_images.dtype)\n",
    "print(\"Tipo de las etiquetas de entrenamiento:\\n\", type(train_labels), train_labels.dtype)\n",
    "print(\"Rango dinánico de valores del conjunto de entrenamiento:\\n\", [np.min(train_images), np.max(train_images)])\n",
    "print(\"Valores de las etiquetas de entrenamiento:\\n\", np.unique(train_labels))\n",
    "\n",
    "print(\"Rango del tensor del conjunto de test:\\n\", test_images.ndim)\n",
    "print(\"Dimensiones del conjunto de test [samples x height x width]:\\n\", test_images.shape)\n",
    "print(\"Número de etiquetas del conjunto de test:\\n\", len(test_labels))\n",
    "print(\"Tipo del conjunto de test:\\n\", type(test_images), test_images.dtype)\n",
    "print(\"Tipo de las etiquetas de test:\\n\", type(test_labels), test_labels.dtype)\n",
    "print(\"Rango dinánico de valores del conjunto de entrenamiento:\\n\", [np.min(test_images), np.max(test_images)])\n",
    "print(\"Valores de las etiquetas de entrenamiento:\\n\", np.unique(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a933ea",
   "metadata": {},
   "source": [
    "### Visualización de datos y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4302eaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Visualizando el quinta muestra del conjunto de imágenes y su etiqueta asociada\n",
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4]\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.title(f\"Etiqueta asociada -> {train_labels[4]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1c64c",
   "metadata": {},
   "source": [
    "### Acondicionaniento de datos\n",
    "\n",
    "El **acondicionamiento de datos** es una etapa fundamental en el flujo de trabajo del aprendizaje automático y redes neuronales en general. Consiste en preparar los datos para que sean compatibles con los modelos y para mejorar el rendimiento y estabilidad del entrenamiento. Esta preparación incluye varias operaciones que ajustan los datos a los formatos, rangos o estructuras requeridas. Entre las operaciones típicas que podemos englobar dentro de esta categoría se encuentran habitualmente: \n",
    "\n",
    "1. **Normalización de datos**:\n",
    "   - Escalar los valores de las características a un rango común, como [0, 1] ó [-1, 1].\n",
    "   - Ejemplo: Dividir los valores de píxel de imágenes (en el rango 0-255) por 255 para normalizarlos entre [0, 1].\n",
    "   - Beneficio:\n",
    "     - Mejora la estabilidad del modelo.\n",
    "     - Acelera la convergencia durante el entrenamiento.\n",
    "\n",
    "2. **Aplanamiento de dimensiones**:\n",
    "   - Transformar datos multidimensionales en vectores unidimensionales.\n",
    "   - Ejemplo: Imágenes 2D (28x28 píxeles) a un vector de 784 elementos para alimentarlas en capas densas.\n",
    "   - Beneficio:\n",
    "     - Permite la entrada de datos a modelos que requieren estructuras lineales.\n",
    "\n",
    "3. **Conversión de tipo de datos**:\n",
    "   - Cambiar el tipo de los datos o las etiquetas, como de enteros (`int`, `uint`) a coma flotante (`float`).\n",
    "   - Ejemplo: Convertir etiquetas categóricas a `float32` para cálculos numéricos.\n",
    "   - Beneficio:\n",
    "     - Asegura compatibilidad con el diseño del modelo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06125d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango del tensor del conjunto de entrenamiento:\n",
      " 2\n",
      "Dimensiones del conjunto de entrenamiento [samples x height x width]:\n",
      " (60000, 784)\n",
      "Número de etiquetas del conjunto de entrenamiento:\n",
      " 60000\n",
      "Tipo del conjunto de entrenamiento:\n",
      " <class 'numpy.ndarray'> float32\n",
      "Tipo de las etiquetas de entrenamiento:\n",
      " <class 'numpy.ndarray'> uint8\n",
      "Rango dinánico de valores del conjunto de entrenamiento:\n",
      " [np.float32(0.0), np.float32(1.0)]\n",
      "Valores de las etiquetas de entrenamiento:\n",
      " [0 1 2 3 4 5 6 7 8 9]\n",
      "Rango del tensor del conjunto de test:\n",
      " 2\n",
      "Dimensiones del conjunto de test [samples x height x width]:\n",
      " (10000, 784)\n",
      "Número de etiquetas del conjunto de test:\n",
      " 10000\n",
      "Tipo del conjunto de test:\n",
      " <class 'numpy.ndarray'> float32\n",
      "Tipo de las etiquetas de test:\n",
      " <class 'numpy.ndarray'> uint8\n",
      "Rango dinánico de valores del conjunto de entrenamiento:\n",
      " [np.float32(0.0), np.float32(1.0)]\n",
      "Valores de las etiquetas de entrenamiento:\n",
      " [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))  # Aplanamiento\n",
    "train_images = train_images.astype(\"float32\") / 255  # Normalización + tipo flotante\n",
    "test_images = test_images.reshape((10000, 28 * 28))  # Aplanamiento\n",
    "test_images = test_images.astype(\"float32\") / 255  # Normalización + tipo flotante\n",
    "\n",
    "print(\"Rango del tensor del conjunto de entrenamiento:\\n\", train_images.ndim)\n",
    "print(\"Dimensiones del conjunto de entrenamiento [samples x height x width]:\\n\", train_images.shape)\n",
    "print(\"Número de etiquetas del conjunto de entrenamiento:\\n\", len(train_labels))\n",
    "print(\"Tipo del conjunto de entrenamiento:\\n\", type(train_images), train_images.dtype)\n",
    "print(\"Tipo de las etiquetas de entrenamiento:\\n\", type(train_labels), train_labels.dtype)\n",
    "print(\"Rango dinánico de valores del conjunto de entrenamiento:\\n\", [np.min(train_images), np.max(train_images)])\n",
    "print(\"Valores de las etiquetas de entrenamiento:\\n\", np.unique(train_labels))\n",
    "\n",
    "print(\"Rango del tensor del conjunto de test:\\n\", test_images.ndim)\n",
    "print(\"Dimensiones del conjunto de test [samples x height x width]:\\n\", test_images.shape)\n",
    "print(\"Número de etiquetas del conjunto de test:\\n\", len(test_labels))\n",
    "print(\"Tipo del conjunto de test:\\n\", type(test_images), test_images.dtype)\n",
    "print(\"Tipo de las etiquetas de test:\\n\", type(test_labels), test_labels.dtype)\n",
    "print(\"Rango dinánico de valores del conjunto de entrenamiento:\\n\", [np.min(test_images), np.max(test_images)])\n",
    "print(\"Valores de las etiquetas de entrenamiento:\\n\", np.unique(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f24ca0",
   "metadata": {},
   "source": [
    "### Noción de lote de datos\n",
    "\n",
    "Recordemos en primer lugar que una **época** es un ciclo completo en el que el modelo procesa todo el conjunto de datos de entrenamiento una vez. Durante una época, el modelo utiliza todos los ejemplos del conjunto de datos para calcular los gradientes y ajustar los pesos. Por otra parte, y a lo largo de cada época, un **lote de datos** (*batch*) es un subconjunto del conjunto de datos de entrenamiento que el modelo procesa en cada iteración del entrenamiento.\n",
    "\n",
    "Por tanto, en lugar de procesar todos los datos de entrenamiento de una vez en cada época, se dividen en pequeños grupos (lotes), y el modelo ajusta sus parámetros utilizando únicamente los datos del lote actual (*Mini-Batch Training*). Algunas de las ventajas del uso de lotes de datos son:\n",
    "\n",
    "1. **Eficiencia computacional**:\n",
    "   - Procesar datos en lotes aprovecha la computación paralela de GPUs/TPUs.\n",
    "2. **Mejor estimación del gradiente**:\n",
    "   - Mini-batches ofrecen un compromiso entre ruido y precisión en el cálculo del gradiente.\n",
    "3. **Eficiencia del uso de memoria**:\n",
    "   - Los lotes permiten entrenar con conjuntos de datos grandes sin necesidad de cargar todo el conjunto en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5d2548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del lote de datos [samples x length]:\n",
      " (128, 784)\n",
      "Dimensiones del lote de etiquetas [samples]:\n",
      " 128\n"
     ]
    }
   ],
   "source": [
    "n = 3 # lote número 3\n",
    "batch_size = 128 # tamaño del lote\n",
    "batch = train_images[batch_size * n:batch_size * (n + 1)]\n",
    "label_batch = train_labels[batch_size * n:batch_size * (n + 1)]\n",
    "print(\"Dimensiones del lote de datos [samples x length]:\\n\", batch.shape)\n",
    "print(\"Dimensiones del lote de etiquetas [samples]:\\n\", len(label_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3686ef",
   "metadata": {},
   "source": [
    "<a class='anchor' id='arquitectura'></a>\n",
    "\n",
    "## La arquitectura de red\n",
    "\n",
    "La **arquitectura de red** refleja la estructura y diseño de una red neuronal, incluyendo las capas, cómo están conectadas, los tipos de operaciones que realizan y los hiperparámetros asociados. Es una especificación que define cómo se organiza la red para procesar datos y alcanzar predicciones.\n",
    "\n",
    "La arquitectura influye directamente en la capacidad del modelo para aprender patrones de los datos. Elegir la arquitectura correcta es el primer requisito para un buen rendimiento del modelo y su capacidad de generalización. Algunos componentes claves de la arquitectura de red son:\n",
    "\n",
    "1. **Capas**:\n",
    "   - Agrupación de operaciones de un determinado tipo, que transforman los datos desde la entrada hasta la salida.\n",
    "   - Ejemplo:\n",
    "     - Capas densas (*fully connected*).\n",
    "     - Capas convolucionales (*convolutional layers*).\n",
    "     - Capas recurrentes (*recurrent layers*).\n",
    "\n",
    "2. **Neuronas por capa**:\n",
    "   - El número de neuronas determina la capacidad de cada capa para reconocer patrones. El número de capas y la cantidad de neuronas de cada capa determina el número total de parámetros o pesos entrenables del modelo.\n",
    "\n",
    "3. **Funciones de activación**:\n",
    "   - Introducen no linealidades para que la red pueda aprender relaciones complejas.\n",
    "   - Ejemplo: `ReLU`, `sigmoid`, `tanh`.\n",
    "\n",
    "4. **Conexiones entre capas**:\n",
    "   - Puede fluir solo hacía delante (*feedforward*) o incluir retroalimentación (como en redes recurrentes).\n",
    "\n",
    "5. **Hiperparámetros**:\n",
    "   - Aspectos configurables de la red, como el número de capas, tamaño del lote, tasa de aprendizaje, etc.\n",
    "\n",
    "\n",
    "Existen varias formas de definir la arquitectura de un modelo de aprendizaje automático en TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5442f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-01-24 08:51:09.636792: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definición secuencial (opción 1)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential, Model\n",
    "model = Sequential([\n",
    "    layers.Dense(512, activation=\"relu\", input_shape=(28 * 28, )), # capa oculta\n",
    "    layers.Dense(10, activation=\"softmax\") # capa de salida\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Definición secuencial (opción 2)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(512, activation=\"relu\", input_shape=(28 * 28, ))) # capa oculta\n",
    "model.add(layers.Dense(10, activation=\"softmax\")) # capa de salida\n",
    "model.summary()\n",
    "\n",
    "# Definición funcional\n",
    "input_layer = layers.Input(shape=(28 * 28, ))  # Capa de entrada\n",
    "hidden_layer = layers.Dense(512, activation=\"relu\")(input_layer)  # Capa oculta\n",
    "output_layer = layers.Dense(10, activation=\"softmax\")(hidden_layer)  # Capa de salida\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a96a7",
   "metadata": {},
   "source": [
    "Observa que con una definición ``Sequential`` del modelo la ``InputLayer`` no aparece en el resumen, incluso si se incluye explícitamente. En ``Functional``, siempre aparece porque la entrada es explícita como parte del diseño del modelo. Esto sucede porque en el flujo típico de ``Sequential`` la capa de entrada se infiere automáticamente a partir de los datos proporcionados en la primera capa, y no se considera como una capa separada en el grafo de computación, si no como parte del flujo de datos implícito, lo cual es más simple y resulta óptimo para arquitecturas convencionales, en particular aquellas que tienen una sola entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291fc93",
   "metadata": {},
   "source": [
    "### Configurar el modelo para el aprendizaje\n",
    "\n",
    "La configuración y compilación del modelo conlleva definir las siguientes componentes claves:\n",
    "\n",
    "   - **Función de coste o pérdida**:\n",
    "     - Establece una métrica para valorar lo bien/mal que está prediciendo el modelo.\n",
    "     - Ejemplo: `mean squared error` para regresión, `categorical crossentropy` para clasificación.\n",
    "   - **Optimizador**:\n",
    "     - Algoritmo que ajusta los parámetros del modelo para minimizar la pérdida.\n",
    "     - Ejemplo: `Adam`, `SGD`.\n",
    "   - **Métricas adicionales**:\n",
    "     - Evalúan las prestaciones del modelo durante el entrenamiento y la validación.\n",
    "     - Ejemplo: precisión (`accuracy`), error absoluto medio (`MAE`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986412bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',                       # Optimizador\n",
    "    loss='sparse_categorical_crossentropy',    # Función de pérdida\n",
    "    metrics=['accuracy']                       # Métrica\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d55d48",
   "metadata": {},
   "source": [
    "<a class='anchor' id='entrenamiento'></a>\n",
    "\n",
    "## Entrenamiento del modelo\n",
    "\n",
    "El método `fit` de TensorFlow es una función fundamental en la API de Keras que entrena un modelo de aprendizaje profundo utilizando un conjunto de datos. Este método ejecuta el proceso de entrenamiento, integrando todas las fases necesarias: cálculo de pérdidas, optimización, y evaluación de métricas.\n",
    "\n",
    "Al llamar al método `fit`, TensorFlow sigue estos pasos:\n",
    "\n",
    "1. **Preparación del entrenamiento**:\n",
    "   - Verifica que el modelo esté correctamente compilado con:\n",
    "     - Una función de pérdida (`loss`).\n",
    "     - Un optimizador (`optimizer`).\n",
    "     - Opcionalmente, métricas (`metrics`) para evaluar las prestaciones.\n",
    "\n",
    "2. **Procesamiento de los datos**:\n",
    "   - Divide los datos en lotes según el tamaño definido en `batch_size`.\n",
    "   - Si se emplea validación, separa una parte de los datos para evaluación.\n",
    "\n",
    "3. **Bucle de entrenamiento**:\n",
    "   Para cada época:\n",
    "   - **Paso hacia adelante (*forward pass*)**:\n",
    "     - Calcula las predicciones del modelo para un lote de datos.\n",
    "   - **Cálculo de la pérdida**:\n",
    "     - Compara las predicciones con las etiquetas reales usando la función de pérdida.\n",
    "   - **Paso hacia atrás (*backward pass*)**:\n",
    "     - Calcula los gradientes de los parámetros del modelo con respecto a la pérdida.\n",
    "   - **Actualización de los pesos**:\n",
    "     - Ajusta los pesos del modelo utilizando el optimizador configurado.\n",
    "\n",
    "4. **Validación (opcional)**:\n",
    "   - Al final de cada época, evalúa el modelo en el conjunto de validación.\n",
    "\n",
    "5. **Almacenamiento de resultados**:\n",
    "   - Guarda métricas como la pérdida y otras definidas en `metrics` para cada época.\n",
    "\n",
    "El método `fit` devuelve un histórico (objeto `history`) que contiene un registro de las prestaciones del modelo durante el entrenamiento, mediante un diccionario con las métricas por época (`loss`, `mae`, `val_loss`, etc.). Además `fit` es compatible con `callbacks` para personalizar y extender el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2ad398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 08:51:09.806334: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.3733\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.1004\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0608\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0421\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0331\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_images, train_labels, # datos y etiquetas de entrenamiento\n",
    "    epochs=5,               # Número de épocas\n",
    "    batch_size=64           # Tamaño del lote\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a35868",
   "metadata": {},
   "source": [
    "<a class='anchor' id='inferencia'></a>\n",
    "\n",
    "## Inferencia o predicciones del modelo\n",
    "\n",
    "El método `predict` de TensorFlow en la API de Keras se utiliza para realizar **inferencia** con un modelo ya entrenado. Es decir, genera predicciones a partir de nuevos datos de entrada, aplicando únicamente la fase de **propagación hacia adelante** (*forward pass*), sin actualizar los pesos del modelo, es decir realiza los siguientes pasos:\n",
    "\n",
    "1. **Propagación hacia adelante**:\n",
    "   - Toma los datos de entrada y los pasa a través de las capas del modelo.\n",
    "   - Realiza todas las operaciones definidas en el modelo, como multiplicaciones de tensores, funciones de activación y normalización.\n",
    "\n",
    "2. **Cálculo de las salidas**:\n",
    "   - Produce una salida en función de las configuraciones del modelo:\n",
    "     - Para problemas de regresión, devuelve valores continuos: el valor estimado por el modelo basado en los datos de entrada.\n",
    "     - Para problemas de clasificación, devuelve probabilidades de cada clase (si la última capa es una función `softmax`). Normalmente se elige la clase con mayor probabilidad para obtener las clases predichas (`np.argmax(y_pred, axis=-1)`).\n",
    "\n",
    "3. **Agrupación en lotes (opcional)**:\n",
    "   - Divide los datos en lotes si el conjunto de datos es grande, para optimizar el uso de memoria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20bac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Etiqueta: 7, Predicción: 7\n",
      "Etiqueta: 2, Predicción: 2\n",
      "Etiqueta: 1, Predicción: 1\n",
      "Etiqueta: 0, Predicción: 0\n",
      "Etiqueta: 4, Predicción: 4\n",
      "Etiqueta: 1, Predicción: 1\n",
      "Etiqueta: 4, Predicción: 4\n",
      "Etiqueta: 9, Predicción: 9\n",
      "Etiqueta: 5, Predicción: 5\n",
      "Etiqueta: 9, Predicción: 9\n",
      "Etiqueta: 0, Predicción: 0\n",
      "Etiqueta: 6, Predicción: 6\n",
      "Etiqueta: 9, Predicción: 9\n",
      "Etiqueta: 0, Predicción: 0\n",
      "Etiqueta: 1, Predicción: 1\n",
      "Etiqueta: 5, Predicción: 5\n",
      "Etiqueta: 9, Predicción: 9\n",
      "Etiqueta: 7, Predicción: 7\n",
      "Etiqueta: 3, Predicción: 3\n",
      "Etiqueta: 4, Predicción: 4\n"
     ]
    }
   ],
   "source": [
    "test_digits = test_images[0:20]\n",
    "predictions = model.predict(test_digits) # probabilidades de clase (one hot encoding)\n",
    "predictions = predictions.argmax(axis=-1) # clase de mayor probabilidad\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Etiqueta: {test_labels[i]}, Predicción: {pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a961daa4",
   "metadata": {},
   "source": [
    "<a class='anchor' id='evaluacion'></a>\n",
    "\n",
    "### Evaluación del modelo\n",
    "\n",
    "La función `evaluate` de TensorFlow en la API de Keras evalúa el modelo entrenado en un conjunto de datos específico, calculando la pérdida y las métricas definidas durante la compilación del modelo. Es una forma de medir el rendimiento del modelo, ya sea en datos de validación o de test, sin modificar los parámetros del modelo. Conlleva la siguiente secuencia:\n",
    "\n",
    "1. **Propagación hacia adelante (*forward pass*)**:\n",
    "   - Pasa los datos de entrada a través del modelo para generar predicciones.\n",
    "\n",
    "2. **Cálculo de la pérdida**:\n",
    "   - Compara las predicciones con las etiquetas reales utilizando la función de pérdida definida.\n",
    "\n",
    "3. **Cálculo de métricas**:\n",
    "   - Evalúa las métricas configuradas al compilar el modelo, como precisión, MAE, etc.\n",
    "\n",
    "4. **Agrupación en lotes (opcional)**:\n",
    "   - Si el conjunto de datos es grande, divide los datos en lotes para optimizar el uso de memoria.\n",
    "\n",
    "5. **Promedio de resultados**:\n",
    "   - Calcula la pérdida y las métricas promedio en todos los lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c898419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9741 - loss: 0.0910\n",
      "test_acc: 0.9784\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48e003",
   "metadata": {},
   "source": [
    "<a class='anchor' id='ejercicios'></a>\n",
    "\n",
    "## Ejercicios\n",
    "\n",
    "**E1:** Crear un modelo de clasificación binaria para predecir si la suma de dos números es mayor a 1 usando un conjunto de datos sintético.\n",
    "\n",
    "   - Se generan 1000 muestras con dos características cada una (`x_data`).\n",
    "   - La etiqueta (`y_data`) es `1` si la suma de las dos características es mayor que 1, y `0` en caso contrario.\n",
    "      - Ejemplo:\n",
    "         - Entrada: `[0.6, 0.7]` → Suma: `1.3` → Etiqueta: `1`.\n",
    "         - Entrada: `[0.3, 0.2]` → Suma: `0.5` → Etiqueta: `0`.\n",
    "\n",
    "   - Se divide el conjunto en entrenamiento (80%) y prueba (20%).\n",
    "\n",
    "   - Construir una red neuronal con dos capas:\n",
    "     - Capa oculta: 64 neuronas y función de activación `relu`.\n",
    "     - Capa de salida: 1 neurona con activación `sigmoid` para obtener una probabilidad entre 0 y 1 (para clasificación binaria).\n",
    "\n",
    "   - Optimizador: `adam`, que ajusta los pesos durante el entrenamiento.\n",
    "   - Pérdida: `binary_crossentropy`, que es adecuada para problemas de clasificación binaria.\n",
    "   - Métrica: `accuracy`, que mide el porcentaje de predicciones correctas.\n",
    "\n",
    "   - Se entrena en el conjunto de entrenamiento durante 30 épocas con un tamaño de lote de 32.\n",
    "   - Utiliza el 20% de los datos de entrenamiento como conjunto de validación para monitorear el rendimiento.\n",
    "\n",
    "   - El modelo se evalúa en el conjunto de prueba, calculando la pérdida y la precisión.\n",
    "\n",
    "   - Se realizan predicciones en nuevas muestras (`x_sample`).\n",
    "   - La salida del modelo son probabilidades (valores entre 0 y 1), y se convierten en clases (`0` o `1`) comparando con un umbral de 0.5.\n",
    "      - Ejemplo:\n",
    "         - Entrada: `[0.6, 0.6]` → Probabilidad: `0.95` → Clase: `1`.\n",
    "\n",
    "**E2:** Cambiar el tamaño de la red (número de neuronas o capas) y analizar el impacto.\n",
    "\n",
    "**E3:** Probar diferentes funciones de activación y analizar el impacto.\n",
    "\n",
    "\n",
    "\n",
    "**E4:** Crear un modelo de regresión para predecir la suma de dos números usando un conjunto de datos sintético..\n",
    "\n",
    "   - Se generan números aleatorios para las entradas ``x_1`` y ``x_2``, separándolo un 30% de ellos para test.\n",
    "   - Las etiquetas ``y`` son la suma de ``x_1 + x_2``.\n",
    "\n",
    "   - Una red neuronal simple con:\n",
    "     - Una capa oculta de 64 neuronas con activación ReLU.\n",
    "     - Una capa de salida con 1 neurona (regresión).\n",
    "\n",
    "   - Optimización con Adam.\n",
    "   - Pérdida: `mse` (error cuadrático medio), adecuada para problemas de regresión.\n",
    "   - Métrica: `mae` (error absoluto medio), que mide la desviación promedio.\n",
    "\n",
    "   - Se entrena el modelo durante 20 épocas con un tamaño de lote de 32.\n",
    "   - El 20% de los datos se reserva para validación en el entrenamiento.\n",
    "\n",
    "   - El modelo se evalúa en el conjunto de test no visto durante el entrenamiento.\n",
    "\n",
    "   - Se realiza inferencia con nuevas muestras para verificar el rendimiento del modelo, por ejemplo para una entrada como `[0.3, 0.7]`, la salida debería estar cerca de `1.0`.\n",
    "\n",
    "**E5:** Cambiar el tamaño del conjunto de datos y analizar el impacto.\n",
    "\n",
    "**E6:** Aumentar la complejidad del problema (por ejemplo, usando ruido en las etiquetas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac13faeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4875 - loss: 0.6709 - val_accuracy: 0.6062 - val_loss: 0.6363\n",
      "Epoch 2/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5317 - loss: 0.6523 - val_accuracy: 0.6250 - val_loss: 0.6145\n",
      "Epoch 3/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5715 - loss: 0.6332 - val_accuracy: 0.6500 - val_loss: 0.5950\n",
      "Epoch 4/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6269 - loss: 0.6157 - val_accuracy: 0.6750 - val_loss: 0.5774\n",
      "Epoch 5/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6725 - loss: 0.5931 - val_accuracy: 0.7125 - val_loss: 0.5583\n",
      "Epoch 6/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6966 - loss: 0.5801 - val_accuracy: 0.7563 - val_loss: 0.5404\n",
      "Epoch 7/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7579 - loss: 0.5566 - val_accuracy: 0.7812 - val_loss: 0.5174\n",
      "Epoch 8/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7854 - loss: 0.5246 - val_accuracy: 0.8500 - val_loss: 0.4947\n",
      "Epoch 9/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.4924 - val_accuracy: 0.8813 - val_loss: 0.4732\n",
      "Epoch 10/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.4766 - val_accuracy: 0.9062 - val_loss: 0.4490\n",
      "Epoch 11/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.4569 - val_accuracy: 0.9250 - val_loss: 0.4246\n",
      "Epoch 12/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8715 - loss: 0.4310 - val_accuracy: 0.9375 - val_loss: 0.4026\n",
      "Epoch 13/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.4153 - val_accuracy: 0.9563 - val_loss: 0.3814\n",
      "Epoch 14/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.3809 - val_accuracy: 0.9563 - val_loss: 0.3602\n",
      "Epoch 15/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.3622 - val_accuracy: 0.9688 - val_loss: 0.3421\n",
      "Epoch 16/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.3489 - val_accuracy: 0.9688 - val_loss: 0.3225\n",
      "Epoch 17/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.3280 - val_accuracy: 0.9750 - val_loss: 0.3073\n",
      "Epoch 18/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9382 - loss: 0.3109 - val_accuracy: 0.9750 - val_loss: 0.2913\n",
      "Epoch 19/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.2995 - val_accuracy: 0.9812 - val_loss: 0.2776\n",
      "Epoch 20/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.2795 - val_accuracy: 0.9875 - val_loss: 0.2653\n",
      "Epoch 21/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.2806 - val_accuracy: 0.9875 - val_loss: 0.2533\n",
      "Epoch 22/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.2657 - val_accuracy: 0.9875 - val_loss: 0.2433\n",
      "Epoch 23/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.2501 - val_accuracy: 0.9875 - val_loss: 0.2339\n",
      "Epoch 24/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.2308 - val_accuracy: 0.9875 - val_loss: 0.2242\n",
      "Epoch 25/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.2235 - val_accuracy: 0.9875 - val_loss: 0.2169\n",
      "Epoch 26/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.2168 - val_accuracy: 0.9875 - val_loss: 0.2101\n",
      "Epoch 27/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.2061 - val_accuracy: 0.9875 - val_loss: 0.2021\n",
      "Epoch 28/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9739 - loss: 0.2113 - val_accuracy: 0.9875 - val_loss: 0.1954\n",
      "Epoch 29/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.1895 - val_accuracy: 0.9875 - val_loss: 0.1897\n",
      "Epoch 30/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.1990 - val_accuracy: 0.9875 - val_loss: 0.1855\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.1817 \n",
      "Pérdida en el conjunto de prueba: 0.17997205257415771\n",
      "Precisión en el conjunto de prueba: 0.9950000047683716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Entrada: [0.6 0.6] → Probabilidad: 0.83 → Clase: 1\n",
      "Entrada: [0.3 0.2] → Probabilidad: 0.03 → Clase: 0\n"
     ]
    }
   ],
   "source": [
    "# E1\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Generar datos sintéticos\n",
    "np.random.seed(42)\n",
    "x_data = np.random.rand(1000, 2)\n",
    "y_data = (np.sum(x_data, axis=1) > 1).astype(int)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construir el modelo\n",
    "model = Sequential([\n",
    "    Dense(64, activation=\"relu\", input_shape=(2,)),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(x_train, y_train, epochs=30, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Pérdida en el conjunto de prueba: {loss}\")\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy}\")\n",
    "\n",
    "# Nuevas pruebas para predicción\n",
    "x_sample = np.array([[0.6, 0.6], [0.3, 0.2]])\n",
    "\n",
    "# Realizar predicciones\n",
    "probabilidades = model.predict(x_sample)\n",
    "clases = (probabilidades > 0.5).astype(int)\n",
    "\n",
    "# Mostrar resultados\n",
    "for i, sample in enumerate(x_sample):\n",
    "    print(f\"Entrada: {sample} → Probabilidad: {probabilidades[i][0]:.2f} → Clase: {clases[i][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3c133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4980 - loss: 0.6648 - val_accuracy: 0.6000 - val_loss: 0.6373\n",
      "Epoch 2/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5564 - loss: 0.6475 - val_accuracy: 0.6125 - val_loss: 0.6231\n",
      "Epoch 3/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5759 - loss: 0.6392 - val_accuracy: 0.6375 - val_loss: 0.6094\n",
      "Epoch 4/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6072 - loss: 0.6286 - val_accuracy: 0.6812 - val_loss: 0.5960\n",
      "Epoch 5/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6537 - loss: 0.6112 - val_accuracy: 0.7063 - val_loss: 0.5839\n",
      "Epoch 6/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6785 - loss: 0.6080 - val_accuracy: 0.7250 - val_loss: 0.5708\n",
      "Epoch 7/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7104 - loss: 0.5870 - val_accuracy: 0.7500 - val_loss: 0.5575\n",
      "Epoch 8/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7511 - loss: 0.5629 - val_accuracy: 0.7875 - val_loss: 0.5433\n",
      "Epoch 9/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7631 - loss: 0.5643 - val_accuracy: 0.8062 - val_loss: 0.5296\n",
      "Epoch 10/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.5500 - val_accuracy: 0.8188 - val_loss: 0.5149\n",
      "Epoch 11/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.5234 - val_accuracy: 0.8438 - val_loss: 0.4990\n",
      "Epoch 12/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8567 - loss: 0.5039 - val_accuracy: 0.8813 - val_loss: 0.4838\n",
      "Epoch 13/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.4945 - val_accuracy: 0.9062 - val_loss: 0.4680\n",
      "Epoch 14/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.4722 - val_accuracy: 0.9125 - val_loss: 0.4514\n",
      "Epoch 15/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.4568 - val_accuracy: 0.9250 - val_loss: 0.4370\n",
      "Epoch 16/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9058 - loss: 0.4420 - val_accuracy: 0.9187 - val_loss: 0.4195\n",
      "Epoch 17/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9064 - loss: 0.4163 - val_accuracy: 0.9187 - val_loss: 0.4051\n",
      "Epoch 18/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.4032 - val_accuracy: 0.9438 - val_loss: 0.3907\n",
      "Epoch 19/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.3972 - val_accuracy: 0.9563 - val_loss: 0.3770\n",
      "Epoch 20/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.3729 - val_accuracy: 0.9500 - val_loss: 0.3611\n",
      "Epoch 21/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.3591 - val_accuracy: 0.9563 - val_loss: 0.3482\n",
      "Epoch 22/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.3562 - val_accuracy: 0.9563 - val_loss: 0.3338\n",
      "Epoch 23/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9376 - loss: 0.3329 - val_accuracy: 0.9688 - val_loss: 0.3230\n",
      "Epoch 24/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.3217 - val_accuracy: 0.9688 - val_loss: 0.3109\n",
      "Epoch 25/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.3130 - val_accuracy: 0.9688 - val_loss: 0.3002\n",
      "Epoch 26/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.2931 - val_accuracy: 0.9688 - val_loss: 0.2895\n",
      "Epoch 27/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.2930 - val_accuracy: 0.9812 - val_loss: 0.2817\n",
      "Epoch 28/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.2693 - val_accuracy: 0.9750 - val_loss: 0.2710\n",
      "Epoch 29/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.2767 - val_accuracy: 0.9750 - val_loss: 0.2631\n",
      "Epoch 30/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.2482 - val_accuracy: 0.9875 - val_loss: 0.2567\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.2498 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.1817 \n",
      "Pérdida en el conjunto de prueba (32 neuronas): 0.24888759851455688\n",
      "Precisión en el conjunto de prueba (32 neuronas): 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "# E2\n",
    "# Construir el modelo con una capa oculta de 32 neuronas\n",
    "model_32 = Sequential([\n",
    "    Dense(32, activation=\"relu\", input_shape=(2,)),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model_32.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history_32 = model_32.fit(x_train, y_train, epochs=30, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo\n",
    "\n",
    "loss_32, accuracy_32 = model_32.evaluate(x_test, y_test)\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Pérdida en el conjunto de prueba (32 neuronas): {loss_32}\")\n",
    "print(f\"Precisión en el conjunto de prueba (32 neuronas): {accuracy_32}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1eb790d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5034 - loss: 0.6679 - val_accuracy: 0.6375 - val_loss: 0.6221\n",
      "Epoch 2/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.6253 - val_accuracy: 0.6562 - val_loss: 0.5886\n",
      "Epoch 3/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 0.6040 - val_accuracy: 0.7063 - val_loss: 0.5649\n",
      "Epoch 4/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7454 - loss: 0.5627 - val_accuracy: 0.7688 - val_loss: 0.5387\n",
      "Epoch 5/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7714 - loss: 0.5468 - val_accuracy: 0.8438 - val_loss: 0.5156\n",
      "Epoch 6/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.5192 - val_accuracy: 0.8562 - val_loss: 0.4853\n",
      "Epoch 7/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.4924 - val_accuracy: 0.8813 - val_loss: 0.4580\n",
      "Epoch 8/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.4591 - val_accuracy: 0.9125 - val_loss: 0.4311\n",
      "Epoch 9/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.4199 - val_accuracy: 0.9438 - val_loss: 0.4057\n",
      "Epoch 10/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.4019 - val_accuracy: 0.9563 - val_loss: 0.3809\n",
      "Epoch 11/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.3842 - val_accuracy: 0.9563 - val_loss: 0.3575\n",
      "Epoch 12/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9351 - loss: 0.3544 - val_accuracy: 0.9688 - val_loss: 0.3372\n",
      "Epoch 13/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.3400 - val_accuracy: 0.9750 - val_loss: 0.3174\n",
      "Epoch 14/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.3130 - val_accuracy: 0.9750 - val_loss: 0.2995\n",
      "Epoch 15/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.2838 - val_accuracy: 0.9812 - val_loss: 0.2853\n",
      "Epoch 16/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.2873 - val_accuracy: 0.9875 - val_loss: 0.2704\n",
      "Epoch 17/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9704 - loss: 0.2599 - val_accuracy: 0.9812 - val_loss: 0.2556\n",
      "Epoch 18/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.2510 - val_accuracy: 0.9875 - val_loss: 0.2440\n",
      "Epoch 19/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9697 - loss: 0.2492 - val_accuracy: 0.9875 - val_loss: 0.2334\n",
      "Epoch 20/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.2299 - val_accuracy: 0.9875 - val_loss: 0.2227\n",
      "Epoch 21/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.2117 - val_accuracy: 0.9875 - val_loss: 0.2151\n",
      "Epoch 22/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.2086 - val_accuracy: 0.9875 - val_loss: 0.2052\n",
      "Epoch 23/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.2123 - val_accuracy: 0.9875 - val_loss: 0.1978\n",
      "Epoch 24/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.1977 - val_accuracy: 0.9812 - val_loss: 0.1898\n",
      "Epoch 25/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.2031 - val_accuracy: 0.9875 - val_loss: 0.1852\n",
      "Epoch 26/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.1939 - val_accuracy: 0.9875 - val_loss: 0.1782\n",
      "Epoch 27/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.1898 - val_accuracy: 0.9875 - val_loss: 0.1716\n",
      "Epoch 28/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.1860 - val_accuracy: 0.9875 - val_loss: 0.1664\n",
      "Epoch 29/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.1772 - val_accuracy: 0.9875 - val_loss: 0.1619\n",
      "Epoch 30/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.1575 - val_accuracy: 0.9812 - val_loss: 0.1557\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.1593 \n",
      "Pérdida en el conjunto de prueba (tanh): 0.15928113460540771\n",
      "Precisión en el conjunto de prueba (tanh): 0.9800000190734863\n",
      "Epoch 1/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5242 - loss: 0.6853 - val_accuracy: 0.8750 - val_loss: 0.6746\n",
      "Epoch 2/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.6742 - val_accuracy: 0.9750 - val_loss: 0.6683\n",
      "Epoch 3/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.6653 - val_accuracy: 0.9625 - val_loss: 0.6601\n",
      "Epoch 4/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.6573 - val_accuracy: 0.9625 - val_loss: 0.6520\n",
      "Epoch 5/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.6513 - val_accuracy: 0.9000 - val_loss: 0.6417\n",
      "Epoch 6/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.6384 - val_accuracy: 0.8813 - val_loss: 0.6325\n",
      "Epoch 7/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9241 - loss: 0.6333 - val_accuracy: 1.0000 - val_loss: 0.6290\n",
      "Epoch 8/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.6226 - val_accuracy: 0.9500 - val_loss: 0.6192\n",
      "Epoch 9/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.6173 - val_accuracy: 0.9438 - val_loss: 0.6100\n",
      "Epoch 10/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9232 - loss: 0.6055 - val_accuracy: 0.9750 - val_loss: 0.6069\n",
      "Epoch 11/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.5945 - val_accuracy: 0.9625 - val_loss: 0.5950\n",
      "Epoch 12/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.5905 - val_accuracy: 0.9875 - val_loss: 0.5894\n",
      "Epoch 13/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.5814 - val_accuracy: 0.9438 - val_loss: 0.5767\n",
      "Epoch 14/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.5760 - val_accuracy: 0.9750 - val_loss: 0.5707\n",
      "Epoch 15/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9374 - loss: 0.5607 - val_accuracy: 0.9625 - val_loss: 0.5612\n",
      "Epoch 16/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.5580 - val_accuracy: 0.9875 - val_loss: 0.5562\n",
      "Epoch 17/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.5454 - val_accuracy: 0.9625 - val_loss: 0.5440\n",
      "Epoch 18/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.5337 - val_accuracy: 0.9750 - val_loss: 0.5362\n",
      "Epoch 19/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.5261 - val_accuracy: 0.9812 - val_loss: 0.5280\n",
      "Epoch 20/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.5281 - val_accuracy: 0.9937 - val_loss: 0.5210\n",
      "Epoch 21/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.5146 - val_accuracy: 0.9750 - val_loss: 0.5101\n",
      "Epoch 22/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.5110 - val_accuracy: 0.9750 - val_loss: 0.5011\n",
      "Epoch 23/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.4945 - val_accuracy: 0.9875 - val_loss: 0.4938\n",
      "Epoch 24/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9483 - loss: 0.4804 - val_accuracy: 0.9750 - val_loss: 0.4825\n",
      "Epoch 25/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.4785 - val_accuracy: 0.9937 - val_loss: 0.4773\n",
      "Epoch 26/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.4678 - val_accuracy: 0.9875 - val_loss: 0.4675\n",
      "Epoch 27/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.4592 - val_accuracy: 0.9750 - val_loss: 0.4571\n",
      "Epoch 28/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.4435 - val_accuracy: 0.9812 - val_loss: 0.4497\n",
      "Epoch 29/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.4471 - val_accuracy: 0.9750 - val_loss: 0.4401\n",
      "Epoch 30/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.4267 - val_accuracy: 0.9875 - val_loss: 0.4335\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.4204 \n",
      "Pérdida en el conjunto de prueba (sigmoid): 0.41852736473083496\n",
      "Precisión en el conjunto de prueba (sigmoid): 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "# E3\n",
    "# Construir el modelo con función de activación tanh\n",
    "model_tanh = Sequential([\n",
    "    Dense(64, activation='tanh', input_shape=(2,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model_tanh.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history_tanh = model_tanh.fit(x_train, y_train, epochs=30, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss_tanh, accuracy_tanh = model_tanh.evaluate(x_test, y_test)\n",
    "print(f'Pérdida en el conjunto de prueba (tanh): {loss_tanh}')\n",
    "print(f'Precisión en el conjunto de prueba (tanh): {accuracy_tanh}')\n",
    "\n",
    "# Construir el modelo con función de activación sigmoid\n",
    "model_sigmoid = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(2,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model_sigmoid.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history_sigmoid = model_sigmoid.fit(x_train, y_train, epochs=30, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss_sigmoid, accuracy_sigmoid = model_sigmoid.evaluate(x_test, y_test)\n",
    "print(f'Pérdida en el conjunto de prueba (sigmoid): {loss_sigmoid}')\n",
    "print(f'Precisión en el conjunto de prueba (sigmoid): {accuracy_sigmoid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da5fcbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0729 - mae: 0.9482 - val_loss: 0.6195 - val_mae: 0.6967\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5565 - mae: 0.6592 - val_loss: 0.2535 - val_mae: 0.4208\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2099 - mae: 0.3826 - val_loss: 0.0788 - val_mae: 0.2276\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0671 - mae: 0.2155 - val_loss: 0.0341 - val_mae: 0.1573\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0309 - mae: 0.1481 - val_loss: 0.0310 - val_mae: 0.1502\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0286 - mae: 0.1416 - val_loss: 0.0279 - val_mae: 0.1425\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0245 - mae: 0.1292 - val_loss: 0.0248 - val_mae: 0.1341\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0231 - mae: 0.1267 - val_loss: 0.0223 - val_mae: 0.1268\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0200 - mae: 0.1165 - val_loss: 0.0199 - val_mae: 0.1194\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168 - mae: 0.1078 - val_loss: 0.0177 - val_mae: 0.1124\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0162 - mae: 0.1045 - val_loss: 0.0157 - val_mae: 0.1053\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0958 - val_loss: 0.0138 - val_mae: 0.0985\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0888 - val_loss: 0.0120 - val_mae: 0.0915\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0841 - val_loss: 0.0105 - val_mae: 0.0848\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092 - mae: 0.0783 - val_loss: 0.0089 - val_mae: 0.0784\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - mae: 0.0726 - val_loss: 0.0075 - val_mae: 0.0720\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - mae: 0.0660 - val_loss: 0.0063 - val_mae: 0.0659\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0624 - val_loss: 0.0051 - val_mae: 0.0594\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0539 - val_loss: 0.0041 - val_mae: 0.0536\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - mae: 0.0483 - val_loss: 0.0033 - val_mae: 0.0476\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mae: 0.0451 \n",
      "Pérdida en el conjunto de prueba: 0.003026240970939398\n",
      "Error absoluto medio en el conjunto de prueba: 0.04461654648184776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Entrada: [0.3 0.7] → Probabilidad: 1.01 → Valor esperado: 1.00\n",
      "Entrada: [0.5 0.5] → Probabilidad: 1.04 → Valor esperado: 1.00\n"
     ]
    }
   ],
   "source": [
    "# E4\n",
    "# Generar datos sintéticos\n",
    "np.random.seed(42)\n",
    "x_1 = np.random.rand(1000)\n",
    "x_2 = np.random.rand(1000)\n",
    "x_data = np.column_stack((x_1, x_2))\n",
    "y_data = x_1 + x_2\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (70%) y prueba (30%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Construir el modelo\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(2,)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, mae = model.evaluate(x_test, y_test)\n",
    "print(f\"Pérdida en el conjunto de prueba: {loss}\")\n",
    "print(f\"Error absoluto medio en el conjunto de prueba: {mae}\")\n",
    "\n",
    "# Nuevas muestras para predicción\n",
    "x_sample = np.array([[0.3, 0.7], [0.5, 0.5]])\n",
    "\n",
    "# Realizar predicciones\n",
    "predicciones = model.predict(x_sample)\n",
    "\n",
    "# Mostrar resultados\n",
    "for i, sample in enumerate(x_sample):\n",
    "    print(f\"Entrada: {sample} → Probabilidad: {predicciones[i][0]:.2f} → Valor esperado: {np.sum(sample):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7cd6bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.3704 - mae: 1.0604 - val_loss: 1.0665 - val_mae: 0.9659\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1502 - mae: 0.9712 - val_loss: 0.8386 - val_mae: 0.8478\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8366 - mae: 0.8068 - val_loss: 0.6364 - val_mae: 0.7278\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6299 - mae: 0.6830 - val_loss: 0.4564 - val_mae: 0.6054\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4977 - mae: 0.5994 - val_loss: 0.3019 - val_mae: 0.4776\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3005 - mae: 0.4586 - val_loss: 0.1845 - val_mae: 0.3594\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1790 - mae: 0.3409 - val_loss: 0.1053 - val_mae: 0.2704\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1104 - mae: 0.2721 - val_loss: 0.0615 - val_mae: 0.2117\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0764 - mae: 0.2344 - val_loss: 0.0438 - val_mae: 0.1786\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0612 - mae: 0.2139 - val_loss: 0.0392 - val_mae: 0.1656\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0530 - mae: 0.1934 - val_loss: 0.0377 - val_mae: 0.1599\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0550 - mae: 0.1997 - val_loss: 0.0354 - val_mae: 0.1546\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0491 - mae: 0.1921 - val_loss: 0.0328 - val_mae: 0.1494\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0466 - mae: 0.1841 - val_loss: 0.0305 - val_mae: 0.1443\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0418 - mae: 0.1754 - val_loss: 0.0285 - val_mae: 0.1393\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0397 - mae: 0.1699 - val_loss: 0.0267 - val_mae: 0.1344\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0393 - mae: 0.1680 - val_loss: 0.0250 - val_mae: 0.1295\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0363 - mae: 0.1619 - val_loss: 0.0235 - val_mae: 0.1247\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0324 - mae: 0.1501 - val_loss: 0.0219 - val_mae: 0.1201\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0293 - mae: 0.1442 - val_loss: 0.0205 - val_mae: 0.1156\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0292 - mae: 0.1400 \n",
      "Pérdida en el conjunto de prueba (500 muestras): 0.029062986373901367\n",
      "Error absoluto medio en el conjunto de prueba (500 muestras): 0.13966381549835205\n"
     ]
    }
   ],
   "source": [
    "# E5\n",
    "# Generar datos sintéticos más pequeños\n",
    "np.random.seed(42)\n",
    "x_1_small = np.random.rand(500)\n",
    "x_2_small = np.random.rand(500)\n",
    "x_data_small = np.column_stack((x_1_small, x_2_small))\n",
    "y_data_small = x_1_small + x_2_small\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (70%) y prueba (30%)\n",
    "x_train_small, x_test_small, y_train_small, y_test_small = train_test_split(x_data_small, y_data_small, test_size=0.3, random_state=42)\n",
    "\n",
    "# Construir y entrenar el modelo\n",
    "model_small = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(2,)),\n",
    "    Dense(1)\n",
    "])\n",
    "model_small.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
    "history_small = model_small.fit(x_train_small, y_train_small, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss_small, mae_small = model_small.evaluate(x_test_small, y_test_small)\n",
    "print(f\"Pérdida en el conjunto de prueba (500 muestras): {loss_small}\")\n",
    "print(f\"Error absoluto medio en el conjunto de prueba (500 muestras): {mae_small}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ad4e17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7558 - mae: 0.7818 - val_loss: 0.2036 - val_mae: 0.3863\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1206 - mae: 0.2819 - val_loss: 0.0234 - val_mae: 0.1253\n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1309 - val_loss: 0.0190 - val_mae: 0.1139\n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0197 - mae: 0.1174 - val_loss: 0.0152 - val_mae: 0.1015\n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - mae: 0.1020 - val_loss: 0.0122 - val_mae: 0.0908\n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - mae: 0.0938 - val_loss: 0.0095 - val_mae: 0.0803\n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - mae: 0.0800 - val_loss: 0.0073 - val_mae: 0.0705\n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - mae: 0.0716 - val_loss: 0.0054 - val_mae: 0.0610\n",
      "Epoch 9/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mae: 0.0620 - val_loss: 0.0038 - val_mae: 0.0512\n",
      "Epoch 10/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0516 - val_loss: 0.0024 - val_mae: 0.0412\n",
      "Epoch 11/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0407 - val_loss: 0.0013 - val_mae: 0.0296\n",
      "Epoch 12/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0279 - val_loss: 4.5074e-04 - val_mae: 0.0177\n",
      "Epoch 13/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6084e-04 - mae: 0.0162 - val_loss: 1.2989e-04 - val_mae: 0.0091\n",
      "Epoch 14/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3975e-05 - mae: 0.0077 - val_loss: 5.6501e-05 - val_mae: 0.0052\n",
      "Epoch 15/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8877e-05 - mae: 0.0050 - val_loss: 4.0846e-05 - val_mae: 0.0045\n",
      "Epoch 16/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3123e-05 - mae: 0.0041 - val_loss: 3.6224e-05 - val_mae: 0.0042\n",
      "Epoch 17/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0958e-05 - mae: 0.0039 - val_loss: 3.3604e-05 - val_mae: 0.0039\n",
      "Epoch 18/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4671e-05 - mae: 0.0035 - val_loss: 3.1301e-05 - val_mae: 0.0036\n",
      "Epoch 19/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5439e-05 - mae: 0.0033 - val_loss: 3.0227e-05 - val_mae: 0.0034\n",
      "Epoch 20/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0535e-05 - mae: 0.0029 - val_loss: 2.8711e-05 - val_mae: 0.0033\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.3619e-05 - mae: 0.0037 \n",
      "Pérdida en el conjunto de prueba (2000 muestras): 3.290706445113756e-05\n",
      "Error absoluto medio en el conjunto de prueba (2000 muestras): 0.0036516357213258743\n"
     ]
    }
   ],
   "source": [
    "# Generar datos sintéticos más grandes\n",
    "np.random.seed(42)\n",
    "x_1_large = np.random.rand(2000)\n",
    "x_2_large = np.random.rand(2000)\n",
    "x_data_large = np.column_stack((x_1_large, x_2_large))\n",
    "y_data_large = x_1_large + x_2_large\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (70%) y prueba (30%)\n",
    "x_train_large, x_test_large, y_train_large, y_test_large = train_test_split(x_data_large, y_data_large, test_size=0.3, random_state=42)\n",
    "\n",
    "# Construir y entrenar el modelo\n",
    "model_large = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(2,)),\n",
    "    Dense(1)\n",
    "])\n",
    "model_large.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
    "history_large = model_large.fit(x_train_large, y_train_large, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss_large, mae_large = model_large.evaluate(x_test_large, y_test_large)\n",
    "print(f'Pérdida en el conjunto de prueba (2000 muestras): {loss_large}')\n",
    "print(f'Error absoluto medio en el conjunto de prueba (2000 muestras): {mae_large}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab2a45c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0683 - mae: 0.9382 - val_loss: 0.6357 - val_mae: 0.7038\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5603 - mae: 0.6669 - val_loss: 0.2875 - val_mae: 0.4542\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2222 - mae: 0.4025 - val_loss: 0.1043 - val_mae: 0.2665\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0875 - mae: 0.2400 - val_loss: 0.0457 - val_mae: 0.1778\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0391 - mae: 0.1598 - val_loss: 0.0386 - val_mae: 0.1599\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1500 - val_loss: 0.0370 - val_mae: 0.1559\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1521 - val_loss: 0.0349 - val_mae: 0.1512\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0328 - mae: 0.1442 - val_loss: 0.0329 - val_mae: 0.1467\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0298 - mae: 0.1395 - val_loss: 0.0310 - val_mae: 0.1421\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0270 - mae: 0.1319 - val_loss: 0.0294 - val_mae: 0.1380\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0266 - mae: 0.1312 - val_loss: 0.0276 - val_mae: 0.1336\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0247 - mae: 0.1262 - val_loss: 0.0259 - val_mae: 0.1293\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0255 - mae: 0.1302 - val_loss: 0.0243 - val_mae: 0.1252\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0227 - mae: 0.1230 - val_loss: 0.0229 - val_mae: 0.1214\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0209 - mae: 0.1176 - val_loss: 0.0215 - val_mae: 0.1180\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0207 - mae: 0.1135 - val_loss: 0.0202 - val_mae: 0.1144\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0172 - mae: 0.1053 - val_loss: 0.0189 - val_mae: 0.1109\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0197 - mae: 0.1116 - val_loss: 0.0178 - val_mae: 0.1074\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 - mae: 0.1063 - val_loss: 0.0167 - val_mae: 0.1042\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.1048 - val_loss: 0.0158 - val_mae: 0.1015\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0946 \n",
      "Pérdida en el conjunto de prueba (con ruido): 0.01435171626508236\n",
      "Error absoluto medio en el conjunto de prueba (con ruido): 0.09611277282238007\n"
     ]
    }
   ],
   "source": [
    "# E6\n",
    "# Generar datos sintéticos con ruido\n",
    "np.random.seed(42)\n",
    "x_1_noise = np.random.rand(1000)\n",
    "x_2_noise = np.random.rand(1000)\n",
    "x_data_noise = np.column_stack((x_1_noise, x_2_noise))\n",
    "y_data_noise = x_1_noise + x_2_noise + np.random.normal(0, 0.1, 1000)  # Añadir ruido gaussiano\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (70%) y prueba (30%)\n",
    "x_train_noise, x_test_noise, y_train_noise, y_test_noise = train_test_split(x_data_noise, y_data_noise, test_size=0.3, random_state=42)\n",
    "\n",
    "# Construir y entrenar el modelo\n",
    "model_noise = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(2,)),\n",
    "    Dense(1)\n",
    "])\n",
    "model_noise.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
    "history_noise = model_noise.fit(x_train_noise, y_train_noise, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss_noise, mae_noise = model_noise.evaluate(x_test_noise, y_test_noise)\n",
    "print(f'Pérdida en el conjunto de prueba (con ruido): {loss_noise}')\n",
    "print(f'Error absoluto medio en el conjunto de prueba (con ruido): {mae_noise}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.503705,
   "end_time": "2024-09-10T18:50:39.408748",
   "environment_variables": {},
   "exception": null,
   "input_path": "./s02.ipynb",
   "output_path": "/home/rufernan/local/DOCENCIA/_2024_2025/C1_PI/PRACTICAS/s02/s02.ipynb",
   "parameters": {},
   "start_time": "2024-09-10T18:50:24.905043",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
