{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWlcCXFsUt1n"
      },
      "source": [
        "# Clustering Particional\n",
        "\n",
        "## Machine Learning. Grado en Ciencia de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Y8pgK5S-Ut1q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.cluster import vq\n",
        "from sklearn.cluster import KMeans,DBSCAN\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqCyLVlaUt1s"
      },
      "source": [
        "### El conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykLjfk3nUt1u"
      },
      "source": [
        "Los datos sobre los que vamos a trabajar se basan en el conjunto de datos `protein`. Después de examinar los datos, vemos que los datos están separados por un tabulador y que los nombres de los países están en la primera columna. Para cargarlos debemos ejecutar la siguiente instrucción, en la que le indicamos el carácter de separación y que el nombre del país va a ser el índice del data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QJWXsE43Ut1v"
      },
      "outputs": [],
      "source": [
        "proteindata = pd.read_csv('proteindata.txt', sep='\\t', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpqYYIJnUt1w"
      },
      "source": [
        "Vamos a examinar los datos para ver si se han leido correctamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEmINthJUt1w",
        "outputId": "46969195-3956-4726-e569-b0aa7fab4a47"
      },
      "outputs": [],
      "source": [
        "proteindata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktOtSY-gUt1x"
      },
      "source": [
        "Aparentemente, todos los datos han sido leídos correctamente. Sin embargo, nos queda por comprobar si los tipos asignados son los adecuados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOKbUG14Ut1y",
        "outputId": "7c0571f2-863d-4b9a-a634-744d24579c7f"
      },
      "outputs": [],
      "source": [
        "proteindata.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrjhLM1wUt1z"
      },
      "source": [
        "Una vez comprobado que hemos leído correctamente los datos, tenemos que comprobar cómo están distribuidos los datos, para ver si es necesario una estandarización de los mismos. Para ello podemos realizar un gráfico de barras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aytDsOAgUt10",
        "outputId": "51ac1aef-0106-4236-ad17-40222eb6c50f"
      },
      "outputs": [],
      "source": [
        "proteindata.boxplot(grid=False, vert=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpTf5DGJUt11"
      },
      "source": [
        "Como se puede apreciar es necesario que transformar los datos para que estos estén en la misma escala y los podamos comparar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "c_a9RmATUt11"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(proteindata)\n",
        "data_scaled = scaler.transform(proteindata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gVX9uANUt11",
        "outputId": "c385523c-0a6e-4be8-ff59-d8258034aebc"
      },
      "outputs": [],
      "source": [
        "protein_scaled = pd.DataFrame(data_scaled, columns=proteindata.columns, index=proteindata.index)\n",
        "protein_scaled.boxplot(grid=False, vert=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9d87yXnUt12"
      },
      "source": [
        "### Kmeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5avYwxEUt12"
      },
      "source": [
        "El módulo `sklearn.cluster` nos ofrece la función `KMeans()` que implementa la técnica de clustering de las **K medias**. Los parámetros más importantes de esta función son:\n",
        "- **n_clusters (int)**: número de clusters objetivo.\n",
        "- **init**: Método de inicialización de los centroides. Se puede utilizar **k-means++**, que es el valor por defecto o la inicialización aleatoria, **ramdom**. También se le puede pasar una matriz con las coordenadas de los centroides.\n",
        "- **n_init (int)**: número de veces que se ejecuta el algoritmo con diferentes inicializaciones de los centroides. Se puede indiciar también **auto** y en ese caso se inicializará a 10 en el caso de que `init='random'` o 1 en el caso de `init='k-means++'`.\n",
        "- **max_iter (int)**: número máximo de iteraciones del algoritmo para cada ejecución. También se le puede indicar la tolerancia, a través del parámetro **tol (float)**, a partir de la cual se considera que la diferencia de los centroides ha hecho converger al algoritmo.\n",
        "- **random_state**: determina la semilla para la inicialización aleatoria de los centroides. Es importante utilizar este parámetro para garantizar la reproducibilidad.\n",
        "\n",
        "A continuación se puede ver un ejemplo de como aplicar la técnica de las `K medias` al conjunto de datos de ejemplo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4INbptPmUt13",
        "outputId": "14e0dcdf-3c39-4691-dd96-e188e1590278"
      },
      "outputs": [],
      "source": [
        "clusters_kmeans = KMeans(n_clusters = 4,random_state = 0,n_init=10)\n",
        "clusters_kmeans.fit(protein_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br5iTAWSUt13"
      },
      "source": [
        "Para poder ver la a qué cluster se ha asignado cada instancia sólo tenemos que acceder al atributo **labels_** del objeto generado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-5sUTUbUt14",
        "outputId": "c25be5ba-a712-497a-8b6c-e97de60f092a"
      },
      "outputs": [],
      "source": [
        "clusters_kmeans.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKEL7QqNUt14"
      },
      "source": [
        "De la misma forma, en el atributo **cluster_centers_** del mismo objeto tenemos la información sobre las coordenadas de los centroides, que pueden ser interesante para mostrar los resultados de forma gráfica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKajn3_dUt14",
        "outputId": "2009559c-5c42-4569-f6bf-5ca62632d27c"
      },
      "outputs": [],
      "source": [
        "clusters_kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK4Pl-kMUt15"
      },
      "source": [
        "A continuación, al igual que hicimos con el agrupamiento jerárquico, podemos ver los resultados del clustering utilizando un gráfico de dispersión al que le añadimos los centroides de cada cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRg5DihjUt15",
        "outputId": "005d5f4e-dafe-4895-9c63-ca9590db52c0"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "centers_x = clusters_kmeans.cluster_centers_[:,protein_scaled.columns.get_loc('RedMeat')]\n",
        "center_y = clusters_kmeans.cluster_centers_[:,protein_scaled.columns.get_loc('Fish')]\n",
        "paises = np.array(protein_scaled.index).astype(str)\n",
        "plt.scatter(protein_scaled[\"RedMeat\"],protein_scaled[\"Fish\"],\n",
        "             c=clusters_kmeans.labels_, cmap='viridis')\n",
        "for i, label in enumerate(paises):\n",
        "    plt.annotate(label, (protein_scaled[\"RedMeat\"][i], protein_scaled[\"Fish\"][i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 5), ha='center', fontsize=6)\n",
        "plt.scatter(centers_x,center_y,marker=\"*\",c=[0,1,2,3],cmap='viridis')\n",
        "plt.xlabel('Red Meat')\n",
        "plt.ylabel('Fish')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7EnIRh0Ut15"
      },
      "source": [
        "También podemos usar la función **kmeans2()** del módulo `scipy.cluster.vq`. En este caso se utiliza el parámetro **k (int)** para indicar el número de clusters y se devuelven dos arrays uno con los centroides y otro con la asignación de instancias a los diferentes clusters. Aquí puedes ver un ejemplo de como utilizarla. En"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uZZdq35cUt16"
      },
      "outputs": [],
      "source": [
        "centroids, labels = vq.kmeans2(protein_scaled,k=4,minit=\"++\",seed=0,iter=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-qo1V8mUt16",
        "outputId": "079c9354-26aa-42b6-c5a8-2f216ca08d31"
      },
      "outputs": [],
      "source": [
        "centroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10q_rw-zUt16",
        "outputId": "ee9c4cab-f020-42a2-fa8c-44e17c1b82f3"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9jM764QUt17"
      },
      "source": [
        "### Kmedoids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F603u1I2Ut17"
      },
      "source": [
        "La técnica de clustering de **K medoides** o **PAM (Partition Arround Medoids)** se puede aplicar a través de la función `KMedodis()` del módulo `sklearn_extra.cluster`. Los parámetros más importantes son:\n",
        "\n",
        "- **n_clusters (int)**: número de clusters objetivo.\n",
        "- **metric** métrica de distancia a utilizar (por defecto está inicializado a 'euclidean').\n",
        "- **init**: Método de inicialización de los centroides. Se puede utilizar **k-medoids++**, que es el valor por defecto o la inicialización aleatoria, **ramdom**. También se le puede pasar una matriz con las coordenadas de los centroides. Otras opciones son: **heuristic**, que selecciona las *n_clusters* instancias con menor distancia total al resto de los elementos, o *build*, inicialización de medoides voraz definida en la descripción original del algoritmo.\n",
        "- **n_init (int)**: número de veces que se ejecuta el algoritmo con diferentes inicializaciones de los centroides. Se puede indiciar también **auto** y en ese caso se inicializará a 10 en el caso de que `init='random'` o 1 en el caso de `init='k-means++'`.\n",
        "- **max_iter (int)**: número máximo de iteraciones del algoritmo para cada ejecución. También se le puede indicar la tolerancia, a través del parámetro **tol (float)**, a partir de la cual se considera que la diferencia de los centroides ha hecho converger al algoritmo.\n",
        "- **random_state**: determina la semilla para la inicialización aleatoria de los centroides. Es importante utilizar este parámetro para garantizar la reproducibilidad.\n",
        "\n",
        "Para aplicar esta técnica  nuestro dataset hay que seguir los mismos pasos que indicamos en la aplicación de las *K medias*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1gqvW8nUt18"
      },
      "outputs": [],
      "source": [
        "from sklearn_extra.cluster import KMedoids\n",
        "\n",
        "clusters_kmediods = KMedoids(n_clusters=4,random_state=0).fit(protein_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf_3kP6cUt18",
        "outputId": "d3075ca9-2bd8-4aa4-8dd6-c332b37aa1ff"
      },
      "outputs": [],
      "source": [
        "clusters_kmediods.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUefFXyaUt18",
        "outputId": "b1dd5de5-55d0-4a07-c9f6-df46645f6efe"
      },
      "outputs": [],
      "source": [
        "clusters_kmediods.medoid_indices_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA8HEnJZUt19"
      },
      "source": [
        "Otra librería interesante que implementa esta técnica es [kmedoids](https://python-kmedoids.readthedocs.io/en/latest/), que implementa versiones más eficientes de *K medoides*. Recuerda que para datasets grandes conviene utilizar la versión **Clara** del *K medoides*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK90rQscUt19"
      },
      "source": [
        "#### Ejercicio 1: Regla del codo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Eku63gnUt19"
      },
      "source": [
        "En este ejercicio vamos a desarrollar todos los pasos necesarios para aplicar la regla del codo. Recuerda que tenemos que calcular la distancia intracluster para determinados números de clusters y elegir aquel en el que se produzca un cambio de tendencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPTvfyQ8Ut19",
        "outputId": "c9c63f9d-aa9e-456e-e15a-ebec5c924deb"
      },
      "outputs": [],
      "source": [
        "## Define una array vacío, wss, para ir almacenando la distancia intracluster para cada número de clusters elegido.\n",
        "## PON TU CÓDIGO AQUÍ\n",
        "\n",
        "\n",
        "## Definir un bucle que vaya del número mínimo de clusters al número máximo de clusters.\n",
        "## Para cada número de clusters aplicar el algoritmo k-medias.\n",
        "## Una vez aplicado el algoritmo determinar la suma de distancia intraclusters y añadirla al array wss.\n",
        "## PON TU CÓDIGO AQUÍ\n",
        "\n",
        "\n",
        "## Una vez terminado el bucle crear un gráfico con los diferentes números de clusters en el eje X y la distancia intracluster en el eje Y.\n",
        "## PON TU CÓDIGO AQUÍ\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckVJcUAjUt1-"
      },
      "source": [
        "¿Cuál crees que puede ser el k óptimo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1q-K9PBUt2C"
      },
      "source": [
        "#### Ejercicio 2. Selección del número de cluster óptimo utilizando el índice silueta.\n",
        "Repite el ejercicio anterior pero dentro del bucle calcula el índice silueta medio. Recuerda que el **k** óptimo será el que tenga asociado el índice máximo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L7w8xw9Ut2D"
      },
      "outputs": [],
      "source": [
        "# PON TU CÓIDIGO AQUÍ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VkwKrjDUt2D"
      },
      "source": [
        "### DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdxw50eZUt2D"
      },
      "source": [
        "El método de clustering **DBSCAN** lo podemos aplicar utilizando la función `DBSCAN()` del módulo `sklearn.cluster`. Los parámetros más importantes son:\n",
        "\n",
        "- **eps (float)**: radio para la definición de la *epsilon-vecindad* (por defecto 0.5).\n",
        "- **min_samples (int)**: mínimo número de puntos en la  *epsilon-vecindad* para definir un punto núcleo (por defecto 5).\n",
        "- **metric**: métrica de distancia a utilizar, por defecto `metric='euclidean'`.\n",
        "\n",
        "Los parámetros *eps* y *min_samples* son críticos para el funcionamiento del algoritmo. Para seleccionarlos de forma adecuada hay que analizar un gráfico en el que se muestren de forma ordenada de menor a mayor las distancias de cada punto a los `min_samples` instancias más cercanas. Esto se puede hacer utilizando la función  `NearestNeighbors()` del módulo `sklearn.neighbors` que nos devuelve una matriz de dimensiones $n\\_samples \\times n\\_vecinos-1$ (la primera columna es la distancia de cada punto consigo mismo, la segunda es la distancia al segundo punto más cercano y, así, sucesivamente).\n",
        "\n",
        "Vamos a construir el gráfico de las *KNN distancias*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ1sv2IHUt2E",
        "outputId": "56ea73f7-d959-475b-d9ff-d512e58f2f4d"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Llamamos a la función NearestNeighbors para calcular la distancia a los 4 vecinos más cercanos.\n",
        "\n",
        "neighbors = NearestNeighbors(n_neighbors=4).fit(protein_scaled)\n",
        "\n",
        "# Extraemos las distancias y los índices de los vecinos más cercanos con la función kneighbors().\n",
        "\n",
        "distances, indices = neighbors.kneighbors(protein_scaled)\n",
        "\n",
        "# Elimina la primera columna ya que contiene la distancia de cada punto consigo mismo\n",
        "distances = distances[:,1:].reshape(-1)\n",
        "\n",
        "# Transforma la matriz de distancia en una array de dimensión 1.\n",
        "distances = distances.reshape(-1)\n",
        "\n",
        "# Ordena las distancias en orden descendente\n",
        "distances = np.sort(distances, axis=0)\n",
        "\n",
        "# Crea un gráfico en el que el eje y represente las distancias.\n",
        "plt.plot(distances)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_Z-cCLAUt2E"
      },
      "source": [
        "Cómo se puede apreciar en el gráfico hay dos cambios de tendencia, uno muy evidente en torno a 3 y otro, más suave cercano a 2.5. Habría que probar estos valores teniendo en cuenta que min_samples lo hemos fijado a 3. Vamos a empezar con `eps=3.0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKiDVId7Ut2E"
      },
      "outputs": [],
      "source": [
        "clusters_dbscan = DBSCAN(eps=3,min_samples=3).fit(protein_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQRdxjH2Ut2E"
      },
      "source": [
        "Para determinar qué cluster ha sido asignado a cada instancia debemos acceder al atributo `labels_` del objeto generado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn_R4QTGUt2F",
        "outputId": "5b22ce90-b05d-4c1e-b81f-1248eff20556"
      },
      "outputs": [],
      "source": [
        "clusters_dbscan.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xREMCqKwUt2F"
      },
      "source": [
        "Como podemos apreciar, se han asignado todos las instancias al mismo cluster, con lo que parece lógico que probemos con un valor localizado cercano a 2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T0oJkM6Ut2F"
      },
      "outputs": [],
      "source": [
        "clusters_dbscan = DBSCAN(eps=2.3,min_samples=3).fit(protein_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6-VPOL6Ut2G",
        "outputId": "d9320658-26ab-4388-ab5d-08f31d00c146"
      },
      "outputs": [],
      "source": [
        "clusters_dbscan.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6_kqzZyUt2G"
      },
      "source": [
        "#### Ejercicio 3.\n",
        "1. ¿Qué crees que significa el cluster marcado con la etiqueta -1?\n",
        "2. Construye un algoritmo para encontrar el eps óptimo utilizando el índice silueta.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
