# Número de subconjuntos o folds para la validación cruzada
numero_folds = 5
# Función utilidad
métrica = 'neg_mean_squared_error'

# Generamos el pipeline
poly = PolynomialFeatures()
pipeline_reg = Pipeline([('elevar_a_potencias', poly), ('regresor_lineal', aproximador_lineal)])

# Los valores de los hiperparámetros se guardan en un diccionario o en una lista de diccionarios
rejilla_hiperparametros_poly = [
{'elevar_a_potencias__degree': np.arange(1,30,1)},
]

# Se crean todas las configuraciones del perceptrón multicapa
grid_search_poly = GridSearchCV(pipeline_reg, rejilla_hiperparametros_poly, cv=numero_folds,
                           scoring=metrica, return_train_score=True)

# Ahora el conjunto de datos de entrenamiento es empleado con grid_search 
# y el conjunto de test se empleará posteriormente una vez seleccionada la mejor configuración
# Como esta partición se ha realizado anteriormente se puede reutilizar

# Entrenamiento y validación de todas las configuraciones
grid_search_poly.fit(x_reg_ent, y_reg_ent)


# Mejores parámetros de entre los probados
print(grid_search_poly.best_params_)

# La configuración con los mejores parámetros
grid_search_poly.best_estimator_