{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Práctica 7: curvas de aprendizaje en Machine Learning: the California housing problem "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una curva de aprendizaje en Machine Learning simplemente es una gráfica donde se representa las epochs (eje horizontal) frente a la función objetivo (eje vertical).\n",
    "\n",
    "En este ejercicio vermos cómo usar las curvas de aprendizaje para analizar el comportamiento de varios algoritmos de optimización. Para ello, estudiaremos el llamado **California housing problem**, el cual es un problema de regresión que consiste en predecir el valor que debe tener una casa en California dependiendo de varias características. La descripción de los datos es la siguiente:\n",
    "\n",
    "**Labels**\n",
    "\n",
    "'MedHouseVal' = Mediana de viviendas para familias en una manzana (medido en dólares estadounidenses)\n",
    "\n",
    "**Features**\n",
    "\n",
    "'MedInc' = Media de ingresos para grupos familiares en una manzana (medido en decenas de miles de dólares estadounidenses)\n",
    "\n",
    "'HouseAge' = Antigüedad media de una casa \n",
    "\n",
    "'AveRooms' = Media de habitaciones en un bloque de casas\n",
    "\n",
    "'AveBedrms' = Media de habitaciones en un barrio\n",
    "\n",
    "'Population' = Cantidad total de personas que residen en un barrio\n",
    "\n",
    "'AveOccup' = media de casa ocupadas\n",
    "\n",
    "'Latitude' = latitud geográfica de la casa\n",
    "\n",
    "'Longitude' = longitud geográfica de la casa\n",
    "\n",
    "Estas dos últimas características hacen referencia a la localización de la casa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos están almacenados es una basa de datos de **scikitlearn**. Con las siguientes líneas de código los cargamos."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:26:23.595045Z",
     "start_time": "2024-11-07T14:26:23.559384Z"
    }
   },
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "housing\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 20640\\n\\n:Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n:Attribute Information:\\n    - MedInc        median income in block group\\n    - HouseAge      median house age in block group\\n    - AveRooms      average number of rooms per household\\n    - AveBedrms     average number of bedrooms per household\\n    - Population    block group population\\n    - AveOccup      average number of household members\\n    - Latitude      block group latitude\\n    - Longitude     block group longitude\\n\\n:Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. rubric:: References\\n\\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n  Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![En este gráfico puedes ver la distribución de casas y precios](..\\data\\california_housing.png)"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes líneas de código hacen la separación entre datos de entrenamiento, validación y test.\n",
    "\n",
    "También normalizan los datos. Esta es una técnica usual en Machine Learning que trata de evitar sesgos en los datos de partida. Para cada una de las 8 columnas de características, la normalización de los datos se hace de manera stándard del siguiente modo:\n",
    "\n",
    "1) Se calculan la media $\\mu_j$ y la desviación típica $\\sigma_j$, $1\\leq j\\leq 8$.\n",
    "\n",
    "2) Si $x^j$ denota la columna $j-$ésima, entonces dicha columna se transforma en \n",
    "\n",
    "$$\n",
    "\\hat{x}^j = \\frac{x^j - \\mu_j}{\\sigma_j}\n",
    "$$\n",
    "\n",
    "con lo cual los nuevos datos tienen media cero y varianza 1.\n",
    "\n",
    "Las siguientes líneas de código hacen el trabajo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:31:14.825717Z",
     "start_time": "2024-11-07T14:31:14.802371Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que ha aparecido un nuevo conjunto de datos **X_valid**. Se trata de un subconjunto de datos que se usa para tunear hiperparámetros del modelo, por ejemplo el número de capas ocultas, neuronas por capa, etc. Por tanto, **X_valid** se usa durante el entrenamiento. Es un subconjunto de los datos de entrenamiento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimer por pantalla las dimensiones de los conjuntos **X_train**, **X_val** y **X_test**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:33:05.551625Z",
     "start_time": "2024-11-07T14:33:05.530822Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "print(f\"Dimesiones de X_train: {X_train.shape}\")\n",
    "print(f\"Dimensiones de X_valid: {X_valid.shape}\")\n",
    "print(f\"Dimesiones de X_test: {X_test.shape}\")\n",
    "# --------------------\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimesiones de X_train: (11610, 8)\n",
      "Dimensiones de X_valid: (3870, 8)\n",
      "Dimesiones de X_test: (5160, 8)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación cargamos **tensorflow** y **numpy**. Asímismo, fijamos semillas en **numpy** y **tensorflow** para que la reproducción de procesos aleatorios de el mismo resultado."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:33:28.218909Z",
     "start_time": "2024-11-07T14:33:12.365969Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:33:28.249595Z",
     "start_time": "2024-11-07T14:33:28.231367Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, construimos el modelo de predicción (la red neuronal). Se trata de un MultiLayerPerceptron (MLP) con $8$ canales de entrada, una sóla capa oculta de $30$ neuronas, y una salida escalar. Es decir\n",
    "$$\n",
    "NN(x,\\theta) =  \\sum_{j=1}^{30} a_j\\sigma \\left(\\omega x + b\\right)_j + b_{output}, \\quad \\theta = (\\omega; b) \n",
    "$$\n",
    "donde $\\sigma$ es la función de activación, la cual se aplica componente a componente, $\\omega$ es una matriz de tamaño $30\\times 8$, $b$ es un vector bias de tamaño $30$, y $b_{output}$ es un bias de salida escalar. Por tanto, nuestro modelo tiene $30\\times 8 + 30 + 30 +1 = 301 $ parámetros de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:33:30.125883Z",
     "start_time": "2024-11-07T14:33:30.118368Z"
    }
   },
   "source": [
    "from tensorflow import keras\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:33:32.037482Z",
     "start_time": "2024-11-07T14:33:31.713629Z"
    }
   },
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", kernel_initializer='glorot_uniform',\n",
    "                        input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcoja\\.conda\\envs\\optim-2\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)             │           \u001B[38;5;34m270\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m31\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m301\u001B[0m (1.18 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m301\u001B[0m (1.18 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explica con tus propias palabras lo que hacen las líneas de código de la celda anterior. Para ello consulta la  [API de Keras](https://keras.io/api/)\n",
    "\n",
    "----\n",
    "Este código crea un modelo de red neuronal con dos capas para hacer predicciones.\n",
    "\n",
    "1. Primero, se define el modelo como una serie de capas que se conectan en orden.\n",
    "2. La primera capa tiene 30 neuronas y usa una función que ayuda a que el modelo aprenda patrones más complejos. También se configura para que reciba los datos de entrada con la misma cantidad de características (columnas) que tiene nuestro conjunto de entrenamiento.\n",
    "3. La segunda capa tiene solo 1 neurona y no usa ninguna función especial; esto indica que se espera un resultado en forma de número continuo (como un precio o una puntuación)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Finalmente, la última línea muestra un resumen del modelo, para ver cuántas capas y parámetros tiene en total, lo cual ayuda a entender mejor su estructura.\n",
    "\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuramos el modelo para el entrenamiento. Elegimos como función objetivo (loss function) el error cuadrático medio, y como optimizador el gradiente estocástico sencillo learning rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:35:00.791302Z",
     "start_time": "2024-11-07T14:35:00.762699Z"
    }
   },
   "source": "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))",
   "outputs": [],
   "execution_count": 10
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con el [método fit](https://keras.io/api/models/model_training_apis/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:35:17.720935Z",
     "start_time": "2024-11-07T14:35:04.237686Z"
    }
   },
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2.7340 - val_loss: 1.0701\n",
      "Epoch 2/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.8365 - val_loss: 0.7330\n",
      "Epoch 3/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.7319 - val_loss: 0.6699\n",
      "Epoch 4/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.6784 - val_loss: 0.6241\n",
      "Epoch 5/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.6366 - val_loss: 0.5863\n",
      "Epoch 6/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.6007 - val_loss: 0.5543\n",
      "Epoch 7/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5712 - val_loss: 0.5270\n",
      "Epoch 8/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5467 - val_loss: 0.5040\n",
      "Epoch 9/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.5267 - val_loss: 0.4846\n",
      "Epoch 10/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5103 - val_loss: 0.4684\n",
      "Epoch 11/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.4974 - val_loss: 0.4548\n",
      "Epoch 12/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.4867 - val_loss: 0.4434\n",
      "Epoch 13/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.4777 - val_loss: 0.4339\n",
      "Epoch 14/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.4713 - val_loss: 0.4259\n",
      "Epoch 15/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.4639 - val_loss: 0.4193\n",
      "Epoch 16/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.4587 - val_loss: 0.4138\n",
      "Epoch 17/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.4543 - val_loss: 0.4092\n",
      "Epoch 18/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.4497 - val_loss: 0.4053\n",
      "Epoch 19/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.4462 - val_loss: 0.4021\n",
      "Epoch 20/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.4435 - val_loss: 0.3993\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Se ha usado mini-batch en el método de gradiente estocástico anterior? En caso afirmativo, ¿cúantos datos contiene cada mini-batch?\n",
    "\n",
    "Te puede ayudar a responder estas preguntas los resultados que obtienes de ejecutar la celda siguiente, que también has de explicar."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:35:17.751843Z",
     "start_time": "2024-11-07T14:35:17.736670Z"
    }
   },
   "source": [
    "print(history.params)\n",
    "print(history.history)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 'auto', 'epochs': 20, 'steps': 363}\n",
      "{'loss': [1.7961151599884033, 0.7711697816848755, 0.6862578392028809, 0.6370391249656677, 0.5980494618415833, 0.5661649107933044, 0.5394650101661682, 0.517589271068573, 0.49987921118736267, 0.48557859659194946, 0.47406521439552307, 0.4646454155445099, 0.4567851424217224, 0.4502040147781372, 0.4446551501750946, 0.43989884853363037, 0.4357775151729584, 0.43217623233795166, 0.42898085713386536, 0.42611315846443176], 'val_loss': [1.0701451301574707, 0.7330297827720642, 0.6699450016021729, 0.6241441369056702, 0.5863320827484131, 0.5543079376220703, 0.5269997119903564, 0.5040370225906372, 0.4846380949020386, 0.4683707058429718, 0.45479467511177063, 0.44336968660354614, 0.43386122584342957, 0.42591989040374756, 0.4193131923675537, 0.4138270616531372, 0.4091998338699341, 0.40533873438835144, 0.4020824730396271, 0.39932486414909363]}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar aquí\n",
    "\n",
    "# --------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación nos ocupamos de analizar la evolución del algoritmo de optimización (training process).\n",
    "Para ello usaremos los módulos **pandas** y **matplotlib** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = pd.DataFrame(history.history)\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(loss_history['loss'], label='Loss')\n",
    "ax.plot(loss_history['val_loss'], label='Validation loss')\n",
    "ax.grid()\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('loss function')\n",
    "ax.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, evaluamos el error cuadrático medio sobre los datos test con  [model.evaluate](https://keras.io/api/models/model_training_apis/) y hacemos predicciones sobre conjuntos de datos con [model.predict](https://keras.io/api/models/model_training_apis/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(f\"MSE_test = {mse_test}\")\n",
    "X_new = X_test[:3]\n",
    "print(f\"X_new = { X_new}\")\n",
    "y_pred = model.predict(X_new)\n",
    "print(f\"y_predict = {y_pred}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acabar la práctica, vamos a entrenar el modelo con otro algoritmo de optimización. Para ello:\n",
    "\n",
    "1) Crea de nuevo el modelo y llámale **model_2**.\n",
    "\n",
    "2) Configura el modelo de entrenamiento  **model_2** para lo cual debes elegir algún otro algoritmo de optimización (el que quieras) de los disponibles en el método **model.compile** \n",
    "\n",
    "3) Entrena **model_2** con mini-batches que contengan $64$ datos y para $50$ epochs. \n",
    "\n",
    "Los resultados que se muestran a continuación se corresponden con el algoritmo **Adam**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar aquí\n",
    "\n",
    "# --------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, dibuja las curvas de aprendizaje para tu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar aquí\n",
    "\n",
    "# --------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
