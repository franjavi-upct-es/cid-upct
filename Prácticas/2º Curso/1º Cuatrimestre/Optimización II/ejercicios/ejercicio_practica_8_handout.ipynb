{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Práctica 8: más sobre inicialización, batch normalization y dropout "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio insistiremos un poco más en la inicialización, batch-normalization y dropout. Entrenaremos un modelo dado y haremos predicciones tomando como punto de partida la base de datos [Fashion MNIST](https://www.tensorflow.org/datasets/catalog/fashion_mnist?hl=es-419)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset\n",
    "\n",
    "Tras llamar a **tensorflow** y **keras**, carga los datos de datos   [Fashion MNIST](https://www.tensorflow.org/datasets/catalog/fashion_mnist?hl=es-419) que usamos en esta práctica, y genera los datos de entrenamiento **(X_train_full, y_train_full)** y de test **(X_test, y_test)**. A continuación, divide **(X_train_full, y_train_full)** en dos subconjunto de datos, a saber  **(X_valid, y_valid)** y **(X_train, y_train)** , el primero de los cuales contiene los primeros $5000$ datos, y el segundo el resto. Has de dividir **X_train** , **X_test** y **X_valid** por $255.0$ para hacer que el rango de grises de las imágenes varíe entre $0$ y $1$.\n",
    "\n",
    "Finalmente, imprime la información referente al tamaño de todo estos datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:19:38.077396Z",
     "start_time": "2024-11-02T09:19:31.630148Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:19:38.581566Z",
     "start_time": "2024-11-02T09:19:38.084849Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Dividir los datos de entrenamiento en datos de validación y de entrenamiento\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "X_valid = X_valid / 255.0\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print(f\"X_train_full shape: {X_train_full.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "# --------------------\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_full shape: (60000, 28, 28)\n",
      "X_valid shape: (5000, 28, 28)\n",
      "X_train shape: (55000, 28, 28)\n",
      "X_test shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación damos nombres a los **labels** de la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:19:38.830205Z",
     "start_time": "2024-11-02T09:19:38.815260Z"
    }
   },
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "print(class_names[y_test[1]])\n",
    "print(y_test[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pullover\n",
      "2\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Construcción del modelo de predicción\n",
    "\n",
    "Construye un modelo de predicción tipo **MultiLayer Perceptron** diferente del que hicimos en la práctica, el que tú quieras, pero ha de incluir inicialización de parámetros, batch normalization y dropout. Imprime por pantalla las características del modelo que hayas creado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compilación del modelo\n",
    "\n",
    "Compilar el modelo significa que hemos de indicar la función de pérdida (función objetivo a minimizar), el algoritmo de optimización que usaremos y, opcionalmente, las métricas que nos pueda interesar medir.\n",
    "\n",
    "Recuerda que todo esto se hace con el método [compile](https://keras.io/api/models/model_training_apis/).\n",
    "\n",
    "Compila el modelo con la función de pérdida **sparse_categorial_crossentropy**, el optimizador será **Adam** y la métrica **accuracy**.\n",
    "\n",
    "La función de pérdida **sparse_categorial_crossentropy** se define como\n",
    "\n",
    "$$\n",
    "J(\\omega) = -\\frac{1}{N}\\sum_{n=1}^Ny_n\\log(\\hat{y}_n(\\omega)) + (1-y_n)\\log(1-\\hat{y}_n(\\omega))\n",
    "$$\n",
    "donde $y_n$ son los true labels e $\\hat{y}_n(\\omega)$ son los que predice el modelo, ambos para la instance $n$.\n",
    "\n",
    "Has de explicar qué significa la métrica **accuracy**.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:19:39.221124Z",
     "start_time": "2024-11-02T09:19:38.865264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Completar aquí\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "# Definimos el model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(layers.Dense(300, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(100, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Mostramos las características del modelo\n",
    "model.summary()\n",
    "# --------------------\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcoja\\.conda\\envs\\optim-2\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m784\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)            │       \u001B[38;5;34m235,500\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)            │         \u001B[38;5;34m1,200\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │        \u001B[38;5;34m30,100\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │           \u001B[38;5;34m400\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │         \u001B[38;5;34m1,010\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m268,210\u001B[0m (1.02 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,210</span> (1.02 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m267,410\u001B[0m (1.02 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">267,410</span> (1.02 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m800\u001B[0m (3.12 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> (3.12 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:19:39.267071Z",
     "start_time": "2024-11-02T09:19:39.253546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Completar aquí\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# --------------------\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "La métrica **accuracy** mide el porcentaje de predicciones correctas realizadas por el modelo sobre el total de ejemplos. En un problema de clasificación, `accuracy` se calcula como: \n",
    "\n",
    "$$\\text{Accuracy}=\\dfrac{\\text{Número de predicciones correctas}}{\\text{Total de predicciones}}$$\n",
    " \n",
    "Esta métrica es particularmente útil para problemas de clasificación balanceados, ya que indica cúantas veces el modelo acertó en la predicción de la clase correcta en comparación con el total de predicciones realizadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the model. Entrenamos el modelo con el [método fit](https://keras.io/api/models/model_training_apis/)\n",
    "\n",
    "Has de entrenar el modelo sobre los datos (X_train, y_train), pero usa también (X_valid, y_valid) para validar. Has de tomar mini-batch de tamaño $100$ y $30$ epochs   "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:20:41.495449Z",
     "start_time": "2024-11-02T09:19:39.300294Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=100, \n",
    "                    validation_data=(X_valid, y_valid)\n",
    "                    )\n",
    "# --------------------\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - accuracy: 0.7392 - loss: 0.7559 - val_accuracy: 0.8416 - val_loss: 0.4479\n",
      "Epoch 2/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8367 - loss: 0.4500 - val_accuracy: 0.8610 - val_loss: 0.3870\n",
      "Epoch 3/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8500 - loss: 0.4128 - val_accuracy: 0.8630 - val_loss: 0.3711\n",
      "Epoch 4/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8598 - loss: 0.3851 - val_accuracy: 0.8740 - val_loss: 0.3400\n",
      "Epoch 5/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8642 - loss: 0.3775 - val_accuracy: 0.8686 - val_loss: 0.3470\n",
      "Epoch 6/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8638 - loss: 0.3711 - val_accuracy: 0.8724 - val_loss: 0.3476\n",
      "Epoch 7/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8672 - loss: 0.3589 - val_accuracy: 0.8774 - val_loss: 0.3267\n",
      "Epoch 8/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8711 - loss: 0.3477 - val_accuracy: 0.8842 - val_loss: 0.3172\n",
      "Epoch 9/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8739 - loss: 0.3418 - val_accuracy: 0.8886 - val_loss: 0.3092\n",
      "Epoch 10/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8783 - loss: 0.3339 - val_accuracy: 0.8820 - val_loss: 0.3215\n",
      "Epoch 11/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8832 - loss: 0.3185 - val_accuracy: 0.8738 - val_loss: 0.3459\n",
      "Epoch 12/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8840 - loss: 0.3192 - val_accuracy: 0.8778 - val_loss: 0.3302\n",
      "Epoch 13/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8843 - loss: 0.3094 - val_accuracy: 0.8882 - val_loss: 0.3029\n",
      "Epoch 14/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8815 - loss: 0.3176 - val_accuracy: 0.8830 - val_loss: 0.3159\n",
      "Epoch 15/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8865 - loss: 0.3069 - val_accuracy: 0.8882 - val_loss: 0.3095\n",
      "Epoch 16/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8880 - loss: 0.3020 - val_accuracy: 0.8874 - val_loss: 0.3012\n",
      "Epoch 21/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8852 - loss: 0.3054 - val_accuracy: 0.8800 - val_loss: 0.3145\n",
      "Epoch 17/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8857 - loss: 0.3042 - val_accuracy: 0.8900 - val_loss: 0.3018\n",
      "Epoch 18/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8868 - loss: 0.3018 - val_accuracy: 0.8950 - val_loss: 0.2935\n",
      "Epoch 19/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8886 - loss: 0.2989 - val_accuracy: 0.8820 - val_loss: 0.3156\n",
      "Epoch 20/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8915 - loss: 0.2918 - val_accuracy: 0.8902 - val_loss: 0.3089\n",
      "Epoch 22/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8959 - loss: 0.2821 - val_accuracy: 0.8916 - val_loss: 0.2942\n",
      "Epoch 23/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8942 - loss: 0.2812 - val_accuracy: 0.8914 - val_loss: 0.2985\n",
      "Epoch 24/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8959 - loss: 0.2778 - val_accuracy: 0.8818 - val_loss: 0.3223\n",
      "Epoch 25/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8958 - loss: 0.2745 - val_accuracy: 0.8946 - val_loss: 0.2869\n",
      "Epoch 26/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9016 - loss: 0.2688 - val_accuracy: 0.8938 - val_loss: 0.2821\n",
      "Epoch 27/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8977 - loss: 0.2767 - val_accuracy: 0.8870 - val_loss: 0.3071\n",
      "Epoch 28/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8988 - loss: 0.2735 - val_accuracy: 0.8922 - val_loss: 0.2932\n",
      "Epoch 29/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9002 - loss: 0.2706 - val_accuracy: 0.8938 - val_loss: 0.2913\n",
      "Epoch 30/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9011 - loss: 0.2619 - val_accuracy: 0.8906 - val_loss: 0.2862\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación nos ocupamos de analizar la evolución del algoritmo de optimización (training process).\n",
    "Para ello usaremos  **pandas**.\n",
    "\n",
    "Importa **pandas** y después almacena e imprime la historia de la evolución del aprendizaje en un DataFrame de pandas.\n",
    "\n",
    "La información importante está en la última línea donde obtenemos el llamado **error de entrenamiento** para los datos de entrenamiento. También devuelve el error sobre los datos de validación. Estos últimos se utilizan para tunear los hiperparámetros del modelo (número de layers, de neuronas por layer, learning rate, etc.) pero de eso no nos ocupamos en esta asignatura. Eso lo dejamos para las asignaturas de Machine Learning. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:20:41.588239Z",
     "start_time": "2024-11-02T09:20:41.544384Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "import pandas as pd\n",
    "\n",
    "# Analizar a evolución del algoritmo\n",
    "history_df = pd.DataFrame(history.history)\n",
    "print(history_df)\n",
    "\n",
    "# Obtener el error de entrenamiento y el error sobre los datos de validación\n",
    "training_error = history_df['loss'].iloc[-1]\n",
    "validation_error = history_df['val_loss'].iloc[-1]\n",
    "print(f\"Error de entrenamiento: {training_error:.4f}\")\n",
    "print(f\"Error de validación: {validation_error:.4f}\")\n",
    "# --------------------"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    accuracy      loss  val_accuracy  val_loss\n",
      "0   0.794800  0.579355        0.8416  0.447919\n",
      "1   0.839909  0.444025        0.8610  0.387030\n",
      "2   0.852000  0.408401        0.8630  0.371115\n",
      "3   0.858327  0.389561        0.8740  0.340020\n",
      "4   0.863873  0.375927        0.8686  0.346990\n",
      "5   0.864673  0.369099        0.8724  0.347556\n",
      "6   0.868636  0.357159        0.8774  0.326679\n",
      "7   0.873745  0.345018        0.8842  0.317230\n",
      "8   0.873418  0.341342        0.8886  0.309179\n",
      "9   0.877455  0.333432        0.8820  0.321510\n",
      "10  0.881818  0.323244        0.8738  0.345933\n",
      "11  0.882236  0.321608        0.8778  0.330205\n",
      "12  0.882655  0.319686        0.8882  0.302880\n",
      "13  0.883091  0.315661        0.8830  0.315882\n",
      "14  0.885836  0.310173        0.8882  0.309511\n",
      "15  0.886836  0.304597        0.8800  0.314512\n",
      "16  0.885964  0.302492        0.8900  0.301768\n",
      "17  0.888000  0.302006        0.8950  0.293495\n",
      "18  0.888473  0.300021        0.8820  0.315579\n",
      "19  0.889473  0.297007        0.8874  0.301157\n",
      "20  0.891855  0.290609        0.8902  0.308856\n",
      "21  0.892164  0.289802        0.8916  0.294155\n",
      "22  0.893345  0.282998        0.8914  0.298454\n",
      "23  0.894655  0.280804        0.8818  0.322256\n",
      "24  0.895782  0.279390        0.8946  0.286858\n",
      "25  0.899236  0.274232        0.8938  0.282138\n",
      "26  0.896527  0.277980        0.8870  0.307122\n",
      "27  0.897200  0.272585        0.8922  0.293192\n",
      "28  0.899855  0.268966        0.8938  0.291310\n",
      "29  0.899000  0.266230        0.8906  0.286176\n",
      "Error de entrenamiento: 0.2662\n",
      "Error de validación: 0.2862\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, evaluamos nuestro modelo de predicción sobre los datos test con  [model.evaluate](https://keras.io/api/models/model_training_apis/). La salida (llamada **error de generalización**) es un vector de dos componentes, una para la función de pérdida y la otra para la métrica. Lo importante aquí es la métrica.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:20:42.723744Z",
     "start_time": "2024-11-02T09:20:41.638734Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "# Evaluamos el modelo sobre los datos de test\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Error de generalización\")\n",
    "print(f\"Función de pérdida: {test_loss:.4f}\")\n",
    "print(f\"Métrica de precisión: {test_accuracy:.4f}\")\n",
    "# --------------------\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.8761 - loss: 0.3270\n",
      "Error de generalización\n",
      "Función de pérdida: 0.3254\n",
      "Métrica de precisión: 0.8768\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer predicciones sobre datos concretos con [model.predict](https://keras.io/api/models/model_training_apis/). Por ejemplo, podemos comparar los resultados que devuelve el modelo de predicción con los datos reales sobre los primeros $3$ datos test: "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:20:42.957096Z",
     "start_time": "2024-11-02T09:20:42.757467Z"
    }
   },
   "source": [
    "X_new = X_test[:3]\n",
    "\n",
    "y_pred = model.predict(X_new)\n",
    "print(f\"y_predict = {y_pred.round(2)}\")\n",
    "\n",
    "print(f\"y_true = {y_test[:3]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 134ms/step\n",
      "y_predict = [[0.   0.   0.   0.   0.   0.   0.   0.01 0.   0.99]\n",
      " [0.   0.   0.99 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "y_true = [9 2 1]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar en los resultados anteriores, **y_pred.round(2)** redondea a 2 cifras decimales la probabilidad de cada clase. Así, el modelo de predicción anterior predice los valores correctos (clases $9$, $2$ y $1$, respectivamente. Recuerda que siempre empezamos a contar en cero). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acabar la práctica, vuelve a ejercutar todo el código pero comentando las líneas que hacen referencia a **batch normalization** y **dropout** y compara los resultados obtenidos, es decir, escribe los errores de entrenamiento y de generalización."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:20:43.064927Z",
     "start_time": "2024-11-02T09:20:42.989438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definimos el modelo\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Flatten(input_shape=[28, 28]))\n",
    "model2.add(layers.Dense(300, kernel_initializer='he_normal', activation='relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Dropout(0.3))\n",
    "model2.add(layers.Dense(100, kernel_initializer='he_normal', activation='relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Dropout(0.3))\n",
    "model2.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Mostramos las características del modelo\n",
    "model2.summary()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcoja\\.conda\\envs\\optim-2\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m784\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)            │       \u001B[38;5;34m235,500\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │        \u001B[38;5;34m30,100\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │         \u001B[38;5;34m1,010\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m266,610\u001B[0m (1.02 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m266,610\u001B[0m (1.02 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:21:42.687942Z",
     "start_time": "2024-11-02T09:20:43.109810Z"
    }
   },
   "cell_type": "code",
   "source": "history2 = model.fit(X_train, y_train, epochs=30, batch_size=100, validation_data=(X_valid, y_valid))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9001 - loss: 0.2664 - val_accuracy: 0.8892 - val_loss: 0.3009\n",
      "Epoch 2/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9018 - loss: 0.2636 - val_accuracy: 0.8914 - val_loss: 0.3037\n",
      "Epoch 3/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9012 - loss: 0.2642 - val_accuracy: 0.8988 - val_loss: 0.2902\n",
      "Epoch 4/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8986 - loss: 0.2677 - val_accuracy: 0.8962 - val_loss: 0.2901\n",
      "Epoch 5/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9017 - loss: 0.2655 - val_accuracy: 0.8952 - val_loss: 0.2970\n",
      "Epoch 6/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9039 - loss: 0.2614 - val_accuracy: 0.8888 - val_loss: 0.2907\n",
      "Epoch 7/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9039 - loss: 0.2533 - val_accuracy: 0.8892 - val_loss: 0.2981\n",
      "Epoch 8/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9045 - loss: 0.2560 - val_accuracy: 0.8912 - val_loss: 0.3014\n",
      "Epoch 9/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9062 - loss: 0.2527 - val_accuracy: 0.8948 - val_loss: 0.2844\n",
      "Epoch 10/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9068 - loss: 0.2477 - val_accuracy: 0.8908 - val_loss: 0.3057\n",
      "Epoch 11/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9068 - loss: 0.2505 - val_accuracy: 0.8970 - val_loss: 0.2910\n",
      "Epoch 12/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9079 - loss: 0.2439 - val_accuracy: 0.8958 - val_loss: 0.2881\n",
      "Epoch 13/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9085 - loss: 0.2439 - val_accuracy: 0.8964 - val_loss: 0.2957\n",
      "Epoch 14/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9085 - loss: 0.2452 - val_accuracy: 0.8916 - val_loss: 0.2943\n",
      "Epoch 15/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9074 - loss: 0.2431 - val_accuracy: 0.8978 - val_loss: 0.2802\n",
      "Epoch 16/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9137 - loss: 0.2333 - val_accuracy: 0.8918 - val_loss: 0.2929\n",
      "Epoch 17/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9097 - loss: 0.2389 - val_accuracy: 0.8990 - val_loss: 0.2813\n",
      "Epoch 18/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9130 - loss: 0.2365 - val_accuracy: 0.8954 - val_loss: 0.2929\n",
      "Epoch 19/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9101 - loss: 0.2364 - val_accuracy: 0.8972 - val_loss: 0.2854\n",
      "Epoch 20/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9134 - loss: 0.2289 - val_accuracy: 0.8932 - val_loss: 0.3010\n",
      "Epoch 21/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9140 - loss: 0.2312 - val_accuracy: 0.8922 - val_loss: 0.2996\n",
      "Epoch 22/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9125 - loss: 0.2334 - val_accuracy: 0.8952 - val_loss: 0.2887\n",
      "Epoch 23/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9160 - loss: 0.2297 - val_accuracy: 0.8978 - val_loss: 0.2847\n",
      "Epoch 24/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9104 - loss: 0.2383 - val_accuracy: 0.8960 - val_loss: 0.2899\n",
      "Epoch 25/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9119 - loss: 0.2340 - val_accuracy: 0.8994 - val_loss: 0.2813\n",
      "Epoch 26/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9144 - loss: 0.2283 - val_accuracy: 0.9006 - val_loss: 0.2918\n",
      "Epoch 27/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9136 - loss: 0.2309 - val_accuracy: 0.8970 - val_loss: 0.2885\n",
      "Epoch 28/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9139 - loss: 0.2316 - val_accuracy: 0.8946 - val_loss: 0.2870\n",
      "Epoch 29/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9112 - loss: 0.2352 - val_accuracy: 0.8996 - val_loss: 0.2813\n",
      "Epoch 30/30\n",
      "\u001B[1m550/550\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9187 - loss: 0.2197 - val_accuracy: 0.8978 - val_loss: 0.2787\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:21:42.735334Z",
     "start_time": "2024-11-02T09:21:42.721222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history_df_2 = pd.DataFrame(history2.history)\n",
    "print(history_df_2)\n",
    "\n",
    "training_error2 = history_df_2['loss'].iloc[-1]\n",
    "validation_error2 = history_df_2['val_loss'].iloc[-1]\n",
    "print(f\"Error de entrenamiento: {training_error2:.4f}\")\n",
    "print(f\"Error de validación: {validation_error2:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    accuracy      loss  val_accuracy  val_loss\n",
      "0   0.899873  0.267729        0.8892  0.300925\n",
      "1   0.900400  0.267160        0.8914  0.303736\n",
      "2   0.900745  0.266476        0.8988  0.290197\n",
      "3   0.900764  0.263024        0.8962  0.290067\n",
      "4   0.901491  0.263819        0.8952  0.297023\n",
      "5   0.905018  0.257005        0.8888  0.290720\n",
      "6   0.901564  0.258023        0.8892  0.298054\n",
      "7   0.904400  0.256395        0.8912  0.301422\n",
      "8   0.904509  0.253283        0.8948  0.284440\n",
      "9   0.904945  0.253229        0.8908  0.305715\n",
      "10  0.907073  0.250020        0.8970  0.290958\n",
      "11  0.907836  0.245698        0.8958  0.288125\n",
      "12  0.907145  0.246933        0.8964  0.295738\n",
      "13  0.909055  0.244792        0.8916  0.294326\n",
      "14  0.909164  0.240209        0.8978  0.280207\n",
      "15  0.911018  0.238900        0.8918  0.292908\n",
      "16  0.910673  0.238958        0.8990  0.281252\n",
      "17  0.911582  0.238225        0.8954  0.292876\n",
      "18  0.911545  0.233708        0.8972  0.285363\n",
      "19  0.912273  0.233316        0.8932  0.300985\n",
      "20  0.912927  0.233347        0.8922  0.299600\n",
      "21  0.912164  0.232357        0.8952  0.288694\n",
      "22  0.913655  0.233207        0.8978  0.284682\n",
      "23  0.910891  0.235491        0.8960  0.289946\n",
      "24  0.912455  0.231362        0.8994  0.281271\n",
      "25  0.913873  0.229682        0.9006  0.291838\n",
      "26  0.913418  0.230992        0.8970  0.288506\n",
      "27  0.913364  0.231867        0.8946  0.286991\n",
      "28  0.913273  0.230456        0.8996  0.281343\n",
      "29  0.915036  0.228959        0.8978  0.278657\n",
      "Error de entrenamiento: 0.2290\n",
      "Error de validación: 0.2787\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:21:43.690338Z",
     "start_time": "2024-11-02T09:21:42.769512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss_2, test_accuracy_2 = model2.evaluate(X_test, y_test)\n",
    "print(\"Error de generalización\")\n",
    "print(f\"Función de pérdida: {test_loss_2:.4f}\")\n",
    "print(f\"Métrica de precisión: {test_accuracy_2:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0354 - loss: 2.3840\n",
      "Error de generalización\n",
      "Función de pérdida: 2.3844\n",
      "Métrica de precisión: 0.0367\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T09:21:43.737138Z",
     "start_time": "2024-11-02T09:21:43.722688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Diferencias totales\n",
    "print(f\"Error de entrenamiento: {(training_error2 - training_error):.4f}\")\n",
    "print(f\"Error de validación: {(validation_error2 - validation_error):.4f}\")\n",
    "print(\"Error de generalización\")\n",
    "print(f\"Función de pérdida: {(test_loss_2 - test_loss):.4f}\")\n",
    "print(f\"Métrica de precisión: {(test_accuracy_2 - test_accuracy):.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de entrenamiento: -0.0373\n",
      "Error de validación: -0.0075\n",
      "Error de generalización\n",
      "Función de pérdida: 2.0591\n",
      "Métrica de precisión: -0.8401\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Análisis de los resultados obtenidos comparando los modelos con y sin Batch Normalization (BN) y Dropout"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Error de entrenamiento\n",
    "El error de entrenamiento es menor porque en el **modelo con BN y Dropout** en comparación con el modelo sin estas técnicas. Esto se debe a que el primer modelo lograba un mejor ajuste a los datos de entrenamiento, posiblemente debido a que la regularización ayuda a evitar el sobreajuste imponiendo restricciones al modelo, forzándolo a ser más general."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Error de validación\n",
    "En cuanto al error de validación, vemos que la diferencia es **positiva**, lo cual indica que el **modelo sin BN y Dropout** tiene un error de validación menor que el modelo con BN y Dropout. Esto puede deberse a que las técnicas de regularización aplicadas están haciendo que el modelo sea menos capaz de ajustarse completamente a los patrones presentes en los datos de validación."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Error de generalización\n",
    "- Función de pérdida\n",
    "\n",
    "El resultado obtenido con la función de pérdida es **significativamente mayor** que en el modelo sin BN y Dropout, lo que indica que el modelo sin técnicas de regularización tiene un peor rendimiento cuando se enfrenta datos nuevos, posiblemente debido a que el modelo está **sobreajustando** los datos de entrenamiento y validación, lo que se traduce en un mal rendimiento en el conjunto de prueba.\n",
    "\n",
    "- Métrica de precisión\n",
    "\n",
    "La métrica de precisión tiene una **diferencia negativa** significativa. Esto indica que la **precisión** del modelo con BN y Dropout es significativamente mejor que la del modelo sin ellas. En otras palabras, el modelo con regularización es más capaz de generalizar a nuevos datos, ya que tiene una mayor precisión"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
