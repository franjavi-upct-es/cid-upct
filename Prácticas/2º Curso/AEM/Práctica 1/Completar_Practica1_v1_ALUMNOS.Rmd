---
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

![](../figures/Escudos.jpg)

COMPLETAR PRÁCTICA 1: ANÁLISIS INICIAL DE DATOS MULTIVARIANTES.

ANÁLISIS ESTADÍSTICO MULTIVARIANTE.

GRADO EN CIENCIA E INGENIERÍA DE DATOS.

**Sumario**:
En esta práctica mostramos cómo realizar un estudio previo de datos multivariantes. Esta parte es fundamental y se repetirá en todas las prácticas posteriores. Usaremos algunas de las técnicas vistas en la asignatura de primero.

## 1) EL MODELO NORMAL MULTIVARIANTE
Para poder trabajar con la función de densidad y para obtener probabilidades con el modelo Normal multivariante, debemos cargar el paquete "mvtnomr".

```{r}
library(mvtnorm)
```

Consideremos un modelo Normal bivariante $(X, Y)$ con vector de medias (0,0), $Var(X)=1$, $Var(Y)=1$ y $Cov(X,Y)=1/2$. Queremos obtener el valor de la función de densidad de dicho modelo en el punto $x=(1,1)$, lo mismo con la función de distribución y calcular probabilidades en recintos rectangulares.

Primero definimos el vector de medias (mu) y la matriz de covarianzas (V), así como el punto $x$ donde queremos evaluar densidad y distribución:

```{r}
mu <- 
V <- matrix(NA, 2, 2)
V[1,] <- 
V[2,] <- 
x <- 

```

### 1.1) Función de densidad, función de distribución y probabilidades

Evaluamos la función de densidad en $x=(1,1)$:
```{r}
dmvnorm(x, mean = mu, sigma = V)
```
Evaluamos la función de distribución en $x=(1,1)$. Indicar que se trata de una aproximación que R permite calcular a través de diferentes algoritmos:

```{r}
pmvnorm(lower = -Inf, upper = , mean = , sigma = )
```

Si queremos calcular la probabilidad en un rectángulo, usaremos la función de distribución indicando los límites inferiores y superiores de cada componente. Por ejemplo, la probabilidad $Pr(-1<X<1, -1<Y<1)$  se obtendría tecleando:

```{r}

```

Para representar la función de densidad el modelo Normal bivariante con el que estamos trabajando haremos:

```{r}
f<-function(x,y) {
  dmvnorm(data.frame(x,y),mu,V)
}
x<-seq(-3,3,length=50)
y<-seq(-3,3,length=50)
z<-outer(x,y,f)
persp(x,y,z,xlab='x',ylab='y',zlab='f(x,y)',col='red')
contour(x,y,z,col='red')
```

### 1.2) Generar valores aleatorios del modelo Normal multivariante

Para generar (simular) 50 pares de datos de nuestro modelo Normal bivariante haremos:

```{r}
set.seed(123)
d <-
```

Representemos los datos simulados junto con las curvas de nivel de la densidad teórica:

```{r}
plot(d,xlab="X",ylab="Y",pch=20,xlim=c(-3,3),lim=c(-3,3))
contour(x,y,z,add=TRUE,col="red")
```
En esta gráfica podemos ver como los datos se sitúan alrededor de la media (0, 0) en elipses con diagonal principal en la recta $y = x$.

Podemos calcular medidas descriptivas de los datos simulados, que deben tomar valores parecidos a los parámetros teóricos del modelo:

```{r}
summary(d)
cov(d) # matriz de cuasi-covarianzas muestrales
cor(d) # matriz de correlaciones muestrales

```

### 1.3) Test de normalidad mutivariante (Shapiro-Wilk)

Como ocurre en el caso univariante, también podemos usar un test para contrastar si un conjunto de datos multivariante se puede asumir Normal multivariante. Para ello, necesitamos cargar el paquete "mvnormtest".

```{r}
library()
```

Y aplicamos la función de R para llevar a cabo el test:

```{r}
mshapiro.test(t(d))  #Necesitamos trasponer los datos del dataframe porque lee 
                    #las variables por filas en lugar de por columnas
```
Observar que el $p-valor = 0.6014$, lo que conduce a aceptar que los datos provienen de una distribución Normal (lo cual sabemos que es cierto, pues se generaron a partir de dicho modelo).

### 1.4) Distancia de Mahalanobis

Veamos cómo calcular la **distancia de Mahalanobis al cuadrado** de cada fila de datos al vector de medias (teórico o muestral). Esta distancia tiene en cuenta las diferentes escalas de los datos y sus correlaciones y nos servirá para detectar las observaciones más “raras” (alejadas de la media) que podrían ser observaciones atípicas (outliers) que no provengan de nuestra población o contengan errores.

```{r}
dM1<-mahalanobis(d, center = , cov = ) #dist Mahalanobis al cuadrado  
                                          #usando parámetros teóricos del modelo

dM2<-                                  #dist Mahalanobis al cuadrado  
                                        #usando parámetros muestrales del modelo

View(data.frame(d[,1],d[,2],dM1,dM2))
```

Si queremos detectar la observación más rara haremos:

```{r}
max(dM1)
which.max(dM1)
max(dM2)
which.max(dM2)
d[49,]
```


## 2) ESTUDIO DESCRIPTIVO DE DATOS MULTIVARIANTES

Cargamos el fichero iris de R y vemos su estructura:

```{r}
d2 <- iris
str(d2)
```
Hacemos resumen descriptivo global:

```{r}
summary()
```

Resumen numérico por especies para la variable longitud del sépalo:

```{r}
tapply(d2$Sepal.Length, d2$Species, summary)
boxplot(d2$Sepal.Length ~ d2$Species)
```

Recordar que también se puede realizar con la colección de paquetes "tidyverse":

```{r}
library(tidyverse)
d2 %>%
  ggplot(aes(x = Species, y = Sepal.Length)) +
  geom_boxplot(aes(color = Species))

```

Estos gráficos demuestran que en realidad tenemos k = 4 variables medidas en tres poblaciones (especies) distintas.

Podemos realizar el test de normalidad multivariante sin distinguir las 3 poblaciones:

```{r}

```
O bien podemos realizar dicho test para cada especie. Primero podemos separar las especies en distintos dataframes:

```{r}
list <- split(d2, d2$Species)
list2env(list, .GlobalEnv)
```

```{r}
mshapiro.test(t(setosa[, 1:4]))
mshapiro.test()
mshapiro.test()
```

Hacemos las nubes de puntos por pares de variables, sin distinguir especies:

```{r}
plot(d2[, 1:4])

```

Y ahora algún ejemplo distinguiendo especies:

```{r}

plot(d2$Sepal.Length,d2$Sepal.Width,pch=as.integer(d2$Species))
legend('bottomright',legend=c('setosa','versic.','virgin.'),pch=1:3,cex=0.8)

```

Otro ejemplo distinguiendo especies:

```{r}
plot(d2$Sepal.Length,d2$Sepal.Width,pch=20,xlab='Long. sepalo',ylab='Anchura sepalo')
points(versicolor$Sepal.Length,versicolor$Sepal.Width,pch=20,col='red')
points(virginica$Sepal.Length,virginica$Sepal.Width,pch=20,col='blue')
text(d2[42,1],d2[42,2],'42',cex=0.8,pos=3)
legend('bottomright',legend=c('setosa negro','versic. rojo','virgin. azul'),cex=0.5)
```

Otro más:

```{r}
plot(d2$Petal.Length,d2$Petal.Width,pch=20,xlab='Long. p?talo',ylab='Anchura petalo')
points(versicolor$Petal.Length,versicolor$Petal.Width,pch=20,col='red')
points(virginica$Petal.Length,virginica$Petal.Width,pch=20,col='blue')
legend('bottomright',legend=c('setosa negro','versic. rojo','virgin. azul'),cex=0.5)

```


Calculemos la **distancia de Mahalanobis al cuadrado* para los datos de cada especie respecto a su vector de medias muestral.

```{r}
Msetosa<-mahalanobis(setosa[,1:4],colMeans(setosa[,1:4]),cov(setosa[,1:4]))
sort(Msetosa)

Mversicolor <- 

Mvirginica <-

```

Observamos que la fila 42 es la que tiene mayor distancia, dentro de la especie setosa.

La verosimilitud de un dato en un modelo estadístico será el valor de la función de densidad (función de probabilidad si es un modelo discreto) en ese punto. Por ejemplo, si asumimos distribuciones normales en los tres grupos, la verosimilitud de la flor 42 en el grupo setosa se calculará con:

```{r}
mu1<-colMeans(setosa[,1:4])
V1<-cov(setosa[,1:4])
dmvnorm()
```

