{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Práctica 2: optimización para el problema de regresión lineal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la carpeta **data** encontrarás el fichero **data_linear_regression.npy** el cual contiene (en formato fichero de numpy) la matriz de datos que usaremos en este ejercicio.\n",
    "\n",
    "Carga dicho fichero y asígnale el nombre **data**. Recuerda, esto se hace en el módulo **numpy** en la forma \n",
    "\n",
    "data = np.load(ruta/nombre del fichero)\n",
    "\n",
    "A continuación, imprime por pantalla dicha matriz y su forma\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:07:55.110486Z",
     "start_time": "2024-09-25T06:07:54.787602Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "import numpy as np\n",
    "data = np.load('../data/data_linear_regression.npy')\n",
    "print(data)\n",
    "print(data.shape)\n",
    "# --------------------\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.22137467e-02  5.82815214e-01  2.12300528e+01]\n",
      " [-1.72428208e-01 -8.77858418e-01 -3.97660505e+01]\n",
      " [-5.28171752e-01 -1.07296862e+00 -7.02963331e+01]\n",
      " [ 3.19039096e-01 -2.49370375e-01  1.41809817e+01]\n",
      " [ 8.65407629e-01 -2.30153870e+00 -1.25613989e+01]\n",
      " [ 1.13376944e+00 -1.09989127e+00  4.38456953e+01]\n",
      " [ 1.62434536e+00 -6.11756414e-01  9.32631853e+01]\n",
      " [-3.22417204e-01 -3.84054355e-01 -3.44784013e+01]\n",
      " [ 1.74481176e+00 -7.61206901e-01  9.65655196e+01]\n",
      " [ 1.46210794e+00 -2.06014071e+00  3.59720885e+01]]\n",
      "(10, 3)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar, **data** es una matriz de $10$ filas y $3$ columnas.\n",
    "\n",
    "Las dos primeras columnas son de **features** y la última es de **labels**. Cada fila es una **instance** (muestra)\n",
    "\n",
    "Vamos a utilizar las $8$ primeras filas para entrenar nuestro modelo de regresión lineal y las dos últimas filas para testear la bondad del modelo. Por tanto, usando la técnica de **slicing** que estudiaste en Álgebra Lineal, construye una matriz **X_train** que contenga las $8$ primeras filas y las $2$ primeras columnas de **data** y luego una matriz **y_train** que contenga los datos de las $8$ primeras filas y última columna de **data**.\n",
    "\n",
    "De igual modo, construye **X_test** e **y_test** con los datos restantes. Imprime todo por pantalla para asegurarte que has seleccionado bien los datos."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:07:55.157275Z",
     "start_time": "2024-09-25T06:07:55.141102Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "X_train = data[:8,:2]\n",
    "y_train = data[:8,2].reshape(8,1)\n",
    "X_test = data[8:,:2]\n",
    "y_test = data[8:, 2].reshape(2,1)\n",
    "\n",
    "print(f\"X_train: \\n{X_train}\")\n",
    "print(f\"y_train: \\n{y_train}\")\n",
    "print(f\"X_test: \\n{X_test}\")\n",
    "print(f\"y_test: \\n{y_test}\")\n",
    "# --------------------\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: \n",
      "[[ 0.04221375  0.58281521]\n",
      " [-0.17242821 -0.87785842]\n",
      " [-0.52817175 -1.07296862]\n",
      " [ 0.3190391  -0.24937038]\n",
      " [ 0.86540763 -2.3015387 ]\n",
      " [ 1.13376944 -1.09989127]\n",
      " [ 1.62434536 -0.61175641]\n",
      " [-0.3224172  -0.38405435]]\n",
      "y_train: \n",
      "[[ 21.23005281]\n",
      " [-39.76605048]\n",
      " [-70.29633308]\n",
      " [ 14.18098172]\n",
      " [-12.56139894]\n",
      " [ 43.84569533]\n",
      " [ 93.26318528]\n",
      " [-34.47840128]]\n",
      "X_test: \n",
      "[[ 1.74481176 -0.7612069 ]\n",
      " [ 1.46210794 -2.06014071]]\n",
      "y_test: \n",
      "[[96.56551964]\n",
      " [35.9720885 ]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resuelve de forma directa el problema de regresión lineal\n",
    "\n",
    "$$\n",
    "\\text{Minimizar en } \\theta : \\quad \tMSE (\\theta) = \\frac{1}{8}\\sum_{i=1}^{8}\\left(\\theta^T x^{(i)} - y^{(i)}\\right)^2.\n",
    "$$\n",
    "\n",
    "donde $x^{(i)}$ es la fila i-ésima de $X$ e $y^{(i)}$ la componente i-ésima del vector de labels.\n",
    "\n",
    "Recuerda añadir la columna de unos para el bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:07:55.762847Z",
     "start_time": "2024-09-25T06:07:55.750169Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "# Columna para el bias\n",
    "X_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "\n",
    "# Calcular 'theta_best' usando la fórmula de la pseudoinversa\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)\n",
    "\n",
    "print(f\"theta_best:\\n {theta_best}\")\n",
    "# --------------------\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_best:\n",
      " [[-5.10622756e-02]\n",
      " [ 6.92758412e+01]\n",
      " [ 3.14819495e+01]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resuelve el mismo problema con el método [scipy.linalg.lstsq](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:07:55.793847Z",
     "start_time": "2024-09-25T06:07:55.782852Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b.T.dot(X_b), X_b.T.dot(y_train), rcond=1e-6)\n",
    "print(f\"theta_best_svd: \\n{theta_best_svd}\")\n",
    "# --------------------\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_best_svd: \n",
      "[[-5.10622756e-02]\n",
      " [ 6.92758412e+01]\n",
      " [ 3.14819495e+01]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define una función que nos de como salida el modelo de predicción de regresión lineal para el $\\theta_{\\text{best}}$ que has calculado previamente."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:07:55.904814Z",
     "start_time": "2024-09-25T06:07:55.895724Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "def model_predict(X, theta):\n",
    "    # Añadir columna de unos a X para el término bias\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    # Realizar predicciones\n",
    "    y_pred = X_b.dot(theta)\n",
    "    return y_pred\n",
    "# --------------------\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalua el modelo de predicción en los dos datos X_test y llama $y_1$, $y_2$ a los resultados obtenidos. Finalmente, compara los resultados con los datos y_test imprimiendo por pantalla:\n",
    "\n",
    "a) y_1\n",
    "\n",
    "b) y_test[0]\n",
    "\n",
    "c) y_2\n",
    "\n",
    "d) y_test[1]\n",
    "\n",
    "e) error de generalización = $\\frac{1}{2}\\left[\\left( y_1-y_{\\text{test}}[0]\\right)^2 + \\left( y_2-y_{\\text{test}}[1]\\right)^2\\right]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:07:55.936508Z",
     "start_time": "2024-09-25T06:07:55.926636Z"
    }
   },
   "source": [
    "# Completar aquí\n",
    "# Calcular predicciones\n",
    "y_pred = model_predict(X_test, theta_best)\n",
    "y_1, y_2 = y_pred[0], y_pred[1]\n",
    "\n",
    "# Calcular error de generalización\n",
    "error_generalizacion = (1/2) * ((y_1 - y_test[0])**2 + (y_2-y_test[1])**2)\n",
    "\n",
    "print(f\"a) y_1: {y_1}\")\n",
    "print(f\"b) y_test[0]: {y_test[0]}\")\n",
    "print(f\"c) y_2: {y_2}\")\n",
    "print(f\"d) y_test[1]: {y_test[1]}\")\n",
    "print(f\"e) Error de generalización: {error_generalizacion}\")\n",
    "\n",
    "# --------------------\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) y_1: [96.8579633]\n",
      "b) y_test[0]: [96.56551964]\n",
      "c) y_2: [36.38044931]\n",
      "d) y_test[1]: [35.9720885]\n",
      "e) Error de generalización: [0.12614092]\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optim-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
