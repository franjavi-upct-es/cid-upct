{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entegable 2- Perceptrones y SVM.\n",
    "\n",
    "Francisco Javier Mercader Martínez\n",
    "\n",
    "## Machine Learning. Grado en Ciencia de datos\n",
    "\n",
    "Los siguientes ejercicios tienen que ser entregados dentro de las dos horas de prácticas. Cómo realizar el entregable:\n",
    "\n",
    "\n",
    "-   La realización se debe de hacer de forma  **INDIVIDUAL**\n",
    "-   Se debe de enviar un notebook con el código y las explicaciones, comentarios, análisis y justificaciones en Markdown.\n",
    "-   Reproducibilidad:\n",
    "    -   Se debe de establecer una variable semilla con un número al inicio, esta variable será la que se utilice para el np.random_seed y para el random_state.\n",
    "    -   Las bases de datos se cargan con rutas relativas.\n",
    "-   El notebook se debe de subir a la tarea del aula virtual creada antes de la finalización de la hora de clase. (Ver tarea y fecha de cierre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Utilizando el dataset Manzanas.csv, cree la SVM no lineal con un kernel de tipo función de base radial que considere para realizar la clasificación de la columna Calidad. \n",
    "\n",
    "\n",
    "Para ello, siga los siguientes pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargue el conjunto de datos o dataset. Utiliza como objetivo o \"y\" la columna de *'Calidad'* y el resto de columnas como características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ent_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "dataset = pd.read_csv(\"Manzanas.csv\")\n",
    "\n",
    "X = dataset.drop('Calidad', axis=1)\n",
    "X = X.values\n",
    "\n",
    "y = dataset['Calidad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cree un hold-out (ent-test) 80-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos un 80% de los datos para entrenamiento y un 20% para test\n",
    "X_ent, X_test, y_ent, y_test  = ent_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Aplique la estandarización de los datos para ajustar la escala de las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Estandarización del conjunto de entrenamiento\n",
    "X_ent_escaladas = scaler.fit_transform(X_ent)\n",
    "\n",
    "# Aplicamos la estandarización calculada con los datos de entrenamiento a los datos de test\n",
    "X_test_escaladas = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Cree una SVM no lineal con un kernel de tipo función de base radial ajustando tres hiperparámetros principales para conseguir una exactitud, precisión y sensibilidad por encima del 70% en el conjunto de entrenamiento y de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud Entrenamiento:  0.8959375\n",
      "Exactitud Test:  0.885\n",
      "Precisión Entrenamiento:  0.8959887650906927\n",
      "Precisión Test:  0.8854647183800349\n",
      "Sensibilidad Entrenamiento:  0.8959375\n",
      "Sensibilidad Test:  0.885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Instanciamos la clase LinearSVC\n",
    "SVM_clasif_no_lineal = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "\n",
    "# Entrenamos la SVM kernelizada no lineal\n",
    "SVM_clasif_no_lineal.fit(X_ent_escaladas, y_ent)\n",
    "\n",
    "y_pred_ent = SVM_clasif_no_lineal.predict(X_ent_escaladas)\n",
    "y_pred_test = SVM_clasif_no_lineal.predict(X_test_escaladas)\n",
    "\n",
    "# Calcular y mostrar las métricas\n",
    "print(\"Exactitud Entrenamiento: \", accuracy_score(y_ent, y_pred_ent))\n",
    "print(\"Exactitud Test: \", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Precisión Entrenamiento: \", precision_score(y_ent, y_pred_ent, average='weighted'))\n",
    "print(\"Precisión Test: \", precision_score(y_test, y_pred_test, average='weighted'))\n",
    "print(\"Sensibilidad Entrenamiento: \", recall_score(y_ent, y_pred_ent, average='weighted'))\n",
    "print(\"Sensibilidad Test: \", recall_score(y_test, y_pred_test, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ¿Qué influencia tiene el parámetro gamma ($\\gamma$) en la capacidad de la SVM en el problema de clasificación? Para responder a esta pregunta realice varios cambios en el valor de gamma ($\\gamma$) manteniendo los valores del resto de hiperparámetros y obtenga las métricas del ejercicio anterior en cada ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.1\n",
      "Exactitud Entrenamiento:  0.891875\n",
      "Exactitud Test:  0.8875\n",
      "Precisión Entrenamiento:  0.891932436308513\n",
      "Precisión Test:  0.8879614280610935\n",
      "Sensibilidad Entrenamiento:  0.891875\n",
      "Sensibilidad Test:  0.8875\n",
      "\n",
      "\n",
      "Gamma: 1\n",
      "Exactitud Entrenamiento:  0.986875\n",
      "Exactitud Test:  0.8875\n",
      "Precisión Entrenamiento:  0.9868954051355797\n",
      "Precisión Test:  0.8874658613941137\n",
      "Sensibilidad Entrenamiento:  0.986875\n",
      "Sensibilidad Test:  0.8875\n",
      "\n",
      "\n",
      "Gamma: 10\n",
      "Exactitud Entrenamiento:  1.0\n",
      "Exactitud Test:  0.4725\n",
      "Precisión Entrenamiento:  1.0\n",
      "Precisión Test:  0.704905807120636\n",
      "Sensibilidad Entrenamiento:  1.0\n",
      "Sensibilidad Test:  0.4725\n",
      "\n",
      "\n",
      "Gamma: 100\n",
      "Exactitud Entrenamiento:  1.0\n",
      "Exactitud Test:  0.46125\n",
      "Precisión Entrenamiento:  1.0\n",
      "Precisión Test:  0.2127515625\n",
      "Sensibilidad Entrenamiento:  1.0\n",
      "Sensibilidad Test:  0.46125\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "gammas = [0.1, 1, 10, 100]\n",
    "\n",
    "for gamma in gammas:\n",
    "    # Instanciamos la clase LinearSVC\n",
    "    SVM_clasif_no_lineal = SVC(kernel='rbf', C=1.0, gamma=gamma)\n",
    "\n",
    "    # Entrenamos la SVM kernelizada no lineal\n",
    "    SVM_clasif_no_lineal.fit(X_ent_escaladas, y_ent)\n",
    "\n",
    "    y_pred_ent = SVM_clasif_no_lineal.predict(X_ent_escaladas)\n",
    "    y_pred_test = SVM_clasif_no_lineal.predict(X_test_escaladas)\n",
    "\n",
    "    # Calcular y mostrar las métricas\n",
    "    print(f\"Gamma: {gamma}\")\n",
    "    print(\"Exactitud Entrenamiento: \", accuracy_score(y_ent, y_pred_ent))\n",
    "    print(\"Exactitud Test: \", accuracy_score(y_test, y_pred_test))\n",
    "    print(\"Precisión Entrenamiento: \", precision_score(y_ent, y_pred_ent, average='weighted'))\n",
    "    print(\"Precisión Test: \", precision_score(y_test, y_pred_test, average='weighted'))\n",
    "    print(\"Sensibilidad Entrenamiento: \", recall_score(y_ent, y_pred_ent, average='weighted'))\n",
    "    print(\"Sensibilidad Test: \", recall_score(y_test, y_pred_test, average='weighted'))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede aprecia que conforme aumenta el valor de $\\gamma$ los valores de las métricas del entrenamiento son cada vez mayores a diferencia que las métricas del test, cuyo valor va disminuyendo conforme aumenta el valor de $\\gamma$ aunque sean diferencias muy pequeñas a nivel numérico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Realice una operación de validación cruzada con 5 subconjuntos o folds con la SVM que ha generado en el ejercicio 4. Obtenga el acierto de cada subconjunto, la media del acierto y la desviación estándar del acierto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto de cada subconjunto:  [0.50125 0.50125 0.50125 0.50125 0.5    ]\n",
      "Media del acierto:  0.501\n",
      "Desviación estándar del acierto:  0.0004999999999999894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "puntuaciones = cross_val_score(SVM_clasif_no_lineal, X, y, cv=5)\n",
    "\n",
    "print(\"Acierto de cada subconjunto: \", puntuaciones)\n",
    "print(\"Media del acierto: \", np.mean(puntuaciones))\n",
    "print(\"Desviación estándar del acierto: \", np.std(puntuaciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.  A la vista de los resultados, ¿es un clasificador robusto, fiable? Razone la respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados muestran que el acierto del clasificador es aproximadamente el mismo para cada subconjunto en la validación cruzada, con una media de 0.501 y una desviación estándar muy baja (<0.0005). Esto indica que el clasificador es bastante consistente en su rendimiento a través de diferentes subconjuntos de los datos.\n",
    "\n",
    "Sin embargo, un acierto de alrededor del 50% no es particularmente alto. Por lo tanto, aunque este clasificador es consistente, no parece ser muy efectivo para este conjunto de datos en particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: este dataset sirve para intentar predecir la calidad de las manzanas a partir de una serie de características: 'Size', 'Weight'\t'Sweetness', 'Crunchiness',\t'Juiciness', 'Ripeness','Acidity'. Utilizaremos todas las características para predecir la calidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Utilizando el dataset Mercado_valores_USA.csv, cree el perceptrón multicapa que considere para realizar la predicción de la columna *'S&P_500_Price'*. \n",
    "\n",
    "\n",
    "Para ello, siga los siguientes pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargue el conjunto de datos o dataset. Seleccione como características: *'Natural_Gas_Price'*, *'Crude_oil_Price'*, *'Copper_Price'*. Seleccione como objetivo o \"y\" la columna *'S&P_500_Price'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercado = pd.read_csv(\"Mercado_valores_USA.csv\")\n",
    "\n",
    "X = mercado[[\"Natural_Gas_Price\", \"Crude_oil_Price\", \"Copper_Price\"]]\n",
    "X = X.values\n",
    "\n",
    "y = mercado[\"S&P_500_Price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cree un hold-out (ent-test) 80-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ent_test_split\n",
    "\n",
    "X_ent, X_test, y_ent, y_test = ent_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Aplique la estandarización de los datos para ajustar la escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_ent_escaladas = scaler.fit_transform(X_ent)\n",
    "X_test_escaladas = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Cree un perceptrón multicapa de una única capa ajustando tres hiperparámetros principales para conseguir un error absoluto medio de entrenamiento y de test por debajo de 200. Obtenga también el error cuadrático medio. ¿Presenta algún problema de sobreajuste? Razone la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error absoluto medio de entrenamiento: 3561.0377745392743\n",
      "Error cuadratico medio de entrenamiento: 12918747.022480378\n",
      "Error absoluto medio de test: 3582.440991128158\n",
      "Error cuadratico medio de test: 13047216.589524295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "perceptron_multicapa_reg = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "perceptron_multicapa_reg.fit(X_ent, y_ent)\n",
    "\n",
    "y_pred_ent = perceptron_multicapa_reg.predict(X_ent_escaladas)\n",
    "y_pred_test= perceptron_multicapa_reg.predict(X_test_escaladas)\n",
    "\n",
    "print(f\"Error absoluto medio de entrenamiento: {mean_absolute_error(y_ent, y_pred_ent)}\")\n",
    "print(f\"Error cuadratico medio de entrenamiento: {mean_squared_error(y_ent, y_pred_ent)}\")\n",
    "print(f\"Error absoluto medio de test: {mean_absolute_error(y_test, y_pred_test)}\")\n",
    "print(f\"Error cuadratico medio de test: {mean_squared_error(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecute varias veces el entrenamiento del perceptrón multicapa utilizado, sin cambiar los valores de los hiperparámetros del perceptrón. En cada ejecución cambie la semilla. Obtenga las métricas pedidas en el ejercicio anterior. ¿Cambia el valor de las métricas? ¿Por qué? Razone la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semilla: 0\n",
      "Error absoluto medio de entrenamiento: 3520.739175009076\n",
      "Error cuadratico medio de entrenamiento: 12613693.618478257\n",
      "Error absoluto medio de test: 3541.9458243803724\n",
      "Error cuadratico medio de test: 12740082.962882027\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semilla: 1\n",
      "Error absoluto medio de entrenamiento: 3529.1522311683766\n",
      "Error cuadratico medio de entrenamiento: 12675674.649289273\n",
      "Error absoluto medio de test: 3550.5006885616253\n",
      "Error cuadratico medio de test: 12803364.636024863\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semilla: 2\n",
      "Error absoluto medio de entrenamiento: 3536.5726893815518\n",
      "Error cuadratico medio de entrenamiento: 12732529.823424544\n",
      "Error absoluto medio de test: 3557.8617186633624\n",
      "Error cuadratico medio de test: 12859727.844515525\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semilla: 3\n",
      "Error absoluto medio de entrenamiento: 3545.6375824831216\n",
      "Error cuadratico medio de entrenamiento: 12801136.543069616\n",
      "Error absoluto medio de test: 3567.0512915009945\n",
      "Error cuadratico medio de test: 12929484.827889152\n",
      "\n",
      "\n",
      "Semilla: 4\n",
      "Error absoluto medio de entrenamiento: 3567.05677538938\n",
      "Error cuadratico medio de entrenamiento: 12964187.360292934\n",
      "Error absoluto medio de test: 3588.548752869486\n",
      "Error cuadratico medio de test: 13093435.963328576\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "semillas = [0, 1, 2, 3, 4]\n",
    "\n",
    "for semilla in semillas:\n",
    "    perceptron_multicapa_reg = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=semilla)\n",
    "    perceptron_multicapa_reg.fit(X_ent, y_ent)\n",
    "\n",
    "    y_pred_ent = perceptron_multicapa_reg.predict(X_ent_escaladas)\n",
    "    y_pred_test= perceptron_multicapa_reg.predict(X_test_escaladas)\n",
    "\n",
    "    print(f\"Semilla: {semilla}\")\n",
    "    print(f\"Error absoluto medio de entrenamiento: {mean_absolute_error(y_ent, y_pred_ent)}\")\n",
    "    print(f\"Error cuadratico medio de entrenamiento: {mean_squared_error(y_ent, y_pred_ent)}\")\n",
    "    print(f\"Error absoluto medio de test: {mean_absolute_error(y_test, y_pred_test)}\")\n",
    "    print(f\"Error cuadratico medio de test: {mean_squared_error(y_test, y_pred_test)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Realice una operación de búsqueda de los mejores parámetros. Emplee una y dos capas, utilice hasta dos números diferentes de neuronas en cada capa. Utilice dos funciones de activación. Utilice como método de cálculo de los pesos únicamente *'lbfgs'* y un valor máximo de iteraciones igual a 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\fcoja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "parametros = {\n",
    "    'hidden_layer_sizes': [(100,), (100, 100), (200,), (200, 200)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [2000]\n",
    "}\n",
    "\n",
    "mlp = MLPRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(mlp, parametros, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "grid_search.fit(X_ent_escaladas, y_ent)\n",
    "\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Obtenga la mejor configuración y su acierto. Dado el acierto obtenido, ¿obtiene la configuración obtenida un rendimiento mejor que la configuración generada en el ejercicio 4? Razone la respuesta. ¿Qué influencia tienen los parámetros que han cambiado en el resultado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: este dataset sirve para intentar predecir el valor del índice bursátil S&P 500 a partir de una serie de características como: precio del gas natural, precio del crudo, precio del cobre, precio de ciertas accione, etc. Únicamente vamos a emplear las siguientes características: 'Natural_Gas_Price', 'Crude_oil_Price', 'Copper_Price'. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
