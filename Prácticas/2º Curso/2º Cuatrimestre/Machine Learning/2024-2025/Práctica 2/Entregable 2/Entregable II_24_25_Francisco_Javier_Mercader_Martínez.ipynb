{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercader Martínez, Francisco Javier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "semilla=80\n",
    "np.random.seed(semilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entregable 2- Perceptrones y SVM.\n",
    "\n",
    "## Machine Learning I. Grado en Ciencia de datos\n",
    "\n",
    "Los siguientes ejercicios tienen que ser entregados dentro de las dos horas de prácticas. Como realizar el entregable:\n",
    "\n",
    "\n",
    "-   La realización se debe de hacer de forma  **INDIVIDUAL**\n",
    "-   Se debe de enviar un notebook con el código y las explicaciones, comentarios, análisis y justificaciones en Markdown.\n",
    "-   Reproducibilidad:\n",
    "    -   Se debe de establecer una variable semilla con un número al inicio, esta variables será la que se utilice para el np.random_seed y para el random_state.\n",
    "    -   Las bases de datos se cargan con rutas relativas.\n",
    "-   El notebook se debe de subir a la tarea del aula virtual creada antes de la finalización de la hora de clase. (Ver tarea y fecha de cierre).\n",
    "\n",
    "\n",
    "⛔ Prohibido: no se puede utilizar ninguna herramienta de generación de código, no se permite el acceso a internet con ningún dispositivo.\n",
    "\n",
    "### DATASET\n",
    "\n",
    "El conjunto de datos Datos_crédito.csv describe los siguientes atributos:\n",
    "- Edad: Edad de la persona en años.\n",
    "- Sexo: Sexo de la persona: male o female.\n",
    "- Trabajo: Tipo de trabajo. 0: sin formación y no residente, 1: sin formación y residente, 2: con formación, 3: formación alta.\n",
    "- Vivienda: el régimen de posesión de la vivienda: own, free, rent.\n",
    "- Ahorro: cantidad de dinero en la cuenta de ahorro: little, quite rich, rich, moderate.\n",
    "- Corriente: cantidad de dinero en la cuenta corriente: 'little', 'moderate', 'rich'.\n",
    "- Credito: cantidad de crédito permitido.\n",
    "- Larga duracion: si el crédito es o no de larga duración. 0:no, 1:si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Utilizando el dataset Datos_crédito.csv, cree el **perceptrón multicapa** que considere para realizar la **clasificación de la columna Larga duracion**. \n",
    "\n",
    "\n",
    "Para ello, siga los siguientes pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargue el conjunto de datos (dataset) y revise los tipos de datos de los atributos del conjunto de datos, analiza si es necesario transformar alguno. En caso de ser necesario realiza la transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edad               int64\n",
      "Sexo              object\n",
      "Trabajo            int64\n",
      "Vivienda          object\n",
      "Ahorro            object\n",
      "Corriente         object\n",
      "Credito            int64\n",
      "Larga duracion     int64\n",
      "dtype: object\n",
      "Edad              int64\n",
      "Sexo              int32\n",
      "Trabajo           int64\n",
      "Vivienda          int32\n",
      "Ahorro            int32\n",
      "Corriente         int32\n",
      "Credito           int64\n",
      "Larga duracion    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Datos_crédito.csv')\n",
    "print(data.dtypes) \n",
    "\n",
    "# Tenemos varias columnas que podemos convertir en variables categóricas\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "columns = ['Sexo', 'Vivienda', 'Ahorro', 'Corriente']\n",
    "\n",
    "for column in columns:\n",
    "    data[column] = encoder.fit_transform(data[column])\n",
    "    \n",
    "print(data.dtypes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cree un hold-out (train-test) 75-25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns=['Larga duracion'], axis=1).values\n",
    "y = data['Larga duracion']\n",
    "\n",
    "X_ent, X_test, y_ent, y_test = train_test_split(X, y, test_size=0.25, random_state=semilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Aplique la estandarización de los datos para ajustar la escala de las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instanciamos el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Estandarización del conjunto de entrenamiento\n",
    "X_ent_escaladas = scaler.fit_transform(X_ent)\n",
    "\n",
    "# Aplicamos la estandarización calculada con los datos de entrenamiento a los datos de test\n",
    "X_test_escaladas = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Cree un perceptrón multicapa dando valores a 4 hiperparámetros principales. Analice si existe un problema de subajuste o de sobreajuste o si, por el contrario no existe ningún problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error absoluto medio de entrenamiento: 0.20133333333333334\n",
      "Error cuadratico medio de entrenamiento: 0.20133333333333334\n",
      "Error absoluto medio de test: 0.264\n",
      "Error cuadratico medio de test: 0.264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5), activation='logistic', \n",
    "                    solver='lbfgs', random_state=semilla)\n",
    "\n",
    "mlp.fit(X_ent_escaladas, y_ent)\n",
    "\n",
    "y_pred_ent = mlp.predict(X_ent_escaladas)\n",
    "y_pred_test = mlp.predict(X_test_escaladas)\n",
    "\n",
    "print(f\"Error absoluto medio de entrenamiento: {mean_absolute_error(y_ent, y_pred_ent)}\")\n",
    "print(f\"Error cuadratico medio de entrenamiento: {mean_squared_error(y_ent, y_pred_ent)}\")\n",
    "print(f\"Error absoluto medio de test: {mean_absolute_error(y_test, y_pred_test)}\")\n",
    "print(f\"Error cuadratico medio de test: {mean_squared_error(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados del cálculo del MSE y el MAE tanto para el conjunto de entrenamiento como para el conjunto de test muestran valores *relativamente* bajos, lo que puede indicar que aunque `mlp` no es totalmente preciso tampoco comete demasiados errores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Realice una operación de validación cruzada con el clasificador. ¿Corroboran los resultados obtenidos con la validación cruzada el resultado obtenido con el conjunto de test en el apartado 4? Razone la respuesta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto de cada subconjunto:  [0.68       0.69333333 0.65333333 0.67333333 0.72666667]\n",
      "Media del acierto: 0.6853\n",
      "Desviación estándar del acierto: 0.0244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "puntuaciones = cross_val_score(mlp, X_ent_escaladas, y_ent, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Acierto de cada subconjunto: \", puntuaciones)\n",
    "print(f\"Media del acierto: {np.mean(puntuaciones):.4f}\")\n",
    "print(f\"Desviación estándar del acierto: {np.std(puntuaciones):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media de la precisión es relativamente alta (0.6853) y la desviación estándar es baja (0.0244), lo que indica que el modelo es bastante estable y robusto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Realice una operación de búsqueda de los mejores hiperparámetros entre los utilizados en el apartado 4. Emplee una y dos capas, utilice dos números diferentes de neuronas en cada capa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'MLP_CL__activation': 'logistic', 'MLP_CL__hidden_layer_sizes': (45, 10), 'MLP_CL__solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([ ('transformador', scaler), ('MLP_CL', mlp)])\n",
    "\n",
    "# Los valores de los hiperparámetros se guardan en un diccionario o en una lista de diccionarios\n",
    "rejilla_hiperparametros = {\n",
    "                            'MLP_CL__hidden_layer_sizes': [(50,), (20,), (50, 30), (45, 10)], \n",
    "                            'MLP_CL__activation': ['logistic', 'tanh', 'relu'], \n",
    "                            'MLP_CL__solver': ['lbfgs', 'adam']\n",
    "                            }\n",
    "\n",
    "# Número de folds para la validación cruzada\n",
    "numero_subconjuntos = 5\n",
    "# Función utilidad\n",
    "funcion_utilidad = \"accuracy\"\n",
    "\n",
    "# Se crean todas las configuraciones del perceptrón multicapa\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid=rejilla_hiperparametros, \n",
    "                           cv=numero_subconjuntos,\n",
    "                           scoring=funcion_utilidad, \n",
    "                           refit=True,\n",
    "                           return_train_score=True)\n",
    "\n",
    "# Ejecutamos la búsqueda de hiperparámetros\n",
    "grid_search.fit(X_ent_escaladas, y_ent)\n",
    "\n",
    "# Mostramos los mejores parámetros\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Obtenga la mejor configuración y sus métricas. Dado los valores de las métricas, ¿obtiene la configuración obtenida un rendimiento mejor que la configuración generada en el ejercicio 4? Razone la respuesta. Si el resultado ha cambiado, ¿qué influencia tienen los parámetros que han cambiado en el resultado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración:  \n",
      "\tPipeline(steps=[('transformador', StandardScaler()),\n",
      "                ('MLP_CL',\n",
      "                 MLPClassifier(activation='logistic',\n",
      "                               hidden_layer_sizes=(45, 10), random_state=80))])\n",
      "\n",
      "Mejor puntuación: 0.7373333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mejor configuración:  \\n\\t{grid_search.best_estimator_}\")\n",
    "print(f\"\\nMejor puntuación: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Utilizando el dataset Datos_crédito.csv, cree la **SVM no lineal** que considere para realizar la **regresión de la columna Edad**. \n",
    "\n",
    "\n",
    "Para ello, siga los siguientes pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargue el conjunto de datos (dataset) y revise los tipos de datos de los atributos del conjunto de datos, analice si es necesario transformar alguno. En caso de ser necesario realiza la transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edad               int64\n",
      "Sexo              object\n",
      "Trabajo            int64\n",
      "Vivienda          object\n",
      "Ahorro            object\n",
      "Corriente         object\n",
      "Credito            int64\n",
      "Larga duracion     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Datos_crédito.csv')\n",
    "print(data.dtypes) \n",
    "\n",
    "# Tenemos varias columnas que podemos convertir en variables categóricas\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "columns = ['Sexo', 'Vivienda', 'Ahorro', 'Corriente']\n",
    "\n",
    "for column in columns:\n",
    "    data[column] = encoder.fit_transform(data[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cree un hold-out (train-test) 70-30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns=['Edad'], axis=0)\n",
    "y = data['Edad']\n",
    "\n",
    "X_ent, X_test, y_ent, y_test = train_test_split(X, y, test_size=0.3, random_state=semilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Aplique la estandarización de los datos para ajustar la escala de las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instanciamos el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Estandarización del conjunto de entrenamiento\n",
    "X_ent_escaladas = scaler.fit_transform(X_ent)\n",
    "\n",
    "# Aplicamos la estandarización calculada con los datos de entrenamiento a los datos de test\n",
    "X_test_escaladas = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Cree una SVM no lineal y fije el valor de C igual a 1. Fije el valor de otros 2 hiperparámetros principales. Analice si existe un problema de subajuste o de sobreajuste o si, por el contrario no existe ningún problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error absoluto medio de entrenamiento: 7.687537343573258\n",
      "Error cuadratico medio de entrenamiento: 119.74402650017883\n",
      "Error absoluto medio de test: 8.610527228431978\n",
      "Error cuadratico medio de test: 125.19607086433516\n"
     ]
    }
   ],
   "source": [
    "# Importamos la clase Linear SVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Instancia de la SVM lineal\n",
    "SVM_no_lineal_reg = SVR(kernel='rbf', gamma=1, epsilon=0.01, C=1)\n",
    "\n",
    "# Entrenamos la SVM lineal de regresión\n",
    "SVM_no_lineal_reg.fit(X_ent_escaladas, y_ent)\n",
    "\n",
    "# Salidas de la SVM de regresión no lineal\n",
    "y_pred_ent = SVM_no_lineal_reg.predict(X_ent_escaladas)\n",
    "y_pred_test = SVM_no_lineal_reg.predict(X_test_escaladas)\n",
    "\n",
    "print(f\"Error absoluto medio de entrenamiento: {mean_absolute_error(y_ent, y_pred_ent)}\")\n",
    "print(f\"Error cuadratico medio de entrenamiento: {mean_squared_error(y_ent, y_pred_ent)}\")\n",
    "print(f\"Error absoluto medio de test: {mean_absolute_error(y_test, y_pred_test)}\")\n",
    "print(f\"Error cuadratico medio de test: {mean_squared_error(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto los valores del MSE como del MAE en los conjuntos de entrenamiento y test son extremadamente altos, lo que implica que hay un problema de sobreajuste importante "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ahora, manteniendo los hiperparámetros que ha fijado, obtenga los resultados para C=0,1 y C=100. ¿Cuál es el efecto de C sobre el rendimiento de la SVM? Razone la respuesta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.1\n",
      "Error absoluto medio de entrenamiento: 8.580314958276503\n",
      "Error cuadratico medio de entrenamiento: 134.58147417227647\n",
      "Error absoluto medio de test: 8.956554566720964\n",
      "Error cuadratico medio de test: 131.63269181071757\n",
      "\n",
      "C=100\n",
      "Error absoluto medio de entrenamiento: 4.028190293550591\n",
      "Error cuadratico medio de entrenamiento: 61.173408755716956\n",
      "Error absoluto medio de test: 10.030368378903587\n",
      "Error cuadratico medio de test: 165.64198165069806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in [0.1, 100]:\n",
    "    print(f\"C={c}\")\n",
    "    # Instancia de la SVM lineal\n",
    "    SVM_no_lineal_reg = SVR(kernel='rbf', gamma=1, epsilon=0.01, C=c)\n",
    "\n",
    "    # Entrenamos la SVM lineal de regresión\n",
    "    SVM_no_lineal_reg.fit(X_ent_escaladas, y_ent)\n",
    "\n",
    "    # Salidas de la SVM de regresión no lineal\n",
    "    y_pred_ent = SVM_no_lineal_reg.predict(X_ent_escaladas)\n",
    "    y_pred_test = SVM_no_lineal_reg.predict(X_test_escaladas)\n",
    "\n",
    "    print(f\"Error absoluto medio de entrenamiento: {mean_absolute_error(y_ent, y_pred_ent)}\")\n",
    "    print(f\"Error cuadratico medio de entrenamiento: {mean_squared_error(y_ent, y_pred_ent)}\")\n",
    "    print(f\"Error absoluto medio de test: {mean_absolute_error(y_test, y_pred_test)}\")\n",
    "    print(f\"Error cuadratico medio de test: {mean_squared_error(y_test, y_pred_test)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que al aumentar el valor de $C$ el MSE y el MAE en el conjunto de entrenamiento disminuye, pero aumentan en el conjunto de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Realice una operación de búsqueda de los mejores hiperparámetros entre los utilizados en el apartado 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'svr__C': 1, 'svr__gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "# Definimos el Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVM_no_lineal_reg)\n",
    "])\n",
    "\n",
    "# Definimos la rejilla de hiperparámetros\n",
    "param_grid = {\n",
    "    'svr__gamma': [1, 5, 10, 20, 50, 100],\n",
    "    'svr__C': [0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Configuramos el GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', refit=True)\n",
    "\n",
    "# Ejecutamos GridSearchCV\n",
    "grid_search.fit(X_ent_escaladas, y_ent)\n",
    "\n",
    "# Mostramos los mejores parámetros\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Obtenga la mejor configuración y sus métricas de error. Dados los errores obtenidos, ¿obtiene la configuración obtenida un rendimiento mejor que la configuración generada en el ejercicio 4? Razone la respuesta. Si el resultado ha cambiado, ¿qué influencia tienen los parámetros que han cambiado en el resultado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración: \n",
      "\tPipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('svr', SVR(C=1, epsilon=0.01, gamma=1))])\n",
      "\n",
      "Mejor puntuación: 133.524462316033\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mejor configuración: \\n\\t{grid_search.best_estimator_}\")\n",
    "print(f\"\\nMejor puntuación: {-grid_search.best_score_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
