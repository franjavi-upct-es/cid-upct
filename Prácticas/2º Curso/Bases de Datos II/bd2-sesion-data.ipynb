{"cells":[{"cell_type":"markdown","metadata":{"id":"yULxkMKuIWqZ"},"source":["# BDII -- Sesión 1 -- Procesado inicial de datos"]},{"cell_type":"markdown","metadata":{"id":"NVBsiBj1IWqc"},"source":["Esta hoja muestra cómo procesar o curar un conjunto de datos para hacerlos más accesibles a la hora de introducirlos en bases de datos. Utilizaremos un conjunto de datos existente en Internet, que se descargará, se procesará y se convertirá en un formato universal como CSV o JSON. En particular se trabajará:\n","\n","- La descarga de los datos\n","- Inspección, identificación del formato y posible procesado\n","- Generación de un formato fácilmente digerible por las BBDD, como CSV o JSON"]},{"cell_type":"markdown","metadata":{"id":"DvNUhF8qIWqe"},"source":["Comenzaremos instalando los paquetes necesarios:"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"c3CXfty1iRum","executionInfo":{"status":"ok","timestamp":1706719308485,"user_tz":-60,"elapsed":319,"user":{"displayName":"Fco Javier Mercader","userId":"12677169545654363736"}}},"outputs":[],"source":["!sudo apt-get update -qq"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1706719308948,"user":{"displayName":"Fco Javier Mercader","userId":"12677169545654363736"},"user_tz":-60},"id":"Xcy7h029JBPQ"},"outputs":[],"source":["!sudo apt-get install -y git p7zip"]},{"cell_type":"markdown","metadata":{"id":"xIaSaxvCLdlZ"},"source":["Importamos algunos paquetes estándar para la hoja"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"F3UMoNLIIWq1","executionInfo":{"status":"ok","timestamp":1706719308948,"user_tz":-60,"elapsed":7,"user":{"displayName":"Fco Javier Mercader","userId":"12677169545654363736"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib\n","\n","%matplotlib inline\n","matplotlib.style.use('ggplot')"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"rsST-J-3jCTA","executionInfo":{"status":"ok","timestamp":1706719308948,"user_tz":-60,"elapsed":6,"user":{"displayName":"Fco Javier Mercader","userId":"12677169545654363736"}}},"outputs":[],"source":["RunningInCOLAB = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False"]},{"cell_type":"markdown","metadata":{"id":"avrO25-tLdle"},"source":["## Datos de Stackoverflow"]},{"cell_type":"markdown","metadata":{"id":"AmXZUR4ELdli"},"source":["## Descarga de los datos"]},{"cell_type":"markdown","metadata":{"id":"RpKnz-A3Ldlj"},"source":["En este caso los datos están disponibles en un repositorio git. Se pueden descargar también de la Web, pero se van actualizando. En este caso los descargamos del repositorio git para que todos tengáis los mismos."]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2886,"status":"ok","timestamp":1706719311828,"user":{"displayName":"Fco Javier Mercader","userId":"12677169545654363736"},"user_tz":-60},"id":"Ch1gjEmDSM6S","outputId":"65c0c7e0-3d32-4ecc-8e55-ad1daf013321"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-31 16:41:49--  https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.001\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/dsevilla/bd2-data/main/es.stackoverflow/es.stackoverflow.7z.001 [following]\n","--2024-01-31 16:41:49--  https://raw.githubusercontent.com/dsevilla/bd2-data/main/es.stackoverflow/es.stackoverflow.7z.001\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 103809024 (99M) [application/octet-stream]\n","Saving to: ‘es.stackoverflow.7z.001.1’\n","\n","es.stackoverflow.7z 100%[===================>]  99.00M   166MB/s    in 0.6s    \n","\n","2024-01-31 16:41:50 (166 MB/s) - ‘es.stackoverflow.7z.001.1’ saved [103809024/103809024]\n","\n","--2024-01-31 16:41:50--  https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.002\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/dsevilla/bd2-data/main/es.stackoverflow/es.stackoverflow.7z.002 [following]\n","--2024-01-31 16:41:50--  https://raw.githubusercontent.com/dsevilla/bd2-data/main/es.stackoverflow/es.stackoverflow.7z.002\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 103809024 (99M) [application/octet-stream]\n","Saving to: ‘es.stackoverflow.7z.002.1’\n","\n","es.stackoverflow.7z 100%[===================>]  99.00M   131MB/s    in 0.8s    \n","\n","2024-01-31 16:41:51 (131 MB/s) - ‘es.stackoverflow.7z.002.1’ saved [103809024/103809024]\n","\n","--2024-01-31 16:41:51--  https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.003\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/dsevilla/bd2-data/main/es.stackoverflow/es.stackoverflow.7z.003 [following]\n","--2024-01-31 16:41:51--  https://raw.githubusercontent.com/dsevilla/bd2-data/main/es.stackoverflow/es.stackoverflow.7z.003\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10263728 (9.8M) [application/octet-stream]\n","Saving to: ‘es.stackoverflow.7z.003.1’\n","\n","es.stackoverflow.7z 100%[===================>]   9.79M  --.-KB/s    in 0.1s    \n","\n","2024-01-31 16:41:52 (80.8 MB/s) - ‘es.stackoverflow.7z.003.1’ saved [10263728/10263728]\n","\n"]}],"source":["!wget https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.001\n","!wget https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.002\n","!wget https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.003"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1706719311828,"user":{"displayName":"Fco Javier Mercader","userId":"12677169545654363736"},"user_tz":-60},"id":"-B_iv7gOLdlm","outputId":"f38b2da9-75ed-47ae-c3a3-ca6994b8c4eb","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["total 6222364\n","-rw-r--r-- 1 root root  215792978 Dec  4 13:19 Comments.xml\n","-rw-r--r-- 1 root root  103809024 Jan 31 16:10 es.stackoverflow.7z.001\n","-rw-r--r-- 1 root root  103809024 Jan 31 16:41 es.stackoverflow.7z.001.1\n","-rw-r--r-- 1 root root  103809024 Jan 31 16:10 es.stackoverflow.7z.002\n","-rw-r--r-- 1 root root  103809024 Jan 31 16:41 es.stackoverflow.7z.002.1\n","-rw-r--r-- 1 root root   10263728 Jan 31 16:10 es.stackoverflow.7z.003\n","-rw-r--r-- 1 root root   10263728 Jan 31 16:41 es.stackoverflow.7z.003.1\n","-rw-r--r-- 1 root root 1212084099 Jan 31 16:14 Posts2.json\n","-rw-r--r-- 1 root root  965533797 Jan 31 16:12 Posts.csv\n","-rw-r--r-- 1 root root 1221848946 Jan 31 16:13 Posts.json\n","-rw-r--r-- 1 root root 1141094239 Jan 31 16:14 Posts.jsonl\n","-rw-r--r-- 1 root root 1029736014 Dec  4 13:20 Posts.xml\n","drwxr-xr-x 1 root root       4096 Jan 29 14:26 sample_data\n","-rw-r--r-- 1 root root     227980 Dec  4 13:20 Tags.xml\n","-rw-r--r-- 1 root root   76430831 Dec  4 13:20 Users.xml\n","-rw-r--r-- 1 root root   73149127 Dec  4 13:20 Votes.xml\n"]}],"source":["!ls -l"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4aRLjuTLdl4","outputId":"9620d193-dc8d-4809-d780-5433bf2d56ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n","p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n","\n","Scanning the drive for archives:\n","  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 103809024 bytes (99 MiB)\n","\n","Extracting archive: es.stackoverflow.7z.001\n","  0% 1 Open\b\b\b\b\b\b\b\b\b\b\b           \b\b\b\b\b\b\b\b\b\b\b--\n","Path = es.stackoverflow.7z.001\n","Type = Split\n","Physical Size = 103809024\n","Volumes = 3\n","Total Physical Size = 217881776\n","----\n","Path = es.stackoverflow.7z\n","Size = 217881776\n","--\n","Path = es.stackoverflow.7z\n","Type = 7z\n","Physical Size = 217881776\n","Headers Size = 244\n","Method = LZMA2:24\n","Solid = +\n","Blocks = 1\n","\n","  0%\b\b\b\b    \b\b\b\b\n","Would you like to replace the existing file:\n","  Path:     ./Comments.xml\n","  Size:     215792978 bytes (206 MiB)\n","  Modified: 2023-12-04 13:19:25\n","with the file from archive:\n","  Path:     Comments.xml\n","  Size:     215792978 bytes (206 MiB)\n","  Modified: 2023-12-04 13:19:25\n","? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? "]}],"source":["!7zr x es.stackoverflow.7z.001"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOUYfUvQLdl5"},"outputs":[],"source":["!ls -l"]},{"cell_type":"markdown","metadata":{"id":"DT_AMyRxPzs5"},"source":["## Inspección y procesado"]},{"cell_type":"markdown","metadata":{"id":"WCWdECvlQoG4"},"source":["Podemos inspeccionar los ficheros `.xml` para ver su contenido. Son XML, sí, pero ¿con qué formato?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YTb3J-jtQwMD"},"outputs":[],"source":["!head Posts.xml"]},{"cell_type":"markdown","metadata":{"id":"PIKskRYjRd6F"},"source":["Aunque se puede procesar el formato XML, lo que podemos ver es que cada entrada es exactamente una línea que comienza por `<row`, y que contiene un conjunto de atributos en formato `atributo=\"valor\"`. Si lo comprobamos, incluso no existirá ninguna comilla doble **dentro** de otra comilla doble, así que podemos extraer esos pares de forma facil."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mWAk2JCeTswM"},"outputs":[],"source":["import re\n","\n","def process_file(fname):\n","  with open(fname, \"r\") as f:\n","    for line in f:\n","      if \"<row\" in line:\n","        attr_dict = {}\n","        (_,attrs) = line.split(\"<row \",2)\n","        for m in re.finditer(r\"(\\w*?)=\\\"(.*?)\\\"\", attrs):\n","          attr_dict[m.group(1)] = m.group(2)\n","        yield attr_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i8HTRYP_gJrU"},"outputs":[],"source":["first_row = next(process_file(\"Posts.xml\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FAgzvrRa6fpO"},"outputs":[],"source":["first_row.keys()"]},{"cell_type":"markdown","metadata":{"id":"-FawjWDD5twt"},"source":["Hay que extraer el conjunto de atributos para saber qué columnas tendrá nuestra tabla/CSV o archivo JSON. Recuérdese que las dos primeras filas del archivo XML tenían diferentes atributos. ¿Cómo se haría esto?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GdRO-j5E6Tr7"},"outputs":[],"source":["def get_all_attrs(iterator):\n","  all_attrs = set()\n","  for row in iterator:\n","    all_attrs.update(row.keys())\n","  return all_attrs\n","\n","all_attrs = get_all_attrs(process_file(\"Posts.xml\"))"]},{"cell_type":"markdown","metadata":{"id":"tBDZnk5CLY42"},"source":["Como sabemos que el atributo `Id` va a ser la clave primaria, lo ponemos al principio. Además, generamos una lista, uno un conjunto, para que el orden sea conocido."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5sHeBZs6W03"},"outputs":[],"source":["all_attrs.remove('Id')\n","all_attrs = list(all_attrs)\n","all_attrs.insert(0,'Id')\n","all_attrs"]},{"cell_type":"markdown","metadata":{"id":"PwI1EwAGNIBl"},"source":["## Escritura del formato CSV"]},{"cell_type":"markdown","metadata":{"id":"397wlUELTA2n"},"source":["El formato CSV está especificado en el estándar RFC 4180. https://www.ietf.org/rfc/rfc4180.txt. En general se puede utilizar la biblioteca `csv` de Python 3 y vamos a exportar una línea de cabecera con todos los campos. https://docs.python.org/3/library/csv.html.\n","\n","Tendremos en cuenta que todas las filas tienen que tener las mismas columnas y en el mismo orden dado por `all_attrs`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxYvaSWUMlxL"},"outputs":[],"source":["import csv\n","\n","def write_csv(destfile, all_attrs, iterator):\n","  with open(destfile, 'w') as wf:\n","    cw = csv.writer(wf)\n","\n","    # Escribir la línea de cabecera\n","    cw.writerow(all_attrs)\n","\n","    # Recorrer el iterador\n","    for row in iterator:\n","      cw.writerow(map(lambda att: row.get(att) or '', all_attrs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U81Z3NJ8Xp9H"},"outputs":[],"source":["write_csv('Posts.csv', all_attrs, process_file('Posts.xml'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAK6raymXv1l"},"outputs":[],"source":["!head Posts.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3gKjEG_6YUsX"},"outputs":[],"source":["def read_csv(filename):\n","  with open(fname, \"r\") as f:\n","    for line in f:\n","      yield line.split(',')"]},{"cell_type":"markdown","metadata":{"id":"sjUZekvLV3cC"},"source":["## Conversión hacia JSON"]},{"cell_type":"markdown","metadata":{"id":"210crSGrV7vU"},"source":["https://www.json.org/json-en.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjF5rNC2e68h"},"outputs":[],"source":["import json\n","\n","def csv_to_json(fname_csv, fname_json, pk):\n","    data_dict = {}\n","\n","    with open(fname_csv, \"r\") as f_csv:\n","        csv_reader = csv.DictReader(f_csv)\n","\n","        for rows in csv_reader:\n","            key = rows[pk]\n","            data_dict[key] = rows\n","\n","    with open(fname_json, 'w') as f_json:\n","        f_json.write(json.dumps(data_dict, indent = 4))\n","\n","# Estamos cargando todo en la memoria, con conjuntos grandes de datos puede\n","# resultar muy pesado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"evSVXVNRAH4h"},"outputs":[],"source":["fname_csv = 'Posts.csv'\n","fname_json = 'Posts.json'\n","\n","csv_to_json(fname_csv, fname_json, 'Id')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VY2wnvOwAihf"},"outputs":[],"source":["!head Posts.json"]},{"cell_type":"markdown","metadata":{"id":"uVMEPMKVIjwd"},"source":["Si nos damos cuenta, tenemos el problema de que el valor Id está por duplicado.\n","\n","Vamos a ver como eliminar columnas que no queramos tener."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-DHnaiaeDq3B"},"outputs":[],"source":["def csv_to_json2(fname_csv, fname_json, pk):\n","    data_dict = {}\n","\n","    with open(fname_csv, \"r\") as f_csv:\n","        csv_reader = csv.DictReader(f_csv)\n","\n","        for rows in csv_reader:\n","            key = rows[pk]\n","\n","            # Borramos los campos que nos interesen.\n","            del rows[pk]\n","\n","            data_dict[key] = rows\n","\n","    with open(fname_json, 'w') as f_json:\n","        f_json.write(json.dumps(data_dict, indent = 4))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pBXBaVxDyfk"},"outputs":[],"source":["fname_csv = 'Posts.csv'\n","fname_json = 'Posts2.json'\n","\n","csv_to_json2(fname_csv, fname_json, 'Id')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1D7hKFCD2nn"},"outputs":[],"source":["!head -n 100 Posts2.json"]},{"cell_type":"markdown","metadata":{"id":"bbsLc5dVFDKK"},"source":["Al escribir en formato JSON se nos queda un fichero compacto que no podemos dividir."]},{"cell_type":"markdown","metadata":{"id":"P2ZC7QteFRtI"},"source":["## JSON Lines"]},{"cell_type":"markdown","metadata":{"id":"YzxiUCJkFTL7"},"source":["\n","\n","https://jsonlines.org/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQpiJSUJFXKW"},"outputs":[],"source":["def csv_to_jsonl(fname_csv, fname_jsonl):\n","    with open(fname_csv, 'r') as f_csv:\n","        csv_reader = csv.DictReader(f_csv)\n","\n","        with open(fname_jsonl, 'w') as f_jsonl:\n","            for row in csv_reader:\n","                json_line = json.dumps(row)\n","                f_jsonl.write(json_line + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2r2jtQoIJKcy"},"outputs":[],"source":["csv_to_jsonl('Posts.csv', 'Posts.jsonl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lsPl8iCIJlRN"},"outputs":[],"source":["!head Posts.jsonl"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}