\begin{center}
    \textbf{\Large Hoja 1: Problemas de Introducción a los Procesos Estocásticos} 
\end{center}
\begin{enumerate}[label=\color{red}\textbf{\arabic*)}]
    \item \lb{¿Qué es un proceso estocástico y cómo se define formalmente?}

        Un \textbf{proceso estocástico} es una colección de variables aleatorias que representan la evolución en el tiempo de un fenómeno aleatorio.

        \begin{itemize}[label=\textbullet, leftmargin=*]
            \item \textbf{Definición formal:}

                Un proceso estocático $(X_t)_{t\in T}$ es una colección de variables aleatorias reales $X_t$, cada una definida sobre un espacio de probabilidad  $(\Omega,\mathcal{F},P)$, donde el índice $t$ representa el tiempo.
        \end{itemize}
    \item \lb{¿Cuáles son los tipos principales de procesos estocásticos en función del tiempo?}
        \begin{enumerate}[label=\arabic*)]
            \item \textbf{Procesos de tiempo discreto:} Son aquellos en los que el conjunto de tiempos $T$ es contable, por ejemplo:  \[
            T=\{0,1,2,\dots\} 
            \]
            En este caso, el proceso se observa en instantes separados.
            \item \textbf{Procesos de tiempo continuo:} Son aquellos en los que el conjunto de tiempos $T$ es un intervalo de la recta real, por ejemplo:  \[
                    T=[0,T]\text{ ó }T=[0,\infty)
            \]
            Aquí el proceso se observa en todos los instantes del intervalo.
        \end{enumerate}
    \item \lb{¿Cómo se clasifica un proceso estocástico según los estados que puede formar?} 
        \begin{enumerate}[label=\arabic*)]
            \item \textbf{Proceso de estado discreto}

                Un proceso estocástico $(X_t)$ es de estado discreto cuando cada variable aleatoria  $X_t$ toma valores en un conjunto discreto (finito o numerable).

            \item \textbf{Proceso de estado continuo}

                Un proceso etocástico $(X_t)$ es de estado continuo cuando cada  $X_t$ toma valores en un intervalo continuo de $\R$.
        \end{enumerate}
    \item \lb{¿Qué es una trayectoria en el contexto de un proceso estocástico?} 

        Dado un proceso estocástico $(X_t)_{t\in T}$, para cada realización $\omega\in \Omega$, la colección de valores: $$(X_t(\omega))_{t\in T}$$ se llama trayectoria del proceso. Es decir, una trayectoria es una observación concreta de cómo evoluciona el proceso a lo largo del tiempo.
        \begin{itemize}[label=\textbullet]
            \item Si el timepo es discreto, una trayectoria es una sucesión $(x_t)_{t=0,1,2,\dots}$.
            \item Si el tiempo es continuo, una trayectoria es una función real $t\mapsto x(t)$.
        \end{itemize}
    \item \lb{¿Qué es un paseo aleatorio y cómo se define en términos de variables aleatorias? Simular, usando  \textbf{\texttt{R}}, 4 trayectorias de un paseo aleatorio con variables aleatorias i.i.d. dadas por la distribución $N(0,1)$.} 

        Un \textbf{paseo aleatorio} es un proceso estocástico $(X_t)_{t=0,1,2,\dots}$ definido por:
        \begin{itemize}[label=\textbullet]
            \item $X_0=0$
            \item $X_t=X_{t-1}+Y_t$ para $t=1,2,3,\dots$
        \end{itemize}
        donde $(Y_t)$ es una sucesión de  \textbf{variables aleatorias i.i.d.}

        \textbf{Paseo aleatorio con $Y_t\sim N(0,1)$} 

        Aquí $Y_t$ ya no solo toma valores  $\pm 1$ como en el paseo aleatorio simple; ahora viene de una \textbf{Normal estándar}, también permitido por la definición general.
        
<<fig=TRUE, fig.width=8, fig.height=5, out.width='0.7\\textwidth', fig.align='center'>>=
set.seed(123)

nsim <- 4         # número de trayectorias
n <- 200          # número de pasos por trayectoria
tiempo <- 0:n

# colores para las curvas
colores <- rainbow(nsim)

# Simular primera trayectoria
Y <- rnorm(n, mean = 0, sd = 1)       # variables i.i.d N(0,1)
X <- c(0, cumsum(Y))                  # paseo aleatorio

plot(tiempo, X, type = "l", col = colores[1],
     lty = 1, ylim = c(-20, 20),
     xlab = "t", ylab = "X_t")

# Simular las otras trayectorias
for (i in 2:nsim) {
  Y <- rnorm(n, mean = 0, sd = 1)
  X <- c(0, cumsum(Y))
  lines(tiempo, X, col = colores[i])
}
@
        
    \item \lb{¿Qué características tiene un paseo aleatorio simple y en qué se diferencia del paseo aleatorio simétrico? Simular, usando \textbf{\texttt{R}}, 6 trayectorias de un paseo aleatorio simple $p=\dfrac{1}{3}$.}

        \begin{itemize}[label=\textbullet]
            \item \textbf{Paseo aleatorio simple}

                Un \textbf{paseo aleatorio simple} es una paseo aleatorio en el que las variables i.i.d. $Y_t$ solo pueden tomar los valores: $$Y_t\in \{1,-1\} $$ con probabilidades: $$P(Y_t=1)=p,\quad P(Y_t=-1)=1-p.$$

            \item \textbf{Paseo aleatorio simétrico}

                Es un caso particular del paseo aleatorio simple en el que: $$p=\dfrac{1}{2}.$$ Es decir, cara o cruz (subida o bajada) tienen la \textbf{misma probabilidad}.

            \item \textbf{Simulación en \texttt{R} de 6 trayectorias del paseo aleatorio simple con $p=\dfrac{1}{3}$:}

                Esto significa:
                \begin{itemize}[label=\textbullet]
                    \item $P(Y_t=1)=\dfrac{1}{3}$ 
                    \item $P(Y_t=-1)=1-\dfrac{1}{3}=\dfrac{2}{3}$
                \end{itemize}

<<fig=TRUE, fig.width=8, fig.height=5, out.width='0.7\\textwidth', fig.align='center'>>=
set.seed(123)

nsim <- 6        # número de trayectorias
n <- 200         # pasos por trayectoria
tiempo <- 0:n
p <- 1/3         # parámetro del paseo aleatorio simple

colores <- rainbow(nsim)

# Primera trayectoria
Y <- sample(c(-1, 1), size = n, replace = TRUE,
            prob = c(1 - p, p))
X <- c(0, cumsum(Y))

plot(tiempo, X, type = "l", lty = 1,
     col = colores[1], ylim = c(-80, 80),
     xlab = "t", ylab = "X_t")

# Otras trayectorias
for (i in 2:nsim) {
  Y <- sample(c(-1, 1), size = n, replace = TRUE,
              prob = c(1 - p, p))
  X <- c(0, cumsum(Y))
  lines(tiempo, X, col = colores[i])
}
@
        \end{itemize}
    \item \lb{¿Qué es una función de distribuión finito dimensional en un proceso estocástico?} 

        En un proceso estocástico, la \textbf{función de distribución finito dimensional} describe la \textbf{distribución conjunta} del proceso en varios instantes de tiempo.

        Sea $(X_t)_{t\in T}$ un proceso estocástico y toma una sucesión finita de tiempos: \[
        t_1<t_2<\cdots<t_n.
        \] 
        La \textbf{función de distribución finito dimensional} del proceso es: \[
        F_{t_1,t_2,\dots,t_n}(x_1,x_2,\dots,x_n)=P(X_{t_1}\le x_1,X_{t_2}\le x_2,\dots,X_{t_n}\le x_n).
        \]  
    \item \lb{¿Cómo se define la función de medias de un proceso estocástico? ¿Y la de covarianzas y correlaciones?} 

        \begin{enumerate}[label=\arabic*)]
            \item \textbf{Función de medias}

                La \textbf{función media} o \textbf{función de medias} de un proceso estocástico $(X_t)$ es: $$\mu_X(t)=E(X_t).$$ 
                \begin{itemize}[label=\textbullet]
                    \item En tiempo discreto: define una sucesión $(\mu_X(t))_{t=0,1,2,\dots}$.
                    \item En tiempo discreto: define una función $t\mapsto \mu_X(t)$.
                \end{itemize}
            \item \textbf{Función de covarianzas}

                La \textbf{función de covarianzas} del proceso se define como: \[
                C_X(s,t)=\mathrm{Cov}(X_s,X_t)=E\left[ (X_s-\mu_X(s))(X_t-\mu_X(t)) \right] =E(X_sX_t)-\mu_X(s)\mu_X(t).
                \]  
            \item \textbf{Función de varianza}

                La función de varianza es un caso particular de la covarianza: \[
                \sigma_X^2(t)=\mathrm{Var}(X_t)=C_X(t,t).
                \] 
            \item \textbf{Función de correlaciones}

                La función de correlación entre los tiempos $s$ y  $t$ es:  \[
                \theta_X(s,t)=\dfrac{C_X(s,t)}{\sigma_X(s)\sigma_X(t)}.
                \] 
        \end{enumerate}
    \item \lb{¿Qué relación existe entre la función de varianza y la función de covarianza en un proceso estocástico?} 

        La \textbf{varianza} es un \textbf{caso particular} de la \textbf{covarianza}.

        En concreto, para cualquier proceso estocástico $(X_t)_{t\in T}$: \[
        \sigma_X^2(t)=\mathrm{Var}(X_t)=C_X(t,t).
        \] 
        Es decir: \textbf{La varianza en un instante $t$ es simplemente la covarianza del proceso consigo mismo en ese mismo instante.} 
    \item \lb{¿Qué condiciones deben cumplirse para que un proceso sea estacionario y en qué se diferencia de la estacionariedad débil?} 
        \begin{enumerate}[label=\arabic*)]
            \item \textbf{Condiciones para que un proceso sea estacionario (en sentido estricto)}

                Un proceso estocástico $(X_t)_{t\in T}$ es \textbf{estacionario} si:

                Para toda sucesión finita de tiempos \(t_1,t_2,\dots,t_n\) y para todo esplazamiento temporal $s>0$: \(X_{t_1},X_{t_2},\dots,X_{t_n}\text{ y }(X_{t_1+s},X_{t_2+s},\dots,X_{t_n+s})\) tienen \textbf{la misma función de distribución conjunta}.

                \textbf{Implica que:}
                \begin{itemize}[label=\textbullet]
                    \item Todas las variables $X_t$ tiene  \textbf{la misma distribución}.
                    \item El comportamiento probabilístico completo del proceso \textbf{no cambia con el tiempo.}
                    \item Se converva toda la estructura de dependencias, no solo momentos con medias o covarianzas.
                \end{itemize}
            \item \textbf{Condiciones para que un proceso sea débilmente estacionario}

                Un proceso es \textbf{débilmente estacionario} si cumple solo dos condiciones:
                \begin{enumerate}[label=(\arabic*)]
                    \item \textbf{Media constante} \[
                        \mu_X(t)=\mu_X(0)\text{, para todo $t$.}
                    \]  
                    \item \textbf{La covarianza depende solo del salto temporal} \[
                    C_X(s,t)=C_X(0,t-s)\text{, si $s\le t$.}
                    \]  
                \end{enumerate}
                \textbf{Consecuencia importante:}

                La varianza es constante, porque \[
                \mathrm{Var}(X_t)=C_X(t,t)
                \] depende solo de $t-t=0$, que es constante.
        \end{enumerate}
    \item \lb{¿Qué diferencias hay entre un proceso estocástico gaussiano y un ruido blanco gaussiano? Simular, usando \textbf{\texttt{R}}, 2 trayectorias de un ruido blanco gaussiano con varianza $\sigma^2$.} 
    \item \lb{¿Cuál es la definición de un proceso de Wiener o movimiento Browniano? Simular, usando \textbf{\texttt{R}}, 3 trayectorias de un movimiento Browniano.} 
    \item \lb{¿Cuál de las siguientes es una condición necesaria para que un proceso estocástico sea débilmente estacionario?}
        \begin{enumerate}[label=\color{red}\textbf{(\alph*)}]
            \item \db{La varianza depende del tiempo.} 
            \item \db{La media es constante en el tiempo.} 
            \item \db{La covarianza es cero para todos los tiempos.} 
        \end{enumerate}
    \item \lb{Si $(X_t)_{t\in [0,\infty)}$ es ruido blanco (gaussiano) con varianza $\sigma^2$, ¿cuál de las siguientes afirmaciones es verdadera?}
        \begin{enumerate}[label=\color{red}\textbf{(\alph*)}]
            \item \db{$\mathrm{Cov}(X_t,X_{t+h})=\sigma^2$ para todo $t$ y  $h$.} 
            \item \db{$\mathrm{Cov}(X_t,X_{t+h})=\sigma^2$ si $h=0,\,\mathrm{Cov}(X_t,X_{t+h})=0$ si  $h\neq 0$.} 
            \item \db{$\mathrm{Cov}(X_t,X_{t+h})=\dfrac{1}{2}\sigma^2$ para todo $t$ y  $h$.} 
        \end{enumerate}
    \item \lb{¿Cuál de las siguientes afirmaciones es verdadera para un ruido blanco?}
        \begin{enumerate}[label=\color{red}\textbf{(\alph*)}]
            \item \db{Tiene una función de correlación que decrece exponencialmente.} 
            \item \db{Su media es no nula.} 
            \item \db{Sus valores en diferentes tiempos son independientes.} 
        \end{enumerate}
    \item \lb{¿Qué describe la función de covarianza de un proceso estocástico?} 
        \begin{enumerate}[label=\color{red}\textbf{(\alph*)}]
            \item \db{La relación lineal en el proceso en dos tiempos diferentes.} 
            \item \db{La suma de todas las realizaciones del proceso.} 
            \item \db{La frecuencia con la que el proceso cruza la media.} 
        \end{enumerate}
    \item \lb{Una condición necesaria para que un proceso estocástico sea débilmente estacionario es que:} 
        \begin{enumerate}[label=\color{red}\textbf{(\alph*)}]
            \item \db{La media debe ser cero.} 
            \item \db{La covarianza depende del tiempo.} 
            \item \db{La función de covarianza depende solo de la diferencia entre los tiempos.} 
        \end{enumerate}
    \item \lb{Consideremos el proceso estocástico de tiempo discreto $(X_t)_{t=0,1,2,\dots}$, con $X_0=a\in \R$ una constante cualquiera y $X_t=3+\varepsilon_t+2\varepsilon_{t-1}$ para todo $t=1,2,\dots$, siendo $(\varepsilon_t)_{t=0,1,2,\dots}$ ruido blanco (gaussiano) de varianza $\sigma^2$.} 
        \begin{enumerate}[label=\color{red}\textbf{(\alph*)}]
            \item \db{Calcular la función de medias, covarianzas y correlaciones del proceso $(X_t)_{t=0,1,2,\dots}$} 
            \item \db{Justificar si el proceso es estacionario en sentido débil.} 
            \item \db{Justificar si el proceso es estacionario (en sentido fuerte).} 
        \end{enumerate}

    \lb{\textbf{Nota:} El proceso del enunciado es un proceso denominado MA(1) que estudiará en el tema posterior.}   
    \item \lb{Consideremos el proceso estocástico de tiempo discreto $(X_t)_{t=0,1,2,\dots}$, con $X_0=a\in \R$ una constante cualquiera y $X_t=\alpha X_{t-1}+\varepsilon_t$, para todo $t=1,2,\dots$, siendo $(\varepsilon_t)_{t=1,2,\dots}$ ruido blanco (gaussiano) de varianza $\sigma^2$. Suponiendo el proceso $(X_t)_{t=0,1,2,\dots}$ es débilmente estacionario, obtener la función de medias y correlaciones.} 
    
        \lb{\textbf{Nota:} El proceso del enunciado es un proceso denominado AR(1) que estudiará en el tema posterior.}

        Supongamos que $X_t$ es débilmente estacionario.

        Nos piden función medias, covarianzas y correlaciones.
         \begin{itemize}[label=\textbullet]
            \item \textbf{Función de medias} del $(X_t)_{t=0,1,2,\dots}$ \[
                    \mathbb{E}(X_t)=\mathbb{E}(\alpha X_{t-1}+\varepsilon_t)=\alpha\lbb{\mathbb{E}(X_{t-1})}{\mu}+\tozero{\mathbb{E}(\varepsilon_t)} 
            \]
            Esto implica que \[
            \mu=\alpha\mu \begin{cases}
                \mu=0\\
                \alpha=1
            \end{cases}
            \] 
            \item \textbf{Función de varianzas} de $(X_t)_{t=0,1,2,\dots}$ \[
                    \begin{aligned}
            \sigma_X^2=\lbb{\mathrm{Var}(X_t)}{C}=\mathrm{Var}(\alpha X_{t-1}+\varepsilon_t)=\alpha^2\lbb{\mathrm{Var}(X_{t-1})}{C}+\lbb{\mathrm{Var}(\varepsilon_t)}{\sigma^2}\\
            C\longleftrightarrow \alpha^2C+\sigma^2\longleftrightarrow C-\alpha^2C=\sigma^2\longleftrightarrow C=\dfrac{\sigma^2}{1-\alpha^2}
                    \end{aligned}
            \]  
            $C=\mathrm{Var}(X_t)\;\forall t$ constante porque hemos supuesto débilmente estacionario.

            Observar que para que exista la varianza $C$, debe cumplirse que  $|\alpha|<1$.
            \item \textbf{Función de correlaciones} 
        \end{itemize}
    \item \lb{Sea $(X_t)_{t=0,1,2,\dots}$ un paseo aleatorio simple. Es decir, $X_0=0$ y $X_t=X_{t-1}+Y_t,(Y_t)_{t=0,1,2,\dots}$ variabls aleatorias i.i.d verificando $P(Y_t=1)=p,P(Y_t=-1)=1-p,p \in (0,1)$.} 
        \begin{enumerate}[label=\color{red}\textbf{(\alph*)}]
            \item \db{Calcular la función de medias, covarianzas y correlaciones del proceso $(X_t)_{t=0,1,2,\dots}$} 
            \item \db{Justificar si el proceso es estacionario en sentido débil.} 
            \item \db{Justificar si el proceso es estacionario (en sentido fuerte).} 
        \end{enumerate}
                Vamos a calcular la media y varianza de la variable aleatoria $Y_t$. 
                 \[
                     \begin{array}{c}
                         \mathbb{E}(Y_t)=1\cdot p+(-1)\cdot (1-p)=2p-1\;\forall t=1,2,\dots\\
                         \mathrm{Var}(Y_t)=\mathbb{E}(Y_t^2)-\left( \mathbb{E}(Y_t) \right) ^2=1-(4p^2-4p+1)=-4p^2+4p=4p(1-p)\;\forall t=1,\dots,n\\
                         \mathbb{E}(Y_t^2)=1^2\cdot p+(-1)^2\cdot (1-p)=1
                     \end{array}
                \] 
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Función de medias} del proceso $(X_t)_{t=0,1,2,\dots}$ 

                        $\begin{array}{l}
                            X_0=0\\
                            X_1=X_0+Y_1=0+Y_1=Y_1\\
                            X_2=X_1+Y_2=Y_1+Y_2\\
                            \vdots\\
                            X_t=Y_1+Y_2+\dots+Y_t\;\forall t=1,2,\dots\\
                            \mu_X(t)=\mathbb{E}(X_t)=\mathbb{E}(Y_1+Y_2+\dots+Y_n)=\mathbb{E}(Y_1)+\mathbb{E}(Y_2)+\dots+\mathbb{E}(Y_t)=t\cdot (2p-1)
                        \end{array}$ 

                        Observar que no es constante $\implies$ el proceso no es estacionario ni débil ni fuerte.
                    \item \textbf{Función de covarianzas} del proceso. Se $t \in \{0,1,2,\dots\} $ y $h\ge 0$:
                        \[
                            \begin{aligned}
                                C_X(t,t+h)&=\mathrm{Cov}(X_t,X_{t+h})\\
                                          &=\mathrm{Cov}(Y_1+Y_2+\dots+Y_t, Y_1+Y_2+\dots+Y_{t+h})\\
                                          &=\mathrm{Cov}(Y_1,Y_1)+\mathrm{Cov}(Y_2,Y_2)+\dots+\mathrm{Cov}(Y_t,Y_t)\\
                                          &=\mathrm{Var}(Y_1)+\mathrm{Var}(Y_2)+\dots+\mathrm{Var}(Y_t)
                            \end{aligned}
                        \] 
                        Observar que $\mathrm{Cov}(Y_t,Y_s)=0\;\forall s\neq t$ (por independencia)
                    \item \textbf{Función de varianzas} del proceso:
                        \[
                        \mathrm{Var}(X_t)=t\cdot 4p(1-p)\text{ depende del tiempo }t.
                        \] 
                    \item \textbf{Función de correlaciones} del proceso $(X_t)_{t=0,1,2,\dots}$ 
                        \[
                        \rho_X(t,t+h)=\dfrac{C_X(t,t+h)}{\sigma_X(t)\sigma_X(t+h)}=\dfrac{t\cdot 4p(1-p)}{\sqrt{t4p(1-p)}\sqrt{(t+h)4p(1-p)}}=\dfrac{t}{\sqrt{t}\sqrt{t+h}  }
                        \] 
                \end{itemize}
    \item \lb{Demostrar que si $(X_t)_{t\in [0,\infty)}$ es un movimiento Browniano, entonces es un proceso estocástico gaussiano no estacionario.}
    \item \lb{Consideremos el proceso estocástico $(X_t)_{t\in [0,\infty)}$ con $X_t=Ae^{\lambda t}+B$, con $A\sim U(0,4)$ y $B\sim \mathrm{Exp}(\lambda)$ siendo $A$ y  $B$ independientes.}
        \begin{enumerate}[label=\color{red}\textbf{\alph*)}]
            \item \db{Calcular la función de medias, covarianzas y correlaciones del proceso $(X_t)_{t\in [0,\infty)}$} 
            \item \db{Justificar si el proceso es estacionario en sentido débil.} 
            \item \db{Justificar si el proceso es estacionario (en sentido fuerte).} 
        \end{enumerate}
    \item \lb{Consideremos el proceso estocástico $(X_t)_{t\in [0,\infty)}$ con $X_t=Y\sin(U+t)$, con $U\sim U(0,2\pi)$ e $Y\sim N(0,1)$ siendo $U$ e  $Y$ independientes.}
        \begin{enumerate}[label=\color{red}\textbf{\alph*)}]
            \item \db{Calcular la función de medias, covarianzas y correlaciones del proceso $(X_t)_{t\in [0,\infty)}$.}
            \item \db{Justificar si el proceso es estacionario en sentido débil.} 
        \end{enumerate}
\end{enumerate}
