\section{Conceptos básicos en series temporales}
\subsection{Introducción}
El estudio de series temporales es fundamental para el proceso de predicción (Forecasting), que consiste en anticipar eventos futuros basándose en datos históricos y patrones identificables. Esta disciplina es esencial en diversos campos, desde la economía hasta la ingeniería, y su aplicación es vital para la toma de decisiones informadas en el ámbito empresarial y gubernamental.

\textbf{¿Qué se puede predecir?}

La predicción se utiliza en múltiples situaciones de la vita cotidiana y la industria, como son la gestión de intervalos, la planificación de la producción, la gestión energética o la asignación de personal. La capacidad de predecir con precisión depende de varios factores, entre ellos la comprensión de las causas subyacentes, la disponibilidad de datos históricos, la consistencia del comportamiento pasado y futuro, y el impacto de las predicciones en los propios eventos. Por ejemplo, las predicciones a corto plazo de la demanda eléctrica residencial suelen ser precisas debido a la estabilidad de los factores que la afectan y la abundancia de datos históricos relevantes.

\textbf{Diferencias entre predicciones, objetivos y planificación}

Es crucial diferenciar entre predicciones, objetivos y planificación. Predecir implica anticipar el futuro con la mayor precisión posible mediante el análisis históricos y el conocimiento de eventos futuros. Los objetivos son metas específicas que deben que deben alinearse con las predicciones y servir como guía para la planificación. La planificación involucra diseñar estrategias y acciones basadas en las predicciones para alcanzar los objetivos establecidos.

\textbf{Determinación de qué predecir}

Decidir qué predecir es un paso crucial. Puede involucrar observaciones individuales o datos agregados. Es importante definir el horizonte de predicción, que puede ser a corto plazo (una hora, o unos días), a medio plazo (por ejemplo, un mes) o a largo plazo (por ejemplo, un año). Además, se debe determinar la frecuencia de las predicciones, que puede ser diaria, semanal, mensual o anual, según las necesidades de los usuarios de las predicciones. La recolección y organización de datos relevantes y precisos es esencial para asegurar la calidad de las predicciones.

\textbf{Datos y métodos de predicción}

Los métodos cuantitativos de predicción son útiles cuando hay datos numéricos disponibles y se espera que los patrones pasados continúen en el futuro. Los datos de series temporales, como las ventas trimetrales o la demanda horaria de electricidad, son fundamentales en estos análisis. La descomposición de datos permite estudiar tendencias y patrones estacionales. Entre los métodos más utilizados se encuentran el análisis clásico de series, el suavizamiento exponencial y los modelos ARIMA, efectivos para capturar y predecir patrones en los datos históricos. Los modelos explicativos, que emplean variables predictoras y los modelos mixtos, que combinan características de varios enfoques, pueden mejorar la precisión y la utilidad de las predicciones.

\textbf{Pasos básicos en Forecasting}

Las etapas a tener en cuenta en un problema de predicciones son:
\begin{enumerate}[label=\arabic*)]
    \item Definición del problema: Entender el uso y los usuarios de las predicciones para asegurar que se adapten a sus necesidades específicas.
    \item Recolección de información: Obtener datos estadísticos relevantes y utilizar la experiencia de expertos en el campo.
    \item Análisis preliminar: Graficar y analizar datos para identificar patrones, tendecias y estacionalidad, lo cual ayuda en la selección del modelo de predicción adecuado.
    \item Elección y ajuste de modelos: Seleccionar y ajustar el método de predicción más apropiado basado en los datos disponibles y la situación específica.
    \item Uso de las predicciones: Aplicar los resultados en la planificación y toma de decisiones, alineando las acciones con las expectativas futuras y los objetivos de la organización o empresa.
\end{enumerate}
\subsection{Definición de serie temporal. Gráficos.}
Una de las técnicas para hacer inferencias sobre el futuro con base en lo ocurrido en el pasado, es el análisis de series de tiempo.

Dada una serie temporal, nuestros objetivos principales serán: describir el comportamiento de la serie, investigar el mecanismo generador de la serie temporal y buscar posibles patrones temporales que permitan sobrepasar la incertidumbre del futuro.

Se suele habkar estudio clásico o descriptivo de las series temporales para referirse a la metodología que se ha venido empleando desde la segunda mitad del siglo XIX. A pesar de sus limitaciones, los métodos clásicos se siguen usando por su sencillez y simplificación. En la década de los 60 se plantearon métodos de previsión alternativos a los clásicos que suplen varias de sus limitaciones, como son los métodos de alisado exponencial, y a principios de los 70 aparece un nuevo enfoque, debido a los estadísticos Box y Jenkins, para los modelos univariantes de series temporales.
\begin{definition}
    Llamamos \textbf{serie temporal} a un conjunto de mediciones de cierto fenómeno o experimento registradas secuencialmente en el tiempo. Estas observaciones suelen denotarse por: \[
    \{x_{t_1},x_{t_2},\dots,x_{t_n}\} \text{ con }\{t_1<t_2<\dots<t_n\}=\mathbb{T}\subset \R 
    \] donde $x_t$, representa el valor, en el instante  $t_i$, de una variable aleatoria que evoluciona con el tiempo.
\end{definition}
\begin{observation}
    Teniendo en cuenta la definición anterior, una serie temporal puede verse también como una realización (o trayectoria) de un proceso estocástico $(X_t)_{t\in \mathbb{T}}$.
\end{observation}
En muchas áreas de conocimiento, las observaciones de interés son obtenidas en instantes del tiempo. Por ejemplo, cada hora, cada día, datos mensuales, trimestrales, semetrales o bien registradas por algún aparato de medición en forma continua.
\begin{itemize}[label=\textbullet]
    \item De una manera sencilla, podemos decir que si $\mathbb{T}\subset\Z$ es un conjunto contable, se dice que la serie es de \textit{tiempo discreto}, mientras que si $T\subset \R$ es un intervalo real, se dice que la serie es de \textit{tiempo continuo}.
    \item Cuando $t_{i+1}-t_i=k$, para todo $i=1,\dots,n-1$, se dice que la serie es \textit{equiespaciada}; en caso contrario será no equiespaciada. 
\end{itemize}
En adelante, trabajaremos por comodidad con series de tiempo equiespaciadas. Por tanto, se denotarán de la siguiente forma: \[
\{x_{t_1},x_{t_2},\dots,x_{t_n}\} =\{x_{1},x_2,\dots,x_{n}\} 
\]
El primer paso en el análisis de cualquier serie de tiempo consiste en representarla gráficamente (\textbf{gráfico temporal}). En la representación gráfica de las series temporales se utilizan los ejes cartesianos. En el eje de abscisas se representa el tiempo $t$, y en el eje de ordenadas, los valores de la magnitud observada  $x_t$. Se obtiene así una nube de puntos  $(t,x_t)$ que unidos por segmentos, proporcionan una visión dinámica de la evolución de la variable a lo largo del tiempo.

Veamos algunos ejemplos de series de datos incluidos en  \textbf{\texttt{R}}. La primera, LakeHuron, contiene las medidas anuales del nivel del lago Huron (en pies), en el tramos 1875-1972. Observamos una tendencia decreciente que parece estabilizarse en el tramos final. La segunda serie de datos, AirPassengers, contiene los viajeros mensuales en aerolíneas internacionales, en el tramos 1949-1960. Observamos un patrón periódico que se repite a lo largo de la serie, así como tendencia creciente. La tercera, EuStockMarkets, contiene los precios diarios al cierre de 4 índices stock europeos (DAX, SMI, CAC y FTSE), en el tramos 1991-1998. Observamos que las cuatro series presentan un patrón de comportamiento similar, con tendencia creciente y picos de crecimiento en los mismo tramos temporales.

<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center'>>=
par(mfrow=c(1,2))
ts.plot(LakeHuron,
        gpars = list(xlab = "Year",
                     ylab = "Level LakeHuron in feet",
                     lwd = 1.5))
ts.plot(AirPassengers,
        gpars = list(xlab = "Month & Year",
                     ylab = "Thousand of passengers",
                     lwd = 1.5))
@

<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center'>>=
ts.plot(EuStockMarkets,
        gpars = list(xlab = "Time",
                     ylab = "Daily closing price",
                     col = rainbow(4),
                     lty = c(1:4)))
@

El gráfico de la serie permitirá:
\begin{enumerate}[label=\alph*)]
    \item \textit{Detectar outliers (datos atípicos):} se refiere a puntos de la serie que se escapan de lo "normal". Un outlier puede corresponderse con un error de medición, o bien con un valor real del fenómenos, el cual a su vez puede tener o no influencia destacada en el modelo propuesto. Conviene identificar los outliers para determinar si deben eliminarse, reemplazarse por otro valor, o bien mantenerlos en el análisis.

    \item \textit{Detectar estacionalidad:} la variación estacional representa un movimiento periódico de la serie de tiempo. Cada estación puede corresponder con un trimestre, un mes, un día, etc. 
    \item \textit{Detectar tendencias:} la tendencia representa el comportamiento predominante de la serie una vez eliminada la estacionalidad. Esta puede ser definida vagamente como la curva maestra que muestra el cambio de la media a lo largo del tiempo.
\end{enumerate}
\subsection{Medidas para evaluación de predicciones}
En esta sección introduciremos conceptos y alguna notación referidos al contexto de predicción con series temporales.

En primer lugar, debemos destacar que para que tenga sentido la realización de predicciones se supondrá que los datos recopilados a lo largo del tiempo se han tomado siempre en las mismas magnitudes y que la serie presenta cierta estabilidad en la estructura del fenómeno estudiado.

En el análisis clásico, las predicciones futuras se realizan teniendo en cuenta únicamente el valor de la serie para instantes pasados. Si disponemos de $T$ observaciones de la serie en estudio, la información disponible viene dada por:  \[
x_1,x_2,\dots,x_T
\] 
Dada esta información, la \textbf{predicción} de la variable en estudio en el instante siguiente $T+1$ se denotará por:  \[
\hat{x}_{T+1}
\] y en un instante posterior cualquiera $T+m$ será:  \[
\hat{x}_{T+m}
\] 
Así, el \textbf{error de predicción} vendrá dado por la diferencia entre el valor observado en la serie y la predicción: \[
e_{T+1}=x_{T+1}-\hat{x}_{T+1}
\] 
Comentar que, al igual que sucede en muchos procesos de inferencia, se pueden realizar predicciones puntuales y predicciones por intervalos de confianza para las observaciones futuras. En la mayoría de los casos, nos limitaremos a proporcionar estimaciones puntuales.

Para poder comparar diversos procedimientos de predicción, es decir, para responder a la pregunta ¿qué método es mejor para predecir esta serie?, necesitamos disponer de algún critero que nos permita evaluar las predicciones realizadas.

Como primer paso, podemos comentar la existencia de algunos métodos extremadamente básicos, denominados métodos ingenuos, que sirven de referencia en la comparación de predicciones. Es decir, las predicciones que se obtienen con cualquier procedimiento suelen compararse con las predicciones que se obtendrían con algún método ingenuo. Si el método ingenuo proporciona mejores predicciones (menores errores de predicción), esto será indicativo de que el método usado no es el adecuado y conviene probar con otro. 

Dos ejemplos de métodos ingenuos que se utilizan como referencia son:
\begin{itemize}[label=\textbullet]
    \item \textit{Método ingenuo I:} La predicción para el próximo instante es igual a la obseración actual (último valor observado). \[
    \hat{x}_{t+1}=x_t
    \]  
    \item \textit{Método ingenuo II:} La predicción para el próximo instante es igual a la observación actual más el último incremento observado. \[
    \hat{x}_{t+1}=x_t+(x_{t}-x_{t-1})
    \]  
\end{itemize}
Como segunda opción para medir la capacidad predictiva de un modelo, se suelen calcular las siguientes medidas. Si se dispone de $T$ observaciones y se han realizado predicciones desde el instante 1, las medidas son:
 \begin{itemize}[label=\textbullet]
    \item \textit{RMSE (la raíz del error cuadrático medio):} \[
    \mathrm{RMSE}=\sqrt{\dfrac{\displaystyle\sum_{t=1}^{T} e_t^{2} }{T}} 
    \] 
    \item \textit{MAE (el error absoluto medio):} \[
    \mathrm{MAE}=\dfrac{\displaystyle \sum_{t=1}^{T} |e_t|}{T}
    \]  
\end{itemize}
Evidentemente, cuanto menores sean estas medidas mayor será la capacidad predictiva del modelo. Conviene indicar la existencia de otras medidas para evaluar predicciones, además de las vistas aquí.

Por último destacaremos que para que un modelo predictivo sea adecuado no basta con que los errores de predicción sean pequeños (valores pequeños de RMSE y de MAE), sino que además pretendemos describir completamente el comportamiento sistemático de la serie (la parte determinista), y de manera que la parte que queda sin describir (los errores de predicción) deberían ser un ruido blanco.

\subsection{Componentes de una serie temporal y esquemas de integración}

El principal fin del estudio de series temporales es realizar predicciones. Un punto muy importante a tener en cuenta en este contexto es la cantidad de información en una serie temporal.

Por ejemplo, podemos considerar la serie temporal correspondiente a la hora de salida del sol (medida todos los días durante 10 años). Con la serie de observaciones pasadas podemos realizar una buena predicción para días futuros, es decir, la serie contiene mucha información relevante para predicir el futuro. Consideremos por otra parte la serie temporal correspondient al número premiado del sorteo de la lotería (medida todos los sábados durante 20 años). En este caso las observaciones pasadas no nos permiten realizar una buena predicción del fenómeno en el futuro, es decir, la serie contiene poca información relevante para predecir el futuro.

Podríamos decir que la primera serie es prácticamente determinista mientras que la segunda es totalmente aleatoria. En general, las series de tiempo contienen una parte determinista (permiten realizar predicciones) y otra parte aleatoria (perturbación impredecible).

En el \textbf{Análisis Clásico} se supone que una serie temporal, $\{x_t\}_{t=1,\dots,n} $, se puede descomponer en todas o algunas de las siguientes componentes:
\begin{itemize}[label=\textbullet]
    \item Componente de Tendencia $(T_t)$
    \item Componente de Ciclo  $(C_t)$
    \item Componente de Estacionalidad  $(S_t)$
    \item Componente Irregular  $(I_t)$

        y que la serie de tiempo se obtiene como una función de sus componentes:  \[
        x_t=f(T_t,C_t,S_t,I_t)
        \] 
        Vamos a continuación el significado de cada una de las componentes, aunque resulta complicado dar una definición exacta de cada una de ellas.
\end{itemize}
\begin{enumerate}[label=\alph*)]
    \item \textbf{Componente de Tendencia (Trend):} Es la componente que representa la evolución a lo largo de la serie, es decir, la curva maestra de evolución del fenómenos en estudio. Las variaciones de la tendencia de una serie pueden deberse a diversos motivos.
    \item \textbf{Componente de Ciclo (Cycle):} El factor cíclico refleja movimientos oscilatorios por encima y por debajo de la tendencia a largo plazo. La duración de un ciclo se suele medir desde un pico al siguiente pico de la serie suaviza (o desde un valle al siguiente valle). Se entiende que el periodo de cada ciclo es siempre superior al año. A veces se confunde con la componente estacional. La diferencia principal es que las fluctuaciones de los ciclos no tienen frecuencia fija, y suelen asociarse a aspectos económicos, mientras que las fluctuaciones de la componente estacional tienen frecuencia fija y se asocian con aspectos del calendario. 

        \textit{Observación:} En general, las componentes de tendencia y ciclo son muy difíciles de separar, de manera que suelen fusionar en una componente denominada Tendencia-Ciclo. En adelante, nosotros trabajaremos con ambas componentes fusionadas y usaremos la notación $T_t$ y hablaremos de Tendencia para referirnos a la componente Tendencia-Ciclo.
    \item \textbf{Componente de Estacionalidad (Seasonal):} La componentes estacional recoge el comportamiento periódico (repetitivo) de la serie. Las razones de la estacionalidad suelen ser tipo físico-natural (tiempo meteorológico, ciclos biológicos, etc) y de tipo institucional (vacaciones, horarios comerciales, etc.). Es decir, aparece debido al efecto del calendario.

        En general, la estacionalidad se refiere a las oscilaciones de una serie temporal que se completan dentro de un año y que se repiten en años sucesivos. Por tanto, el periodo de esta componente suele ser menor o igual a un año. Por ejemplo, si disponemos de datos mensuales podemos tener estacionalidad con periodo 12 meses (un año), si disponemos de datos trimestrales podemos tener estacionalidad con periodo 4 trimestres (un año). Si disponemos de datos diarios, podemos tener estacionalidad con periodo 7 días (una semana), si disponemos de datos cada hora, podemos tener estacionalidad con periodo 24 horas (un día), etc. El \textbf{periodo} de la componente estacional hace referencia al número de datos que conforman la parte repetitiva de la serie.

        \textbf{En Análisis Clásico, se supone que la componente estacional (patrón periódico) se repite de forma fija a lo laro de toda la serie.} Por tanto, si el periodo es $L$, diremos que la componente estacional tiene  \textbf{$L$ estaciones} que podemos denotar por $\{h_1,h_2,\dots,h_L\} $ y buscamos estimar un valor correspondiente a cada estación.

        Por ejemplo, si se trata de datos mensuales, probablemente observamos en la serie temporal un patrón repetitivo (cada 12 datos). Tendremos entonces que el periodo es $L=12$, cada mes del año sería una estación  $(h_1=enero,h_2=febrero,\dots,h_{12}=diciembre)$ y por tanto estimaremos un valor que se repetirá para todos los eneros, un valor que se repetirá para todos los febreros, ..., un valor que se repetirá para todos los diciembres. Si se trata de datos diarios (por ejemplo, ingresos por ventas de unos grandes almacenes), observaremos en la serie temporal un patrón repetitivo cada semana (cada 7 datos). Tendremos entonces que el periodo es $L=7$, cada día sería una estación  $(h_1=lunes,h_2=martes,\dots,h_7=domingo)$ y por tanto estimaremos un valor que se repetirá para todos los lunes, un valor que se repetirá para todos los martes, ..., un valor que se repetirá para todos los domingos.

    \item \textbf{Componente Irregular (Reminder):} Esta componente viene dada por las variaciones de la serie que no están recogidas en las demás componentes. La idea es que recoja la perturbación aleatoria pura de la serie, es decir, la parte impredecible de la serie. Lo ideal es que se corresponda con un \textit{ruido blanco}, de manera que toda la parte determinista de la serie quede recogida en las componentes Tendencia-Ciclo y Estacional.  
\end{enumerate}
Como ya hemos indicado, en el análisis clásico se supone que el valor que toma la serie $\{x_t\}_t $ en cada instante se puede expresar como una función del valor correspondientes a sus componentes en dicho instante: \[
x_t=f(T_t,S_t,I_t),
\] donde $T_t$ representa la TEndencia-Ciclo. Conviene señalar que una serie temporal no tienen por qué estar presentes todas las componentes.

Los esquemas más utilizados para describir la forma en que las componentes se integran para dar lugar a la serie son el esquema  \textit{aditivo} y el \textit{multiplicativo}.
\begin{itemize}[label=\textbullet]
    \item \textbf{Esquema aditivo:} Según este esquema, el valor de la serie en cualquier instante se obtiene como \textit{suma} de los valores correspondientes a sus componentes en dicho instante: \[
            \boxed{x_t=T_t+S_t+I_t}
    \]  
    \item \textbf{Esquema multiplicativo:} Según este esquema, el valor de la serie en cualquier instante se obtiene como \textit{producto} de los valores correspondientes a sus componentes en dicho instante: \[
            \boxed{x_t=T_T\times S_t\times I_t}
    \] 
    Obsérvese que al tomar logaritmo neperianos, el esquema multiplicativo se transforma en aditivo.
\end{itemize}
Aunque por su sencillez los esquemas más utilizados son los dos anteriores, también suelen utilizarse los esquemas mixtos, donde algunas componentes se integran de forma multiplicativa y otras de forma aditiva. Un ejemplo de \textbf{esquema mixto} sería: \[
x_t=T_t\times S_t+I_t
\]  
\textbf{¿Esquema aditivo o multiplicativo?} Para determinar si las componentes de la serie se combinan de forma aditiva o multiplicativa, se pueden usar varias herramientas:
\begin{enumerate}[label=\arabic*)]
    \item Inspección visual: En un esquema aditivo, la representación gráfica de la serie mostrará una componente estacional aproximadamente estable en todo momento, independientemente de los valores que tome la tendencia (nivel de la serie). Sin embargo, en un esquema multiplicativo, las desviaciones típicas aumentan cuando crece la media.
\end{enumerate}
A continuación mostramos un ejemplo de esquema multiplicativo (figura de la izquierda) y un esquema aditivo (figura de la derecha).

<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center'>>=
par(mfrow=c(1,2))
ts.plot(AirPassengers, lwd = 1.5)
ts.plot(log(AirPassengers), lwd = 1.5)
@
\subsection{Diferenciación de una serie temporal y medias móviles}
La representación gráfica de la serie temporal nos puede ayudar a decidir el tipo de tendencia de la serie, pero a veces no es tan sencillo. Un método que permite determinar el tipo de tendencia de una serie y a su vez eliminarla consiste en \textit{tomar diferencias}. 

\textbf{Diferenciación de una serie} 
\begin{definition}
    Dada una serie temporal $\{x_t\}_{t=1,\dots,n} $, se define su \textbf{diferencia de primer orden} como la serie que resulta de restar a cada observación, la observación anterior: \[
    \Delta x_t=x_{t}-x_{t-1}
    \] 
\end{definition}
De manera análoga, se puede definir la \textit{diferencia de orden 2} de la serie como: \[
\Delta^2x_t=\Delta(x_t-x_{t-1})=(x_t-x_{t-1})-(x_{t-1}-x_{t-2})=x_t-2x_{t-1}+x_{t-2}
\] así como la \textit{diferencia de orden $k$}, en general.
\begin{observation}
    Al tomar diferencias de orden uno, la serie resultante tiene un dato menos (se puede el primer dato). Si se toman diferencias de orden dos, la serie resultante tiene dos datos menos (se pierden los dos primeros). En general, al tomar diferencias de orden $k$, la serie resultante tiene  $k$ datos menos (se pierden los $k$ primeros datos).
\end{observation}
\begin{itemize}[label=\textbullet]
    \item \textbf{Si la tendencia es de tipo lineal,} ésta se puede eliminar tomando diferencias de orden uno:
        \[
        \begin{aligned}
            x_t & = b_0+b_{1}\cdot t+\varepsilon_t \text{ con $\varepsilon_t$ ruido blanco}\\
             & \Rightarrow \Delta x_t=x_t-x_{t-1}=(b_0+b_1\cdot t+\varepsilon_t)-(b_0+b_1\cdot (t-1)+\varepsilon_{t-1})\\
             & \Rightarrow\Delta x_t=b_1+(\varepsilon_t-\varepsilon_{t-1})=b_1+\tilde{\varepsilon}_t
        \end{aligned}
    \] es decir, la serie obtenida al tomar diferencias de orden uno en una constante $(b_1)$ más un ruido blanco $(\tilde{\varepsilon}_t)$.
    \item En general, \textbf{si la tendencia es de tipo polinómico} de orden $k$, ésta se puede eliminar tomando diferencias de orden  $k$.
\end{itemize}
Veamos un ejemplo del efecto de tomar diferencias de orden 1 sobre la serie de precios del índice DAX sobre la serie de pasajeros:

<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center'>>=
DAX_index <- EuStockMarkets[ , 1]
par(mfrow = c(2,2))
ts.plot(DAX_index)
ts.plot(diff(DAX_index, differences = 1))
ts.plot(AirPassengers)
ts.plot(diff(AirPassengers, differences = 1))
@
\begin{itemize}[label=\textbullet]
    \item \textbf{Si la tendencia es de tipo exponencial,} ésta se puede eliminar tomando diferencias en el logaritmo de la serie: \[
    \begin{aligned}
        x_t&= e^{b_0+b_1\cdot t}\times e^{\varepsilon_t}\Rightarrow\ln(x_t)=b_0+b_1\cdot t+\varepsilon_t   \\
           &\Rightarrow \Delta\ln(x_t)=\ln(x_t)-\ln(x_{t-1})=b_1+\tilde{\varepsilon}_t
    \end{aligned}
    \]  
    Por otra parte, la diferencia de logaritmos coincide con el logaritmo del cociente, así que: \[
    \Rightarrow\Delta\ln(x_t)=\ln(x_t)-\ln(x_{t-1})=\ln\left( \dfrac{x_t}{x_{t-1}} \right)
    \] y usando el desarrollo de Taylor para el logaritmo se tiene que: \[
    \Delta\ln(x_t)=\ln\left( \dfrac{x_t}{x_{t-1}} \right) \simeq \dfrac{x_t-x_{t-1}}{x_{t-1}}\text{ (Tasa de varianción relativo) }
    \] 
    Por tanto, si la tendencia es de tipo exponencial, las tasas de variación relativa oscilarán alrededor de un valor constante.
\end{itemize}
\textbf{Medias Móviles}

Otro método para ayudar a identificar la tendencia de una serie (análisis descriptivo de la serie), son las \textbf{medias móviles}, aunque también puede usarse para realizar predicciones y para eliminar la componente estacional de una serie.

Este método consiste en realizar, para cada instante de tiempo $t$, la media de unas cuantas observaciones. Necesitamos determinar cuántas observaciones se usarán para el cálculo de la media móvil (longitud u orden de la media móvil).

Las medias móviles eliminan las irregularidades de la serie observada, es decir, se produce un suavizado de la serie eliminando o atenuando el efecto de la componente irregular, consiguiendo así identificar la trayectoria que sigue la tendencia. Además, en cuanto mayor sea el orden de la media móvil no es tan inmediato porque, si es demasiado pequeño, puede que no elimine las irregularidades, y si es demasiado grande, podemos perder información sobre cambio de la serie (en el caso extremo tendríamos siempre unaa tendencia constante).

Un aspecto importante de este método frente al ajuste de la tendencia por mínimos cuadrados es que en este caso el análisis de la tendencia se realiza desde un enfoque local, es decir, la trayectoria de la tendencia se obtiene localmente utilizando algunas observaciones de la serie (no todas). En este sentido, este método permitirá obtener mejores predicciones a corto plazo que si ajustamos la tendencia por mínimos cuadrados. Por contra, no dispondremos de un modelo matemático que nos permita describir la serie y realizar predicciones a largo plazo.

Podemos distinguir dos tipos: medias móviles centradas y medias móviles asimétricas.

Las  \textbf{medidas móviles centradas} revisten mayor interés, se suelen utilizar para \underline{describir} la tendencia de la serie de forma más flexible y adecuada usando mínimos cuadrados.
\begin{definition}
    Dada una serie temporal $\{x_t\}_{t=1,\dots,n} $, se define su \textbf{media móvil centrada de orden} $(2p+1)$ como la serie obtenida mediante la siguiente expresión: \[
    MM(2p+1)_t=\dfrac{x_{t-p}+x_{t-p+1}+\dots+x_t+\dots+x_{t+p-1}+x_{t+p}}{2p+1}
    \] es decir, en cada instante $t$, se calcula la media usando las  $p$ observaciones anteriores, las  $p$ observaciones posteriores y la propia observación en el instante  $t$.
\end{definition}
Si el orden de la media móvil es par, entonces debemos realizar dos veces medias móviles para conseguir que sea centrada.
\begin{definition}
    Dada una serie temporal $\{x_t\}_{t=1,\dots,n} $, se define su \textbf{media móvil centrada de orden} $(2p)$ como la serie obtenida mediante la siguiente expresión: \[
    MM(2p)_t=\dfrac{MM(2p)_{t-0.5}+MM(2p)_{t+0.5}}{2}
    \] donde: \[
    MM(2p)_{t-0.5}=\dfrac{x_p+\dots+x_{t-1}+x_t+\dots+x_{t+p-1}}{2p}
    \] y \[
    MM(2p)_{t+0.5}=\dfrac{x_{t-p+1}+\dots+x_t+x_{t+1}+\dots+x_{t+p}}{2p}
    \] 
\end{definition}
\begin{observation}
    La serie obtenida por médias móviles centradas (ya sea de orden impar $2p+1$ o de orden par  $2p$) pierde los $p$ primeros valores y los  $p$ últimos. Es decir, la serie suavizada tendrá  $2p$ datos menos que la original, así que no conviene tomar el orden de la media móvil demasiado alto porque se perderían muchos datos.
\end{observation}
La siguiente figura muestra cómo aumenta el suavizado de una serie (eliminación de las irregularidades) conforme aumentamos el orden de la media móvil (en negro, la serie original; en azul, medias móviles de orden 5; en verde nedias móviles de orden 8; en rojo, medias móviles de orden 12):

<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center', message=FALSE>>=
library(forecast)
ts.plot(AirPassengers, lwd = 2)
lines(ma(AirPassengers, order = 5),
      col = "blue", lwd = 1.5)
lines(ma(AirPassengers, order = 8, centre = TRUE),
      col = "green", lwd = 1.5)
lines(ma(AirPassengers, order = 12),
      col = "red", lwd = 1.5)
@

\begin{definition}
    Dada una serie temporal $\{x_t\}_{t=1,\dots,n} $, la \textbf{media móvil asimétrica de orden $p$} se define de la siguiente forma: \[
    MMA(p)_t=\dfrac{x_{t-p+1}+\dots+x_{t-1}+x_{t}}{p}
    \] es decir, consiste en realizar la media aritmética de las $p$ últimas observaciones de la serie.
\end{definition}
Esta variante de las medias móviles se puede usar para realizar predicciones en un modelo con tendencia aproximadamente constante localmente. Suele ser más adecuado para las predicciones a corto plazo que un ajuste por mínimos cuadrados, debido a su enfoque local para la estimación de la tendencia. Es decir, si disponemos de las observaciones hasta el instante $T$, la predicción para el instante siguiente viene dada por la media de las  $p$ últimas observaciones:  \[
\hat{x}_{T+1}=\dfrac{x_{T-p+1}+\dots+x_{T-1}+x_T}{p}
\] 
En esta expresión se aprecia que todas las observaciones que intervienen en la media tienen el mismo peso. En el tema siguiente veremos que los métodos de alisado exponencial suelen dar mejores resultados porque se les da más peso a las observaciones más recientes que a las más antiguas.

\subsection{Descomposición clásica de series temporales}

El objetivo de esta sección es mostrar las técnicas clásicas para descomponer una serie temporal en sus 3 componentes fundamentales (Tendencia-Cielo, Estacional e Irregular). Para ello, es necesario determinar previamente si el esquema de integración de dichas componentes se considera aditivo, o multiplicativo.

Comenzamos con el \textbf{enfoque clásico} para extraer las componentes en un esquema aditivo, conocido como el método de la diferencia a la media móvil.
\subsubsection{Método de la diferencia a la media móvil}
El método de la diferencia a la media móvil es el método que se usa para desestacionalizar una serie que presenta un esquema aditivo: \[
x_t=T_t+S_t+I_t
\] 
Consideramos una serie temporal con el esquema anterior, presentando componente estacional, y llamaremos $L$ al periodo de la componentes estacional. En muchas ocasiones $L$ será un número par, por ejemplo  $L=12$ para datos mensuales,  $L=4$ para datos trimestrales, etc.

La idea fundamental para intentar eliminar la componentes estacional consiste en tomar medias móviles de orden  $L$ (periodo de la componente estacional). Realizamos los siguientes pasos:
 \begin{enumerate}[label=\arabic*)]
    \item \textit{Calcular la media móvil centrada de orden $L$ para la serie y determinar la componente Tendencia-Ciclo.}

        Calculando la media móvil centrada de orden $L$, donde  $L$ representa el periodo de la componente estacional, se consigue eliminar en gran parte el efecto de la componente estacional así como de la componente irregular.

        Por tanto, la serie obtenida por medias móviles servirá como estimación de la componente Tendencia-Ciclo  $(T_t)$:  \[
        T_t=MM(L)_t
        \] 
        Recordar que si $L$ es par, la media móvil centrada se obtiene realizando el promedio de dos series de medias móviles. Además, si  $L$ es par, la serie obtenida por medias móviles tiene  $L$ datos menos que la serie original. Por ejemplo, si la serie original se refiere a datos mensuales, tendremos un datos menos cada mes. Y si  $L$ es impar, la serie obtenida por medias móviles tiene  $L-1$ datos menos que la serie original.
    \item  \textit{Obtener los índices brutos de variación estacional (IBVE).}

        Como el esquema es aditivo: \[
        x_t=T_t+S_t+I_t
        \] una estimación de las componentes Estacional e Irregular conjuntamente viene dada por: \[
        \widehat{S_t+I_t}=x_t-T_t=x_t-MM(L)_t
        \] es decir, hay que restar a la serie original la serie obtenida mediante medias móviles de orden $L$ (de ahí el nombre de método de la diferencia a la media móvil).

        Cada uno de los valores obtenidos mediante la diferencia anterior se denomina índice bruto de variación estacional en el instante  $t$:  \[
            (IBVE)_t=\widehat{S_t+I_t}=x_t-MM(L)_t
        \] donde el valificativo de "bruto" se debe a que el índice estacional está contaminado por la componente irregular.

    \item \textit{Obtener los índices de variación estacional no normalizados (IVENN).}

        Con el fin de eliminar la componente irregular de los índices anteriores, calcularemos la media de los índices para cada estación. Si disponemos de información correspondiente a $K$ periodos completos y un total de  $N$ observaciones, entonces se cumple que:  \[
        N=L\cdot K
        \] 
        Por ejemplo, pensemos en datos mensuales y un total de 5 años completos, es decir, $12\cdot 5=60$ datos. Como ya hemos indicado, al realizar medias móviles se pierden $L$ datos (uno por cada estación, si $L$ es par), de manera que para cada estación dispondríamos de exactamente $K-1$ datos (en lugar de $K$).

        Llamaremos índice de variación estacional no normalizado al promedio de los IBVE para cada estación $h$:  \[
        (IVENN)_h=\dfrac{\sum_{\{t:h(t)=h\}} (IBVE)_t}{K-1}\quad h=h_1,h_2,\dots,h_L
        \] donde $\{t:h(t)=h\} $ denota el conjunto de instantes de tiempo que se corresponden con la estación $h$. Si  $K$ no es muy pequeño, con el promedio conseguimos atenuar enormemente el efecto de la componente irregular, de manera que estos nuevos índices contienen información de la componente estacional pero no de la componente irregular.

        Podemos poner una expresión más general para obtener los índices de variación estacional no normalizados, que contemple la posibilidad de que la serie tenga periodos incompletos o bien que  $L$ sea impar, en cuyo caso, el número de datos $(IBVE)_t$ disponible para cada estación puede ser diferente. Denotemos por  $K_h$ al número de datos  $(IBVE)_t$ disponible para cada estación  $h$, entonces:  \[
            (IVENN)_h=\dfrac{\sum_{\{t:h(t)=h\}}(IBVE)_t }{K_h}\quad h=h_1,h_2,\dots,h_L
        \] 
    \item \textit{Obtener los índices de variación estacional normalizados (IVE) y determinar la componente Estacional}

        Si una serie no tiene componente estacional, en un modelo aditivo se tendría que $S_t\equiv 0$. Por otra parte, es razonable suponer que la componente estacional no debe afectar al nivel de la serie, de manera que en el modelo aditivo la media de la componente estacional debería ser 0.

        Por tanto, definimos los índices de variación estacional normalizados para cada estación $h$ como  \[
            (IVE)_h=(IVENN)_h=\dfrac{\sum_{h\in \{h_1,\dots,h_L\} }(IVENN)_h}{L}
        \] aunque existen otras formas de normalizar los índices de variación estacional.

        Estos índices suponen una \textbf{estimación de la componente estacional} de la serie para cada estación $h$. Es decir, en este paso determinamos la componente estacional para cada instante de tiempo  $t$, haciéndola coincidir con el índice de variación estacional para la estación,  $h(t)$, correpondiente al instante $t$:  \[
        S_t=(IVE)_{h(t)}
        \] 

    \item \textit{Desestacionalizar la serie.} 

        En el modelo aditivo, la desestacionalización de la serie se consigue restando a la serie original los índices de variación estacional: \[
        D_t=x_t-S_t=x_t-(IVE)_{h(t)}\quad\text{(serie desestacionalizada)}
        \] 
    \item \textit{Determinar la componente Irregular.}

        Una vez extraidas la componente Estacional $(S_t)$ y la Tendencia-Ciclo  $(T_t)$, la componente Irregular  $(I_t)$ se obtiene de forma inmediata mediante:  \[
        I-t=x_t-T_t-S_t
        \] 
        La situación ideal sería que dicha componente irregular se comportara como un ruido blanco.
\end{enumerate}
A continuación, mostramos el \textbf{enfoque clásico} para extraer las componentes de una serie temporal si el esquema es multiplicativo.

\subsubsection{Método de la razón a la media móvil}

El método de la razón a la media móvil es el método que se usa para desestacionalizar una serie que presenta un esquema multiplicativo: \[
x_t=T_t\times S_t\times I_t
\] 
Los pasos para desestacionalizar la serie y extraer las componentes son similares al caso aditivo, pero realizando cocientes en lugar de diferencias:
\begin{enumerate}[label=\arabic*)]
    \item \textit{Calcular la media móvil centrada de orden $L$ para la serie y determinar la componente Tendencia-Ciclo.}
        \[
        T_t=MM(L)_t
        \] 
    \item \textit{Obtener los índices brutos de variación estacional (IBVE).}

        Como el esquema es multiplicativo, una estimación de las componentes Estacional e Irregular conjuntamente viene dada por: \[
        \widehat{S_t\times I_t}=\dfrac{x_t}{\hat{T}_t}=\dfrac{x_t}{MM(L)_t}.
        \] 
    \item \textit{Obtener los índices de variación estacional no normalizados (IVENN).}

        Llamaremos índice de variación estacional no normalizado al promedio de los $IBVE$ para cada estación  $h$. Denotemos por  $K_h$ al número de datos  $(IBVE)_t$ disponible para cada estación  $h$, entonces: \[
            (IVENN)_h=\dfrac{\sum_{\{t:h(t)=h\} }(IBVE)_t}{K_h}\quad h=h_1,h_2,\dots,h_L
        \] 
    \item \textit{Obtener los índices de variación estacional normalizados (IVE) y determinar la componente Estacional}

        Si una serie no tiene componente estacional, en un modelo multiplicativo se tendría que $S_t\equiv 1$. Por otra parte, es razonable suponer que la componente estacional no debe afectar al nivel de la serie, de manera que en el modelo multiplicativo la media de la componente estacional debería ser 1.

        Sin embargo, los índices calculados en el apartado anterior pueden no tener media uno. Por tanto, definimos los índices de variación estacional normalizados para cada estación  $h$ como:  \[
            (IVE)_h=\dfrac{(IVENN)_h}{\dfrac{\sum_{h\in \{h_1,\dots,h_L\} }(IVENN)_h}{L}}
        \] los cuales suponen una \textbf{estimación de la componente estacional} de la serie para cada estación $h$. Es decir, en este paso determinamos la componente estacional para cada instante de tiempo  $t$, haciéndola coincidir con el índice de variación estacional para la estación, $h(t)$, correspondiente al instante $t$:  \[
        S_t=(IVE)_{h(t)}
        \]  
    \item \textit{Desestacionalizar la serie.}

        En el modelo multiplicativo, la desestacionalización de la serie se consigue dividiendo la serie por los índices de variación estacional: \[
        D_t=\dfrac{x_t}{(IVE)_{h(t)}}
        \] 
    \item \textit{Determinar la componente Irregular.}

        Una vez extraidas la componente estacional $S_t$, y la Tendencia  $T_t$, la componente Irregular o restante se obtiene de forma inmediata mediante:  \[
        I_t=\dfrac{x_t}{T_t\times S_t}
        \] 
        La situación ideal sería que dicha componente se comportara como un ruido gaussiano de media 1, o bien como la exponencial de un ruido gaussiano de media cero.
\end{enumerate}
A modo de ejemplo, a continuación mostramos una serie temporal y las componentes que resultan con la \textbf{descomposición clásica:}


<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center', message=FALSE>>=
plot(decompose(AirPassengers, type = 'multiplicative'))
@

\textbf{Nota:} Podemos comprobar que la componente estacional se mantiene estable a lo largo del tiempo. Es decir, todos los meses de enero toman el mismo valor independientemente del año. Lo mismo sucede con los febreros, marzos, ..., diciembres. Esta situación es característica para la descomposición clásica.

\subsection{Predicciones con Análisis Clásico y limitaciones}

En el enfoque clásico, la forma de realizar predicciones se basa en la descomposición de la serie en sus componentes fundamentales (tendencia, estacionalidad e irregular). Extraídas las componentes, se predice cada una de ellas y la predicción de la serie original se obtiene combinando dichas predicciones según se trate de un esquema aditivo o multiplicativo.

\textbf{¿Cómo realizar predicciones de la componente irregular $I_t$?}

Como se trata de la parte aleatoria de la serie, las predicciones de la componente irregular valdrán cero en el esquema aditivo y uno en el multiplicativo.

Es decir, para todo instante $t$, tendremos que la predicción de la componente irregular en dicho instante es:  \[
\hat{I}_t=0\text{ (esquema aditivo), }\hat{I}_t=1\text{ (esquema multiplicativo) }
\] 
¿Cómo realizar predicciones de la Componente Estacional $S_t$?

Bastará con repetir el valor obtenido para cada estación. Por ejemplo, si tenemos datos mensuales y la componente estacional extraída asigna un valor de 50 a los eneros, entonces la predicción de la componente estacional será siempre de 50 para los futuros eneros. De la misma forma se realizaría la predicción para el resto de meses, pues el enfoque clásico considera componente estacional estable.

Si la serie original tiene periodo $L$ y disponemos de observaciones hasta el instante  $T$, entonces la predicción de la componente estacional en el instante  $T+m$ es:  \[
\hat{S}_{T+m}=S_{T+m-L}\quad m=1,2,\dots,L
\] donde $S_{T+m-L}$ representa el valor de la componente estacional en el instante $T+m-L$, es decir, el valor del  $IVE$ en la estación que corresponde a dicho instante.

 \textbf{¿Cómo realizar predicciones de la componente Tendencia-Ciclo $T_t$?}

 La componente tendencia puede modelizarse con cualquier método para serie sin estacionalidad. Por ejemplo, realizando un ajuste por mínimos cuadrados como predicto (predictores) el tiempo o potencias del mismo. El modelo obtenido para la tendencia usando mínimos cuadrados es adecuado para representar el comportamiento de la serie y captar los aspectos más permanentes del fenómeno estudiado (predicciones a medio o largo plazo). Sin embargo, no es aconsejable para las predicciones a corto plazo.

 Por ejemplo, si la Tendencia es lineal respecto al tiempo: \[
 T_t=b_0+b_1\cdot t,
 \] podemos estimar la ecuación de dicha recta usando regresión lineal simple. Por tanto, en este caso las predicciones de la tendencia en cualquier instante $t$, se obtendrán mediante:  \[
 \hat{T}_t=\hat{b}_0+\hat{b}_1\cdot t
 \] 
 Y si la Tendencia es polinómica: \[
 \hat{T}_t=\hat{b}_0+\hat{b}_1\cdot t+\hat{b}_2\cdot t^2+\dots+\hat{b}_k\cdot t^k
 \] también podemos estimar los coeficientes del modelo usando regresión lineal simple.

 Obsérvese que se trata de un \textit{enfoque global} del análisis de la tendencia, el cual permite obtener un modelo matemático que modeliza la tendencia de la serie usando \underline{todas} las observaciones de la serie, y además todas con el \underline{mismo peso}.   

 Los procedimientos adecuados para obtener la tendencia desde un \textit{enfoque local} que permita realizar predicciones adecuadas a corto plazo son, por ejemplo, el método de las medias móviles asimétricas o los métodos de alisado exponencial, que veremos en un tema posterior.

 \textbf{¿Cómo realizar predicciones de la serie original?} 

 Si disponemos de $T$ observaciones de la serie y queremos realizar predicciones para los  $L$ instantes siguiente ($L$ es el periodo), en el caso de esquema aditivo tendremos: \[
 \hat{x}_{T+m}=\hat{T}_{T+m}+\hat{S}_{T+m}\quad m=1,2,\dots,L
 \] y en el caso de esquema multiplicativo tendremos: \[
 \hat{x}_{T+m}=\hat{T}_{T+m}\times \hat{S}_{T+m}\quad m=1,2,\dots,L
 \] 
 \textbf{Limitaciones del Análisis Clásico}

 El análisis clásico de series temporales tiene dos usos principalmente:
 \begin{itemize}[label=\textbullet]
     \item \textit{Describir el comportamiento de la serie temporal} (análisis descriptivo), haciendo uso por ejemplo de la descomposición de la serie en las componentes Tendencia, Estacionalidad e Irregular.
     \item \textit{Realizar predicciones a medio o largo plazo}. 
 \end{itemize}
 Como método descriptivo sigue siendo interesante su uso gracias a la sencillez de los métodos expuestos. Del mismo modo, cuando sólo nos interesa estudiar el comportamiento futuro de la serie a largo plazo, es decir, estudiar cómo evolucionaría la serie a grandes rasgos, también interesa emplear un análisis clásico.

 Sin embargo, el enfoque global de los métodos clásicos impide realizar predicciones adecuadas a corto plazo, siendo ésta la principal limitación de un análisis clásico. Además, los métodos clásicos proporcionan demasiada rigidez al modelo, perdiendo en ocasiones información relevante.

 Para suplir las carencias del método clásico, se propusieron nuevos métodos como la descomposición STL, que veremos a continuación, o los métodos de alisado exponencial, que veremos en el tema posterior.

\subsection{La descomposición STL}

El método STL (\textit{Seasonal and Trend decomposition using LOESS}) es una técnica alternativa a la descomposición clásica utilizada para descomponer una serie temporal en sus componentes básicas: tendencia, estacionalidad e irregular. Se basa en el suavizado de datos mediante LOESS (\textit{locally estimated scatterplot smoothing}), que permite la obtención de las componentes forma más versátil y flexible.

Mientras que la descomposición clásica considera que la componente estacional es completamente estable, la descomposición STL permite que la componente estacional varíe a lo largo del tiempo. La diferencia fundamental radica en el proceso de desestacionalización de la serie: mientras que el enfoque clásico usa medias móviles, el STL usa el suavizado local LOESS.

\textbf{Importante:} El método STL considera que las componentes de la serie se combinan siguiendo un \textbf{esquema aditivo}. En el caso de esquema multiplicativo, primero debe realizarse una transformación logarítmica para convertirlo en esquema aditivo.

\textbf{¿En qué consiste el método LOESS?}

LOESS realiza agresiones locales a lo largo de los datos. En cada punto $x_{i}$ de la serie, se ajusta un polinomio (generalmente de primer o segundo grado) utilizando solo los datos cercanos a ese punto. Los puntos cercanos se definen por una ventana de vecindad, cuyo tamaño está determinado por un parámetro de suavizado. Este parámetro puede ser una proporción del total de puntos (ancho de banda o bandwitdth). Los puntos dentro de la ventana de vecindad se ponderan de acuerdo con su distancia al punto $x_i$. Los puntos más cercanos tienen mayor peso en la estimación del polinomio local que los puntos más lejanos. Para cada punto  $x_{i}$ de la serie, se calcula un valor ajustado $\hat{x}$ mediante la regresión local ponderada. Este proceso se repite para cada punto de la serie, resultando en una curva suavizada.

LOESS es una técnica eficaz para suavizar los datos y detectar tendencias locales sin imponer una estructura global rígida. Es especialmente útil para datos que no siguen una forma predefinida y permite capturar patrones locales mediante ajustes flexibles y ponderados.

A continuación mostramos un ejemplo del método LOESS, así como el efecto del parámetro de suavizado. Para ello usaremos el conjunto de datos "economics" del paquete \textbf{\texttt{ggplot2}}, y suavizaremos la serie correspondiente al tiempo de desempleo (variable \textbf{\texttt{uempmed}}, que representa la mediana del número de días sin empleo). Observamos que la serie original (en negro) contiene numerosas irregularidades, que se suavizan al aplicar LOESS con parámetros de suavizado 10\% (en azul), 30\% (en verde) y 50\% (en rojo). Indicar que si la serie original tiene por ejemplo 100 observaciones y se usa un suavizado del 50\% (parámetro \textbf{\texttt{span=0.5}} ), entonces para cada punto $x_{i}$ de la serie, la ventana de vecindad se construye con 25 datos a la izquierda de $x_{i}$ y otros 25 datos a la derecha de $x_{i}$.

<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center', message=FALSE>>=
library(ggplot2)
datos <- economics
datos$index <- 1:nrow(datos)
loess10 <- loess(uempmed ~ index, data=datos, span = 0.10)
loess30 <- loess(uempmed ~ index, data=datos, span = 0.30)
loess50 <- loess(uempmed ~ index, data=datos, span = 0.50)

plot(datos$uempmed, x=datos$date, type="l", main="Loess Smoothing",
     xlab="Date", ylab="Unemployment (Median)", lwd = 2)
lines(predict(loess10), x=datos$date, col="blue", lwd = 2)
lines(predict(loess30), x=datos$date, col="green", lwd = 2)
lines(predict(loess50), x=datos$date, col="red", lwd = 2)
@

Y para valores altos del parámetro de suavizado tendremos un suavizado global en lugar de local (obsérvese que la curva marrón  se corresponde con la ecuación de una parábola que ajusta globalmente los datos de la serie):

<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center'>>=
loess100 <- loess(uempmed ~ index, data = datos, span = 1)
loess200 <- loess(uempmed ~ index, data = datos, span = 2)
plot(datos$uempmed, x=datos$date, type="l", main="Loess Smoothing",
     xlab="Date", ylab="Unemployment (Median)", lwd = 2)
lines(predict(loess100), x=datos$date, col="orange", lwd = 2)
lines(predict(loess200), x=datos$date, col="brown", lwd = 2)
@

\textbf{Resumen de las etapas en la descomposición STL}
\begin{enumerate}[label=\arabic*)]
    \item Realizar un suavizado de la serie original mediante LOESS con un acho de banda grande, con el fin de captar las variaciones a largo plazo (eliminando así las fluctuaciones debidas a la componente estacional). El resultado de este suavizado nos dará una primera estimación de la Tendencia-Ciclo $(T_{t})$.
\end{enumerate}
En \textbf{\texttt{R}}, se puede fijar el parámetro de ancho de banda correspondiente a la tendencia (\textbf{\texttt{t.window}} ) o dejar que tome un valor por defecto. En \textbf{\texttt{R}}, dicho parámetro además debe tomar un valor impar y representa el número de observaciones consecutivas usadas para estimar la tendencia. Valores pequeños permiten cambios más rápidos.
\begin{enumerate}[label=\arabic*), start=2]
    \item Restar a la serie original la Tendencia obtenida en la etapa anterior. Es decir, hacemos $x_t-T_t$, para conseguir una serie temporal con tendencia constante.
    \item Dividir la serie de la etapa anterior (sin tendencia) en subseries: Supongamos que la serie original tiene estacionalidad de periodo  $L$, entonces hay que dividir la serie de la etapa anterior en  $L$ subseries, una para cada estación. Por ejemplo, para datos mensuales durante varios años, tendremos que  $L=12$. Esta etapa implica considerar una serie para cada estación, es decir, una serie con los datos de enero, otra con los datos de febrero, ..., y otra con los datos de diciembre.
    \item Obtener una estimación de la componente Estacional  $(S_t)$ mediante suavizado LOESS: En esta etapa se fija el valor del parámetro  \textbf{\texttt{s.window}} correspondiente al ancho de banda del suavizado para la estacionalidad. En \textbf{\texttt{R}}, dicho parámetro debe tomar un valor impar y no tiene valor por defecto. Para cada subserie de la etapa anterior, se aplica el suavizado LOESS y \textbf{\texttt{s.window}} representa el número de periodos (años) consecutivos usados en la estimación de cada valor de la componentes estacional. Valores pequeños permiten cambios más rápidos. Y en el caso de usar todos los periodos se considera estacionalidad estable (igual que en un enfoque clásico). Al igual que en la descomposición clásica, las estimaciones resultantes se normalizan para conseguir que la media de cada periodo (año) completo sea cero (recordar que se supone esquema aditivo).
    \item Obtener la componente Irregular: Para ello bastará restar a la serie original, las estimaciones obtenidas para la estacionalidad y la tendencia $(I_t=x_t-T_t-S_t)$.
\end{enumerate}
\textbf{Nota:} La extracción de las componentes puede ser mejorada siguiendo un ciclo iterativo como el siguiente.

Con la tendencia inicial $T_t$ y la estacionalidad inicial  $S_t$ estimadas, se sigue un ciclo iterativo para ajustar y mejorar las estimaciones:
 \begin{enumerate}[label=\alph*)]
    \item Ajuste de la Tendencia: eliminar el efecto de la estacionalidad de la serie original (serie desestacionalizada) \[
    x_t-S_t
    \] y obtener una nueva estimación de la componente Tendencia-Ciclo (nueva $T_t$) mediante un nuevo suavizado LOESS sobre la serie desestacionalizada. En este proceso se requiere nuevamente del parámetro \textbf{\texttt{t.window}} correspondiente al ancho de banda del suavizado para capturar la tendencia subyacente.
    \item Ajuste de la Estacionalidad: Se elimina la tendencia ajustada de la serie $$x_t-T_t$$ 
        Las subseries estacionales se suavizan de nuevo para recalcular $S_t$, teniendo en cuenta nuevamente un parámetro del ancho de banda para la estacionalidad (\textbf{\texttt{s.window}}).
    \item Ajuste de la componente Irregular: Se recalcula como \[
    I_t=x_t-T_t-S_t
    \] 
\end{enumerate}
Este ciclo se repite varias veces para mejorar la precisión de las componentes.

Veamos como ejemplo la descomposición STL sobre la serie \textbf{\texttt{AirPassengers}}  incluida en \textbf{\texttt{R}}.

<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center'>>=
serie_pasajeros <- AirPassengers
ts.plot(serie_pasajeros, lwd = 2)
@

Observamos esquema multiplicativo, así que transformamos los datos para conseguir esquema aditivo, necesario para descomposición STL.

<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center'>>=
serie_aditiva <- log(serie_pasajeros)
ts.plot(serie_aditiva, lwd = 2)
@

Realizando ahora la descomposición STL sobre la serie aditiva, fijando \textbf{\texttt{s.window}} (ancho de banda de la estacionalidad):

<<fig=TRUE, fig.width=7, fig.height=5, out.width='0.7\\textwidth', fig.align='center'>>=
modelo_STL <- stl(serie_aditiva, s.window = 7)

plot(modelo_STL)
@

\textbf{Nota:} Obsérvese que el aspecto de la componente estacional varía a lo largo del tiempo, a diferencia de lo que sucede en el enfoque clásico.
