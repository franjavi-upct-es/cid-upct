\begin{center}
    \textbf{\Large Hoja 6: Modelos ARIMA} 
\end{center}
\textbf{\large Cuestiones Teóricas}
\begin{enumerate}[label=\color{red}\textbf{\arabic*)}]
    \item \lb{¿Qué es la estacionaeridad en una serie temporal?}

        La \textbf{estacionariedad} es una propiedad fundamental que se exige al proceso estocástico que genera una serie temporal para poder modelizarla y realizar predicciones.

        Se define mediante las siguientes características principales:
        \begin{enumerate}[label=\textbf{\arabic*)}]
            \item \textbf{Definición Formal (Estacionariedad Débil)}

                Un proceso estocástico $\{X_t\}_{t=1,2,\dots}$ es estacionario en sentido débil si cumple dos condiciones matemáticas:
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Media constante:} La función de medias es invariable a lo largo del tiempo. $$\mu_X(t)=\mu\text{ (para cierta constante $\mu$). }$$ 
                    \item \textbf{Convarianza estable:} La función de covarianzas entre dos momentos del tiempo no depende del instante específico $t$, sino únicamente de la distancia temporal (retardo o \textit{lag}) entre ellos. \[
                    C_X(t,t+k)=\gamma_k\text{ (donde $\gamma_k$ solo depende de $k$). }
                    \]  
                \end{itemize}
            \item \textbf{Implicaciones Prácticas}

                Cuando un proceso cumple lo anterior, se derivan dos consecuencias clave para el análisis de datos:
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Varianza constante:} La dispersión de los datos se mantiene estable en el tiempo $(\sigma_X(t)=\sigma)$.
                    \item \textbf{Correlación dependiente del retardo:} La correlación entre variables solo varía en función del desfase temporal $k$, lo que permite el uso del  \textbf{correlograma} para su análisis. 
                \end{itemize}
        \end{enumerate}
    \item \lb{¿Por qué es importante que una serie sea estacionaria para la modelización ARIMA?} 

        La importancia de la estacionaeridad en la modelización ARIMA radica fundamentalmente en la necesidad de poder \textbf{inferir el comportamiento futuro a partir de los datos pasados}, dado que habitualmente trabajamos con una única muestra de datos. 
        \begin{enumerate}
            \item \textbf{El problema de la "Única Realización":} En la práctica, solemos tener una limitación importante: la serie observada es la \textbf{única realización accesible} del proceso (por ejemplo, solo hay una historia real del PIB o de las ventas de una empresa). No disponemos de múltiples universos paralelos (múltiples realizaciones) para calcular promedios y distribuciones en cada instante de tiempo.
            \item \textbf{Estabilidad para la Predicción:} Al asumir que el proceso es estacionario (y ergódico), garantizamos dos cosas esenciales para que el modelo matemático funciones:
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Representatividad:} Los datos observados en un periodo de tiempo son representativos del comportamiento probabilístico general del proceso.
                    \item \textbf{Validez Futura:} El conocimiento obtenido de los datos actuales sigue siendo útil para comprender el comportamiento en el futuro. Si la media o la varianza cambiaran aleatoriamente con el tiempo si un patrón estable, lo aprendido en el pasado no serviría para predecir el futuro. 
                \end{itemize}
            \item \textbf{Posibilidad de Estimación Estadística:} La estacionariedad implica que parámetros clave como la media $(\mu)$ y la varianza $(\sigma^2)$ son constantes. Esto permite utilizar la totalidad de los datos de la serie para estimar estos valores únicos. Si no fuera estacionaria, la media y la varianza serían distintas en cada instante $t$, y sería imposible estimarlas con una sola observación por instante temporal.
        \end{enumerate}
    \item \lb{¿Qué es la diferencia en el contexto de las series temporales y cómo ayuda a estabilidar una serie?} 

        Es una transformación matemática aplicada a una serie temporal no estacionaria para convertirla en estacionaria, estabilizando principalmente su \textbf{media}.

        La operación consite en restar a cada valor de la serie su valor inmediatamente anterior. Matemáticamente, el proceso de "primera diferencia" se define como: \[
        Z_t=X_tX_{t-1}
        \] 
        Esta operación se denota habitualmente con el operador nabla $(\nabla)$, tal que $\nabla X_t=X_t-X_{t-1}$.

        El objetivo de tomar diferencias es corregir la \textbf{no estacionariedad en media}, es decir, eliminar tendencias para conseguir que la serie oscile alrededor de un nivel constante.

        Según el tipo de tendencia observada se aplicará el siguiente órden de diferencia:
        \begin{itemize}[label=\textbullet]
            \item \textbf{Diferencia de orden 1 $(d=1)$:} Se utiliza cuando la serie presenta una \textbf{tendencia lineal}. Al aplicar una vez el operador diferencia, se consigue un nivel constante. Un ejemplo clásico es el \textit{paseo aleatorio}, que no es estacionario, pero su primera diferencia $(\epsilon_t)$ sí lo es.
            \item \textbf{Diferencia de orden 2 $(d=2)$:} Se aplcia si la tendencia es \textbf{cuadrática}. 
        \end{itemize}
    \item \lb{Explica la diferencia entre diferenciación de primer orden, diferenciación de segundo orden y diferencia estacional.} 

        \begin{enumerate}
            \item \textbf{Diferenciación de Primer Orden $(d=1)$} 

                Es la transformación más común y consiste en restar a cada valor de la serie el valor del instante inmediatamente anterior.
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Objetivo:} Se utiliza para eliminar \textbf{tendencias lineales} (cuando la serie crece o decrece a un ritmo constante) y estabilizar a nivel de la serie.
                    \item \textbf{Fórmula:} $\nabla X_t=X_t-X_{t-1}$.
                \end{itemize}
            \item \textbf{Diferenciación de Segundo Orden $(d=2)$} 

                Consiste en aplicar el operador diferencia dos veces consecutivas. Es decir, se calcula la diferencia de la serie que ya ha sido diferenciada una vez.
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Objetivo:} Se aplica cuando la tendencia de la serie es \textbf{cuadrática} (la serie crece o decrece de forma acelerada o curva, no lineal).
                    \item \textbf{Fórmula:} Matemáticamente equivale a $(1-B)^2X_t$. 
                \end{itemize}
            \item \textbf{Diferencia Estacional $(D)$} 

                Esta diferencia se utiliza en el contexto de los modelos \textbf{SARIMA} (ARIMA estacional).
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Objetivo:} Eliminar patrones que se repiten en intervalos regulares de tiempo (ciclos estacionales), como variaciones mensuales, trimestrales o anuales.
                    \item \textbf{Funcionamiento:} En lugar de restar el valor inmediatamente anterior $(t-1)$, se resta el valor correspondiente al mismo periodo de la temporada anterior  $(t-L)$.
                    \item \textbf{Parámetros:} Se denota con la letra $D$ en la notación  $SARIMA(p,d,q)(P,D,Q)_L$, donde $K$ es la periodicidad (por ejemplo, $L=12$ para datos mensuales).
                \end{itemize}
        \end{enumerate}
    \item \lb{¿Cuál es la expresión formal para un modelo $AR(p)$?} 

        La expresión formal que define un modelo Autorregresivo de orden $p$, denotado como  $AR(p)$, es la siguiente:  \[
        X_t=\delta+a_1X_{t-1}+a_2X_{t-2}+\dots+a_pX_{t-p}+\epsilon_t
        \] 
        Donde los componentes se definen de la siguiente manera:
        \begin{itemize}[label=\textbullet]
            \item $X_t$: Es el valor actual del proceso en el instante  $t$.
            \item $X_{t-1},\dots,X_{t-p}$: Son los valores pasados del propio proceso (retardos).
            \item $a_1,\dots,a_p$: Son los coeficientes o parámetros del modelo que ponderan la influencia del pasado.
            \item $\delta$: Representa una constante (término independiente).
            \item $\epsilon_t$: Es la perturbación aleatoria, que se comporta como un \textbf{ruido blanco gaussiano}; es decir, variables independientes idénticamente distribuidas (i.i.d.) con distribución Normal $\mathcal{N}(0,\sigma^2)$. 
        \end{itemize}
    \item \lb{¿Qué diferencia hay entre correlaciones simples y correlaciones parciales?} 

        La diferencia radica en cómo miden la dependencia entre observaciones separadas por un tiempo determinado (retardo $k$).
        \begin{enumerate}
            \item \textbf{Correlación Simple (ACF)} 

                La función de autocorrelación simple (o simplemente correlograma) mide la \textbf{relación total} entre dos observaciones separadas por $k$ periodos ($X_t$ y  $X_{t-k}$), sin importar qué sucede en medio.
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Qué captura:} Incluye tanto la influencia directa como la indirecta que se transmite a través de los periodos intermedios.
                    \item \textbf{Comportamiento:} En procesos autorregresivos, muestra una mezcla de decrecimientos exponenciales y sinusoidales que no se cortan abruptamente, lo que dificulta identificar el orden del modelo solo con esta gráfica. 
                \end{itemize}
            \item \textbf{Correlación Parcial (PACF)}

                La función de autocorrelación parcial mide la \textbf{relación directa} o "pura" entre dos observaciones separadas por $k$ periodos,  \textbf{eliminando el efecto} de los valores intermedios $(X_{t-1},\dots,X_{t-k+1})$.
                \begin{itemize}[label=\textbullet]
                    \item \textbf{El concepto clave:} Se interpreta como la correlación entre $X_t$ y  $X_{t-k}$ una vez que se ha limpiado la influencia de los retardos que están entre ellos.
                    \item \textbf{Utilidad:} Es fundamental para identificar el orden $p$ de un proceso autorregresivo  $AR(p)$, ya que los coeficientes serán significativos hasta el retardo $p$ y nulos después.
                \end{itemize}
        \end{enumerate}
    \item \lb{¿Cómo se identifica un ruido blanco gaussiano?} 

        Un \textbf{ruido blanco gaussiano} es el bloque básico de construcción de los modelos estocásticos y representa un proceso "puramente aleatorio".

        Para identificarlo, se debe verificar que cumple las tres condiciones fundamentales, las cuales se pueden comprobar visual y estadísticamente:
        \begin{itemize}[label=\textbullet]
            \item \textbf{Definición Estadística Formal}

                Un proceso $(\epsilon_t)_{t=1,2,\dots,n}$ es ruido blanco gaussiano si cumple rigurosamente con:
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Media Cero:} $E(\epsilon_t)=0$.
                    \item \textbf{Varianza Constante:} $\mathrm{Var}(\epsilon)=\sigma^2$ (Homocedasticidad).
                    \item \textbf{Independencia:} Las variables son independientes entre sí. Conocer el pasado no ayuda a predecir el futuro.
                    \item \textbf{Normalidad:} Sigue una distribución Normal $N(0,\sigma^2)$.
                \end{itemize}
        \end{itemize}
    \item \lb{¿Cómo se identifica un modelo $AR(p)$?} 

        La identificación del orden $p$ de un modelo autorregresivo  $AR(p)$ se basa fundamentalmente en el análisis del \textbf{correlograma parcial} (PACF), aunque el comportamiento del correlograma simple (ACF) también proporciona información complementaria.

        Pautas específicas para su identificación:
        \begin{enumerate}
            \item \textbf{El Indicador Clave: Correlograma Parcial (PACF)}

                Es la herramienta principal para determinar el orden $p$.
                 \begin{itemize}[label=\textbullet]
                    \item \textbf{Regla de corte:} En un proceso $AR(p)$, los primeros $p$ coeficientes de autocorrelación parcial son distintos de cero, y para retardos superiores a  $p(k>p)$ se vuelven nulos.
                    \item \textbf{Identificación visual:} Se debe observar el gráfico de autocorrelación parcial y contar cuántas barras (lags) sobresalen significativamente de las bandas de confianza (son distintas de cero) antes de que la función se "corte" o caiga a cero. Ese número de barras significativas indica el orden $p$. 
                \end{itemize}
            \item \textbf{El comportamiento Complementario: Correlograma Simple (ACF)} 

                El correlograma simple \textbf{no sirve} para identificar el orden exacto directamente, porque no se corta abruptamente.
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Comportamiento:} Muestra una estructura de \textbf{decrecimiento infinito}. Las correlaciones se amortiguan o decaen gradualmente a medida que aumenta el retardo.
                    \item \textbf{Forma:} Generalmente se observa como una mezcla de decrecimientos exponenciales y/o sinusoidales (ondas) que van desapareciendo poco a poco. 
                \end{itemize}
        \end{enumerate}
    \item \lb{Para un modelo $AR(p)$, ¿cuándo tendremos que se trata de un proceso estacionario?} 
        Para que un modelo autorregresivo de orden $p$, denotado como  $AR(p)$, sea estacionario, debe cumplirse una \textbf{condición necesaria y suficiente} relacionada con su ecuación matemática.

        La condición es la siguiente:

        \textbf{Las raíces del polinomio característico deben estar fuera del círculo unidad del plano complejo.}

        \textbf{Desglose de la condición:}
        \begin{enumerate}
            \item \textbf{El Polinomio Característico:} Si expresamos el proceso $AR(p)$ utilizando el operador de retardos $B$:  \[
                    (1-a_1B-a_2B^2-\dots-a_pb^p)X_t=\epsilon_t
            \]  
            El polinomio característico asociado es la ecuación algebraica: \[
            a_p(x)=1-a_1x-a_2x^2-\dots-a_px^p=0
            \] 
        \item \textbf{"Fuera del Círculo Unidad":} Al resolver la ecuación anterior para encontrar los valores de $x$ (las raíces), el  \textbf{módulo} (valor absoluto si son reales, o magnitud si son complejas) de todas las soluciones debe ser estrictamente \textbf{mayor que 1} $(|x|>1)$.   
        \end{enumerate}
    \item \lb{¿Qué es un modelo de media móvil $MA(q)$?} 

        Un modelo de medias móviles de orden $q$, denotado como  $MA(q)$, es un proceso estocástico donde el valor actual de la serie se representa como una combinación lineal de perturbaciones aleatorias (ruido blanco) presente y pasadas.

        Características principales:
         \begin{enumerate}
            \item \textbf{Expresión Matemática}

                El valor actual $X_t$ es el resultado de una perturbación aleatoria actual más una suma ponderada de  $q$ perturbaciones aleatorias. Su ecuación es:  \[
                X_t=\epsilon_t+b_1\epsilon_{t-1}+b_2\epsilon_{t-2}+\dots+b_q\epsilon_{t-q}
                \] 
                Donde:
                \begin{itemize}[label=\textbullet]
                    \item $\epsilon_t$ es un ruido blanco gaussiano (sucesión de valores independientes e idénticamente distribuidos).
                    \item $b_1,\dots,b_q$ son los coeficientes o parámetros del modelo.
                \end{itemize}
                También se puede expresar utilizando el \textbf{operador de retardos} $B$ y su polinomio característico  $b_q(B)$:  \[
                    X_t=(1+b_1B+b_2B^2+\dots+b_qB^q)\epsilon_t=[b_q(B)]\epsilon_t.
                \]  
            \item \textbf{Propiedades Fundamentales}
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Estacionariedad:} A diferencia de los modelos AR, los procesos $MA(q)$ \textbf{son siempre estacionarios}, independientemente de los valores de sus coeficientes $b_i$.
                    \item \textbf{Invertibilidad:} Un proceso $MA(q)$ se dice invertible si se puede reescribir como un proceso autorregresivo de orden infinito  $(AR(\infty))$. Para que esto ocurra, las raíces de su polinomio característico deben estar  \textbf{fuera del círculo unidad}.  
                \end{itemize}
            \item \textbf{Identificación}

                La clave para identificar un modelo $MA(q)$ reside en su  \textbf{correlograma simple (ACF):}
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Correlograma Simple (ACF):} Las correlaciones son distintas de cero hasta el retardo $q$ y se vuelven  \textbf{nulas para retardos mayores que} $q$ ($\rho_k=0$ si  $k>q$). Es decir, el gráfico se "corta" después del retardo $q$.
                    \item \textbf{Correlograma Parcial (PACF):} Muestra infinitos valores no nulos que decrecen de manera amortiguada (exponencial o sinusoidal), sin un corte abrupto. 
                \end{itemize}
        \end{enumerate}
    \item \lb{¿Cómo se identifica un modelo $MA(q)$? Demostrar que en un $MA(q)$ las correlaciones simples son nulas para retardos superiores a $q$.} 

        \begin{enumerate}
            \item \textbf{Identificación de un modelo $MA(q)$}

                La herramienta fundamental para identificar el orden $q$ de un proceso de medias móviles es el  \textbf{correlograma simple (ACF).}
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Regla de identificación:} El número de coeficientes de autocorrelación simple que sean "significativamente" distintos de cero indica el orden del proceso $MA$. Es decir, las correlaciones son significativas hasta el retardo  $q$ y se vuelven nulas para retardos mayores.
                    \item \textbf{Comportamiento visual:} En el gráfico de autocorrelación simple, se observa un "corte" abrupto después del retardo $q$. Por el contrario, en el correlograma parcial (PACF), los valores decrecen de manera amortiguada (exponencial o sinusoidal) sin anularse de golpe.
                \end{itemize}
            \item \textbf{Demostración: $\rho_k=0$ para  $k>q$}
                
                Para demostrar que las correlaciones simples se anula, debemos analizar la función de autocovarianza $\gamma_k$.
                \begin{enumerate}[label=\textbf{Paso \arabic*:}]
                    \item \textbf{Definición del proceso}

                        Consideremos un proceso $MA(q)$ centrado (media nula):  \[
                        X_t=\epsilon+b_1\epsilon_{t-1}+b_2\epsilon_{t-2}+\dots+b_q\epsilon_{t-q}
                        \] 
                        Donde $\epsilon_t$ es un ruido blanco gaussiano, lo que implica que $E(\epsilon_t)=0$ y que las perturbaciones son independientes entre sí $(E(\epsilon_t\epsilon_{t-k})=0\text{ si }k\neq 0)$.
                    \item \textbf{Definición de la covarianza}

                        La autocovarianza para un retardo $k$ se define como:  \[
                            \gamma_k=\mathrm{Cov}(X_t,X_{t-k})=E[(X_t-\mu)(X_{t-k}-\mu)]
                        \] 
                        Como la media es cero, esto se simplifica a: \[
                        \gamma_k=E(X_tX_{t-1}).
                        \] 
                    \item \textbf{Análisis de la covarianza para $k>q$}

                        Al multiplicar $X_t$ por $X_{t-k}$ y calcular la esperanza, buscamos términos de error común $(\epsilon)$ entre ambos instantes.
                        \begin{itemize}[label=\textbullet]
                            \item $X_t$ depende de las perturbaciones desde el instante  $t$ hasta  $t-q$.
                            \item  $X_{t-k}$ depende de las perturbaciones desde el instante $t-k$ hasta  $t-k-q$.
                        \end{itemize}
                        Si el retardo $k$ es mayor que el orden  $q\,(k>q)$, no existe solapamiento temporal entre las perturbaciones que componen  $X_t$ y las que componen  $X_{t-k}$. Debido a la propiedad de independencia del ruido blanco, el valor esperado del producto de perturbaciones en distintos instantes es cero.

                        Por tanto, la función de covarianzas es: \[
                        \gamma_k=0\text{ si }k>q.
                        \] 
                \end{enumerate}
                \textbf{Conclusión:} Dado que el coeficiente de autocorrelación simple $\rho_k$ es el cociente entre la autocovarianza  $\gamma_k$ y la varianza  $\gamma_0$: \[
                \rho_k=\dfrac{\gamma_k}{\gamma_0}
                \]  
                Si $\gamma_k=0$ para  $k>q$, entonces necesariamente:  \[
                \rho_k=0\text{ si }k>q.
                \] 
                Esto confirma que las correlaciones son nulas para retardos superiores al orden del modelo.
        \end{enumerate}
    \item \lb{Para un modelo $MA(q)$, ¿cuándo tendremos que se trata de un proceso estacionario?} 

        La repuesta es redundante: un proceso de medias móviles $MA(q)$  \textbf{es siempre estacionario.}

        A diferencia de los modelos autorregresivos, los modelos $MA(q)$ tienen las siguientes características respecto a su estabilidad:
         \begin{itemize}[label=\textbullet]
            \item \textbf{Sin condiciones sobre los parámetros:} No es necesario que los coeficientes $b_1,b_2,\dots,b_q$ cumplan ninguna condición específica para garantizar la estacionariedad.
        \end{itemize}
    \item \lb{Define formalmente un modelo $ARMA(p,q)$.}

        Un modelo $ARMA(p,q)$ (AutoRegressive Moving Average) se define formalmente como un proceso estocástico que combina una parte autorregresiva de orden  $p$ y una parte de medias móviles de orden  $q$.

        Su expresión matemática se representa mediante la siguiente igualdad:  \[
        X_t-a_1X_{t-1}-\dots-a_pX_{t-p}=\epsilon_t+b_1\epsilon_{t-1}+\dots+b_q\epsilon_{t-q}
        \] 
        Donde:
        \begin{itemize}[label=\textbullet]
            \item $X_t$: Es la variable de la serie temporal en el instante  $t$.
            \item  $p$: Indica el orden de la parte autorregresiva (número de retardos de $X$).
            \item $q$: Indica el orden de la parte de medias móviles (número de retardos del error).
            \item $\epsilon_t$: Representa un ruido blanco gaussiano (perturbación aleatoria).
        \end{itemize}

        \textbf{Notación con Operador de Retardos}

        El modelo se expresa de manera más compacta utilizando el operador de retardos $B$ (donde $B^kX_t=X_{t-k}$): \[
            (1-a_1B-a_2B^2-\dots-a_pB^p)X_t=(1+b_1B+b_2B^2+\dots+b_qB^q)\epsilon_t
        \]
        O de forma abreviada utilizando los polinomios característicos: \[
            [a_p(B)]X_t=[b_q(B)]\epsilon_t
        \] 
        Donde $a_p(B)$ es el polinomio autorregresivo y  $b_q(B)$ es el polinomio característico de medias móviles.
    \item \lb{¿Cómo se seleccionan los órdenes $p$ y  $q$ en un modelo  $ARMA$?}

        $p$ y  $q$ se seleccionan representando correlación simple y parcial, y proponiendo unos valores de  $p$ y  $q$ de partida que tengan sentido. Posteriormente se estudia si son reducibles a través de los  $p$-valores de los contrastes individuales de significación.
    \item \lb{Indica la fórmula general de un modelo $ARIMA(p,d,q)$ usando el operador de retardo.} 

        La fórmula general de un modelo $ARIMA(p,d,q)$ expresada mediante el operador de retardo  $B$ es la siguiente:  \[
            (1-a_1B-a_2B^2-\dots-a_pB^p)(1-B)^dX_t=(1+b_1B+b_2B^2+\dots+b_qB^q)\epsilon_t
        \] 
        \textbf{Desglose de los componentes de la fórmula:}
        \begin{enumerate}
            \item \textbf{Parte Autorregresiva (AR):} El primer polinomio representa la estructura autorregresiva de orden $p$:  \[
                a_p(B)=(1-a_1B-a_2B^2-\dots-a_pB^p)
            \]  
            Sus raíces determinan la estacionariedad una vez diferenciada la serie.
            \item \textbf{Parte Integrada (I):} El término central representa la  diferenciación necesaria para convertir la serie no estacionaria $X_t$ en estacionaria. El parámetro $d$ indica cuántas veces se aplica el operador diferencia  $\Delta=(1-B)$:  \[
                \Delta^pX_t=(1-B)^dX_t
            \]  
            \item \textbf{Parte de medias móviles (MA):} El polinomio del lado derecho representa la estructura de medias móviles de orden $q$:  \[
            b_q(B)=(1+b_1B+b_2B^2+\dots+b_qB^q)
            \]  
            De forma compacta, si consideramos $Y_t$ como al serie ya diferenciada  $(Y_t=(1-B)^dX_t)$, el problema modelo se reduce a un  $ARMA(p,q)$ sobre dicha serie diferenciada:  \[
                [a_p(B)]Y_t=[b_q(B)]\epsilon_t
            \] 
        \end{enumerate}
    \item \lb{¿Cómo se estiman los coeficientes de un modelo $ARIMA$? Deducir las ecuaciones de Yule-Walker en términos de correlaciones para un proceso $AR(p)$} 
        \begin{enumerate}
            \item \textbf{Estimación de Coeficientes en modelos ARIMA}

                La estimación de los parámetros de un modelo ARIMA (coeficietnes, $a_i$ de la parte autorregresiva,  $b_j$ de la media móvil y la constante) se realiza una vez determinados los órdenes $p,d,q$.

                Existen dos métodos principales para realizar esta estimación:
                 \begin{itemize}[label=\textbullet]
                    \item \textbf{Minimización de la Suma de Cuadrados Residual:} Se buscan los parámetros que minimizan la suma de los errores al cuadrado.
                    \item \textbf{Maximización de la Verosimilitud:} Se buscan los parámetros que hacen más probable la muestra observada. 
                \end{itemize}
                \textbf{Dificultad según el tipo de modelo:}
                \begin{itemize}[label=\textbullet]
                    \item \textbf{Modelos AR puros:} La estimación es más sencilla, ya que el criterio de mínimos cuadrados coincide con las ecuaciones lineales de Yule-Walker.
                    \item \textbf{Modelos con componente MA (MA o ARMA):} La estimación es mucho más compleja porque las ecuaciones resultantes \textbf{no son lineales} en los parámetros. Por ello, es necesario recurrir a \textbf{procedimientos iterativos} (algoritmos numéricos) para resolverlos.   
                \end{itemize}
            \item \textbf{Deducción de las Ecuaciones de Yule-Walker para un proceso $AR(p)$}

                Las ecuaciones de Yule-Walker relacionan las autocorrelaciones teóricas con los parámetros del modelo, permitiendo estimar los coeficientes $a_i$ a partir de las correlaciones observadas.

                \begin{enumerate}[label=\textbf{Paso \arabic*:}]
                    \item \textbf{Definición del proceso}

                        Consideramos un proceso $AR(p)$ centrado (media cero) para simplificar la notación:  \[
                        X_t=a_1X_{t-1}+a_2X_{t-2}+\dots+a_pX_{t-p}+\epsilon_t
                        \] 
                    \item \textbf{Multiplicación por un retardo}

                        Multiplicamos ambos lados de la ecuación por $X_{t-j}$ (donde $j>0$): \[
                        X_tX_{t-j}=a_1X_{t-1}X_{t-j}+a_2X_{t-2}X_{t-j}+\dots+a_pX_{t-p}X_{t-j}+\epsilon_tX_{t-j}
                        \] 
                    \item \textbf{Aplicación de Esperanzas} 

                        Tomamos la esperanza matemática $E[\cdot ]$ en toda la expresión. Dado que los coeficientes $a_i$ son constantes, salen fuera de la esperanza:  \[
                        E(X_tX_{t-j})=a_1E(X_{t-1}X_{t-j})+\dots+a_pE(X_{t-p}X_{t-j})+E(\epsilon_tX_{t-j})
                        \] 
                    \item \textbf{Simplificación del término de error}

                        Analizamos el término $E(\epsilon_tX_{t-j})$. Como $X_{t-j}$ ( con $j>0$) es un valor pasado, solo depende de errores pasados $(\epsilon_{t-j},\epsilon_{t-j-1},\dots)$. Dado que $\epsilon_t$ es ruido blanco (independiente del pasado), la esperanza del producto es cero: \[
                        E(\epsilon_tX_{t-j})=0\text{ para }j>0
                        \] 
                    \item \textbf{Expresión en Covarianzas ($\gamma$)}

                        Sustituimos las esperanzas por la función de autocovarianza $\gamma_k=E(X_tX_{t-k})$: \[
                        \gamma_j=a_1\gamma_{j-1}+a_2\gamma_{j-2}+\dots+a_p\gamma_{j-p}
                        \] 
                    \item \textbf{Expresión en Correlaciones ($\rho$)}

                        Dividimos toda la ecuación por la varianza del proceso, $\gamma_0$, sabiendo que $\rho_k=\dfrac{\gamma_k}{\gamma_0}$: \[
                        \dfrac{\gamma_j}{\gamma_0}=a_1\dfrac{\gamma_{j-1}}{\gamma_0}+a_2 \dfrac{\gamma_{j-2}}{\gamma_0}+\dots+a_p \dfrac{\gamma_{j-p}}{\gamma_0}
                        \] 
                        Esto nos da las \textbf{Ecuaciones de Yule-Walker en términos de correlaciones:}\[
                        \rho_j=a_1\rho_{j-1}+a_2\rho_{j-2}+\dots+a_p\rho_{j-p}\text{ para }j>0
                        \]  
                \end{enumerate}
                \textbf{Resultado Final (Sistema Matricial)} 

                Particularizando para $j=1,2,\dots,p$, obtenemos un sistema de ecuaciones lineales que permite despejar los parámetros $a$ si conocemos las correlaciones  $\rho$:  \[
                \rho=R\cdot a\implies a=R^{-1}\cdot \rho
                \] 
        \end{enumerate}
    \item \lb{¿Cuál es la utilidad de los criterios de información de Akaike (AIC) y de Bayes (BIC) en el contexto de metodología $ARIMA$?} 
    \item \lb{¿Cuál es la importancia de verificar que los residuos de un modelo $ARIMA$ se asemejen a ruido blanco?} 
    \item \lb{Resume los pasos para analizar una serie temporal usando modelos $ARIMA$.} 
    \item \lb{¿Qué efectos tiene la transformación logarítmica en una serie temporal y cuándo se utiliza?} 
\end{enumerate}
\textbf{\large Problemas} 
\begin{enumerate}[label=\color{red}\textbf{\arabic*)}, start=21]
    \item \lb{En la siguiente tabla se muestra una serie temporal con datos trimestrales. Para modelar dicha serie se propuso el modelo $ARMA$ dado por  \[
                (1-0.9B+0.5B^2)X_t=(1+0.7B+B^2)\varepsilon_t
    \] } 
    \begin{enumerate}[label=\color{red}\textbf{\alph*)}]
        \item \db{Escribe órdenes y polinomios característicos}

            Observando la ecuación dada, podemos identificar la estructura de un modelo $ARMA(p,q)$:
             \begin{itemize}[label=\textbullet]
                \item \textbf{Parte AR (Autorregresiva):} El lado izquierdo tiene términos hasta $B^2$, por lo que el orden es $p=2$.
                \item \textbf{Parte MA (Medias Móviles):} El lado derecho tiene términos hasta $B^2$, por lo que el orden es $q=2$. 
            \end{itemize}
            Por lo tanto, se trata de un modelo $ARMA(2,2)$.
        \item \db{Prueba que el modelo es estacionario} 

            La condición necesaria y suficiente para que un proceso AR sea estacionario es que las raíces de su polinomio característico estén \textbf{fuera del círculo unidad} del plano complejo (su módulo debe ser mayor que 1).

            El polinomio característico es: $1-0.9z+0.5z^2=0$. Por lo tanto:
            \[
            \begin{array}{c}
                z=\dfrac{-b\pm\sqrt{b^2-4ac} }{2a}=\dfrac{0.9\pm\sqrt{(-0.9)^2-4\cdot 0.5\cdot 1} }{2\cdot 0.5}\\
                z=\dfrac{0.9\pm\sqrt{0.81-2} }{1}=0.9\pm\sqrt{-1.19}\\
                z=0.9\pm i\sqrt{1.19} 
            \end{array}
            \] 
            Calculamos el módulo de las raíces complejas($|z|=\sqrt{a^2+b^2} $): \[
            |z|=\sqrt{0.9^2+(\sqrt{1.19} )^2}=\sqrt{0.81+1.19}=\sqrt{2}\approx 1.414   
            \] 
            Como el módulo $|z|=1.414>1$, las raíces están fuera del círculo unidad. Por tanto,  \textbf{el modelo es estacionario}. 
        \item \db{Completa los huecos de la tabla tomando como valores iniciales $X(-1)=0.2,\,X(0)=0.5,\,e(-1)=0,\,e(0)=0$.}

            Para completar la tabla, necesitamos despejar $X_t$ o  $\varepsilon_t$ de la ecuación en diferencias según lo que necesitemos calcular. La ecuación explicita es: \[
            X_t-0.9X_{t-1}+0.5X_{t-2}=\varepsilon_t+0.7\varepsilon_{t-1}+\varepsilon_{t-2}
            \] 
            \begin{itemize}[label=\textbullet]
                \item Fórmula para hallar residuos ($\varepsilon_t$): $\varepsilon_t=X_t-0.9X_{t-1}+0.5X_{t-2}+0.7\varepsilon_{t-1}-\varepsilon_{t-2}$ 
                \item Fórmula para hallar valores de la serie ($X_t$):  $X_t=0.9X_{t-1}-0.5X_{t-2}+\varepsilon_t+0.7\varepsilon_{t-1}+\varepsilon_{t-2}$.
            \end{itemize}

            $\begin{array}{l}
                \varepsilon_2=X_2-0.9X_1+0.5X_0-0.7\varepsilon_1-\varepsilon_0=4.01-0.9\cdot 2.45+0.5\cdot 0.5-0.7\cdot 2.10-0=\bboxed{0.585}\\
                X_3=0.9X_2-0.5X_1+\varepsilon_3+0.7\varepsilon_2+\varepsilon_1=0.9\cdot 4.01-0.5\cdot 2.45-0.18+0.7\cdot 0.585+2.10=\bboxed{4.7135}\\
                X_9=0.9X_8-0.5X_7+\varepsilon_9+0.7\varepsilon_8+\varepsilon_7=0.9\cdot 0.03-0.5\cdot (-2.45)-0.62+0.7\cdot 1.05-1.26=\bboxed{0.107}\\
                \varepsilon_{15}=X_{15}-0.9X_{14}+0.5X_{13}-0.7\varepsilon_{14}-\varepsilon_{13}=-0.85-0.9\cdot (-2.88)+0.5\cdot (-3.33)-0.7\cdot 0.3+0.79=\bboxed{0.657}\\
                \varepsilon_{16}=X_{16}-0.9X_{15}+0.5X_{14}-0.7\varepsilon_{15}-\varepsilon_{14}=1.22-0.9\cdot (-0.85)+0.5\cdot (-2.88)-0.7\cdot 0.657-0.3=\bboxed{-0.215} 
            \end{array}$
        \item \db{Calcula las predicciones para el año 2024.} 

            Para $h\ge 1$, el término de error esperado $\hat{\varepsilon}_{T+h}$ es 0.

            $\begin{array}{l}
                \hat{X}_{17}=0.9X_{16}-0.5\cdot X_{15}+0.7\varepsilon_{16}+\varepsilon_{15}=0.9\cdot 1.22-0.5\cdot (-0.85)+0.7\cdot (-0.215)+0.657=\bboxed{2.0295}\\
                \hat{X}_{18}=0.9\hat{X}_{17}-0.5X_{16}+\tozero{0.7 \hat{\varepsilon}_{17}}+\varepsilon_{16}=0.9\cdot 2.0295-0.5\cdot 1.22+0-0.215=\bboxed{1.00155}\\
                \hat{X}_{19}=0.9\hat{X}_{18}-0.5\hat{X}_{17}+\tozero{0.7\hat{\varepsilon}_{18}}+\tozero{\hat{\varepsilon}_{17}}=0.9\cdot 1.00155-0.5\cdot 2.0295=\bboxed{-0.11335}\\
                \hat{X}_{20}=0.9\hat{X}_{19}-0.5\hat{X}_{18}=0.9\cdot (-0.11335)-0.5\cdot 1.00155=\bboxed{-0.6028} 
            \end{array}$
    \end{enumerate}
    \begin{center}
        \color{blue}
    	\begin{tabular}{|c|c|c|c|c|}
    		\hline
    		t & Año & Trimestre & Serie & residuos \\
    		\hline
    		1 & 2020 & T1 & 2.45 & 2.10 \\
    		\hline
            2 & 2020 & T2 & 4.01 & \textcolor{black}{0.585} \\
    		\hline
    		3 & 2020 & T3 & \textcolor{black}{4.7135} & -0.18 \\
    		\hline
    		4 & 2020 & T4 & 2.73 & 0.04 \\
    		\hline
    		5 & 2021 & T1 & -1.03 & -0.98 \\
    		\hline
    		6 & 2021 & T2 & -1.74 & 1.20 \\
    		\hline
    		7 & 2021 & T3 & -2.45 & -1.26 \\
    		\hline
    		8 & 2021 & T4 & 0.03 & 1.05 \\
    		\hline
    		9 & 2022 & T1 & \textcolor{black}{0.107} & -0.62 \\
    		\hline
    		10 & 2022 & T2 & 0.20 & -0.50 \\
    		\hline
    		11 & 2022 & T3 & -1.01 & -0.16 \\
    		\hline
    		12 & 2022 & T4 & -2.51 & -0.89 \\
    		\hline
    		13 & 2023 & T1 & -3.33 & -0.79 \\
    		\hline
    		14 & 2023 & T2 & -2.88 & 0.30 \\
    		\hline
    		15 & 2023 & T3 & -0.85 & \textcolor{black}{0.657} \\
    		\hline
    		16 & 2023 & T4 & 1.22 & \textcolor{black}{-0.215} \\
    		\hline
    	\end{tabular}
    \end{center}
    \item \lb{En la siguiente tabla se muestra una serie temporal con datos trimestrales. Para modelar dicha serie se propuso el modelo $ARIMA$ dado por \[ \left(1-\dfrac{1}{2}B+\dfrac{1}{8}B^2\right)(1-B)X_t=(1+0.4B-0.2B^2+0.1B^3)\varepsilon_t \]} 
        \begin{enumerate}[label=\color{red}\textbf{\alph*)}]
            \item \db{Escribe órdenes y polinomios característicos.} 

                Para identificar el modelo $ARIMA(p,d,q)$, observamos los polinomios en el operador de retardos $B$:
                 \begin{enumerate}
                    \item \textbf{Parte Autorregresiva (AR) y Diferenciador (I):}
                        \begin{itemize}[label=\textbullet]
                            \item El término $(1-B)$ indica una diferenciación de orden 1, por lo que  $d=1$.
                            \item El polinomio  $\left( 1-\dfrac{1}{2}B+\dfrac{1}{8}B^2 \right) $ corresponde a la parte AR. Al ser de grado 2, tenemos $p=2$.
                        \end{itemize}
                    \item \textbf{Parte de Medias Móviles (MA):}
                        \begin{itemize}[label=\textbullet]
                            \item El polinomio del lado derecho $(1+0.4B-0.2B^2+0.1B^3)$ es de grado 3, por lo que $q=3$.
                        \end{itemize}
                \end{enumerate}
                \textbf{Identificación:} Modelo $ARIMA(2,1,3)$.
            \item \db{Comprueba que la serie obtenida al aplicar el operador diferencia es estacionaria.} 

                La condición necesaria y suficiente para que un proceso AR sea estacionario es que las raíces de su polinomio característico estén \textbf{fuera del círculo unidad} del plano complejo (su módulo debe ser mayor que 1).

                Tomamos el polinomio AR: $1-0.5z+0.125z^2=0$. Para hallar las raíces, resolvemos la ecuación de segundo grafo (multiplicamos por 8 para simplificar: $z^2-4z+8=0$):
                \[
                \begin{array}{c}
                    z=\dfrac{-(-4)\pm\sqrt{(-4)^2-4\cdot 1\cdot 8} }{2\cdot 1}=\dfrac{4\pm\sqrt{16-32} }{2}=\dfrac{4\pm\sqrt{-16} }{2}\\
                    z=\frac{4\pm 4i}{2}=2\pm 2i
                \end{array}
                \] 

                Calculamos el módulo de las raíces complejas ($|z|=\sqrt{a^2+b^2} $):
                \[
                |z|=\sqrt{2^2+2^2}=\sqrt{4+4}=\sqrt{8}\approx 2.83   
                \] 
                Como el módulo $|z|=2.83>1$, las raíces caen fuera del círculo unidad. Por lo tanto,  \textbf{la serie obtenida tras diferenciar es estacionaria}. 
            \item \db{Completa los huecos de la tabla tomando como valores iniciales $X(-2)=0.1,\,X(-1)=0.2,\,X(0)=0.5,\,e(-2)=0,\,e(-1)=0,\,e(0)=0$.} 

                Para calcular los valores, expandimos la ecuación del modelo para dejar $X_t$ (para predecir valores de la serie) o  $\varepsilon_t$ (para calcular residuos).

                Expandimos la parte izquierda:  $(1-0.5B+0.125B^2)(1-B)X_t=(1-1.5B+0.625B^2-0.125B^3)X_t$. La ecuación en diferencias es:
                \[
                X_t-1.5X_{t-1}+0.625X_{t-2}-0.125X_{t-3}=\varepsilon_t+0.4\varepsilon_{t-1}-0.2\varepsilon_{t-2}+0.1\varepsilon_{t-3}
                \] 
                Despejamos $X_t$ para cálculos recursivos:
                 \[
                X_t=1.5X_{t-1}-0.625X_{t-2}+0.125X_{t-3}+\varepsilon_t+0.4\varepsilon_{t-1}-0.2\varepsilon_{t-2}+0.1\varepsilon_{t-3}
                \] 

                $\begin{array}{l}
                	\begin{aligned}
                    X_2&=1.5X_1-0.625X_0+0.125X_{-1}+\varepsilon_2+0.4\varepsilon_1-\tozero{0.2\varepsilon_0}+\tozero{0.1\varepsilon_{-1}}\\
                        &=1.5\cdot 0.99-0.625\cdot 0.5+0.125\cdot 0.2+0.56+0.4\cdot 0.35=\bboxed{1.90}\\
                    \end{aligned}\\
                    \begin{aligned}
                    \varepsilon_3&=X_3-[1.5X_2-0.625X_1+0.125X_0+0.4\varepsilon_2-0.2\varepsilon_1+\tozero{0.1\varepsilon_0}]\\
                                 &=0.17-[1.5\cdot 1.9-0.25\cdot 0.99+0.125\cdot 0.5+0.4\cdot 0.56-0.2\cdot 0.35]=\bboxed{-2.28}\\
                    \end{aligned}\\
                    \begin{aligned}
                    \varepsilon_6&=X_6-[1.5X_5-0.625X_4+0.125X_3+0.4\varepsilon_5-0.2\varepsilon_4+0.1\varepsilon_3]\\
                                 &=-3.68-[1.5\cdot (-2.84)-0.625\cdot (-1.84)+0.125\cdot 0.17+0.4\cdot (-0.7)-0.2\cdot (-0.05)+0.1\cdot (-2.28)]=\bboxed{-0.09}\\
                    \end{aligned}\\
                   \begin{aligned}
                       X_{16}&= 1.5\cdot X_{15}-0.625X_{14}+0.125X_{13}+\varepsilon_{16}+0.4\varepsilon_{15}0.2\varepsilon_{14}+0.1\varepsilon_{13}\\
                       &= 1.5\cdot (-0.59)-0.625\cdot (-1.17)+0.125\cdot (-1.71)-0.7+0.4\cdot 0.01-0.2\cdot 0.59+0.1\cdot (-0.23)=\bboxed{-1.20}  \\
                   \end{aligned} 
                \end{array}$
            \item \db{Calcula las predicciones para el año 2024.} 

                $\begin{array}{l}
                    \hat{X}_{17}=1.5\cdot (-1.2)-0.625\cdot (-0.59)+0.125\cdot (-1.17)+\tozero{\hat{\varepsilon}_{17}}+0.4\cdot (-0.7)-0.2\cdot 0.01+0.1\cdot 0.59=\bboxed{-1.8}\\
                    \hat{X}_{18}=1.5\cdot (-1.8)-0.625\cdot (-1.2)+0.125\cdot (-0.59)+\tozero{\hat{\varepsilon}_{18}}+\tozero{0.4\cdot \hat{\varepsilon}_{17}}-0.2\cdot (-0.7)+0.1\cdot 0.01=\bboxed{-1.88}\\
                    \hat{X}_{19}=1.5\cdot (-1.88)-0.625\cdot (-1.8)+0.125\cdot (-1.2)+\tozero{\hat{\varepsilon}_{19}}+\tozero{0.4\cdot \hat{\varepsilon}_{18}}-\tozero{0.2\cdot \hat{\varepsilon}_{17}}+0.1\cdot 0.01=\bboxed{-1.92}\\
                    \hat{X}_{20}=1.5\cdot (-1.92)-0.625\cdot (-1.88)+0.125\cdot (-1.8)=\bboxed{-1.93}\\ 
                \end{array}$
        \end{enumerate}
        \begin{center}
            \color{blue}
            \begin{tabular}{|c|c|c|c|c|}
                \hline
                t & Año & Trimestre & Serie & residuos \\
                \hline
                1 & 2020 & T1 & 0.99 & 0.35 \\
                \hline
                2 & 2020 & T2 & \textcolor{black}{1.9} & 0.56 \\
                \hline
                3 & 2020 & T3 & 0.17 & \textcolor{black}{-2.28} \\
                \hline
                4 & 2020 & T4 & -1.84 & -0.05 \\
                \hline
                5 & 2021 & T1 & -2.84 & -0.70 \\
                \hline
                6 & 2021 & T2 & -3.68 & \textcolor{black}{-0.09} \\
                \hline
                7 & 2021 & T3 & -3.95 & -0.08 \\
                \hline
                8 & 2021 & T4 & -4.21 & -0.14 \\
                \hline
                9 & 2022 & T1 & -4.03 & 0.32 \\
                \hline
                10 & 2022 & T2 &-3.94  & -0.18 \\
                \hline
                11 & 2022 & T3 & -3.94 & 0.13 \\
                \hline
                12 & 2022 & T4 & -2.60 & 1.23 \\
                \hline
                13 & 2023 & T1 & -1.71 & -0.23 \\
                \hline
                14 & 2023 & T2 & -1.17 & 0.59 \\
                \hline
                15 & 2023 & T3 & -0.59 & 0.01 \\
                \hline
                16 & 2023 & T4 & \textcolor{black}{-1.20} & -0.70 \\
                \hline
            \end{tabular}
        \end{center}
\end{enumerate}
