\input{../../../Macros.tex}
\renewcommand{\arraystretch}{1.3}
\setlength{\arraycolsep}{6pt}

\title{Álgebra Lineal\\Ejercicios Tema 5: Transformaciones lineales}

\begin{document}
\maketitle
\begin{enumerate}[label=\color{red}\textbf{\arabic*)}]
    \item \lb{Comprueba que si $v=(a_1,a_2,a_3)$ es un vector fijo, entonces la aplicación $T_V:\R^3\to \R^3$ definida por $T_V(x)=x+v$  \underline{no} es lineal. Este tipo de aplicación se llama una \textbf{traslación de vector} $v$ y no se puede representar por medio de una matriz $3\times 3$. Sin embargo, esta dificultad se soluciona aumentando en uno el tamaño de la matriz de modo que la traslación de vector $v=(a_1,a_2,a_3)$ se calcula por medio de la matriz \[
    T=\begin{bmatrix} 
        1 & 0 & 0 & a_1\\
        0 & 1 & 0 & a_2\\
        0 & 0 & 1 & a_3\\
        0 & 0 & 0 & 1
    \end{bmatrix} ,
    \]es decir, se tiene que \[
    \begin{bmatrix} 
        1 & 0 & 0 & a_1\\
        0 & 1 & 0 & a_2\\
        0 & 0 & 1 & a_3\\
        0 & 0 & 0 & 1
    \end{bmatrix} \begin{bmatrix} 
    x_1\\x_2\\x_3\\1 
    \end{bmatrix} =\begin{bmatrix} 
    a_1+x_1\\ a_2+x_2\\a_3+x_3\\1 
    \end{bmatrix} 
    \] Las 4 coordenadas $(x_1,x_2,x_3,1)$ del vector tridimensional $x$ se llaman coordenadas homogéneas de $x$.} 

    \textbf{Verificación de que $T_V(x)=x+v$ no es una transformación lineal:}

    Una transformación $T:\R^3\to \R^3$ es lineal si satisface las siguientes dos propiedades para todos $u,w\in \R^3$ y $\lambda\in \R$:
    \begin{enumerate}[label=\arabic*)]
        \item $T(u+w)=T(u)+T(w)$ (preserva la suma de vectores).
        \item  $T(\lambda u)=\lambda T(u)$ (preserva la multiplicación por escalar).
    \end{enumerate}
    En caso de $T_V(x)=x+v$, con  $v=(a_1,a_2,a_3)$, veamos si estas propiedades se cumplen: 
    \begin{enumerate}[label=\arabic*)]
        \item Preservación de la suma: \[
        T_V(u+w)=(u+w)+v,
        \] pero \[
        T_V(u)+T_V(w)=(u+v)+(w+v)=u+w+2v.
        \] 
        Como $T_V(u+w)\neq T_V(u)+T_V(w)$ (debido al término extra $v$), $T_V$ preserva la suma de vectores.
    \item Preservación de la multiplicación por escalar:  \[
    T_V(\lambda u)=\lambda u+v,
    \] pero \[
    \lambda T_V(u)=\lambda(u+v)=\lambda u+\lambda v.
    \] 
    Como $T_V(\lambda u)\neq \lambda T_V(u)$ (debido al término $\lambda v\neq v$), $T_V$ no preserva la multiplicación por escalar.

    Por lo tanto,  $T_V$  \textbf{no es lineal}.

    \end{enumerate}
    \textbf{Representación de la traslación mediante una matriz en coordenadas homogéneas}

    Para resolver la dificultad de que $T_V$ no es lineal, se utiliza un truco geométrico añadiendo una coordenada adicional para representar los punto en  $\R^3$ como vectores en $\R^4$. Este sistema se llama \textbf{coordenadas homogéneas}.

    Dado $x=(x_1,x_2,x_3)\in \R^3$, su representación en coordenadas homogéneas es $(x_1,x_2,x_3,1)$. 

    La traslación por un vector $v=(a_1,a_2,a_3)$ se puede representar mediante la matriz $T$ en coordenadas homogéneas:  \[
    T=\begin{bmatrix} 
        1 & 0 & 0 & a_1\\
        0 & 1 & 0 & a_2\\
        0 & 0 & 1 & a_3\\
        0 & 0 & 0 & 1
    \end{bmatrix}. 
    \] 
    \textbf{Entonces, aplicando $T$ a un vector homogéneo $\begin{bmatrix} 
    x_1\\x_2\\x_3\\1 
    \end{bmatrix} $, obtenemos:} \[
    T\begin{bmatrix} 
    x_1\\x_2\\x_3\\1 
    \end{bmatrix} =\begin{bmatrix} 
        1 & 0 & 0 & a_1\\
        0 & 1 & 0 & a_2\\
        0 & 0 & 1 & a_3\\
        0 & 0 & 0 & 1
    \end{bmatrix} \begin{bmatrix} 
    x_1\\x_2\\x_3\\1 
    \end{bmatrix} \begin{bmatrix} 
    x_1+a_1\\ x_2+a_2\\ x_3+a_3\\ 1 
    \end{bmatrix} .
    \]  
    De esta manera, la traslación de $x$ se representa linealmente en el espacio de coordenadas homogéneas.
\item \lb{Sea $\mathcal{B}=\{v_1,v_2,v_3\} $ con $v_1=(-2,3,-2),v_2=(-4,5,-3)$ y $v_3=(5,-6,4)$ una base de $\R^3$. Calcula la matriz en la base $\mathcal{B}$ de la transformación lineal cuya matriz en las bases canónicas es \[
A=\begin{bmatrix} 
    6 & 26 & 34\\
    -6 & -31 & -42\\
    4 & 20 & 27
\end{bmatrix} 
\] } 

Para calcular la matriz de la transformación linea $T$ en la base $\mathcal{B}=\{v_1,v_2,v_3\} $, procedemos como sigue:
\begin{enumerate}[label=Paso \arabic*:]
    \item Transformación de la base $\mathcal{B}$ mediante $A$

        Sabemos que la matriz de la transformación en la base  $\mathcal{B}$, que llamaremos $[T]_{\mathcal{B}}$, está relacionada con la matriz en la base canónica $A$ por la fórmula: \[
            [T]_{\mathcal{B}}=P^{-1}AP,
        \]donde $P$ es la matriz de cambio de base de $\mathcal{B}$ a la base canónica. Esto significa que las columnas de $P$ son los vectores de la base $\mathcal{B}$ expresados en la base canónica, es decir: \[
        P=\begin{bmatrix} 
            v_1 & v_2 & v_3 
        \end{bmatrix}\begin{bmatrix} 
            -2 & -4 & 5\\
            3 & 5 & -6\\
            -2 & -3 & 4
        \end{bmatrix}. 
        \] 
    \item Calcular $P^{-1}$

        Invertimos la matriz $P$ para obtener $P^{-1}$. \[
        P^{-1}=\dfrac{1}{|P|}(\mathrm{adj}(P))^\intercal=\dfrac{1}{1}\cdot \begin{bmatrix} 
            2 & 1 & -1\\
            0 & 2 & 3\\
            1 & 2 & 2
        \end{bmatrix}=\begin{bmatrix} 
            2 & 1 & -1\\
            0 & 2 & 3\\
            1 & 2 & 2
        \end{bmatrix}  
        \] 
        $\mathrm{det}(P)=\begin{vmatrix} 
            -2 & -4 & 5\\
            3 & 5 & -6\\
            -2 & -3 & 4
        \end{vmatrix}=1\neq 0 \to $es invertible
    \item Calcular $[T]_{\mathcal{B}}$

        Una vez obtenida $P^{-1}$, calculamos: \[
            [T]_{\mathcal{B}}=P^{-1}AP=\begin{bmatrix} 
            -2 & -4 & 5\\
            3 & 5 & -6\\
            -2 & -3 & 4
            \end{bmatrix} \begin{bmatrix} 
            6 & 26 & 34\\
            -6 & -31 & -42\\
            4 & 20 & 27
            \end{bmatrix}\begin{bmatrix} 
            -2 & -4 & 5\\
            3 & 5 & -6\\
            -2 & -3 & 4
            \end{bmatrix} =\begin{bmatrix} 
            2 & 1 & -1\\
            0 & -2 & -3\\
            2 & 4 & 4
            \end{bmatrix}\begin{bmatrix} 
            -2 & -4 & 5\\
            3 & 5 & -6\\
            -2 & -3 & 4
            \end{bmatrix} =\begin{bmatrix} 
            1 & 0 & 0\\
            0 & -1 & 0\\
            0 & 0 & 2
            \end{bmatrix}.
        \] 
\end{enumerate}
\item \lb{Las llamadas \textbf{rotaciones de Givens} son las transformaciones lineales que vienen dadas por las matrices \[
R_X(\alpha)=\begin{bmatrix} 
    1 & 0 & 0\\
    0 & c & -s\\
    0 & s & c
\end{bmatrix},\quad R_y(\alpha) =\begin{bmatrix} 
    c & 0 & -s\\
    0 & 1 & 0\\
    s & 0 & c
\end{bmatrix},\quad R_z(\alpha)=\begin{bmatrix} 
    c & -s & 0\\
    s & c & 0\\
    0 & 0 & 1
\end{bmatrix}  
\]donde $c=\cos\alpha$ y $s=\sin\alpha$ para un cierto ángulo $\alpha$. ¿Qué interpretación geométrica tienen?\newline
Dada la transformación lineal que tiene por matriz en las bases canónicas \[
A=\begin{bmatrix} 
    1 & -2 & 2\\
    0 & -1 & 2\\
    -1 & 0 & 1
\end{bmatrix} 
\]calcula la matriz en la base $\mathcal{B}=\{u_1,u_2,u_3\} $, donde \[
u_1=(1,1,1),\quad u_2=(0,1,1),\quad u_3=(1,1,0)
\]A la vista del resultado, ¿cuál es la interpretación geométrica de la transformación lineal dada por la matriz $A$?}

\textbf{Interpretación geométrica de las rotaciones de Givens} 

Las matrices $R_X(\alpha), R_Y(\alpha),R_Z(\alpha)$ representan \textbf{rotaciones en $R^3$} alrededor de los ejes coordenados $X,Y,$ y $Z$, respectivamente:
 \begin{enumerate}[label=\arabic*.]
    \item $R_X(\alpha)$: Rotación en el plano $YZ$ alrededor del eje $X$ por un ángulo $\alpha$.
    \item $R_Y(\alpha)$: Rotación en el plano $XZ$ alrededor del eje $Y$ por un ángulo $\alpha$.
    \item $R_Z(\alpha)$: Rotación en el plano $XY$ alrededor del eje $Z$ por un ángulo $\alpha$.
\end{enumerate}
Estas matrices preservan las nromas de los vectores (son ortogonales) y no cambian volúmenes, lo que significa que son \textbf{transformaciones isométricas} (rotaciones propiamente dichas).

\textbf{Cálculo de la matriz en la base $\mathcal{B}$} 

La matriz de la transformación lineal en la base $\mathcal{B}$, denotada como $[T]_{\mathcal{B}}$, se calcula con la fórmula: \[
    [T]_{\mathcal{B}}=P^{-1}AP,
\] donde:
\begin{itemize}[label=\textbullet]
    \item $A$ es la matriz en la base canónica
    \item $P$ es la matriz de cambio de base, cuyas columnas son los vectores de la base $\mathcal{B}=\{u_1,u_2,u_3\} $ : \[
            P=\begin{bmatrix} 
                u_1 & u_2 & u_3 
            \end{bmatrix} =\begin{bmatrix} 
                1 & 0 & 1 \\
                1 & 1 & 1 \\
                1 & 1 & 0
            \end{bmatrix} .
    \] 
    Procedemos a calcular $[T]_{\mathcal{B}}$.

    $P^{-1}=\dfrac{1}{|P|}(\mathrm{adj}(P))^\intercal=\dfrac{1}{-1}\cdot \begin{bmatrix} 
        -1 & 1 & -1\\
        1 & -1 & 0\\
        0 & -1 & 1
    \end{bmatrix}=\begin{bmatrix} 
        1 & -1 & 1 \\
        -1 & 1 & 0\\
        0 & 1 & -1
    \end{bmatrix}  $ 

    \[
        [T]_{\mathcal{B}}=P^{-1}AP=\begin{bmatrix} 
        1 & -1 & 1 \\
        -1 & 1 & 0\\
        0 & 1 & -1
        \end{bmatrix} \begin{bmatrix} 
        1 & -2 & 2\\
        0 & -1 & 2\\
        -1 & 0 & 1
        \end{bmatrix} \begin{bmatrix} 
                1 & 0 & 1 \\
                1 & 1 & 1 \\
                1 & 1 & 0
        \end{bmatrix} =\begin{bmatrix} 
                0 & -1 & 1 \\
                -1 & 1 & 0 \\
                1 & -1 & 1
        \end{bmatrix} \begin{bmatrix} 
                1 & 0 & 1\\
                1 & 1 & 1\\
                1 & 1 & 0
        \end{bmatrix} =\begin{bmatrix} 
                0 & 0 & -1\\
                0 & 1 & 0\\
                1 & 0 & 0
        \end{bmatrix} 
    \] 
\end{itemize}
\item \lb{Consideremos un plano $\R^3$ que pasa por el origen, es decir, un subespacio vectorial de ecuación $ax+by+cz=0$. Sea $v=(a,b,c)$ el vector normal al plano y consideremos la matriz  \[
H=I-\dfrac{2uv^\intercal}{v^\intercal v}
\]Entonces, $H$ es la matriz de la simetría ortogonal respecto del plano y recibe el nombre de \textbf{reflexión de Householder}. Para verlo, prueba que si $x$ es un vector arbitrario, entonces $x+Hx$ es ortogonal a  $v$ (es decir, $x+HX$ pertenece al plano) y $x-Hx$ es proporcional a  $v$ (estas dos cosas prueba que $Hx$ es el simétrico de  $x$ respecto del plano dado).} 

\begin{enumerate}[label=Paso \arabic*:]
    \item Probar que $x+Hx$ es ortogonal a $v$

        Dado un vector arbitrario  $x\in \R^3$, calculemos $Hx$:  \[
        Hx=x-\dfrac{2vv^\intercal}{v^\intercal v}x.
        \] 
        Entonces: \[
            x+Hx=x+\left( x-\dfrac{2vv^\intercal}{v^\intercal v}x \right) =2x-\dfrac{2vv^\intercal}{v^\intercal v}x.
        \] 

        Ahora verificamos que $x+Hx$ es ortogonal a  $v$, es decir, que:  \[
        v^\intercal(x+Hx)=0\longrightarrow v^\intercal\left( 2x-\dfrac{2vv^\intercal}{v^\intercal v}x \right) =2v^\intercal x-\dfrac{2}{v^\intercal v}v^\intercal vv^\intercal x
        \] 
        Notamos que $v^\intercal v$ es un escalar, así que: \[
        v^\intercal (x+Hx)=2v^\intercal x-\dfrac{2v^\intercal x}{v^\intercal v}v^\intercal v=2v^\intercal x-2v^\intercal x=0
        \] 
        Por lo tanto, $x+Hx$ es ortogonal a  $v$, y pertence al plano.
    \item Probar que  $x-Hx$ es proporcional a  $v$

        Ahora calculamos  $x-Hx$:  \[
        x-Hx=x-\left( x-\dfrac{2vv^\intercal}{v^\intercal v}x \right) =\dfrac{2vv^\intercal}{v^\intercal v}x.
        \] 
        Notamos que $\dfrac{2vv^\intercal}{v^\intercal v}x$ es un múltiplo escalar del vector $v$, porque	  $vv^\intercal$ es una matriz de rango 1 que proyecta sobre $v$. Por lo tanto:  \[
        x-Hx\propto v.
        \] 
        
\end{enumerate}
\item \lb{Calcula la proyección del vector $(2,3,4)$ sobre el subespacio  $\mathrm{Col}(A)$, donde $A=\begin{bmatrix} 
            1 & 1\\ 0 & 1\\ 0 & 0 
\end{bmatrix} $. Hazlo de tres formas distintas: como en el ejemplo 5.17, como en el ejemplo 5.18 y como en el ejemplo 5.21.}

\begin{enumerate}[label=\underline{\arabic*ª forma:}]
    \item \[
    A=\begin{bmatrix} 
        1 & 1 \\
        0 & 1\\
        0 & 0
    \end{bmatrix} 
    \] 
    $\mathrm{Col}(A)=<\overbrace{(1,0,0)}^{u_1},\overbrace{(1,1,0)}^{u_2} > =u$ 

    Calculamos una base ortogonal de $u$

     $\begin{array}{l}
         v_1=u_1\\
         v_2=u_2+\alpha u_1\\
         0=v_1\cdot v_2=u_1\cdot u_2+\alpha\cdot u_1\cdot u_1\longrightarrow \alpha=-\dfrac{u_1\cdot u_2}{u_1\cdot u_1}=-1\\
         v_2=(1,1,0)-(1,0,0)=(0,1,0)\\
         \mathcal{B}=\{v_1=(1,0,0),v_2=(0,1,0)\} \text{ base ortonormal de $u$ }\\
        P_u(e_1)=\dfrac{e_1\cdot u_1}{\|v_1\|}v_1+\dfrac{e_1\cdot v_2}{\|v_2\|}v_2=v_1=(1,0,0)\\
        P_u(e_2)=e_2=(0,1,0)\\
        P_u(e_3)=(e_3\cdot e_1)e_1+(e_3\cdot e_2)e_2=0
     \end{array}$
     \[
     \begin{array}{c}
         M_{C\to C}(P_u)=\begin{bmatrix} 
             1 & 0 & 0\\
             0 & 1 & 0\\
             0 & 0 & 0
         \end{bmatrix}\\
         P_u(v)=\begin{bmatrix} 
             1 & 0 & 0\\
             0 & 1 & 0\\
             0 & 0 & 0
         \end{bmatrix}\begin{bmatrix} 
             2 \\ 3 \\ 4 
         \end{bmatrix}  =\begin{bmatrix} 
         2\\3\\0 
         \end{bmatrix} 
     \end{array}
     \] 
 \item Igual que la 1ª forma.
 \item \[
 \begin{array}{c}
         M_{C\to C}(P_u)=A(A^\intercal A)^{-1}A^\intercal\\
         A^\intercal A=\begin{bmatrix} 
             1 & 0 & 0\\
             1 & 1 & 0
         \end{bmatrix}\begin{bmatrix} 
             1 & 1\\ 0 & 1\\ 0 & 0 
         \end{bmatrix}=\begin{bmatrix} 
             1 & 1\\ 1 & 2 
         \end{bmatrix}\\
         \left[ \begin{array}{cc:cc}
                 1 & 1 & 1 & 0\\
                 1 & 2 & 0 & 1
         \end{array} \right]\xrightarrow{F_2\to F_2-F_1}\left[ \begin{array}{cc:cc}
                 1 & 1 & 1 & 0\\
                 0 & 1 & -1 & 1
         \end{array} \right] \xrightarrow{F_1\to F_1-F_2}\left[ \begin{array}{cc:cc}
                 1 & 0 & 2 & -1\\
                 0 & 1 & -1 & 1
         \end{array} \right]\\
         M_{C\to C}(P_u)=\begin{bmatrix} 
             1 & 1\\ 0 & 1\\0 & 0 
         \end{bmatrix} \begin{bmatrix} 
             2 & -1\\ -1 & 1 
         \end{bmatrix} \begin{bmatrix} 
             1 & 0 & 0\\
             1 & 1 & 0
         \end{bmatrix}=\begin{bmatrix} 
             1 & 1\\ 0 & 1\\ 0 & 0 
         \end{bmatrix}  \begin{bmatrix} 
             1 & -1 & 0\\
             0 & 1 & 0
         \end{bmatrix}=\begin{bmatrix} 
             1 & 0 & 0\\
             0 & 1 & 0\\
             0 & 0 & 0
         \end{bmatrix}  
 \end{array}
 \] 
 
\end{enumerate}
\item \lb{¿Qué combinación lineal de los vectores $(1,2,-1)$ y  $(1,0,1)$ está más "cerca" del vector $(2,1,1)$?}

    \begin{enumerate}[label=Paso \arabic*:]
        \item Definir la combinación lineal

            Sea $x$ la combinación lineal de los vectores: \[
            x=\alpha(1,2,-1)+\beta(1,0,1),
            \] donde $\alpha$ y $\beta$ son escalares. Entonces: \[
            x=(\alpha+\beta,2\alpha,-\alpha+\beta)
            \] 
            Queremos minimizar la distancia entre $x$ y el vector $(2,1,1)$. La distancia es dada por la nomra del vector diferencia:  \[
            \|x-(2,1,1)\|^2=(\alpha+\beta-2)^2+(2\alpha-1)^2+(-\alpha+\beta-1)^2
            \] 
        \item Expresa la función objetivo

            La función objetivo a minimizar es: \[
            f(\alpha,\beta)=(\alpha+\beta-2)^2+(2\alpha-1)^2+(-\alpha+\beta-1)^2.
            \] 
        \item Derivar con respecto a $\alpha$ y $\beta$

            Derivamos $f(\alpha,\beta)$ respecto a $\alpha$ y $\beta$ para encontrar los puntos críticos.

            \[
            \begin{array}{l}
                \frac{\partial f}{\partial \alpha} =2(\alpha+\beta-2)+4(2\alpha-1)-2(\alpha+\beta-1)=2\alpha+\cancel{2\beta}-4+8\alpha-4+2\alpha-\cancel{2\beta}+2=12\alpha-6\\
                \frac{\partial f}{\partial \beta} =2(\alpha+\beta-2)+2(-\alpha+\beta-1)=\cancel{2\alpha}+2\beta-3-\cancel{2\alpha}+2\beta-2=4\beta-6
            \end{array}
            \] 
        \item Resolver el sistema de ecuaciones

            Igualamos las derivadas parciales a cero para encontrar los valores óptimos de $\alpha$ y $\beta$: \[
            \begin{array}{l}
                \frac{\partial f}{\partial \alpha} =0\longrightarrow 12\alpha-6=0\longrightarrow 12\alpha=6\longrightarrow \alpha=\dfrac{1}{2}.\\
                \frac{\partial f}{\partial \beta} =0\longrightarrow 4\beta-6=0\longrightarrow \beta=\dfrac{3}{2}.
            \end{array}
            \] 
        \item Construir la combinación lineal

            Sustituimos $\alpha=\dfrac{1}{2}$ y $\beta=\dfrac{3}{2}$ en la combinación lineal: \[
            x=\alpha(1,2,-1)+\beta(1,0,1)
            \] 
            Expandiendo: \[
            x=\dfrac{1}{2}(1,2,-1)+\dfrac{3}{2}(1,0,1)=\left( \dfrac{1}{2},1,-\dfrac{1}{2} \right) +\left( \dfrac{3}{2},0,\dfrac{3}{2} \right) =\left( \dfrac{1}{2}+\dfrac{3}{2},1+0,-\dfrac{1}{2}+\dfrac{3}{2} \right) =(2,1,1)
            \] 
    \end{enumerate}
\item \lb{Encuentra una base ortonormal $\{u_1,u_2,u_{3}\} $ de $R^3$ tal que $\mathrm{Col}(A)$ sea el subespacio generado por $u_1,u_2$, donde \[
A=\begin{bmatrix} 
    1 & 1\\
    2 & -1\\
    -2 & 4
\end{bmatrix} 
\]¿Cuál de los cuatro subespacios fundamentales de $A$ contiene $u_3$? Calcula la proyección ortogonal de $b^\intercal=(1,2,7)$ sobre $\mathrm{Col}(A)$ y explica por qué esta proyección es una solución aproximada del sistema de ecuaciones $Ax=b$.} 

\begin{enumerate}[label=Paso \arabic*:]
    \item Encontrar una base ortonormal $\{u_1,u_2,u_3\}$ de $\R^3$

\textbf{Encontrar una base para $\mathrm{Col}(A)$}

La columna de $A$, $\mathrm{Col}(A)$, es generada por las columnas de $A$. Sean los vectores columna: \[
v_1=\begin{bmatrix}1\\2\\-2\end{bmatrix}\quad v_2=\begin{bmatrix}1\\-1\\4\end{bmatrix}.
\]
Vamos a aplicar el \textbf{proceso de Gram-Schmidt} para obtener vectores ortogonales y luego normalizarlos.

\begin{enumerate}[label=1.\arabic*)]
    \item Primer vector ortogonal ($u_1$):

Tomamos $v_1$ como el primer vector ortogonal: \[u_1=\dfrac{v_1}{\|v_1\|},\quad \|v_1\|=\sqrt{1^2+2^2+(-2)^2}=\sqrt{9}=3.\]
Entonces: \[u_1=\dfrac{1}{3}\begin{bmatrix}1\\2\\-2\end{bmatrix}=\begin{bmatrix}\frac{1}{3}\\\frac{2}{3}\\-\frac{2}{3}\end{bmatrix}.\]
\item Segundo vector ortogonal ($u_2$):

Proyectamos $v_2$ sobre $u_1$: \[\text{Proyección}_{u_1}(v_2)=\dfrac{v_2^\intercal u_1}{u_1^\intercal u_1}u_1.\]

Calculamos: \[
v_2^\intercal u_1=\begin{bmatrix}1 & -1 & 4\end{bmatrix}\cdot\begin{bmatrix}\frac{1}{3}\\\frac{2}{3}\\-\frac{2}{3}\end{bmatrix}=\dfrac{1}{3}-\dfrac{2}{3}-\dfrac{8}{3}=-3.
\]
Entonces: \[
\text{Proyección}_{u_1}(v_2)=-3\cdot \begin{bmatrix} 
\frac{1}{3} \\\frac{2}{3}\\-\frac{2}{3}
\end{bmatrix} =\begin{bmatrix} 
-1\\-2\\2 
\end{bmatrix} .
\] 
Resta de $v_2$: \[
v_2^{\perp}=v_2-\text{Proyección}_{u_1}(v_2)=\begin{bmatrix} 
1\\-1\\4 
\end{bmatrix} -\begin{bmatrix} 
-1\\-2\\2 
\end{bmatrix} =\begin{bmatrix} 
2\\1\\2 
\end{bmatrix} .
\] 
Normalizamos $v_2^\perp$ para obtener $u_2$: \[
\|v_2^\perp\|=\sqrt{2^2+1^2+2^2}=\sqrt{9} =3 
\] 
Entonces: \[
u_2=\dfrac{1}{3}\begin{bmatrix} 
2\\1\\2 
\end{bmatrix} =\begin{bmatrix} 
\frac{2}{3} \\\frac{1}{3} \\\frac{2}{3}  
\end{bmatrix} .
\] 
\item Tercer vector ortogonal ($u_3$):

    El subespacio generado por $u_3$ debe ser ortogonal a $\mathrm{Col}(A)$. Como $\mathrm{Col}(A)$ tiene dimensión 2, $u_3$ es cualquier vector ortogona a $u_1$ y $u_2$. Una forma práctica es tomar el producto cruz de $u_1$ y $u_2$: \[
    u_3=u_1\times u_2.
    \] 
    Calculamos: \[
    u_3=\begin{vmatrix} 
        \mathbf{i} &\mathbf{j} & \mathbf{k} \\
        \frac{1}{3} & \frac{2}{3} &-\frac{2}{3}\\
        \frac{2}{3} & \frac{1}{3} & \frac{2}{3} 
    \end{vmatrix} =\begin{bmatrix} 
    \frac{4}{9} +\frac{2}{9} \\
	 -\left(\frac{2}{9}+\frac{4}{9}\right)\\
    \frac{1}{9} -\frac{4}{9} 
    \end{bmatrix}=\begin{bmatrix}\frac{2}{3}\\-\frac{2}{3}\\-\frac{1}{3}\end{bmatrix} 
    \] 
\end{enumerate}
\textbf{Subespacio fundamental al que pertence $u_3$} 

El vector $u_3$ es ortogonal a $\mathrm{Col}(A)$, por lo que pertenece al subespacio $\mathrm{Nuc}(A^\intercal)$ (el núcleo de la traspuesta de $A$).
\item Proyección ortogonal de $b=(1,2,7)$ sobre  $\mathrm{Col}(A)$ 

    La proyección de $b$ sobre  $\mathrm{Col}(A)$ es: \[
    \mathrm{Proj}_{\mathrm{Col}(A)}(b)=Pb,
    \] 
    donde $P=A(A^\intercal A)^{-1} A^\intercal$ es la matriz de proyección. Calculamos $P$:  \[
    P=\begin{bmatrix}
1 & 1 \\ 2 & -1 \\ -2 & 4  
    \end{bmatrix} \left( \begin{bmatrix} 
        1 & 2 & -2\\
        1 & -1 & 4
    \end{bmatrix} \begin{bmatrix} 
        1 & 1\\ 2 & -1\\ -2 & 4 
    \end{bmatrix}  \right)^{-1} \begin{bmatrix} 
        1 & 2 & -2\\
        1 & -1 & 4
    \end{bmatrix} =\begin{bmatrix} 
        \frac{1}{3} & \frac{2}{9} \\
        \frac{1}{3} & \frac{1}{9} \\
        0 & \frac{2}{3} 
    \end{bmatrix} \begin{bmatrix} 
        1 & 2 & -2\\
        1 & -1 & 4
    \end{bmatrix} =\begin{bmatrix} 
        \frac{5}{9} & \frac{4}{9} & \frac{2}{9} \\
        \frac{4}{9} & \frac{5}{9} & -\frac{2}{9} \\
        \frac{2}{9} & -\frac{2}{9} & \frac{8}{9} 
    \end{bmatrix} 
    \] 

    $\begin{aligned}(A^\intercal A)^{-1}=\left( \begin{bmatrix} 
        1 & 2 & -2\\
        1 & -1 & 4
    \end{bmatrix} \begin{bmatrix} 
        1 & 1\\ 2 & -1\\ -2 & 4 
    \end{bmatrix}  \right)^{-1}&=\left(\begin{bmatrix}9 & -9\\ -9 & 18\end{bmatrix}\right)^{-1}=\left[ \begin{array}{cc:cc}
    9 & -9  & 1 & 0\\
    -9 & 18 & 0 & 1
    \end{array} \right]\xrightarrow{F_2\to F_2+F_1}\\ & \left[ \begin{array}{cc:cc}
    9 & -9 & 1 & 0\\
    0 & 9 & 1 & 1\\
\end{array} \right]\xrightarrow{F_1\to F_1+F_2}=\left[ \begin{array}{cc:cc}
    9 & 0 & 2 & 1\\
    0 & 9 & 1 & 1
\end{array} \right]\xrightarrow[F_2\to \frac{1}{9} F_2]{F_1\to \frac{1}{9} F_1}\\ 
& 	\left[ \begin{array}{cc:cc}
    1 & 0 & \frac{2}{9} & \frac{1}{9} \\
    0 & 1 & \frac{1}{9} & \frac{1}{9}  
\end{array} \right]\longrightarrow (A^\intercal A)^{-1}=\begin{bmatrix} 
    \frac{2}{9} & \frac{1}{9} \\
    \frac{1}{9} & \frac{1}{9} 
\end{bmatrix}\end{aligned}$

La proyección ortogonal del vector $b=(1,2,7)$ sobre  $\mathrm{Col}(A)$ es: \[
Pb=\begin{bmatrix} 
        \frac{5}{9} & \frac{4}{9} & \frac{2}{9} \\
        \frac{4}{9} & \frac{5}{9} & -\frac{2}{9} \\
        \frac{2}{9} & -\frac{2}{9} & \frac{8}{9} 
\end{bmatrix} \begin{bmatrix} 
1\\2\\7 
\end{bmatrix} =\begin{bmatrix} 
3\\0\\6 
\end{bmatrix} 
\] 
La proyección $\mathrm{Proj}_{\mathrm{Col}(A)}(b)$ es el vector en $\mathrm{Col}(A)$ más cercano a $b$. Por lo tanto, si no existe un solución exacta para el sistema  $Ax=b$ (porque $b$ no pertence a  $\mathrm{Col}(A)$), entonces la proyección ortogonal de $b$ sobre $\mathrm{Col}(A)$ es la mejor aproximación.
\end{enumerate}
\end{enumerate}
\end{document}
