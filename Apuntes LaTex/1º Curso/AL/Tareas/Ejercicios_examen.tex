\begin{center}
	\large\textbf{\rc{Ejercicios Tipo Examen}}
\end{center}
\begin{enumerate}[label=\color{red}\textbf{\arabic*)}, leftmargin=*]
	\item \lb{En una red eléctrica se tienen dos fuentes de tensión $\vec{V}_1$ y
$\vec{V}_2$, siendo $\vec{V}_2=5_{45^\circ}$, esto es, el número complejo de
módulo 5 y argumento $45^\circ$. La ley de Ohm conduce al sistema de ecuaciones
lineales $\vec{V}=R\vec{I}$, donde \[ \vec{V}=\begin{bmatrix}
			\vec{V}_1 \\
			0 \\
			\vec{V}_2
		\end{bmatrix},\qquad R=\begin{bmatrix}
			1+\jm & -5\jm & 0\\
			-5\jm & 0 & -3 \\
			0 & -3& 1
		\end{bmatrix}\quad\mathrm{e}\quad\vec{I}=\begin{bmatrix}
			\vec{I}_1 \\
			\vec{I}_2 \\
			\vec{I}_3
		\end{bmatrix}.\]Calcula el valor que debe tomar $\vec{V}_1$ de modo que
$\vec{I}_2$ sea igual a cero.}

	Por la regla de Cramer se tiene que \[ \vec{I}_2=\dfrac{\begin{bmatrix}
				1+\jmath & \vec{V}_1 & 0\\
				-5\jmath & 0 & -3 \\
				0& \vec{V}_2 & 1
			\end{bmatrix}}{|R|} \] Por tanto, $\vec{I}_2=0$ si y sólo si \[
		\begin{array}{l}
			0=\begin{bmatrix}
				1+\jmath & \vec{V}_1& 0\\
				-5\jmath & 0& -3 \\
				0& 5_{45^\circ} & 1
			\end{bmatrix}=\begin{bmatrix}
				\sqrt{2}_{45^\circ} & \vec{V}_1& 0 \\
				5_{-90^\circ} & 0& 3_{180^\circ} \\
				0 & 5_{45^\circ} & 1_{0^\circ}
			\end{bmatrix} \\
			\begin{rcases}
				|1+j|=\sqrt{1^2+1^2}=\sqrt{2} \\
				\theta =\arctan\dfrac{1}{1}=45^\circ
			\end{rcases}\longrightarrow 1+j=\sqrt{2}_{45^\circ}\\
			-5\jmath=5(-\jmath)=5_{-90^\circ}=5_{270^\circ}\\
			-3=3_{180^\circ}
		\end{array} \] Hemos tomado el argumento principal en $[0,360^\circ[.$ Así:

	$0=\begin{bmatrix}
			\sqrt{2}_{45^\circ} & \vec{V}_1& 0 \\
			5_{270^\circ }& 0& 3_{180^\circ} \\
			0 & 5_{45^\circ} & 1_{0^\circ}
	
\end{bmatrix}=-(5_{45^\circ}\cdot3_{180^\circ}\cdot\sqrt{2}_{45^\circ}+1\cdot5_{270^\circ}\cdot\vec{V}_1)=-15\sqrt{2}_{270^\circ}-5_{270^\circ}\cdot\vec{V}_1$

	Despejando: \[
\vec{V}_1=\dfrac{-15\sqrt{2}_{270^\circ}}{5_{270^\circ}}=\dfrac{15\sqrt{2}_{270^\circ}\cdot1_{180^\circ}}{5_{270^\circ}}=3\sqrt{2}_{180^\circ}=\bboxed{-3\sqrt{2}}
	\]
	\item \lb{Sea \[ Q=\begin{bmatrix}
			a & b \\
			c & d
		\end{bmatrix} \] una matriz ortogonal con determinante $|Q|=1$. Consideremos
	la norma matricial \[
		\|Q_2\|=\underset{x\in\R^2,x\neq0}{\max}\dfrac{\|Qx\|_2}{\|x\|_2}, \] donde
	$\|v\|_2^2=v_1^2+v_1^2$ para todo $v=[v_1,v_2]\in\R^2$. Se pide:}
	\begin{enumerate}[label=\color{red}\alph*)]
		\item \db{Demuestra que el número de condicionamiento de $Q$, para la norma
anterior, es igual a 1.}

		$\mathrm{c}(Q)=\|Q\|_2\cdot\|Q^{-1}\|_2$

		Recordemos que este tipo de matrices tienen la forma $Q=\begin{bmatrix}
				a& b \\
				-b & a
			\end{bmatrix}$ con $a^2+b^2=1$.

		También se tiene que \[ Q^{-1}=Q^\intercal=\begin{bmatrix}
				a & -b \\
				b & a
			\end{bmatrix} \]Por tanto:
		\[ \begin{aligned}
				\|Q\|_2 & =\underset{\begin{array}{c}
						 x\in\R^2\\
						 x\neq0
					
\end{array}}{\max}\dfrac{\|Qx\|_2}{\|x\|_2}=\underset{\begin{array}{c}
x\in\R^2\\
x\neq0
\end{array}}{\max}\dfrac{\left\|\begin{bmatrix}
a& b \\
-b & a
\end{bmatrix}\cdot\begin{bmatrix}
						 x_1 \\
						 x_2
					 \end{bmatrix}\right\|_2}{\sqrt{x_1^2+x_2^2}} \\
				& =\underset{\begin{array}{c}
						 x\in\R^2\\
						 x\neq0
					
\end{array}}{\max}\dfrac{\|(ax_1+bx_2-bx_1+ax_2)\|_2}{\sqrt{x_1^2+x_2^2}} \\
				& =\underset{\begin{array}{c}
						 x\in\R^2\\
						 x\neq0
					
\end{array}}{\max}\dfrac{\sqrt{(ax_1+bx_2)^2+(-bx_1+ax_2)^2}}{\sqrt{x_1^2+x_2^2}}
\\
				&=\underset{\begin{array}{c}
										 x\in\R^2\\
										 x\neq0
									
\end{array}}{\max}\dfrac{\sqrt{a^2x_1^2+b^2x_2^2+2abx_1x_2+b^2x_1^2+a^2x_2^2-2abx_1x_2}}{\sqrt{x_1^2+x_2^2}}\\
				&=\underset{\begin{array}{c}
										 x\in\R^2\\
										 x\neq0
									
\end{array}}{\max}\dfrac{\sqrt{\cancelto{1}{(a^2+b^2)}(x_1^2+x_2^2)}}{\sqrt{x_1^2+x_2^2}}=1
			\end{aligned} \]Análogamente, 
			\[ \begin{aligned}
			\|Q^{-1}\|_2&=\underset{\begin{array}{c}
									 x\in\R^2\\
									 x\neq0
								
\end{array}}{\max}\dfrac{\|Q^{-1}x\|_2}{\|x\|_2}=\underset{\begin{array}{c}
								 						 x\in\R^2\\
								 						 x\neq0
								 					 \end{array}}{\max}\dfrac{\left\|\begin{bmatrix}
								 					 a & -b \\
								 					 b & a
								 					 \end{bmatrix}\cdot\begin{bmatrix}
								 					 x_1\\
								 					 x_2
								 					 \end{bmatrix}\right\|_2}{\|(x_1,x_2)\|_2}\\
									&=\underset{\begin{array}{c}
															 x\in\R^2\\
															 x\neq0
														
\end{array}}{\max}\dfrac{\|(ax_1-bx_2,bx_1+ax_2)\|_2}{\|(x_1,x_2)\|_2}\\
									&=\underset{\begin{array}{c}
															 x\in\R^2\\
															 x\neq0
														
\end{array}}{\max}\dfrac{\sqrt{(ax_1-bx_2)^2+(bx_1+ax_2)^2}}{\sqrt{x_1^2+x_2^2}}\\
									&=\underset{\begin{array}{c}
															 x\in\R^2\\
															 x\neq0
														
\end{array}}{\max}\dfrac{\sqrt{a^2x_1^2+b^2x_2^2-2abx_1x_2+b^2x_1^2+a^2x_2^2+2abx_1x_2}}{\sqrt{x_1^2+x_1^2}}\\
									&=\underset{\begin{array}{c}
															 x\in\R^2\\
															 x\neq0
														
\end{array}}{\max}\dfrac{\sqrt{(a^2+b^2)\cdot(x_1^2+x_2^2)}}{\sqrt{x_1^2+x_2^2}}=1
			\end{aligned} \]Por tanto, \[
\mathrm{c}(Q)=\|Q\|_2\cdot\|Q^{-1}\|_2=1\cdot1=1 \]
		\item \db{Se puede probar que la propiedad anterior es cierta si la matriz $Q$
del apartado anterior es de orden $ n$, siendo $n\ge2$ un número natural.
Supongamos que queremos resolver un sistema lineal de la forma $Qx=b$ y que,
debido a errores de redondeo o de medida, cometemos un error relativo en el
término independiente de aproximadamente $10^{-3}$. Obtén una cota del error
relativo que se cometería en la solución $x$. Se ha de justificar la respuesta.}
		
		Recordemos que \[ \dfrac{\|\triangle
x\|}{\|x\|}\le\mathrm{c}(Q)\dfrac{\|\triangle b\|}{\|b\|} \]Como
$\mathrm{c}(Q)=1$, si $\dfrac{\|\triangle b\|}{\|b\|}=10^{-3}$, entonces \[
\dfrac{\|\triangle x\|}{\|x\|}\le1\cdot10^{-3}=10^{-3}. \]
	\end{enumerate}

	\item \lb{Explica en qué consisten las factorizaciones $LU,\,PLU$ y Cholesky de
una matriz cuadrada $A$. Explica también cómo se resolvería un sistema lineal de
la forma $Ax=b$ usando ambas factorizaciones. Finalmente, supongamos que la
matriz $A$ es simétrica y definida positiva. ¿Cuál de las factorizaciones
usarías para resolver el sistema $Ax=b$? ¿Por qué?}
	
	Sea $A\in M_{m\times n}(\K)$. Una factorización $LU$ de $A$ es una
factorización de la forma \[ A=LU \]con $L\in M_{m\times m}(\K)$ triangular
inferior con unos en la diagonal, y $U$ una matriz triangular superior de tamaño
$m\times n$.
	
	Se llama factorización $PLU$ de $A$ a toda factorización de la forma \[ PA=LU
\]con $L$ y $U$ como antes y $P$ una matriz de permutación.
	
	Se llama factorización Cholesky de $A $ a toda factorización de la forma \[
A=L\cdot L^{\intercal} \]con $L$ una matriz triangular inferior.
	
	Dado el sistema $Ax=b$, si $A$ se factoriza en la forma $A=LU$, entonces \[
LUx=b \] y llamando $z=Ux$, se tiene que el sistema $Ax=b$ es equivalente a los
dos sistemas \[ \begin{rcases}
	Lz=b\\
	Ux=z
	\end{rcases} \]Para el caso Cholesky, donde $A=L\cdot L^{\intercal}$, \[ L\cdot
L^{\intercal}x=z \]y llamando $L^{\intercal}x=z$ se tiene los sistemas \[
\begin{rcases}
	Lz=b\\
	L^{\intercal}x=z
	\end{rcases} \]Si $A$ es simétrica y definida positiva, entonces la factorización Cholesky es posible. 
	
	Debemos usar la factorización Cholesky en este caso ya que su coste computacional para resolver $Ax=b$ es $\dfrac{n^3}{6}$, justo la mitad que si usamos la factorización $LU$.
	\item \lb{Una clase de matrices que aparecen en varias aplicaciones en Ciencia
de Datos (por ejemplo, en el famoso PageRank de Google) son las llamadas
\textit{matrices de Markov}. Se caracterizan porque todas sus entradas son no
negativas y además la suma de las entradas de cada columna siempre da como
resultado 1. La siguiente matriz es un ejemplo de matriz de Markov: \[
			M=\begin{bmatrix}
				\frac{1}{2} & \frac{1}{3} & \frac{1}{4} \\
				\frac{1}{2} & \frac{1}{3} & \frac{1}{4} \\
				0 & \frac{1}{3} & \frac{1}{2}
			\end{bmatrix} \]Se pide:}
	\begin{enumerate}[label=\color{red}\alph*)]
		\item \db{Encuentra matrices $P$ y $Q$ de modo que $B=PMQ$, con $B$ una matriz
por bloques que tiene a la identidad $I_r$ en el primer bloque, y en el resto de
bloques vale cero.}

Para obtener la factorización pedida empezamos haciendo operaciones elementales filda de la siguiente forma:

$\left[\begin{array}{ccc:ccc}
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} & 1 & 0 & 0 \\ 
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} & 0 & 1 & 0 \\ 
0 & \frac{1}{3} & \frac{1}{2} & 0 & 0 & 1
\end{array} \right]\xrightarrow{F_2\to F_2-F_1}\left[\begin{array}{ccc:ccc}
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} & 1 & 0 & 0 \\ 
0 & 0 & 0 & -1 & 1 & 0 \\ 
0 & \frac{1}{3} & \frac{1}{2} & 0 & 0 & 1
\end{array} \right]\xrightarrow{F_2\longleftrightarrow F_3}\linebreak\left[\begin{array}{ccc:ccc}
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} & 1 & 0 & 0 \\ 
0 & \frac{1}{3} & \frac{1}{2} & 0 & 0 & 1 \\ 
0 & 0 & 0 & -1 & 1 & 0
\end{array} \right]\xrightarrow{F_1\to F_1-F_2}\left[\begin{array}{ccc:ccc}
\frac{1}{2} & 0 & -\frac{1}{4} & 1 & 0 & -1 \\ 
0 & \frac{1}{3} & \frac{1}{2} & 0 & 0 & 1 \\ 
0 & 0 & 0 & -1 & 1 & 0
\end{array} \right]$\[P=\begin{bmatrix}
1 & 0 & -1 \\ 
0 & 0 & 1 \\ 
-1 & 1 & 0
\end{bmatrix} \]Hacemos ahora operaciones elementales columna:

$\left[\begin{array}{ccc}
\frac{1}{2} & 0 & -\frac{1}{4} \\ 
0 & \frac{1}{3} & \frac{1}{2} \\ 
0 & 0 & 0 \\ \hdashline
1 & 0 & 0 \\ 
0 & 1 & 0 \\ 
0 & 0 & 1
\end{array} \right]\xrightarrow{C_3\to C_3+\frac{1}{2}C_1}\left[\begin{array}{ccc}
\frac{1}{2} & 0 & 0 \\ 
0 & \frac{1}{3} & \frac{1}{2} \\ 
0 & 0 & 0 \\ \hdashline
1 & 0 & \frac{1}{2} \\ 
0 & 1 & 0 \\ 
0 & 0 & 1
\end{array} \right]\xrightarrow{C_3\to C_3-\frac{3}{2}C_2}\left[\begin{array}{ccc}
\frac{1}{2} & 0 & 0 \\ 
0 & \frac{1}{3} & 0 \\ 
0 & 0 & 0 \\ \hdashline
1 & 0 & \frac{1}{2} \\ 
0 & 1 & -\frac{3}{2} \\ 
0 & 0 & 1
\end{array} \right]\xrightarrow[C_2\to3C_2]{C_1\to 2C_1}\left[\begin{array}{ccc}
1 & 0 & 0 \\ 
0 & 1 & 0 \\ 
0 & 0 & 0 \\ \hdashline
2 & 0 & \frac{1}{2} \\ 
0 & 3 & -\frac{3}{2} \\ 
0 & 0 & 1
\end{array} \right]$ \[Q=\begin{bmatrix}
2 & 0 & \frac{1}{2}\\
0 & 3 & -\frac{3}{2}\\
' & 0 & 1
\end{bmatrix}\]

Por tanto:\[\underbrace{\left[\begin{array}{cc|c}
1 & 0 & 0\\
0 & 1 & 0\\ \hline
0 & 0 & 0
\end{array}\right] }_{B}=\underbrace{\begin{bmatrix}
1 & 0 & -1 \\ 
0 & 0 & 1 \\ 
-1 & 1 & 0
\end{bmatrix} }_{P}\cdot\underbrace{\begin{bmatrix}
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} \\ 
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} \\ 
0 & \frac{1}{3} & \frac{1}{2}
\end{bmatrix} }_{M}\cdot\underbrace{\begin{bmatrix}
2 & 0 & \frac{1}{2} \\ 
0 & 3 & -\frac{3}{2} \\ 
0 & 0 & 1
\end{bmatrix} }_{Q} \]
		\item \db{¿Cuál es el rango de $M$?}

		El rango de $M$ es 2.
		\item \db{Resuleve el sistema lineal $Mx=x$, donde
		$x=[x_1,x_2,x_3]^{\intercal}$ es la incógnita.}
		
		$\begin{bmatrix}
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} \\ 
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} \\ 
0 & \frac{1}{3} & \frac{1}{2}
\end{bmatrix}\cdot\begin{bmatrix}
x_1\\
x_2\\
x_3
\end{bmatrix}\begin{bmatrix}
x_1\\
x_2\\
x_3
\end{bmatrix} $

$\left.\begin{array}{r}
\dfrac{1}{2}x_1+\dfrac{1}{3}x_2+\dfrac{1}{4}x_3=x_1\\
\dfrac{1}{2}x_1+\dfrac{1}{3}x_2+\dfrac{1}{4}x_3=x_2\\
\dfrac{1}{3}x_2+\dfrac{1}{2}x_3=x_3
\end{array}\right\}$

De las 2 primeras ecuaciones se tiene que $x_1=x_2$ y la tercera ecuación se escribe en la forma más sencilla \[ \dfrac{1}{3}x_2-\dfrac{1}{2}x_3=0. \]Tenemos pues el sistema homogéneo: \[\setlength{\arraycolsep}{1pt} \left.\begin{array}{rr}
x_1-x_2&=0\\
\dfrac{1}{3}x_2&-\dfrac{1}{2}=0
\end{array}\right\} \]
	\end{enumerate}
\end{enumerate}
