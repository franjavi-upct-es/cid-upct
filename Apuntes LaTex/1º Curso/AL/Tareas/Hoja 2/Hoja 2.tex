\begin{center}
	\large\textbf{\rc{Hoja de ejercicios Tema 2: Vectores, matrices y tensores}}
\end{center}
\begin{enumerate}[label=\color{red}\textbf{\arabic*)}, leftmargin=*]
	\item \lb{Determina la verdad o falses de la siguiente afirmación: si $u_1$ es
		combinación lineal de $u_2$ y $u_3$, entonces $u_3$ es combinación lineal de
		$u_1$ y$u_2$}
	\item \lb{Consideremos los vectores $u=(1,1,0)$ y $v=(0,1,1)$. Encuentra un
		vector $w$ ortogonal a $u$ y $v$. Comprueba que $w$ es ortogonal a cualquier
		combinación lineal de $u$ y $v$. Encuentra ahora un vector que \underline{no}
		sea combinación lineal de $u,\,v$ y comprueba que no es ortogonal a $w$.}
	\item \textcolor{lightblue}{Haz un dibujo de los siguientes subconjuntos de
		$\mathbb{R}^2$: \[ \begin{array}{l}
			\{(x,y)\in\mathbb{R}^2\text{ tal que }\|(x,y)\|_1=1\}\\
			\{(x,y)\in\mathbb{R}^2\text{ tal que }\|(x,y)\|_2=1\}\\
			\{(x,y)\in\mathbb{R}^2\text{ tal que }\|(x,y)\|_\infty=1\}\\
		\end{array} \]}
	
	$\{x,y\in\mathbb{R}^2:\|(x,y)\|_1=1\}$
	
	$\|(x,y)\|_1=|x|+|y|$
	
	\begin{itemize}[label=\color{lightblue}\textbullet, leftmargin=*]
		\item Posibles casos
	\end{itemize}
	
	
	$\textcolor{lightblue}{1)}~x,y\ge0\rightarrow\|(x,y)\|_1=|x|+|y|=x+y=1\rightarrow
	y=-x+1$
	
	\begin{center}
		\begin{tikzpicture}
			\draw[-latex] (-1.25,0) -- (1.25,0) node[below] {$x$};
			\draw[-latex] (0,-1.25) -- (0,1.25) node[right] {$y$};
			\draw[lightblue] (1,-0.15) node[below] {$1$} -- (1,0.15) ;
			\draw[lightblue] (-0.15,1) -- (0.15,1) node[right] {$1$};
			\draw[lightblue] (0,1) -- (1,0);
		\end{tikzpicture}
	\end{center}
	$\textcolor{lightblue}{2)}~x\le0,y\ge0\rightarrow\|(x,y)\|_1=|x|+|y|=-x+y=1\rightarrow
	y=x+1$
	
	\begin{center}
		\begin{tikzpicture}
			\draw[-latex] (-1.25,0) -- (1.25,0) node[below] {$x$};
			\draw[-latex] (0,-1.25) -- (0,1.25) node[right] {$y$};
			\draw[lightblue] (-1,-0.15) node[below] {$-1$} -- (-1,0.15) ;
			\draw[lightblue] (-0.15,1) -- (0.15,1) node[right] {$1$};
			\draw[lightblue] (-1,0) -- (0,1);
		\end{tikzpicture}
	\end{center}
	$\textcolor{lightblue}{3)}~x,y\le0\rightarrow\|(x,y)\|_1=|x|+|y|=-x-y=1\rightarrow
	y=-x-1$
	
	\begin{center}
		\begin{tikzpicture}
			\draw[-latex] (-1.25,0) -- (1.25,0) node[below] {$x$};
			\draw[-latex] (0,-1.25) -- (0,1.25) node[right] {$y$};
			\draw[lightblue] (-1,-0.15) node[below] {$-1$} -- (-1,0.15) ;
			\draw[lightblue] (-0.15,-1) -- (0.15,-1) node[right] {$-1$};
			\draw[lightblue] (-1,0) -- (0,-1);
		\end{tikzpicture}
	\end{center}
	$\textcolor{lightblue}{4)}~x\ge0,y\le0\rightarrow\|(x,y)\|_1=|x|+|y|=x-y=1\rightarrow
	y=x-1$
	
	\begin{center}
		\begin{tikzpicture}
			\draw[-latex] (-1.25,0) -- (1.25,0) node[below] {$x$};
			\draw[-latex] (0,-1.25) -- (0,1.25) node[right] {$y$};
			\draw[lightblue] (1,-0.15) node[below] {$1$} -- (1,0.15) ;
			\draw[lightblue] (-0.15,-1) -- (0.15,-1) node[right] {$-1$};
			\draw[lightblue] (0,-1) -- (1,0);
		\end{tikzpicture}
	\end{center}
	
	En resumen:
	
	\begin{center}
		\begin{tikzpicture}[scale=1.5]
			\draw[-latex] (-1.25,0) -- (1.25,0) node[below] {$x$};
			\draw[-latex] (0,-1.25) -- (0,1.25) node[right] {$y$};
			\draw[lightblue] (-1,-0.15) node[below] {$-1$} -- (-1,0.15) ;
			\draw[lightblue] (1,-0.15) node[below] {$1$} -- (1,0.15) ;
			\draw[lightblue] (-0.15,-1) -- (0.15,-1) node[right] {$-1$};
			\draw[lightblue] (-0.15,1) -- (0.15,1) node[right] {$1$};
			\draw[lightblue] (0,1) -- (1,0) -- (0,-1) -- (-1,0) -- cycle;
		\end{tikzpicture}
	\end{center}
	
	$\{(x,y)\in\mathbb{R}^2:\|(x,y)\|_2=1\},\: \|(x,y)\|_2=\sqrt{x^2+y^2}=1\longleftrightarrow x^2+y^2=1$
	
	\begin{center}
		\begin{tikzpicture}
			\draw (-1.2,0) -- (1.2,0);
			\draw (0,-1.2) -- (0,1.2);
			\draw[lightblue] (0,0) circle (1);
		\end{tikzpicture}
	\end{center}
	
	$\{(x,y)\in\mathbb{R}^2:\|(x,y)\|_\infty=1\}$
	
	$\|(x,y)\|_\infty=\max\{|x|,|y|\}$
	
	\begin{minipage}[l]{0.5\textwidth}
		$\textcolor{lightblue}{\bullet}\quad $Posibles casos
	
	$\textcolor{lightblue}{1)}~x\ge0,y\ge0\quad\|(x,y)\|_\infty=\max\{x,y\}=1$
	
	$\textcolor{lightblue}{2)}~x\le0,y\ge0\quad\|(x,y)\|_\infty=\max\{-x,y\}=1$
	
	$\textcolor{lightblue}{3)}~x\le0,y\le0\quad\|(x,y)\|_\infty=\max\{-x,-y\}=1$
	\end{minipage}\qquad\begin{minipage}[l]{0.5\textwidth}
	\begin{tikzpicture}[baseline=(current bounding box.center)]
		\begin{axis}[axis lines=center, ymin=-2, ymax=2, xmin=-2, xmax=2, width=8cm, height=8cm]
			\addplot[lightblue, domain=-1.2:1.2] {x} node[pos=1, above right] {$y=x$};
			\draw[lightblue] (axis cs:-1,1) rectangle (axis cs:1,-1);
		\end{axis}
	\end{tikzpicture}
	\end{minipage}
	\item \lb{Prueba que $\|u\|_2\le\sqrt{\|u\|_1\cdot\|u\|_\infty}$}
	
	$\begin{array}{l}
		\|u\|_2\le\sqrt{\|u\|_1\cdot\|u\|_\infty},\qquad u=(x_1,x_2,\dots,x_n)\\
		\|u\|_2^2=x_1^2+x_2^2+\cdots+x_n^2\\
		\|u\|_1=|x_1|+|x_2|+\cdots+|x_n|\\
		\|u\|_\infty=\max\{|x_1|,|x_2|,\dots,|x_n|\}\\
		\begin{aligned}
			\|u\|_2^2&=|x_1|\,|x_1|+|x_2|\,|x_2|+\cdots+|x_n|\,|x_n|\\
			
			&\le|x_1|\max\{|x_1|,|x_2|,\dots,|x_n|\}+|x_2|\max\{|x_1|,|x_2|,\dots,|x_n|\}+\cdots+|x_n|\max\{|x_1|,|x_2|,\dots,|x_n|\}\\
			&\le(|x_1|+\cdots+|x_n|)\max\{|x_1|,|x_2|,\dots,|x_n|\}\\
			&=\|u\|_1\cdot\|u\|_\infty
		\end{aligned}
	\end{array}$
	\item \lb{Dos vectores son ortogonales cuando su podructo escalar es cero, pero
		¿qué pasa si su producto es próximo a cero? Sean $x=[1,-0.75]$ e $y=[0.3,0.3]$.
		Calcular el producto escalar $x\cdot y$ y el ángulo que forman. ¿Qué conclusión
		puedes sacar?\\
		Si dos vectores $x,y$ son unitarios, entonces $-1\le x\cdot y\le1$ (¿por
		qué?). En este caso, ¿qué podemos decir si $x\cdot y$ es aproximadamente $-1,1$
		o cero?}
	
	$\|x\|=\|y\|=1\qquad-1\le x\cdot y\le1\qquad$ ¿Por qué?
	
	$-1\le x\cdot y=\|x\|\cdot\|y\|\cos(x,y)=\cos(x,y)\le1$
	
	Si $x\cdot
	y\simeq-1\longrightarrow\qquad$\begin{tikzpicture}[baseline=(current bounding
		box.center)]
		\draw (-1.2,0) -- (1.2,0);
		\draw (0,-0.2) -- (0,1);
		\draw[latex-latex, lightblue, line width=1.5pt] (-1,0)  node[below] {$y$} --
		(1,0) node[below] {$x$};
	\end{tikzpicture} \qquad Paralelos y de sentido contrario
	
	Si $x\cdot y\simeq1\longrightarrow\qquad$\begin{tikzpicture}[baseline=(current
		bounding box.center)]
		\draw (-0.5,0) -- (1.5,0);
		\draw (0,-0.2) -- (0,1.2);
		\draw[-latex, lightblue, line width=1.5pt] (0,0) -- (1,1) node[right] {$y$};
		\draw[-latex, blue, line width=1.5pt] (0,0) -- (0.5,0.5) node[right] {$x$};
	\end{tikzpicture}\qquad Paralelos y del mismo sentido
	
	Si $x\cdot y\simeq0\longrightarrow\qquad$
	Ortogonales\qquad\begin{tikzpicture}[baseline=(current bounding box.center)]
		\draw (-1.2,0) -- (1.2,0);
		\draw (0,-0.2) -- (0,1.2);
		\draw[lightblue, -latex, line width=1.5pt] (0,0) -- (-1,1) node[left] {$y$};
		\draw[lightblue, -latex, line width=1.5pt] (0,0) -- (1,1) node[right] {$x$};
	\end{tikzpicture}
	\item \lb{Sean $u,\,v$ dos vectores unitarios de $\R^n$ que forman un ángulo de
		$60^\circ$. Calcula $\|2u+v\|$.}
	
	\begin{align*}
		\|2u+v\|^2&=(2u+v)\cdot(2u+v)\\
		&=4u\cdot u+2u\cdot v+2v\cdot u+v\cdot v\\
		&=4\underbrace{\|u\|^2}_1+\underbrace{2u\cdot v+2v}_{\lb{(\ast)}}\cdot
		u+\underbrace{\|v\|^2}_1\\
		\lb{(\ast)=}~4u\cdot
		v&=4\underbrace{\|u\|}_1\cdot\underbrace{\|v\|}_1\underbrace{\cos(u,v)}_{\cos60^\circ}
	\end{align*}
	\item \lb{Sean $u,\,v$ dos vectores de $\R^n$ de norma 2 y 3 repectivamente que
		forman un ángulo de $60^\circ$. ¿Qué angulo forman los vectores $u$ y $2u-v$?}
	\item \lb{Calcula $A+B,\,(A+B)^\intercal,AB,BA,(AB)^\intercal,A^\intercal
		B^\intercal$ y $B^\intercal A^\intercal$ para las matrices: \[ A=\begin{bmatrix}
			1 & 0 & 3 \\
			2 & 2 & 3 \\
			3 & 0 & 3
		\end{bmatrix}\qquad\mathrm{y}\qquad B=\begin{bmatrix}
			2 & 1 & 0 \\
			1 & 2 & 0 \\
			0 & 1 & 2
		\end{bmatrix} \]}
	\item  \textcolor{lightblue}{Prueba que no existe ninguna matriz $A$ tal que
		$A^2=\begin{bmatrix}
			0 & 1\\
			0 & 0
		\end{bmatrix}$.}
	
	Por reducción al absurdo, supongamos que existe $A$
	
	$A=\underset{\displaystyle\begin{array}{cc}
			u_1 & u_2
	\end{array}}{\begin{bmatrix}
			a_{11} & a_{12}\\
			a_{21} & a_{22}
	\end{bmatrix}}\begin{array}{c}
		u_1^\intercal \\
		u_2^\intercal 
	\end{array}$
	
	$A\cdot A=$
	
	\begin{wrapfigure}[3]{r}{0.3\textwidth}
		\begin{tikzpicture}[baseline=(current bounding box.center), scale=1.5]
			\draw[-latex] (-1.5,0) -- (1.5,0);
			\draw[-latex] (0,-1.5) -- (0,1.5);
			\draw[-latex, lightblue, line width=1.5] (0,0) -- (-1,0);
			\draw[-latex, lightblue, line width=1.5] (0,0) -- (0,-1);
		\end{tikzpicture}
	\end{wrapfigure}
	
	$u_1^\intercal \cdot v_1=0\rightarrow u_1^\intercal $ y $v_1$ son ortogonales
	
	$u_2^\intercal \cdot v_1=0\rightarrow u_2^\intercal $ y $v_1$ son ortogonales
	
	$u_2^\intercal \cdot v_2=0\rightarrow u_2^\intercal $ y $v_2$ son ortogonales
	
	$\left.\begin{array}{l}
		u_1^\intercal \cdot v_2=1\\
		u_1^\intercal \cdot v_2=u_1^\intercal \cdot\lambda v_1=\lambda u_1^\intercal
		\cdot v_1=0
	\end{array}\right\}$ NO
	\item \lb{¿Es cierta para matrices la igualdad $(A+B)^2=A^2+B^2+2AB$?}
	
	$(A+B)^2=(A+B)\cdot(A+B)=A^2+A\cdot B+b\cdot A+B^2$
	
	Para que fuese cierto, el producto de matrice debería ser conmutativo. Sabemos
	que no lo es. Por ejemplo:\[ \begin{array}{ll}
		A=\begin{bmatrix}
			1 &0\\
			1 & 0
		\end{bmatrix} & B=\begin{bmatrix}
			0 & 1\\
			0 & 1
		\end{bmatrix}\\
		A\cdot B=\begin{bmatrix}
			0 & 1\\
			0 & 1
		\end{bmatrix} & B\cdot A=\begin{bmatrix}
			1 &0 \\
			1 & 0
		\end{bmatrix}
	\end{array} \]
	\item \textcolor{lightblue}{¿Existen matrices reales no nulas $2\times 2$ tales
		que $A\cdot A^\intercal =0$? ¿y si son matrices complejas?}
	
	¿Existen matrices reales no nulas $2\times 2$ tales que $A\cdot A^\intercal
	=0$? ¿Y complejas?
	
	\begin{tikzpicture}
		\node {$A=\begin{bmatrix}
				a_{11} & a_{12}\\
				a_{21} & a_{22}
			\end{bmatrix}$};
		\draw[latex-]  (1.4,0.3) -- (2,0.3) node[right] {$u_1^\intercal $};
		\draw[latex-]  (1.4,-0.5) -- (2,-0.5) node[right] {$u_2^\intercal $};
		\draw[latex-] (-0.2, -0.6) -- (-0.2, -1) node[below] {$u_1$};
		\draw[latex-] (1.1, -0.6) -- (1.1, -1) node[below] {$u_2$};
	\end{tikzpicture}\qquad\begin{tikzpicture}
		\node {$A^\intercal =\begin{bmatrix}
				a_{11} & a_{21}\\
				a_{12} & a_{22}
			\end{bmatrix}$};
		\draw[latex-]  (1.4,0.3) -- (2,0.3) node[right] {$u_1^\intercal $};
		\draw[latex-]  (1.4,-0.5) -- (2,-0.5) node[right] {$u_2^\intercal $};
		\draw[latex-] (-0.2, -0.6) -- (-0.2, -1) node[below] {$u_1$};
		\draw[latex-] (1.1, -0.6) -- (1.1, -1) node[below] {$u_2$};
	\end{tikzpicture}
	
	$A\cdot A^\intercal =\begin{bmatrix}
		u_1^\intercal \\
		u_2^\intercal 
	\end{bmatrix}\cdot\begin{bmatrix}
		u1 & u_2
	\end{bmatrix}=\begin{bmatrix}
		u_1^\intercal \cdot u_1 & u_1^\intercal \cdot u_2\\
		u_2^\intercal \cdot u_1 & u_2^\intercal \cdot u_2
	\end{bmatrix}$
	
	$u_1^\intercal \cdot u_1=\|u_1\|^2=0\rightarrow u_1^\intercal
	=[0,0]=\begin{bmatrix}
		0 & 0\\
		0 & 0
	\end{bmatrix}$
	
	$u_2^\intercal \cdot u_2=\|u_2\|^2=0\rightarrow u_2^\intercal =[0,0]$
	
	$A=\begin{bmatrix}
		z_1 & z_2\\
		z_3 & z_4
	\end{bmatrix}\qquad A^\intercal =\begin{bmatrix}
		z_1 & z_3\\
		z_2 & z_4
	\end{bmatrix}$
	
	$A\cdot A^\intercal =\begin{bmatrix}
		z_1 & z_2\\
		z_3 & z_4
	\end{bmatrix}\cdot\begin{bmatrix}
		z_1 & z_3\\
		z_2 & z_4
	\end{bmatrix}=\begin{bmatrix}
		z1^2+z_2^2 & z_1z_3+z_2z_4\\
		z_2z_1+z_4z_2 & z_3^2+z_4^2
	\end{bmatrix}$
	
	$A=\begin{bmatrix}
		j & 1\\
		j  & 1
	\end{bmatrix}\qquad\begin{array}{ll}
		z_1=j & z_3=j\\
		z_2=1 & z_4=1\\
		\multicolumn{2}{l}{z_1\cdot z_3+z_2\cdot z_4=j^2+1=0 } 
	\end{array}$
	\item \textcolor{lightblue}{Sean $A,B$ matrices tales que $I+AB$ es invertible
		y sea $S$ la inversa de $I+AB$. Prueba que $I+BA$ también es invertible y su
		inversa es $I-BSA$.}
	
	\textcolor{lightblue}{\underline{Hipótesis:} ¿qué es lo que sabemos?}
	
	\boxed{\begin{array}{l}
			(I+AB)\cdot S=I\\
			S(I+AB)=I
	\end{array}}
	
	\textcolor{lightblue}{\underline{Tesis:} lo que queremos probar}
	
	$\begin{array}{l}
		(I+BA)\cdot(I-BSA)\overset{?}{=}I\\
		(I-BSA)\cdot(I+BA)\overset{?}{=}I
	\end{array}$
	
	$\begin{aligned}
		(I+BA)\cdot(I-BSA)&=I-\overline{BSA}+BA-BA\overline{BSA}\overset{?}{=}I\\
		&=I+BA-B(SA+ABSA)\\
		&=I`BA-B\underbrace{(S+ABS)}_{I\text{ por hipótesis}}A\\
		&=I+\cancel{BA}-\cancel{BA}\\
		&=I
	\end{aligned}$
	\item \textcolor{lightblue}{Sea $A$ una matriz $n\times p$ y $B$ una matriz
		$p\times m$. Si llamamos \textbf{flop} a una operación, ya sea una suma, resta,
		multiplicación o división, prueba que para calcular }
	
	$A_{n\times p}\quad B_{p\times m}$
	
	$A\cdot B$ requiere $m\times n(2p-1)$ flops
	
	$\begin{bmatrix}
		a_{11} & \cdots & a_{1p}\\
		\\
		a_{n1} & \cdots & a_{np}
	\end{bmatrix}\cdot\begin{bmatrix}
		b_{11} & \cdots & b_{1m}\\
		\\
		b_{p1} & \cdots & b_{pm}
	\end{bmatrix}$
	
	$\begin{bmatrix}
		1 & 2 & 3
	\end{bmatrix}\cdot\begin{bmatrix}
		4 \\
		5\\
		6
	\end{bmatrix}=1\cdot 4+2\cdot 5+3\cdot 6$
	
	$\begin{array}{l}
		\mathrm{fila}\times\mathrm{columna}= p+p-1=2p-1\\
		\mathrm{fila}\times\text{todas columnas}=m(2p-1)\\
		\text{todas las filas}\times\text{todas columnas}=\boxed{nm(2p-1)}
	\end{array}$
	
	$A_{\underset{n}{10}\times\underset{p}{2}}\qquad
	B_{\underset{p}{2}\times\underset{m}{10}}\qquad C_{10\times10}$
	
	$\underset{\xrightarrow[\mathrm{backward}]{\hspace{2cm}}}{(A\cdot B)_{n\times
			m}\cdot C}=\underset{\xleftarrow[\mathrm{backward}]{\hspace{2cm}}}{A\cdot(B\cdot
		C)_{2\times10}}$
	\item \textcolor{lightblue}{Dadas dos matrices cuadradas $A,B$, se define el
		\textbf{conmutador} de $A,B$ como \[ [A,B]=AB-BA \] Por otra parte, el spin de
		un electrón se suele representar a través de las siguientes tres matrices,
		llamadas matrices de Pauli: \[  \]}
	
	$S_x=\dfrac{1}{2}\hbar\begin{bmatrix}
		0 & 1 \\
		1 & 0
	\end{bmatrix},\:S_y=\dfrac{1}{2}\hbar\begin{bmatrix}
		0&-j\\
		j&0
	\end{bmatrix},\:S_z=\dfrac{1}{2}\hbar\begin{pmatrix}
		1 & 0\\
		0 & -1
	\end{pmatrix}$ matrices de Pauli
	
	$\hbar=\dfrac{h}{2\pi},\: h$ constante de Plank
	
	$\begin{array}{l}
		[S_x, S_y] = \hbar
		S_z[S_x,S_y]=S_xS_y-S_yS_x=\dfrac{1}{4}\hbar^2\begin{bmatrix}
			2j & 0\\
			0 & -2j
		\end{bmatrix}=\dfrac{1}{2}\hbar^2j\begin{bmatrix}
			1 & 0\\
			0 & -1
			
		\end{bmatrix}=j\hbar{\color{lightblue}\underbracket[1pt]{\color{black}\dfrac{1}{2}\hbar\begin{bmatrix}
					1 &0 \\
					0  &-1
			\end{bmatrix}}_{\displaystyle S_z}}\\
		S_xS_y=\dfrac{1}{2}\hbar\begin{bmatrix}
			0 & 1\\
			1 & 0
		\end{bmatrix}\cdot\dfrac{1}{2}\hbar\begin{bmatrix}
			0 & -j\\
			j & 0
		\end{bmatrix}=\dfrac{1}{4}\hbar^2\begin{bmatrix}
			j & 0\\
			0 & -j
		\end{bmatrix}\\
		S_yS_x=\dfrac{1}{2}\hbar\begin{bmatrix}
			0 & -j\\
			j & 0
		\end{bmatrix}\cdot\dfrac{1}{2}\hbar\begin{bmatrix}
			0 & 1\\
			1 & 0
		\end{bmatrix}=\dfrac{1}{4}\hbar^2\begin{bmatrix}
			-j & 0\\
			0 & j
		\end{bmatrix}
	\end{array}$
	\item \lb{Si $A$ es una matriz simétrica, ¿son las matrices $B^\intercal
		AB,A+A^\intercal$ y $A-A^\intercal$ simétricas?}
	
	$ \begin{aligned}
		(B^\intercal AB)^\intercal&=(A\cdot B)^\intercal(B^\intercal)^\intercal\\
		&=B^\intercal A^\intercal B\\
		&=B^\intercal AB\\
		&\text{por ser $A$ simétrica}
	\end{aligned}$
	
	Por tanto, $B^\intercal AB$ es simétrica.
	
	$\begin{array}{l}
		
		(A+A^\intercal)^\intercal=A^\intercal+(A^\intercal)^\intercal=A^\intercal+A=A+A^\intercal
		\text{ Si es simétrica}\\
		
		(A-A^\intercal)^\intercal=A^\intercal-(A^\intercal)^\intercal=A^\intercal-A\neq
		A-A^\intercal \text{ No es simétrica}\\
	\end{array}$
	\item \lb{Prueba que si $A$ es una matriz invertible simétrica, entonces
		$A^{-1}$ es también simétrica.}
	
	$(A^{-1})^\intercal=(A^\intercal)^{-1}=\{\text{$A$ simétrica}\}=A^{-1}$
	\item \lb{Sean $u_1,\dots,u_m$ vectores de $\K^n$ y supongamos que para ciertos
		escalares $x_1,\dots,x_m$ se tiene $x_1u_1+\cdots+x_mu_m=0$. Expresa esta última
		igualdad en forma matricial.}
	
	$x_1u_1+\cdots+x_mu_m=0\longleftrightarrow Ax=0$ donde $A=\begin{bmatrix}
		u_1 & u_2 &  \cdots & u_m
	\end{bmatrix}, X=\begin{bmatrix}
		x_1\\
		x_2\\
		\vdots\\
		x_m
	\end{bmatrix}$
	\item \lb{Sean $u,v$ dos vectores no nulos vistos como matrices columna
		$n\times1$. Observa que $1+v^\intercal u$ es un escalar, que suponemos no nulo.
		Prueba que la matriz $I+u\,v^\intercal$ es no singular y su inversa es \[
		(I+u\,v^\intercal)^{-1}=I-\dfrac{u\,v^\intercal}{1+v^\intercal u} \]}
	
	$\begin{array}{l}
		u=\begin{bmatrix}
			u_1\\
			\vdots\\
			u_m
		\end{bmatrix}\qquad v=\begin{bmatrix}
			v_1\\
			\vdots\\
			v_n
		\end{bmatrix}\\
		v^\intercal\cdot u=\begin{bmatrix}
			v_1 & \cdots & v_n
		\end{bmatrix}\cdot\begin{bmatrix}
		u_1\\
		\vdots\\
		u_n
		\end{bmatrix}\\
		I+u\,v^\intercal\in M_{n\times n}\\
		\begin{aligned}
			\left(I-\dfrac{u\,v^\intercal}{1+v^\intercal u}\right)(I+u\,v^\intercal)&=I+u\,v^\intercal-\dfrac{u\,v^\intercal}{1+v^\intercal u}-\dfrac{u\,v^\intercal}{1+v^\intercal u}\cdot u\,v^\intercal\\
			&=I+u\,v^\intercal-\dfrac{u\,v^\intercal}{1+v^\intercal u\cdot u\cdot v^\intercal}\\
			&=I+u\,v^\intercal-\dfrac{(u+u\cdot v^\intercal\cdot u)v^\intercal}{1+v^\intercal u}\\
			&=I+u\,v^\intercal-\dfrac{u\cancel{(1+v^\intercal u)}\cdot v^\intercal}{\cancel{1+v^\intercal}}\\
			&=I+u\,v^\intercal-u\,v^\intercal=I
		\end{aligned}
	\end{array}$
	
	De igual manera se prueba que \[ (I+u\,v^\intercal)\cdot\left(I-\dfrac{u\,v^\intercal}{1+v^\intercal u}\right)=I \]
	\item \lb{Sea $A$ la matriz dada por bloques \[ A=\begin{bmatrix}
			A_{11} & A_{12}\\
			A_{21} & A_{22}
		\end{bmatrix} \] con $A_{11}$ invertible. Prueba que existen matrices $X,Y$
		tales que \[ A=\begin{bmatrix}
			1 & 0\\
			X & 1
		\end{bmatrix}\cdot\begin{bmatrix}
			A_{11} & 0\\
			0 & S
		\end{bmatrix}\cdot\begin{bmatrix}
			I & Y\\
			0 & I
		\end{bmatrix} \] donde $S=A_{22}-A_{21}A_{11}^{-1}A_{12}$ e $I$ es la matriz
		identidad del tamaño adecuado (la matriz $S$ se denomina \textbf{complemento de
			Schur} de $A_{11}$).}
		
		$\begin{bmatrix}
			i  & 0\\
			X & I
		\end{bmatrix}\cdot\begin{bmatrix}
		A_{11} & 0\\
		0 & S
		\end{bmatrix}\cdot\begin{bmatrix}
		I & Y\\
		0 & I
		\end{bmatrix}=\begin{bmatrix}
		A.11 & 0 \\ 
		XA_{11} & S
		\end{bmatrix}\cdot\begin{bmatrix}
		I & Y \\ 
		0 & I
		\end{bmatrix}=\begin{bmatrix}
		A_{11} & A_{11}Y \\ 
		XA_{11} & XA_{11}Y+S
		\end{bmatrix} $
		
		$\begin{array}{l}
		A_{11}Y=A_{12}\longrightarrow Y=A_{11}^{-1}A_{12}\\
		XA_{11}=A_{21}\longrightarrow X=A_{21}A_{11}^{-1}\\
		\begin{aligned}
			A_{22}=XA_{11}Y+S&=A_{21}\underbrace{A_{11}^{-1}A_{11}}_1A_{11}^{-1}A_{12}+A_{22}-A_{21}A_{11}^{-1}A_{12}\\
			&=A_{21}A_{11}^{-1}A_{12}+A_{22}-A_{21}A_{11}^{-1}A_{12}\\
			&=A_{22}
		\end{aligned}
		\end{array}$
	\item \lb{Expresa la matriz $AB$ como suma de matrices de rango 1, donde \[
		A=\begin{bmatrix}
			2 & -1 & 3 \\
			2 & 1 & 4
		\end{bmatrix},\qquad B=\begin{bmatrix}
			1 & 2 & 3 \\
			0 & 1 & 4 \\
			1 & 0 & 5
		\end{bmatrix} \]}
	
	$A=\begin{bmatrix}
		1 & -1 & 3 \\
		2 & 1 & 4
	\end{bmatrix}_{2\times3},\qquad B=\begin{bmatrix}
		1 & 2 & 3 \\
		0 & 1 & 4 \\
		1 & 0 & 5
	\end{bmatrix}$
	
	$A\cdot B$ como suma de matrices de rango 1. 
	
	$A\cdot B_{2\times3}=v_1u_1^\intercal +v_2u_2^\intercal +v_3u_3^\intercal
	=\begin{bmatrix}
		1 & 2 & 3 \\
		2 & 4 & 6
	\end{bmatrix}+\underset{\begin{bmatrix}
			-1 \\
			1
		\end{bmatrix}\begin{bmatrix}
			0 & 1 & 4
	\end{bmatrix}}{\begin{bmatrix}
			0 & -1 & -4 \\
			0 & 1 & 4
	\end{bmatrix}}+\underset{\begin{bmatrix}
			3\\
			4
		\end{bmatrix}\begin{bmatrix}
			1 & 0 & 5
	\end{bmatrix}}{\begin{bmatrix}
			3 & 0 & 15 \\
			4 & 0 & 20
	\end{bmatrix}}$
	\item \lb{Sea
		$u^\intercal=\left[\dfrac{1}{\sqrt{2}},\:0,\:\dfrac{1}{\sqrt{2}}\right],
		\:v^\intercal=\left[-\dfrac{1}{\sqrt{3}},\:\dfrac{1}{\sqrt{3}},\:\dfrac{1}{\sqrt{3}}\right]$
		y $w^\intercal=[a,b,c]$. Halla $a,b,c$ para que la matriz $Q=[u,v,w]$ sea
		ortogonal de determinante 1.}
		
		$\begin{array}{l}
			u^\intercal=\left[\dfrac{1}{\sqrt{2}},\:0,\:\dfrac{1}{\sqrt{2}}\right]\\
			v^\intercal=\left[-\dfrac{1}{\sqrt{3}},\:\dfrac{1}{\sqrt{3}},\:\dfrac{1}{\sqrt{3}}\right]\\
			w^{\intercal}=[a,\:b,\:c]\\
			\begin{aligned}
				0=u^\intercal\cdot w^\intercal&=\left[\dfrac{1}{\sqrt{2}},\:0,\:\dfrac{1}{\sqrt{2}}\right]\cdot[a,\:b,\:c]\\
			&=\dfrac{1}{\sqrt{2}}a+\dfrac{1}{\sqrt{2}}c
			\end{aligned}\\
			\begin{aligned}
				0=v^\intercal\cdot w^\intercal&=\left[-\dfrac{1}{\sqrt{3}},\:\dfrac{1}{\sqrt{3}},\:\dfrac{1}{\sqrt{3}}\right]\cdot[a,\:b,\:c]\\
				&=-\dfrac{1}{\sqrt{3}}a+\dfrac{1}{\sqrt{3}}b+\dfrac{1}{\sqrt{3}}c
			\end{aligned}\\
			0=\begin{vmatrix}
			\dfrac{1}{\sqrt{2}} & 0 & \dfrac{1}{\sqrt{2}} \\ 
			-\dfrac{1}{\sqrt{3}} & \dfrac{1}{\sqrt{3}} & \dfrac{1}{\sqrt{3}} \\ 
			a & b & c
			\end{vmatrix} =\dfrac{c}{\sqrt{2}\sqrt{3}}-\dfrac{b}{\sqrt{2}\sqrt{3}}-\dfrac{a}{\sqrt{2}\sqrt{3}}-\dfrac{b}{\sqrt{2}\sqrt{3}}
		\end{array}$
		
		Se resuelve el sistema:
		
		$\begin{array}{l}
			\left.\begin{array}{rcrcrcr}
		a &  &  & + & c & = & 0 \\ 
		-a & + & b & + & c & = & 0 \\ 
		-a & - & 2b & + & c & = & \sqrt{2}\sqrt{3}
		\end{array} \right\rbrace\begin{array}{l}
		\longrightarrow
		 c=-a\\
		\\
		\longrightarrow 3b=-\sqrt{2}\sqrt{3}\longrightarrow b=-\dfrac{1}{3}\sqrt{2}\sqrt{3}
		\end{array}\\
		2c=-b\longrightarrow c=-\dfrac{b}{2}=\dfrac{\sqrt{2}\sqrt{3}}{2\cdot3}\longrightarrow a=-\dfrac{\sqrt{2}\sqrt{3}}{2\cdot3}
		\end{array}$
\end{enumerate}
