\section{Sistemas de ecuaciones y determinantes}
\subsection{Operaciones elementales en una matriz}
Dada $A\in M_{m\times n}(\mathbb{K})$ llamaremos \textcolor{lightblue}{operaciones elementales} de filas en $A$ a cualquiera de las siguientes operaciones:
\begin{enumerate}[label=\color{lightblue}\arabic*)]
	\item Intercambiar dos filas
	\item Multiplicar una fila por un escalar.
	\item Añadir a una fila otra fila multiplicada por un escalar.
\end{enumerate}
Estas operaciones se pueden llevar a cabo multiplicando $A$ por una determinada matriz que llamaremos \textcolor{lightblue}{elemental}. Hay tres tipos de matrices elementales:
\begin{enumerate}[label=\color{lightblue}\arabic*)]
	\item Matriz de permutación simple $P_{ij}$: se obtiene permutando las filas $\imath$ y $\jmath$ en la identidad.
	
	\Ej 
	\[ \begin{array}{l}
		\begin{bmatrix}
			1 & 0\\
			0 & 1
		\end{bmatrix}\qquad P_{12}=\begin{bmatrix}
		0 & 1\\
		1 & 0
		\end{bmatrix},\qquad A=\begin{bmatrix}
		a_{11} & a_{12}\\
		a_{21} & a_{22}
		\end{bmatrix}\\
		P_{12}\cdot A=\begin{bmatrix}
			0 & 1\\
			1 & 0
		\end{bmatrix}\cdot\begin{bmatrix}
		a_{11} & a_{12}\\
		a_{21} & a_{22}
		\end{bmatrix}=\begin{bmatrix}
		a_{21} & a_{22}\\
		a_{11} & a_{12}
		\end{bmatrix}\\
		\begin{bmatrix}
			a_{11} & a_{12}\\
			a_{21} & a_{22}
		\end{bmatrix}\xrightarrow{F_1\longleftrightarrow F_2}\begin{bmatrix}
		a_{21} & a_{22}\\
		a_{11} & a_{12}
		\end{bmatrix}
	\end{array} \]
	\item Matriz de dilatación $D_s(r)$: se obtiene multiplicando la fila $S$ de la identidad por $r$.
	
	\Ej
	
	$D_2(5)=\begin{array}{cc}
		1 & 0 \\
		0 & 5
	\end{array},\quad D_2(5)\cdot\begin{bmatrix}
	a_{11} & a_{12}\\
	a_{21} & a_{22}
	\end{bmatrix}=\begin{bmatrix}
	1 & 0 \\
	0 & 5
	\end{bmatrix}\cdot\begin{bmatrix}
	a_{11} & a_{12}\\
	a_{21} & a_{22}
	\end{bmatrix}=\begin{bmatrix}
	a_{11} & a_{12}\\
	5a_{21} & 5a_{22}
	\end{bmatrix}$
	\item Matriz de adición $S_{ij}(r)$: se obtiene sumando a la fila $\imath$ la $\jmath$ multiplicada por $r$.
	
	\Ej
	
	$\begin{array}{l}
		S_{12}(2)=\begin{bmatrix}
			1 & 2 \\
			0 & 1
		\end{bmatrix}\\
		\begin{bmatrix}
			1 & 2 \\
			0 & 1
		\end{bmatrix}\cdot\begin{bmatrix}
		a_{11} & a_{12}\\
		a_{21} & a_{22}
		\end{bmatrix}=\begin{bmatrix}
		a_{11}+2a_{21} & a_{12}+2a_{22}\\
		a_{21} & a_{22}
		\end{bmatrix}
	\end{array}$
\end{enumerate}
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Propiedades
\end{itemize}
La matrices elementales son invertibles. Además:
\begin{enumerate}[label=\color{lightblue}\arabic*)]
	\item $P_{ij}^{-1}=P_{ji}$
	\item $D_s(r)^{-1}=D_s\left(\dfrac{1}{r}\right)$
	\item $S_{ij}(r)^{-1}=S_{ij}(-r)$
\end{enumerate}
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Definición (Matriz de permutación)
\end{itemize}
Llamaremos matriz de permutación $P$ a aquella que se expresa como producto de matrices de permutación elementales.

\Ej

$P_{12}=\begin{bmatrix}
	0 & 1\\
	1 & 0
\end{bmatrix}\qquad P_{12}P_{12}=\begin{bmatrix}
0 & 1\\
1 & 0
\end{bmatrix}\cdot\begin{bmatrix}
0 & 1\\
1 & 0
\end{bmatrix}=\begin{bmatrix}
1 & 0\\
0 & 1
\end{bmatrix}$
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Definición (Matrices equivalentes)
\end{itemize}
Se dice que dos matrices $A$ y $B$ son \textcolor{lightblue}{equivalentes} si existen matrices invertibles $P$ y $Q$ de modo que \[ \bboxed{B=P\,A\,Q} \]
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Definición
\end{itemize}
Dada una matriz, se llama \textcolor{lightblue}{pivote} de una fila a la primera entrada (contando de izquierda a derecha) no nula de esa fila.

Se dice que la \textcolor{lightblue}{matriz escalonada} por filas si:
\begin{enumerate}[label=\color{lightblue}\arabic*)]
	\item El pivote de cada fila no nula está estrictamente a la derecha del pivote de la fila anterior.
	\item Las filas nulas, si las hay, son las últimas.
\end{enumerate}
La matriz escalonada reducida por filas si además:
\begin{enumerate}[label=\color{lightblue}\arabic*')]
	\item El pivote de cada fila no nula vale 1.
	\item Cada pivote es el único elemento no nulo de su columna.
\end{enumerate}
\Ej
\[ A=\underbrace{\begin{bmatrix}
		2 & 0 & 0 & 5 \\ 
		0 & 1 & 0 & 2 \\ 
		0 & 3 & 1 & 4
\end{bmatrix} }_{\text{No escalonada}} \qquad B=\underbrace{\begin{bmatrix}
		1 & 2 & 0 & 4 & 5 \\ 
		0 & 0 & -1 & 1 & 5 \\ 
		0 & 0 & 0 & 2 & 2
\end{bmatrix} }_{\text{Escalonada pero no
		reducida}} \qquad C=\underbrace{\begin{bmatrix}
		1 & 0 & 2 & 0 & 5 \\ 
		0 & 1 & 6 & 0 & 2 \\ 
		0 & 0 & 0 & 1 & 4
\end{bmatrix}}_{\text{Escalonada reducida}} \]
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Teorema (Factorización $PAQ$)
\end{itemize}

\begin{wrapfigure}[3]{r}{0.35\linewidth}
	\begin{tikzpicture}
		\node[red, fill=red!10, draw=red, rectangle, line width=1.5, text width=7cm] {\underline{Nota:} La forma de llegar de $A$ a $B$ es utilizando operaciones elementales. Este proceso se llama \textbf{eliminación gaussiana}.};
	\end{tikzpicture}
\end{wrapfigure}

Toda matriz $A$ es equivalente a un matriz de la forma 
\begin{center}
	\begin{tikzpicture}
		\node at (0,0) {$B=\begin{bmatrix}
				Ir &  0 \\ 
				0 & 0
			\end{bmatrix},$};
		\draw (0.4,0.7) -- (0.4,-0.7);
		\draw (-0.2,0) -- (0.9,0);
	\end{tikzpicture}
\end{center}
es decir, existen matrices invertibles $P$ y $Q$ de modo que \[ B=PAQ \]

Al número $r$, es decir, al número de filas no nulas que resultan después de escalonar una matriz se le llama rango de $A$ y se denota $r=\mathrm{rg}(A)$

\Ej

$$A=\begin{bmatrix}
	1 & 2 & -1 & 2 \\ 
	2 & 4 & 1 & 1 \\ 
	3 & 6 & 0 & 3
\end{bmatrix} $$

Hacemos operaciones elementales fila con la matriz.

$(A|I_3)=\left[\begin{array}{cccc:ccc}
	1 & 2 & -1 & 2 & 1 & 0 & 0 \\ 
	2 & 4 & 1 & 1 & 0 & 1 & 0 \\ 
	3 & 6 & 0 & 3 & 0 & 0 & 1
\end{array} \right]\overset{F_2\rightarrow
	F_2-2F_1}{\underset{F_3\rightarrow
		F_3-3F_1}{\xrightarrow{\hspace{1.5cm}}}}\left[\begin{array}{cccc:ccc}
	1 & 2 & -1 & 2 & 1 & 0 & 0 \\ 
	0 & 0 & 3 & -3 & -2 & 1 & 0 \\ 
	0 & 0 & 3 & -3 & -3 & 0 & 1
\end{array} \right]\overset{F_3\rightarrow
	F_3-F_2}{\xrightarrow{\hspace{1.5cm}}}$

$\left[\begin{array}{cccc:ccc}
	1 & 2 & -1 & 2 & 1 & 0 & 0 \\ 
	0 & 0 & 3 & -3 & -2 & 1 & 0 \\ 
	0 & 0 & 0 & 0 & -1 & -1 & 1
\end{array} \right]\overset{F_2\rightarrow
	\frac{1}{3}F_2}{\xrightarrow{\hspace{1.5cm}}}\left[\begin{array}{cccc:ccc}
	1 & 2 & -1 & 2 & 1 & 0 & 0 \\ 
	0 & 0 & 1 & -1 & -\textstyle\frac{2}{3} & \textstyle\frac{1}{3}
	& 0 \\
	0 & 0 & 0 & 0 & -1 & -1 & 1
\end{array} \right]\overset{F_1\rightarrow
	F_1+F_2}{\xrightarrow{\hspace{1.5cm}}}\left[\begin{array}{cccc:ccc}
	1 & 2 & 0 & 1 & \textstyle\frac{1}{3} & \textstyle\frac{1}{3} &
	0 \\
	0 & 0 & 1 & -1 & \textstyle-\frac{2}{3} & \textstyle\frac{1}{3}
	& 0 \\
	0 & 0 & 0 & 0 & -1 & -1 & 1
\end{array} \right]$

Se tiene que 

$$\begin{bmatrix}
	1 & 2 & 0 & 1 \\ 
	0 & 0 & 1 & -1 \\ 
	0 & 0 & 0 & 0
\end{bmatrix}=PA,$$ con $$P=\begin{bmatrix}
	\textstyle\frac{1}{3} & \textstyle\frac{1}{3} & 0 \\ 
	-\textstyle\frac{2}{3} & \textstyle\frac{1}{3} & 0 \\ 
	-1 & -1 & 1	
\end{bmatrix} $$

Ahora realizamos operaciones elementales columna:

$\left[\begin{array}{cccc}
	1 & 2 & 0 & 1 \\ 
	0 & 0 & 1 & -1 \\ 
	0 & 0 & 0 & 0 \\ \hdashline
	1 & 0 & 0 & 0 \\ 
	0 & 1 & 0 & 0 \\ 
	0 & 0 & 1 & 0 \\ 
	0 & 0 & 0 & 1
\end{array}\right]\overset{C_2\longleftrightarrow
	C_3}{\xrightarrow{\hspace{1.5cm}}}\left[\begin{array}{cccc}
	1 & 0 & 2 & 1 \\ 
	0 & 1 & 0 & -1 \\ 
	0 & 0 & 0 & 0 \\ \hdashline
	1 & 0 & 0 & 0 \\ 
	0 & 1 & 0 & 0 \\ 
	0 & 0 & 1 & 0 \\ 
	0 & 0 & 0 & 1
\end{array}\right]\overset{C_3\rightarrow
	C_3-2C_1}{\underset{C_4\rightarrow
		C_4-C_1}{\xrightarrow{\hspace{1.5cm}}}}\left[\begin{array}{cccc}
	1 & 0 & 0 & 0 \\ 
	0 & 1 & 0 & 0 \\ 
	0 & 0 & 0 & 1 \\ 
	\hdashline
	1 & 0 & -2 & -1 \\ 
	0 & 1 & 0 & 0 \\ 
	0 & 0 & 1 & 0 \\ 
	0 & 0 & 0 & 1
\end{array}\right] $

Se tiene que $Q=\begin{bmatrix}
	1 & 0 & -2 & -1 \\ 
	0 & 0 & 1 & 0 \\ 
	0 & 1 & 0 & 1 \\ 
	0 & 0 & 0 & 1
\end{bmatrix} $ \[ \left[\begin{array}{cc|cc}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\ \hline
0 & 0 & 0 & 0
\end{array}\right]=PAQ \]$\mathrm{rg}(A)=2$
\subsection{Sistemas de ecuaciones}
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Definición
\end{itemize}
Un sistema lineal de $m$-ecuaciones con $n$-incógnitas es un sistema del tipo: \[ (\ast)\begin{cases}
	a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n=b_1\\
	a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n=b_2\\ \hdashline
	a_{m1}x_1+a_{m2}x_2+\cdots+a_{mn}x_n=b_m
\end{cases} \] que en forma matricial escribimos como \[ (\ast)\qquad Ax=n \] donde:
\begin{itemize}[label=\color{lightblue}\textbullet]
	\item $A=(a_{ij})\in M_{m\times n}(\R)$ es la matriz del sistema.
	\item $b=(b_i)\in M_{m\times n}(\R)$ es el término independiente.
	\item $x=(x_j)$ es el vector incógnita.
\end{itemize}
El sistema $(\ast)$ se dice:
\begin{itemize}[label=\color{lightblue}\textbullet]
	\item Homogéneo si $b=0$
	\item Incompatible: si no tiene solución.
	\item Compatible determinado: si tiene una única solución.
	\item Compatible indeterminado: infinitas soluciones.
\end{itemize}
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue} Teorema (Rouché-Frobenius)
\end{itemize}
Consideremos el sistema $(\ast)$ y sea $(A|b)$ la llamada matriz. Entonces:
\begin{enumerate}[label=\color{lightblue}\arabic*)]
	\item Si $\mathrm{rg}(A)=\mathrm{rg}(A|b)=$nº de incógnitas, entonces el sistema $(\ast)$ es compatible determinado. (SCD)
	\item Si $\mathrm{rg}(A)=\mathrm{rg}(A|b)<$nº de incógnitas, entonces $(\ast)$ es compatible indeterminado (SCI). La solución depende de nº de incógnitas$-\mathrm{rg}(A)$ parámetros.
	\item Si $\mathrm{rg}(A)\neq\mathrm{rg}(A|b)$, el sistema $(\ast)$ es incompatible.
\end{enumerate}
\subsubsection{Método de Gauss para la resolución de sistemas lineales}
Consiste en hacer operaciones elementales fila sobre la matriz $(A|b)$ hasta conseguir una matriz escalonada cuyo sistema asociado se resuelva fácilmente.

\Ej

$\begin{cases}
	2x+y+2z+3t=6\\
	x+2y-2z-t=3\\
	4x+5y-2z+t=12
\end{cases}$

$$\begin{aligned}
	(A|b)=&\left[\begin{array}{cccc:c}
	2 & 1 & 2 & 3 & 6 \\
	1 & 2 & -2 & -1 & 3 \\
	4 & 5 & -2 & 1 & 12
\end{array}\right]\xleftrightarrow{F_1\leftrightarrow F_2}\left[\begin{array}{cccc:c}
1 & 2 & -2 & -1 & 3 \\
2 & 1 & 2 & 3 & 6 \\
4 & 5 & -2 & 1 & 12
\end{array}\right]\xrightarrow[F_2\to F_3-4F_1]{F_2\to F_2-2F_1}\\
& \left[\begin{array}{cccc:c}
1 & 2 & -2 & -1 & 3 \\
0 & -3 & 6 & 5 & 0 \\
0 & -3 & 6 & 5 & 0
\end{array}\right]\xrightarrow{F_3\to F_3-F_2}\left[\begin{array}{cccc:c}
1 & 2 & -2 & -1 & 3 \\
0 & -3 & 6 & 5 & 0 \\
0 & 0 & 0 & 0 & 0
\end{array}\right]
\end{aligned}$$
\[ \mathrm{rg}(A)=\mathrm{rg}(A|b)=2<4=\text{nº de incógnitas. SCI} \]
La solución depende de 2 parámetros.
\[ \begin{array}{c}
	\left.\begin{array}{lr}
	t=\lambda & x+2y-2\mu-\lambda=3\\
	z=\mu & -3y+6\mu+5\lambda=0
\end{array}\right\}\\\\

y=2\mu+\dfrac{5}{3}\lambda \\\\

\begin{aligned}
	x=3-2y+2\mu+\lambda & =3-2\left(2\mu+\dfrac{5}{3}\lambda\right)+2\mu+\lambda\\
	&=3-4\mu-\dfrac{10}{3}\lambda+2\mu+\lambda\\
	&=\bboxed{3+2\mu-\dfrac{7}{3}\lambda}
\end{aligned}
\end{array}\]
\subsubsection{Cálculo de la inversa de una matriz mediante eliminación Gaussiana}
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Método
\end{itemize}
Realizar operaciones elementales fila sobre la matriz $(A|I)$ hasta conseguir que a la izquierda aparezca la identidad. A la derecha tendremos $A^{-1}$.

\Ej

$A=\begin{bmatrix}
	1 & 2 & -1 \\
	2 & 4 & 1 \\
	3 & 7 & 0
\end{bmatrix}$

$ \begin{aligned}
	[A|I_3]=&\left[\begin{array}{ccc:ccc}
		1 & 2 & -1 & 1 & 0 & 0 \\
		2 & 4 & 1 & 0 & 1 & 0 \\
		3 & 7 & 0 & 0 & 0 & 1
	\end{array}\right]\xrightarrow[F_3\to F_3-3F_1]{F_2\to F_2-2F_1} \left[\begin{array}{ccc:ccc}
		1 & 2 & -1 & 1 & 0 & 0 \\
		0 & 0 & 3 & -2 & 1 & 0 \\
		0 & 1 & 3 & -3 & 0 & 1
	\end{array}\right]\xleftrightarrow{F_2\leftrightarrow F_3}\\
	&\left[\begin{array}{ccc:ccc}
		1 & 2 & -1 & 1 & 0 & 0 \\
		0 & 1 & 3 & -3 & 0 & 1 \\
		0 & 0 & 3 & -2 & 1 & 0
	\end{array}\right]\xrightarrow{F_3\to\frac{1}{3}F_3}\left[\begin{array}{ccc:ccc}
		1 & 2 & -1 & 1 & 0 & 0 \\
		0 & 1 & 3 & -3 & 0 & 1 \\
		0 & 0 & 1 & -\frac{2}{3} & \frac{1}{3} & 0
	\end{array}\right]\xrightarrow{F_1\to F_1+F_3}\\
	&\left[\begin{array}{ccc:ccc}
	1 & 2 & 0 & \frac{1}{3} & \frac{1}{3} & 0 \\ 
	0 & 1 & 3 & -3 & 0 & 1 \\ 
	0 & 0 & 1 & -\frac{2}{3} & \frac{1}{3} & 0
	\end{array} \right]\xrightarrow{F_2\to F_2-3F_3}\left[\begin{array}{ccc:ccc}
	1 & 2 & 0 & \frac{1}{3} & \frac{1}{3} & 0 \\ 
	0 & 1 & 0 & -1 & -1 & 1 \\ 
	0 & 0 & 1 & -\frac{2}{3} & \frac{1}{3} & 0
	\end{array} \right]\xrightarrow{F_1\to F_1-2F_2}\\
	& \left[\begin{array}{ccc:ccc}
	1 & 0 & 0 & \frac{7}{3} & \frac{7}{3} & -2 \\ 
	0 & 1 & 0 & -1 & -1 & 1 \\ 
	0 & 0 & 1 & -\frac{2}{3} & \frac{1}{3} & 0
	\end{array} \right]
\end{aligned} $
\[ A=\left[\begin{array}{ccc}
\frac{7}{3} & \frac{7}{3} & -2 \\ 
-1 & -1 & 1 \\ 
-\frac{2}{3} & \frac{1}{3} & 0
\end{array} \right] \]
\subsection{Determinantes}
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Definición
\end{itemize}
Sea $A\in M_2(\mathbb{K})$. Se define el determinante de $A$, denotado $|A|$ o $\mathrm{det}(A)$, como \[ \begin{vmatrix}
	a_{11} & a_{12}\\
	a_{21} & a_{22}
\end{vmatrix}=a_{11}a_{22}-a_{21}a_{12}. \]
Si $A\in M_3(\mathbb{K})$, entonces \[ \begin{vmatrix}
	a_{11} & a_{12} & a_{13}\\
	a_{21}  & a_{22} & a_{23}\\
	a_{31} & a_{32} & a_{33}
\end{vmatrix}\begin{aligned}
\\
=&a_{11}a_{22}a_{33}+a_{12}a_{23}a_{31}+a_{21}a_{32}a_{13}\\
&-(a_{31}a_{22}a_{13}+a_{32}a_{23}a_{11}+a_{33}a_{21}a_{12})
\end{aligned} \]
Para matrices de mayor tamaño, el determinante se define de manera recursiva. Veámoslo:
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Definición
\end{itemize}
Sea $A\in M_n(\mathbb{K})$. Se llama \textcolor{lightblue}{menor complementario} del elemento $a_{ij}$ al determinante $(|A_{ij}|)$ de la submatriz $A_{ij}$ que se obtiene eliminando la fila $\imath$ y la columna $\jmath$ de la matriz original $A$.

Se llama \textcolor{lightblue}{adjunto de $a_{ij}$}, denotado $\triangle_{ij}$, al escalar \[ \triangle_{ij}=(-1)^{\imath+\jmath}|A_{ij}|. \]
\Ej
\[ \begin{array}{l}
	A=\begin{bmatrix}
	1 & 2 & 3 & 4 \\
	2 & 3 & 4 & 5 \\
	2 & 0 & 1 & 1 \\
	4 & 3 & 1 & 2
\end{bmatrix}\\\\

A_{23}=\begin{vmatrix}
	1 & 2 & 4 \\
	2 & 0 & 1 \\
	4 & 3 & 2
\end{vmatrix}=8+24-(3+8)=21\\
\triangle_{23}=(-1)^{2+3}A_{23}=-21
\end{array} \]
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Definición
\end{itemize}
Sea $A\in M_n(\mathbb{K})$. El determinante de $A$ se define de manera recurrente como:

$\begin{array}{ll}
	n=1, & |(a)|=a\\
	n>1 & |A|=a_{i1}\triangle_{i1}+a_{i2}\triangle_{i2}+\cdots+a_{in}\triangle_{in}
\end{array}$

\begin{tikzpicture}
	\node[red, draw=red, fill=red!10, rectangle, line width=1.5pt, text width=18.5cm]  {\underline{Nota:} También se puede definir eligiendo una columna. La definición no depende de la fila o columna elegidas.};
\end{tikzpicture}

\Ej
\[ A=\begin{bmatrix}
	1 & 2 & 4\\
	2 & 0 & 1\\
	4 & 3 & 2
\end{bmatrix} \]
Desarrollando por la primera fila:

$\begin{aligned}
	|A|& =(-1)^{1+1}\begin{vmatrix}
		0 & 1\\
		3 & 2
	\end{vmatrix}+2\cdot(-1)^{1+2}\begin{vmatrix}
	2 & 1\\
	4 & 2
	\end{vmatrix}+4\cdot(-1)^{1+3}\begin{vmatrix}
	2 & 0\\
	4 & 3
	\end{vmatrix}\\
	&=-3-2\cdot(4-4)+4\cdot6=21
\end{aligned}$

Desarrollando por la segunda columna:

$2\cdot(-1)^{1+2}\begin{vmatrix}
	2 & 1\\
	4 & 2
\end{vmatrix}+0\cdot|~~|+3\cdot(-1)^{3+2}\begin{vmatrix}
1 & 4\\
2 & 1
\end{vmatrix}=-2(4-4)+0-3\cdot(1-8)=21$
\subsubsection{Propiedades básicas}
\begin{enumerate}[label=\color{lightblue}\arabic*)]
	\item $|A|=|A^\intercal |$
	\item $|A\cdot B|=|A|\cdot|B|$
	\item $A$ es no singular (invertible) si y sólo si $|A|\neq0$. En este caso \[ |A^{-1}|=\dfrac{1}{|A|} \]
\end{enumerate}
\subsubsection{Propiedades de los determinantes y las operaciones elementales}
\begin{enumerate}[label=\color{lightblue}\arabic*)]
	\item $\left|[u_1,\dots,u_j+u_j',\dots,u_n]\right|=\left|[u_1,\dots,u_j,\dots,u_n]\right|+\left|[u_1,\dots,u_j',\dots,u_n]\right|$
	\item $\mathrm{det}[u_1,\dots,\alpha u_j,\dots,u_n]=\alpha\cdot\mathrm{det}[u_1,\dots,u_j,\dots,u_n]$
	\item $\mathrm{det}[u_1,\dots,u_i,\dots,u_j,\dots,u_n]=-\mathrm{det}[u_1,\dots,u_j,\dots,u_i,\dots,u_n]$
	\item Si a una fila (o columna) se le suma otra multiplicada por un escalar, el determinante no cambia.
\end{enumerate}
\Ej

$\begin{vmatrix}
	a & a+1 & a+2 \\
	a+3 & a+4 & a+5 \\
	a+6 & a+7 & a+8
\end{vmatrix}\xrightarrow[F_3\to F_3-F_1]{F-2\to F_2-F_1}\begin{vmatrix}
a & a+1 & a+2 \\
3 & 3 & 3 \\
6 & 6 & 6
\end{vmatrix}=2\cdot\begin{vmatrix}
a & a+1 & a+2 \\
3 & 3 & 3 \\
3 & 3 & 3
\end{vmatrix}\xrightarrow{F_3\to F_3-F_2}2\cdot\begin{vmatrix}
a & a+1 & a+2 \\
3 & 3 & 3 \\
0 & 0 & 0
\end{vmatrix}=0$
\subsubsection{Resolución de sistemas lineales usando determinantes}
Consideremos el sistema $Ax=b$. Si $|A|\neq0$, entonces el sistema tiene una única solución que viene dada por \[ x_i=\dfrac{\triangle_i}{|A|},\qquad\text{(regla de Cramer)} \]donde $\triangle_i$ es el determinante de la matriz que se obtiene sustituyendo la columna $i$-ésima de $A$ por el término independiente $b$.

\Ej

$\begin{rcases}
	x+y+z=1\\
	-x+z=1\\
	x+y-z=1
\end{rcases}\quad|A|=\begin{vmatrix}
1 & 1 & 1 \\
-1 & 0 & 1 \\
1 & 1 & -1
\end{vmatrix}=1-1-(1+1)=-2\neq0.$

$\triangle_1=\begin{vmatrix}
	1 & 1 & 1 \\
	1 & 0 & 1 \\
	1 & 1 & -1
\end{vmatrix}=1+1-(1-1)=2$

$\triangle_2=\begin{vmatrix}
	1 & 1 & 1 \\
	-1 & 1 & 1 \\
	1 & 1 & -1
\end{vmatrix}=-1+1-1-(1+1+1)=-4$

$\triangle_3=\begin{vmatrix}
	1 & 1 & 1 \\
	-1 & 0 & 1 \\
	1 & 1 & 1
\end{vmatrix}=1-1-(1-1)=0$

$x_1=\dfrac{\triangle_1}{|A|}=\dfrac{2}{-2}=-1,\: x_2=\dfrac{\triangle_2}{|A|}=\dfrac{-4}{-2}=2,\: x_3=\dfrac{\triangle_3}{|A|}=0$
\subsubsection{Cálculo de la inversa mediante determinantes}
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Definición (Matriz adjunta)
\end{itemize}
Sea $A\in M_n(\mathbb{K})$. Se llama matriz adjunta de $A$, denotado $\hat{A}$, a la matriz cuyas entradas son los adjuntos de la entrada de $A$, es decir, si $A=(a_{ij})$, entonces $\hat{A}=(\triangle_{ij})$.
\begin{itemize}[label=\color{red}\textbullet, leftmargin=*]
	\item \color{lightblue}Proposición
\end{itemize}
Si $A$ es invertible, entonces \[ A^{-1}=\dfrac{1}{|A|}\hat{A}^\intercal . \]
\Ej

Sea $Q=\begin{bmatrix}
	a & c\\
	b & d
\end{bmatrix}$ ortogonal con $|Q|=+1$. Vamos a calcular su inversa.

$\begin{array}{ll}
	\triangle_{11}=|d|=d & \triangle_{12}=-|b|=-b\\
	\triangle_{21}=-|c|=-c & \triangle_{22}=|a|=a\\
	\hat{Q}=\begin{bmatrix}
		d & -b\\
		-c & a
	\end{bmatrix} & \hat{Q}^\intercal =\begin{bmatrix}
	d & -c\\
	-b & a
	\end{bmatrix}
\end{array}$

Como $|Q|=+1\longrightarrow Q^{-1}=\begin{bmatrix}
	d & -c\\
	-b & a
\end{bmatrix}$

Recordaremos que como $Q$ es ortogonal, $Q^{-1}=Q^\intercal $.

Por tanto \[ \begin{bmatrix}
	d & -c\\
	-b & a
\end{bmatrix}=\begin{bmatrix}
a & b\\
c & d
\end{bmatrix}\longrightarrow\begin{array}{l}
a=d\\
b=-c
\end{array} \]En resumen:\[ Q^{-1}=\begin{bmatrix}
a & b\\
-b & a
\end{bmatrix} \]$|Q|=\begin{bmatrix}
a & -b\\
b & a
\end{bmatrix}=a^2+b^2=1 $