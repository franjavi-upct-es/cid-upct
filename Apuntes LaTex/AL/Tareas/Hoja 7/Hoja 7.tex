\begin{center}
	\textbf{\rc{\large Hoja de ejercicios Tema 7: Vectores y Valores Propios}}
\end{center}

\begin{enumerate}[label=\color{red}\textbf{\arabic*)}, leftmargin=*]
	\item \lb{Halla la matriz real más general posible que tiene como vectores propios los vectores $(1,1)$ y $(1,-1)$}
	
	$A=P^{-1}DP=\dfrac{1}{\sqrt{2}}\begin{bmatrix}
		1 & 1 \\
		1 & -1
	\end{bmatrix}\cdot\begin{bmatrix}
		\lambda_1  & 0\\
		0 & \lambda_2
	\end{bmatrix}\dfrac{1}{\sqrt{2}}\begin{bmatrix}
		1 & 1\\
		1 & -1
	\end{bmatrix}=\dfrac{1}{2}\begin{bmatrix}
		1 & 1\\
		1 & -1
	\end{bmatrix}\cdot\begin{bmatrix}
		\lambda_1 & \lambda_1\\
		\lambda_2 & -\lambda_2
	\end{bmatrix}=\bboxed{\dfrac{1}{2}\begin{bmatrix}
			\lambda_1+\lambda_2 & \lambda_1-\lambda_2\\
			\lambda_1-\lambda_2 & \lambda_1+\lambda_2
	\end{bmatrix}}\lambda_1,\lambda_2\in\R$
	
	$P^{-1}=\dfrac{1}{\sqrt{2}}\begin{bmatrix}
		1 & 1\\
		1 & -1
	\end{bmatrix},\:\lambda_1,\lambda_2\equiv$ valores propios
	
	\item \lb{Dada la matriz $\begin{bmatrix}
			a & 0\\
			b & a
		\end{bmatrix}$ con $b\neq0$, explica por qué no existe ninguna matriz invertible $P$ tal que  para la matriz $P^{-1}AP$ sea una matriz diagonal. ¿Puedes generalizar este resultado para matrices de tamaño mayor?}
	
	$A=\begin{bmatrix}
		a & 0 \\
		b & a
	\end{bmatrix}\:b\neq0$ No existe $P$ invertible tal que $P^{-1}AP=D$
	
	$P_A(\lambda)=\det[A-\lambda_i]=\det\begin{bmatrix}
		a-\lambda & 0 \\
		b & a-\lambda
	\end{bmatrix}=(a-\lambda)^2=0$
	
	Valor propio $\lambda=a$ multiplicidad 2.
	
	$\begin{array}{ll}
		\nuc(A-aI) \qquad\begin{bmatrix}
			0 & 0\\
			b & 0
		\end{bmatrix}\cdot\begin{bmatrix}
			x\\
			y
		\end{bmatrix}=\begin{bmatrix}
			0\\
			0
		\end{bmatrix}\longrightarrow&bx=0\longrightarrow x=0\\
		\dimn(A-aI)=1 & v=(0,1)
	\end{array}$
	
	\underline{Conclusión:} para que $P^{-1}AP=D$ es necesario que la dimensión de los subespacios de vectores propios coincidan con la multiplicidad de los correspondientes valores propios.
	\item \lb{Sea $A$ una matriz diagonalizable con valores propios $\lambda_1,\dots,\lambda_n$. Prueba que la matriz $A^2$ también es diagonalizable con valores propios $\lambda_1^2,\dots,\lambda_n^2$}
	
	$A$ diagonalizable, $\lambda_1,\dots,\lambda_n$ valores propios $\longrightarrow\{v_1,\dots,v_n\}$ base de vectores propios $A^2$ diagonalizable, $\lambda_1^2,\dots,\lambda_n^2$ valores propios.
	\[Av_j=\lambda_jv_j,\;1\le j\le n\qquad A^2v_j=\lambda_jAv_j=\lambda_j\lambda_jv_j=\lambda_j^2v_j  \]
	¿$A^2v_j=\lambda_j^2v_j?$
	
	$A^2$ tiene valores propios $\lambda_j^2$
	
	$A^2$ tiene vectores propios los mismo que $A$
	
	\item \lb{Sea $A$ una matriz invertible y sean $\lambda_1,\dots,\lambda_n$ los autovalores de $A$. ¿Cuáles son los autovalores de $A^{-1}$?}
	
	
	$\begin{aligned}
		\exists v_j\neq0 & Av_j=\lambda_jv_j\\
		&=\underbrace{A^{-1}A}_Iv_j=\lambda_jA^{-1}v_j\longrightarrow\bboxed{A^{-1}v_j=\dfrac{1}{\lambda_j}v_j}
	\end{aligned}$
	
	$Av=0\longrightarrow\nuc(A)\neq\{0\}$
	
	$v\neq0\qquad\begin{array}{c}
		\dimn(A)\ge1\\
		+\\
		\dimr(A)=n
	\end{array}$
	
	
	\item \lb{Determina los valores $a$ para los cuales la matriz $\begin{bmatrix}
			5 & -3 & a \\
			6 & -4 & 6 \\
			0 & 0 & 2
		\end{bmatrix}$ es diagonalizable.}
	
	$A=\begin{bmatrix}
		5 & -3 & a \\
		6 & -4 & 6 \\
		0 & 0 & 2
	\end{bmatrix}\qquad a$ para que $A$ sea diagonalizable.
	
	$\begin{aligned}
		P_A(\lambda)=\det[A-\lambda I]=\det\begin{bmatrix}
			5-\lambda & -3 & a \\
			6 & -4-\lambda & 6 \\
			0 & 0 & 2-\lambda
		\end{bmatrix}&=(5-\lambda)(-4-\lambda)(2-\lambda)+18(2-\lambda)\\
		&=(2-\lambda)\underbrace{\left((5-\lambda)(-4-\lambda)+18\right)}_{\begin{array}{l}
				-20-5\lambda+4\lambda+\lambda^2+18\\
				\lambda^2-\lambda-2=0\\
				\lambda=\dfrac{1\pm\sqrt{1+8}}{2}=\left\langle\begin{array}{l}
					2\\
					-1
				\end{array}\right.
		\end{array}}
	\end{aligned}$
	
	Valores propios
	
	$\lambda_1=2$ multiplicidad 2\\
	$\lambda_2=-1$ multiplicidad 1\\
	$\begin{array}{l}
		\bboxed{\nuc(A-2I)}\\
		\begin{bmatrix}
			3 & -3 & a\\
			6 & -6 & 6\\
			0 & 0 & 0
		\end{bmatrix}\cdot\begin{bmatrix}
			x\\
			y\\
			z
		\end{bmatrix}=\begin{bmatrix}
			0\\
			0\\
			0
		\end{bmatrix}\\
		\begin{rcases}
			3x-2y+az=0\\
			6x-6y+6z=0
		\end{rcases}\longrightarrow\begin{bmatrix}
			3 & -3 & a\\
			6 & -6 & 6
		\end{bmatrix},\\
	\end{array}$
	
	$a=3\longrightarrow$ rango 1$\longrightarrow$ 2 parámetros $\longrightarrow$ 2 vectores propios $\longrightarrow A$ diagonalizable. 
	
	$a\neq3\longrightarrow$ rango 2$\longrightarrow$ 1 parámetro$\longrightarrow$1 vector propio$\longrightarrow A$ no diagonaliza.
	\item \lb{Una empresa comercializa dos marcas de un producto. Entre los usuarios de estas marcas la empresa ha podido determinar que la probabilidad de que un usuario de la marca 1 se pase a la marca 2 después de un mes es de 0.4, y la probabilidad de que un usuario de la marca 2 se pase a la marca 1 después de un mes es de 0.2. Con esta información, observa que la matriz \[ A=\begin{bmatrix}
			0.6 & 0.2 \\
			0.4 & 0.8
		\end{bmatrix} \]es tal que $a_{ij}$ es la probabilidad de que un usuarios de la marca $j$ se pase a la marca $i$ después de un mes. Este tipo de matrices se llaman \textbf{matrices de Markov}.}
	
	\lb{Si inicialmente hay, por ejemplo, un 20\% de usuarios que prefieren la marca 1 y un 80\% que prefieren la marca 2, se puede ver, usando argumentos probabilísticos, que las preferencias de los usuarios después de $n$ meses vienen dadas por \[ A^n\begin{bmatrix}
			0.2\\
			0.8
		\end{bmatrix} \]Determina cuáles serán las preferencias por cada marca en el futuro.}
	
	¿Cómo calcular $A^n,n\in\N,n$ grande?
	
	$\begin{array}{ll}
		A=P^{-1}DP & A^2=\underbrace{P^{-1}DP}_A\underbrace{P^{-1}DP}_A=P^{-1}D^2P\\
		D=\begin{bmatrix}
			\lambda_1 & 0 \\
			0 & \lambda_2
		\end{bmatrix} & A^n=P^{-1}D^nP\\
		D^2=\begin{bmatrix}
			\lambda_1^2 & 0\\
			0 & \lambda_2^2
		\end{bmatrix}& D^n=\begin{bmatrix}
			\lambda_1^n & 0\\
			0 & \lambda_2^n
		\end{bmatrix}
	\end{array}$
	\item \lb{\textbf{El secreto de Google y el Álgebra Lineal.} El teorema que sugye es una pieza clave en el algoritmo \textit{PageRank} que usa (o usaba) \textit{Google} para ordenar las búsquedas de las páginas de Internet. En su versión más sencilla, el Teorema de Perron-Frobenius se enuncia así: Sea $A$ una matriz cuadrada con entradas positivas, es decir, $a_{ij}>0$. Entonces existe un autovalor simple (es decir, de multiplicidad 1) cuyo autovector asociado puede elegirse con todas sus componentes estrictamente positivas. Calcula los autovalores y autovectores de la maatriz \[ A=\begin{bmatrix}
			1 & 3 & 4 \\
			3 & 1 & 1 \\
			1 & 3 & 2
		\end{bmatrix} \]y comprueba que se satisface el Teorema de Perron-Frobenius. Se recomienda la lectura del artículo \href{https://sctmates.webs.ull.es/modulo1lp/8/pfernandez.pdf}{\texttt{https://sctmates.webs.ull.es/modulo1lp/8/pfernandez.pdf}} a aquellos alumnos que tengan curiosidad por saber las Matemáticas en el algoritmo \textit{PageRank} de Google. En particular, se podrá apreciar el papel destacado del Teorema de Perron-Frobenius.}
	
		autovalores, autovectores$=\mathrm{eig}(A)$
	
	$A=\begin{bmatrix}
		1 & 3 & 4\\
		3 & 1 & 1\\
		1 & 3 & 2
	\end{bmatrix}\longrightarrow$ valor propio dominante $=6.1933$
	
		$v=(0.69,0.5,0.53)$
	\item \lb{Calcula y compara los valores propios y los valores singulares de las matrices $$A=\begin{bmatrix}
			0 & 1 & 0 & 0 \\
			0 & 0 & 2 & 0 \\
			0 & 0 & 0 & 3 \\
			0 & 0 & 0 & 0
		\end{bmatrix}\qquad B=\begin{bmatrix}
			0 & 1 & 0 & 0 \\
			0 & 0 & 2 & 0 \\
			0 & 0 & 0 & 3 \\
			\dfrac{1}{60000} & 0 & 0 & 0
		\end{bmatrix}$$¿Qué conclusión puedes sacar? }
	
	$\begin{array}{l}
		\det(A-\lambda I)=\det\begin{bmatrix}
		-\lambda & 1 & 0 & 0 \\
		0 & -\lambda & 2 & 0 \\
		0 & 0 & -\lambda & 3 \\
		0 & 0 & 0 & -\lambda
	\end{bmatrix}=\lambda^4=0\\
	\begin{aligned}
		\det[B-\lambda I]\begin{bmatrix}
	-\lambda & 1 & 0 & 0 \\
	0 & -\lambda & 2 & 0 \\
	0 & 0 & -\lambda & 3 \\
	\dfrac{1}{60000} & 0 & 0 & -\lambda
	\end{bmatrix}&=-\lambda\begin{vmatrix}
	-\lambda & 2 & 0 \\
	0 & -\lambda & 3 \\
	0 & 0 & -\lambda
	\end{vmatrix}-1\begin{vmatrix}
	0 & 2 & 0 \\
	0 & -\lambda & 3 \\
	\dfrac{1}{60000} & 0 & -\lambda
	\end{vmatrix}\\
	&=\lambda^4-\dfrac{6}{60000}=0\\
	&\lambda^4=10^{-4}\left\langle\begin{array}{l}
		\lambda=\pm0.1\\
		\lambda=\pm0.1j
	\end{array}\right.
	\end{aligned}
	\end{array}$
	
	
	
	Valores propios y singulares de $A$ y $B$
	
	Valores propios de $A\longrightarrow\lambda=0$ multiplicidad 4
	
	Valores propios de $B\longrightarrow\left\langle\begin{array}{l}
		\lambda=\pm0.1\\
		\lambda=\pm0.1j
	\end{array}\right.$
	
	$\begin{cases}
		A^\intercal A\longrightarrow\text{ valores propios }\longrightarrow\text{ valores singulares }\sigma_1=3,\sigma_2=\sigma_3=1,\sigma_4=0\\
		B^\intercal B\longrightarrow\text{ valores propios }\longrightarrow\text{ valores singulares }\sigma_1=3,\sigma_2=\sigma_3=1,\sigma_4\approx2.27\cdot10^{}
	\end{cases}$
	
	Son simétricas$\longrightarrow$valores propios son reales.
	\item \lb{Consideremos la matriz $A=\begin{bmatrix}
			3 & 8\\
			0 & 3
		\end{bmatrix}$}
	
	\begin{enumerate}[label=\color{red}\alph*)]
		\item \db{Calcula los valores propios y los valores singulares de $A$}
		
		$P_A(\lambda)=\det[A-\lambda I]=\det\begin{bmatrix}
			3-\lambda & 8\\
			0 & 3-\lambda
		\end{bmatrix}=(3-\lambda)^2=\lambda^2-6\lambda+9\longrightarrow\lambda=\dfrac{6\pm\sqrt{36-36}}{2}=\dfrac{6\pm}{2}=3$
		
		$\lambda=3$ multiplicidad 2
		\item \db{¿Es $A$ diagonalizable?}
		
		$\bboxed{\lambda=3}\quad\nuc(A-3I)=\nuc\begin{bmatrix}
			0 & 8\\
			0 & 0
		\end{bmatrix}$
		
		$\begin{bmatrix}
			0 & 8 \\
			0 & 0
		\end{bmatrix}\cdot\begin{bmatrix}
		x\\
		y
		\end{bmatrix}=\begin{bmatrix}
		0\\
		0
		\end{bmatrix}\longrightarrow\begin{array}{l}
		8y=0\longrightarrow y=0\\
		\bboxed{v=(1,0)}
		\end{array}$
		
		$\dimn(A-3I)=1\neq2$ multiplicidad de $\lambda=3$
		
		$A$ no factoriza, no diagonaliza.
		\item 
		\db{Calcula las matrices $U$ y $V$ ortogonales tales que $A=U\Sigma V^\intercal$, donde $\Sigma=\begin{bmatrix}
				\sigma_1 & 0\\
				0 & \sigma_2
			\end{bmatrix}$ con $\sigma_1,\sigma_2$ los valores singulares de $A$.}
		
		Calcular los valores y vectores propios de $A^\intercal A$
		
		$A^\intercal A=\begin{bmatrix}
			3 & 0\\
			8 & 3
		\end{bmatrix}\cdot\begin{bmatrix}
		3 & 8\\
		0 & 3
		\end{bmatrix}=\begin{bmatrix}
		9 & 24\\
		24 & 73
		\end{bmatrix}$
		
		$\det\begin{bmatrix}
			9-\lambda & 24\\
			24 & 73-\lambda
		\end{bmatrix}=(9-\lambda)(73-\lambda)-576=\lambda^2-82\lambda+81=0$
		
		$\lambda=\dfrac{82\pm\sqrt{82^2-4\cdot81}}{2}=\left\langle\begin{array}{l}
			\lambda_1=81\longrightarrow\sigma_1=9\\
			\lambda_2=1\longrightarrow\sigma_2=1
		\end{array}\right.\Sigma=\begin{bmatrix}
		9 & 0\\
		0 & 1
		\end{bmatrix}$
		
		$V=\begin{bmatrix}
			\dfrac{1}{\sqrt{10}} & -\dfrac{3}{\sqrt{10}}\\
			\dfrac{3}{\sqrt{10}} & \dfrac{1}{\sqrt{10}}
		\end{bmatrix}$
		
		$\bboxed{\lambda_1=81}\quad\nuc(A^\intercal A-81I)=\nuc\begin{bmatrix}
			-72 & 24\\
			24 & -8
		\end{bmatrix}$
		
		$\begin{bmatrix}
			-72 & 24\\
			24 & -8
		\end{bmatrix}\cdot\begin{bmatrix}
		x\\
		y
		\end{bmatrix}=\begin{bmatrix}
		0\\
		0
		\end{bmatrix}\longrightarrow\begin{cases}
		-72x+24y=0\\
		24x-8y=0
		\end{cases}\longrightarrow8y=24\alpha\longrightarrow y=3\alpha$
		
		$v=(1,3)\longrightarrow\|v\|=\sqrt{1^2+3^2}=\sqrt{10}$
		
		$\bboxed{\lambda_2=1}\quad\nuc(A^\intercal A-I)=\nuc\begin{bmatrix}
			8 & 24\\
			24 & 72
		\end{bmatrix}$
		
		$\begin{bmatrix}
			8 & 24\\
			24 & 72
		\end{bmatrix}\cdot\begin{bmatrix}
		x\\
		y
		\end{bmatrix}=\begin{bmatrix}
		0\\
		0
		\end{bmatrix}\longrightarrow\begin{rcases}
		8x+24y=0\\
		24x+72y=0
		\end{rcases}\longrightarrow y=\alpha\longrightarrow x=-\dfrac{24\alpha}{8}=-3\alpha;\bboxed{\alpha=1}$
		
		$\begin{array}{l}
			v=(-3,1)\\
			\|v\|=\sqrt{(-3)^2+1^2}=\sqrt{10}
		\end{array}$
		
		\underline{Cálculo de $U$}
		
		$U=\dfrac{1}{\sqrt{10}}\begin{bmatrix}
			3 & -3\\
			1 & 1
		\end{bmatrix}$
		
		$u_1=\dfrac{1}{\sigma_1}Av_1=\dfrac{1}{9}\begin{bmatrix}
			3 & 8\\
			0 & 3
		\end{bmatrix}\cdot\begin{bmatrix}
		\dfrac{1}{\sqrt{10}}\\
		\dfrac{3}{\sqrt{10}}
		\end{bmatrix}=\dfrac{1}{9\sqrt{10}}\cdot\begin{bmatrix}
		27\\
		9
		\end{bmatrix}=\dfrac{1}{\sqrt{10}}\begin{bmatrix}
		3\\
		1
		\end{bmatrix}$
		
		$u_2=\dfrac{1}{\sigma_2}Av_2=\dfrac{1}{\sqrt{10}}\begin{bmatrix}
			3 & 8\\
			0 & 3
		\end{bmatrix}\cdot\begin{bmatrix}
		-3\\
		1
		\end{bmatrix}=\dfrac{1}{\sqrt{10}}\cdot\begin{bmatrix}
		-1\\
		3
		\end{bmatrix}$
		
		$\bboxed{A=U\Sigma V^\intercal}$
	\end{enumerate}
	\item \lb{Encuentra la factorización $SVD$ de la matrices \[ \begin{bmatrix}
			0 & 0\\
			0 & 3\\
			-2 & 0
		\end{bmatrix}\qquad\begin{bmatrix}
		2 & 0 & 1\\
		0 & 2 & 0
		\end{bmatrix} \]Para la primera de ellas, escribe la matriz como suma de matrices de rango 1, según se explica en la página 121 de los apuntes.}
	
	$A= \begin{bmatrix}
		0 & 0\\
		0 & 3\\
		-2 & 0
	\end{bmatrix}$
	
	$A^\intercal A=\begin{bmatrix}
		0 & 0 & -2\\
		0 & 3 & 0
	\end{bmatrix}_{2\times3}\cdot \begin{bmatrix}
	0 & 0\\
	0 & 3\\
	-2 & 0
	\end{bmatrix}_{3\times2}=\begin{bmatrix}
	4 & 0\\
	0 & 9
	\end{bmatrix}$
	
	$P_{A^\intercal A}=\det(A^\intercal A-\lambda I)=\det\begin{bmatrix}
		4-\lambda & 0\\
		0 & 9-\lambda
	\end{bmatrix}=(4-\lambda)(9-\lambda)=0$
	
	$\begin{array}{l}
		\lambda_1=9\longrightarrow\sigma_1=\sqrt{9}=3\\
		\lambda_2=4\longrightarrow\sigma_2=\sqrt{4}=2
	\end{array}$
	
	$\begin{aligned}
		\bboxed{\lambda_1=9}&\nuc(A^\intercal A-9I)\longrightarrow\begin{bmatrix}
		-5 & 0\\
		0 & 0
	\end{bmatrix}\cdot\begin{bmatrix}
	x\\
	y
	\end{bmatrix}=\begin{bmatrix}
	0\\
	0
	\end{bmatrix}\\
	&-5x=0\longrightarrow x=0\longrightarrow y=1\longrightarrow v_1=(0,1)
	\end{aligned}$\\
	$\begin{aligned}
		\bboxed{\lambda_2=4}&\nuc(A^\intercal A-4I)\longrightarrow\begin{bmatrix}
			0 & 0\\
			0 & 5
		\end{bmatrix}\cdot\begin{bmatrix}
		x\\
		y
		\end{bmatrix}=\begin{bmatrix}
		0\\
		0
		\end{bmatrix}\\
		&=5y=0\longrightarrow y=0\longrightarrow x=1\longrightarrow v_2=(1,0)
	\end{aligned}$
	
	$V=\begin{bmatrix}
		0 & 1\\
		1 & 0
	\end{bmatrix}\longrightarrow V^\intercal=\begin{bmatrix}
	0 & 1\\
	1 & 0
	\end{bmatrix}$
	
	Cálculo de $U$:
	
	$u_1=\dfrac{1}{\sigma_1}Av_1=\dfrac{1}{3}\begin{bmatrix}
			0 & 0\\
			0 & 3\\
			-2 & 0
		\end{bmatrix}\cdot\begin{bmatrix}
		0\\
		1
		\end{bmatrix}=\dfrac{1}{3}\begin{bmatrix}
		0\\
		3\\
		0
		\end{bmatrix}=\begin{bmatrix}
		0\\
		1\\
		0
		\end{bmatrix}$\\
		$u_2=\dfrac{1}{\sigma_2}Av_2=\dfrac{1}{2}\begin{bmatrix}
			0 & 0\\
			0 & 3\\
			-2 & 0
		\end{bmatrix}\cdot\begin{bmatrix}
		1\\
		0
		\end{bmatrix}=\dfrac{1}{2}\begin{bmatrix}
		0\\
		0\\
		-2
		\end{bmatrix}=\begin{bmatrix}
		0\\
		0\\
		-1
		\end{bmatrix}$
		
		Completamos $u_1=(0,1,0), u_2(0,0,-1)$ a una base ortonormal de $\R^3$. Basta tomar \[ u_3=(1,0,0) \]Por tanto:\[\begin{array}{l}
			U=\begin{bmatrix}
				0 & 0 & 1 \\
				1 & 0 & 0 \\
				0 & -1 & 0
			\end{bmatrix}_{3\times3}\\
			\Sigma=\begin{bmatrix}
				3 & 0\\
				0  & 2\\
				0 & 0
			\end{bmatrix}_{3\times2}\\
			V^\intercal=\begin{bmatrix}
				0 & 1\\
				1 & 0
			\end{bmatrix}\\ \hdashline
			
		\end{array} \]
		$B=\begin{bmatrix}
			2 & 0 & 1\\
			0 & 2 & 0
		\end{bmatrix}$
		
		Como el número de condicionamiento de $B$ es 3 y el de filas es 2, hemos de hacer la factorización $SVD$ de $B^\intercal$ y a partir de ella deduciremos la de $B$.\\
		Empezamos Pues considerando la matriz \[ A=B^\intercal=\begin{bmatrix}
			2 & 0\\
			0 & 2\\
			1 & 0
		\end{bmatrix} \]
		\begin{enumerate}[label=\color{lightblue}\arabic*$^\circ$)]
			\item Cálculo de los autovalores y autovectores de $A^\intercal A$.
			
			$A^\intercal A=\begin{bmatrix}
				2 & 0 & 1\\
				0 & 2 & 0
			\end{bmatrix}\cdot\begin{bmatrix}
			2 & 0\\
			0 & 2\\
			1 & 0
			\end{bmatrix}=\begin{bmatrix}
			5 & 0\\
			0 & 4
			\end{bmatrix}$
			
			\begin{tabular}{cc}
				Valores propios de $A^\intercal A$: & Valores singulares de $A$:\\
				$\begin{array}{l}
					\lambda_1=5\\
					\lambda_2=4
				\end{array}$ & $\begin{array}{l}
				\sigma_1=\sqrt{5}\\
				\sigma_2=\sqrt{2}
				\end{array}$
			\end{tabular}
		\end{enumerate}
		$\begin{aligned}
			\bboxed{\lambda_1=5} & \nuc(A^\intercal A-5I)=\nuc\begin{bmatrix}
				0 & 0\\
				0 & -1
			\end{bmatrix}\\
			&\begin{bmatrix}
				0 & 0\\
				0 & -1
			\end{bmatrix}\cdot\begin{bmatrix}
			x\\
			y
			\end{bmatrix}=\begin{bmatrix}
			0\\
			0
			\end{bmatrix}\longrightarrow-y=0\longrightarrow y=0\longrightarrow v_1=(1,0)
		\end{aligned}$
		
		$\begin{aligned}
			\bboxed{\lambda_2=4}&\nuc(A^\intercal A-4I)=\nuc\begin{bmatrix}
				1 & 0\\
				0 & 0
			\end{bmatrix}\\
			&\begin{bmatrix}
				1 & 0\\
				0 & 0
			\end{bmatrix}\cdot\begin{bmatrix}
			x\\
			y
			\end{bmatrix}=\begin{bmatrix}
			0\\
			0
			\end{bmatrix}\longrightarrow x=0\longrightarrow v_2=(0,1)
		\end{aligned}$
		
		$V=\begin{bmatrix}
			1 & 0\\
			0 & 1
		\end{bmatrix}\qquad\Sigma=\begin{bmatrix}
		\sqrt{5} & 0 \\
		0 & 2\\
		0 & 0
		\end{bmatrix}$
		
		\bu{Cálculo de $U$:}
		
		$u_1=\dfrac{1}{\sigma_1}Av_1=\begin{bmatrix}
			2 & 0\\
			0 & 2\\
			1 & 0
		\end{bmatrix}\cdot\begin{bmatrix}
		1\\
		0
		\end{bmatrix}=\dfrac{1}{\sqrt{5}}\begin{bmatrix}
		2\\
		0\\
		1
		\end{bmatrix}$\\
		$u_2=\dfrac{1}{\sigma_2}Av_2=\dfrac{1}{2}\begin{bmatrix}
			2 & 0\\
			0 & 2\\
			1 & 0
		\end{bmatrix}\cdot\begin{bmatrix}
		0\\
		1
		\end{bmatrix}=\dfrac{1}{2}\begin{bmatrix}
		0\\
		2\\
		0
		\end{bmatrix}=\begin{bmatrix}
		0\\
		1\\
		0
		\end{bmatrix}$\\
		Completamos $\{u_1,u_2\}$ a una base ortonormal de $\R^3$.\\
		Se puede calcular el tercer vector $u_3$ usando Gram-Schmidt, pero de manera directa se puede ver que podemos tomar \[ u_3=\dfrac{1}{\sqrt{5}}(-1,0,2) \]Por tanto: \[ U=\begin{bmatrix}
			\dfrac{2}{\sqrt{5}} & 0 & -\dfrac{1}{\sqrt{5}}\\
			0 & 1 & 0\\
			\dfrac{1}{\sqrt{5}} & 0 & \dfrac{2}{\sqrt{5}}
		\end{bmatrix} \]En resumen:\[ B^\intercal=\underbrace{\begin{bmatrix}
			\dfrac{2}{\sqrt{5}} & 0 & -\dfrac{1}{\sqrt{5}}\\
			0 & 1 & 0\\
			\dfrac{1}{\sqrt{5}} & 0 & \dfrac{2}{\sqrt{5}}
			\end{bmatrix}}_U\cdot\underbrace{\begin{bmatrix}
			\sqrt{5} & 0\\
			0 & 2\\
			0 & 0
		\end{bmatrix}}_{\Sigma}\cdot\underbrace{\begin{bmatrix}
		0 &1\\
		1 & 0
	\end{bmatrix}}_{V^\intercal} \]Tomando la traspuesta:\[ B=V\Sigma^\intercal U^\intercal=\begin{bmatrix}
	1 & 0\\
	0 & 1
\end{bmatrix}\cdot\begin{bmatrix}
\sqrt{5} & 0& 0\\
0 & 2 & 0
\end{bmatrix}\cdot\begin{bmatrix}
\dfrac{2}{\sqrt{5}} & 0 & \dfrac{1}{\sqrt{5}}\\
0 & 1 & 0\\
-\dfrac{1}{\sqrt{5}} & 0 & \dfrac{2}{\sqrt{5}}
\end{bmatrix} \]
	\item \lb{Sea $A$ una matriz real y simétrica. Prueba que los valores singulares de $A$ son los valores absolutos de los valores propios  de $A$. ¿Qué pasa si $A$ es semidefinida positiva?}
	
	\begin{tikzpicture}
		\node[red,draw=red,fill=red!10,text width=\textwidth,line width=1.5] {\underline{Nota:} Antisimétrica.\\
			Valores singulares de $A$ son los valores absolutos de los valores propios de $A$. ¿$A$ semidefinida positiva?};
	\end{tikzpicture}
	
	Valores singulares de $A$ son las raíces cuadradas de los valores propios de $A^\intercal A$.
	
	$\begin{array}{l}
		\underbrace{A^\intercal Av_j}\longrightarrow\sigma_j=\sqrt{\lambda_j}\\
		A^2v_j=\lambda_j^2v_j\longrightarrow\sigma_j=\sqrt{\lambda_j^2}=|\lambda_j|
	\end{array}$
	
	donde $\lambda_j$ son los valores propios de $A$. $A\ge0\longrightarrow\lambda_j\ge0$
\end{enumerate}