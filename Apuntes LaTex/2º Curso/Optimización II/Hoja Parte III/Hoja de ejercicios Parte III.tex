\input{../../../Macros.tex}

\begin{document}
\begin{center}
    HOJA DE EJERCICIOS. PARTE III: PROBLEMAS CON RESTRICCIONES
\end{center}

\begin{enumerate}[label=\color{red}\arabic*.]
    \item \lb{Consideremos el problema \[ \begin{cases}
    \text{Minimizar en }(x_1,x_2) & f(x_1,x_2)=-2x_{1}+x_{2}\\
    \text{Sujeto a} & x_{1}+x_{2}-3=0\\
     & (x_{1},x_{2})\in X=\{(0,0),(0,4),(4,4),(4,0),(1,2),(2,1)\}
    \end{cases} \]Se pide:}
    \begin{enumerate}[label=\color{red}\alph*)]
    	\item \db{Comprueba que $(x_{1},x_{2})=(2,1)$ es la solución de dicho problema.}
    	
    	\item \db{Comprueba que la función dual $\Theta(\lambda)$ viene dada por \[ \begin{cases}
    	-4+5\lambda, & \lambda\le-1\\
    	-8+\lambda, & -1\le\lambda\le 2\\
    	-3\lambda, & \lambda\ge2
    	\end{cases} \]}
    	
    	\item \db{Calcula la solución del problema dual y el \textit{duality group}}
    \end{enumerate}
    \item \lb{\textbf{Ejercicio para entrega.} En este ejercicio estudiaremos una versión sencilla del problema de clasificación con máquinas de vector soporte. Consideremos un conjunto de datos con sólo dos datos \[ X=\{(-1,-,1;-1),(1,1;1)\} \]donde las dos primeras componentes de cada uno de los vectores anteriores representa sus características, y la tercera componente sirve para clasificar dicho dato dentro de dos clases $y=+1$ e $y=-1$. Supongamos que el hiperplano de separación de las dos clases de datos se escribe como \[ x_{1}+x_{2}x+x_{3}y=0 \]Se pide:}
    \begin{enumerate}[label=\color{red}\alph*)]
    	\item \db{Demuestra que el problema de clasificación con SVD para estos datos se formula como \[ (Primal)\begin{cases}
    	\text{Minimizar en }(x_{1},x_{2},x_{3}) & f(x_1,x_2,x_3)=\dfrac{1}{2}(x_2^2+x_3^2)\\
    	\text{Sujeto a } & -x_{1}+x_{2}+x_{3}\ge1 \\
    	 & x_1+x_2+x_3\ge1
    	\end{cases} \]}
    	\item \db{Escribe el problema (Primal) en su forma estándar y demuestra que se satisfacen las condiciones de convexidad adecuadas para que dicho problema sea equivalente a su dual, el cual calcularemos a continuación.}
    	
    	\item \db{Demuestra que el problema dual asociado a (Primal) viene dado por \[ (Dual)\begin{cases}
    	\text{Maximizar} & \Theta(\mu)=-4\mu^2+2\mu\\
    	\text{Sujeto a }& \mu\ge0
    	\end{cases} \]}
    	
    	\item \db{Resuelve el problema dual anterior e infiere de ello que la solución del problema original es $x_1=0,x_2=x_3=\dfrac{1}{2}$.}
    \end{enumerate}
    \item \lb{Consideremos el problema \[ (Primal)\begin{cases}
    \text{Minimizar en }(x_1,x_2) & f(x_1,x_2)=x_1+x_2+\dfrac{1}{2}(x_1^2+x_2^2)\\
    \text{Sujeto a} & x_1+x_2\ge1
    \end{cases} \]Se pide:}
    \begin{enumerate}[label=\color{red}\alph*)]
    	\item \db{Escribe y resuelve las condiciones necesarias de optimalidad de Karush-Kuhn-Tucker de problema anterior.}
    	
    	\item \db{Deduce que el problema dual asociado al primal anterior viene dado por \[ (Dual)\begin{cases}
    	\text{Maximizar} & \Theta(\mu)=-\mu^2+3\mu-1\\
    	\text{Sujeto a }& \mu\ge0
    	\end{cases} \]}
    	\item \db{Resuelve el problema dual anterior e infiere de ello que la solución del problema original es $x_1=x_2=\dfrac{1}{2}$.}
    \end{enumerate}
    \item \lb{Consideremos el problema \[ \begin{cases}
    \text{Minimizar en }(x_1,x_2) & f(x_1,x_2)=x_2\\
    \text{Sujeto a}& x_1\ge1\\
     & x_1^2+x_2^2\le1
    \end{cases} \]Se pide:}
    \begin{enumerate}[label=\color{red}\alph*)]
    	\item \db{Comprueba que $x_1=1,\, x_2=0$ es solución del problema anterior.}
    	\item \db{Comprueba que la función dual viene dada por \[ \Theta(\mu)=\mu-\sqrt{1-\mu^2}. \]}
    	\item \db{Calcula $\sup\{\Theta(\mu):\mu\ge0\}$ y deduce de ello que el problema dual no tiene solución. Razona a qué es debido esto. \textit{Indicación: comprueba que no se cumple alguna de las hipótesis del teorema de dualidad fuerte.}}
    \end{enumerate}
    \item \lb{Consideremos al problema de complementariedad lineal asociado a los datos siguientes: \[ M=\begin{bmatrix}
    -2 & 1 \\
    1 & -2
    \end{bmatrix},\quad q=(1,1)^\intercal. \] Escribe las 4 matrices complementarias, dibuja los 4 conos complementarios, y deduce de ello que el problema \[ \begin{cases}
    \omega-Mz=q\\
    \omega,z\ge0\\
    \omega_j\cdot z_j=0,\quad 1\le j\le 2
    \end{cases} \]tiene 4 soluciones y calcúlalas.}
    
    \item \lb{Utiliza el algoritmo de Lemke para resolver el problema de complementariedad lineal asociado a los datos \[ M=\begin{bmatrix}
    1 & -1 \\
    -1 & 1
    \end{bmatrix},\quad q=(1,-1)^\intercal.\]}
    
    \item \lb{\textbf{El problema de la distancia mínima.} Sea $K$ la región poligonal que aparece en la Figura 1 y fijemos el punto $P_0=(-2,-1)$. Nos planteamos de encontrar el punto de $K$ que está más cerca de $P_0$, en la distancia Euclídea usual.}
    
    \begin{center}
    \begin{tikzpicture}
    \draw (-3,0) -- (8,0);
    \draw (0,-2) -- (0,7);
    \foreach \x in {-2,...,6}{\draw (\x,0.1) -- (\x,-0.1);}
    \foreach \y in {-1,...,5}{\draw (0.1,\y) -- (-0.1, \y);}
    % Puntos y etiquetas
        \fill (-2,-1) circle (2pt) node[above] {\small $P_0$} node[below right] {\small $(-2,-1)$};
        \fill (1,3) circle (2pt) node[below left] {\small $P_1$} node[above] {\small $(1,3)$};
        \fill (4,0) circle (2pt) node[below] {\small $P_2$} node[below right] {$\quad(4,0)$};
        \fill (5,2) circle (2pt) node[right] {\small $P_3\:(5,2)$};
        \fill (5,4) circle (2pt) node[above right] {\small $P_4\:(5.4)$};
    
        % Región sombreada (K)
        \fill[pattern=north west lines] 
            (1,3) -- (4,0) -- (5,2) -- (5,4) -- cycle;
        \node[circle, fill=white, draw=black] at (3.5,2.2) {\large $K$};
    \end{tikzpicture}
    
    \lb{Figura 1: Problema de la distancia mínima}
    \end{center}
    \lb{El problema puede formularse de la siguiente forma\footnote{El vector $(\lambda_1,\cdots,\lambda_4)$ representa un punto de $K$ y surge del Teorema de representación de un conjunto poliédrico. Para el caso sencillo en que $K$ es un triángulo, $(\lambda_1,\lambda_2,\lambda_3)$ son las coordenadas baricéntricas, que se calculan del siguiente modo: si $P_1=(x_1,y_1),\, P_2=(x_2,y_2)\, P_3=(x_3,y_3)$ son los vértices de un triángulo y $P=(x,y)$ es un punto del triángulo, entonces las coordenadas baricéntricas de $P$ son: \[ \lambda_1=\dfrac{\text{área del triángulo }PP_1P_2}{\text{área del triángulo }P_1P_2P_3},\quad\lambda_2=\dfrac{\text{área del triángulo }PP_2P_3}{\text{área del triángulo } P_1P_2P_3},\quad\lambda_3=\dfrac{\text{área del triángulo }PP_1P_3}{\text{área del triángulo }P_1P_2P_3}. \]}: \[ \begin{cases}
    \text{Minimizar} & f(\lambda_1,\cdots,\lambda_4)=(\lambda_1+4\lambda_2+5\lambda_3+5\lambda_4-(-2))^2+(\lambda_1+2\lambda_3+4\lambda_4-(-1)^2)\\
    \text{Sujeto a} & \lambda_1+\lambda_2+\lambda_3+\lambda_4=1\\
     & \lambda_j\ge0,\quad 1\le j\le 4
    \end{cases} \]Se pide:}
    \begin{enumerate}[label=\color{red}\alph*)]
    	\item \db{Utiliza la sustitución $\lambda_4=1-\lambda_1-\lambda_2-\lambda_3$ para comprobar que el problema anterior se puede reescribir como el problema cuadrático siguiente:  \begin{equation}
    	(\mathrm{PQ})\begin{cases}
    	\text{Minimizar} & (-66,-54,-20)\lambda+\dfrac{1}{2}\lambda^\intercal\begin{bmatrix}
    	34 & 16 & 4 \\
    	16 & 34 & 16 \\
    	4 & 16 & 8
    	\end{bmatrix}\lambda\\
    	\text{Sujeto a} & -\lambda_1-\lambda_2-\lambda_3\ge1\\
    	 &\lambda_j\ge0,\quad 1\le j\le 3
    	\end{cases}
    	\end{equation} donde $\mathrm{\lambda}=(\lambda_1,\lambda_2,\lambda_3)^\intercal$.}
    	
    	\item \db{Comprueba que el problema (1) es equivalente al problema de complementariedad lineal \begin{equation}
    	(\mathrm{PCL})\begin{cases}
    	\omega-Mz=q\\
    	\omega,z\ge0\\
    	\omega_j\cdot z_j=0,\quad 1\le j\le4
    	\end{cases}
    	\end{equation}donde, siguiendo la notación de clase, \[ \omega=(y,v_1,v_2,v_3)^\intercal,\quad z=(y,\lambda_1,\lambda_2,\lambda_3)^\intercal,\quad q=(1,-66,-54,-20)^\intercal \]y\[ M=\begin{bmatrix}
    	0 & -1 & -1 & -1 \\
    	1 & 34 & 16 & 4 \\
    	1 & 16 & 34 & 16 \\
    	1 & 4 & 16 & 8
    	\end{bmatrix}. \]}
    	
    	\item \db{Resuelve el problema (2) en Python mediante el algoritmo de Lemke y usando el módulo \texttt{lemkelep}.}
    	
    \end{enumerate}
    \item \lb{Consideremos el problema de optimización cuadrática siguiente: \[ (\mathrm{PQ})\begin{cases}
    \text{Minimizar} & f(x_{1},x_{2})=\dfrac{1}{2}(x_{1}^{2}+x_{2}^{2})+x_{1}+x_{2}\\
    \text{Sujeto a} & x_1+x_2\ge1\\
     & x_1,x_2\ge0
    \end{cases} \]Se pide:}
    \begin{enumerate}[label=\color{red}\alph*)]
    	\item \db{Comprueba que el problema de complementariedad lineal asociado es el correspondiente al sistema: \[ (\mathrm{PCL})\quad\begin{bmatrix}
    	y\\
    	v_{1}\\
    	v_{2}
    	\end{bmatrix}-\begin{bmatrix}
    	0 & 1 & 1 \\
    	-1 & 1 & 0 \\
    	-1 & 0 & 1
    	\end{bmatrix}\cdot\begin{bmatrix}
    	u\\
    	x_1\\
    	x_2
    	\end{bmatrix} =\begin{bmatrix}
    	-1 \\
    	1 \\
    	1
    	\end{bmatrix}\]}
    	
    	\item \db{Resuelve por el método de Lemke en Python, y usando el módulo \texttt{lemkelep}, el problema (PCL) anterior.}
    \end{enumerate}
    \item \lb{Consideremos el problema de optimización cuadrática siguiente: \[ (\mathrm{PQ})\begin{cases}
    \text{Minimizar} & f(x_1,x_2)=23x_1^2+5x_1x_2+4x_2^2+3x_1+5x_2+8\\
    \text{Sujeto a} & x_1-x_2-3\ge0\\
    & -4x_1-5x_2\le13\\
    &8x_1+14x_2\ge-9\\
    &x_1,x_2\ge0
    \end{cases} \]Se pide:}
    \begin{enumerate}[label=\color{red}\alph*)]
    	\item \db{Estudia la convexidad del problema.}
    	
    	\item \db{Escribe las ecuaciones de Karush-Kuhn-Tucker y el problema de complementariedad lineal asociados.}
    	
    	\item \db{Resuelve el método de Lemke en Python, y usando el módulo de \texttt{lemkelep}, el problema de complementariedad lineal.}
    \end{enumerate}
\end{enumerate}
\end{document}