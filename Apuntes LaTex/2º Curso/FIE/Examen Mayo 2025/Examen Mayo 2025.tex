\input{../../../Macros.tex}
\title{Fundamentos de Inferencia Estadística\\Problemas Examen Mayo 2025}

\begin{document}
\maketitle
\begin{enumerate}[label=\color{red}\textbf{\arabic*)}]
    \item \lb{Sea $X$ una población con función de densidad  \[
    f(x;\theta)=\dfrac{4}{\theta}x^3e^{-\frac{x^4}{\theta} }\text{ para } x \in (0,+\infty),
    \]donde $\theta$ es un parámetro desconocido estrictamente positivo. Sea  $X_1,\dots,X_n$ una muestra aleatoria simple de $X$.}
    \begin{enumerate}[label=\color{red}\textbf{\alph*)}]
        \item \db{Obtener el estimador de máxima verosimilitud de $\theta$.} 

            \begin{enumerate}[label=\arabic*)]
                \item Función de verosimilitud:

                    Dada una muestra aleatoria $X_1,\dots,X_n$, la función de verosimilitud es: \[
                    \begin{array}{c}
                        L(\theta)=\prod_{i=1}^{n} f(X_i,\theta)=\left( \dfrac{4}{\theta} \right) ^n\cdot \prod_{i=1}^{n} X_i^3\cdot e^{-\sum_{i=1}^{n} \frac{X_i^4}{\theta} } \\
                        L(\theta)=\left( \dfrac{4}{\theta} \right) ^n \cdot \left( \prod_{i=1}^{n} X_i^3  \right) \cdot e^{-\frac{1}{\theta} \sum X_i^4} 
                    \end{array}
                    \] 
                \item Log-verosimilitud

                    \[
                    \ell(\theta)=\log L(\theta)=n\log 4-n\log\theta+3\sum \log X_i-\dfrac{1}{\theta}\sum X_i^4
                    \] 
                \item Derivada de la log-verosimilitud: \[
                \dfrac{\mathrm{d}\ell}{\dth }=-\dfrac{n}{\theta}+\dfrac{1}{\theta}\sum X_i^4
                \] 
                \item Iugalamos a cero:
                    \[
                    -\dfrac{n}{\theta}+\dfrac{1}{\theta^2}\sum X_i^4=0\implies \hat{\theta}=\dfrac{1}{n}\sum_{i=1}^{n} X_i^4
                    \] 
            \end{enumerate}
            Estimador de máxima verosimilitud: \[
            \hat{\theta}=\dfrac{1}{n}\sum_{i=1}^{n} X_i^4
            \] 
        \item \db{Obtener su distribución en el muestreo.} 

            Queremos la \textbf{distribución muestral} de $\hat{\theta}$. Para ello, veamos cómo se distribuye $Y=X^4$.
            \begin{enumerate}[label=\arabic*)]
                \item \textbf{Cambio de variable:}

                    Sea $Y=X^4\implies X=Y^{\frac{1}{4}}\implies \dfrac{\dx }{\dy}=\dfrac{1}{4}Y^{-\frac{3}{4} }$ 
                    \[
                    \begin{array}{c}
                        f_Y(y)=f_X(y^{\frac{1}{4} })\cdot \left| \dfrac{\mathrm{d}}{\mathrm{d}y} y^{\frac{1}{4} }\right| =\dfrac{4}{\theta}\cdot (y\frac{1}{4} )^3\cdot e^{-\frac{y}{\theta} } \cdot \dfrac{1}{4}y^{-\frac{3}{4} }\\
                        f_Y(y)=\dfrac{1}{\theta}=\dfrac{1}{\theta}\cancelto{1}{y^{(\frac{3}{4} -\frac{3}{4} )}} e^{-\frac{y}{\theta} } ,\quad y>0
                    \end{array}
                    \] 
            \end{enumerate}
            Entonces: \[
            Y=X^4\sim \text{Exponencial}(\theta)
            \] 
            Como $\hat{\theta}=\dfrac{1}{n}\sum_{i=1}^{n} X_i^4=\dfrac{1}{n}\sum_{i=1}^{n} Y_i$, donde $Y_i\sim \text{Exp}(\theta)$: \[
            \sum Y_i\sim \text{Gamma}(n,\theta)\implies \hat{\theta}=\dfrac{1}{n}\sum Y_i\sim \text{Gamma}(n,n\theta)
            \] 
            Ditribución muestral: \[
            \hat{\theta}\sim \text{Gamma}(n,n\theta)
            \] 
        \item \db{Estudiar su sesgo y su error cuadrático medio.}
            \begin{itemize}[label=\textbullet]
                \item Esperanza: \[
                        \mathbb{E}[\hat{\theta}]=\theta\implies\text{sesgo}=0
                \] 
            \item Varianza: \[
            \text{Var}(\hat{\theta})=\dfrac{\theta^2}{n}
            \] 
        \item ECM: \[
        \mathrm{ECM}(\hat{\theta})=\mathrm{Var}(\hat{\theta})+(\text{sesgo})^2=\dfrac{\hat{\theta}^2}{n}
        \] 
            \end{itemize}
        \item \db{Obtener un intervalo de confianza para $\theta$ con un nivel de confianza de  $100(1-\alpha)\%$.}

            Como: \[
            \hat{\theta}\sim \text{Gamma}(n,n\theta)\implies \dfrac{\hat{n}\theta}{\theta}\sim \chi_{2n}^2
            \] 
            Entoces, usando cuantiles de la chi-cuadrado: \[
\begin{array}{c}
            \mathrm{Pr}\left( \chi_{2n,\frac{\alpha}{2} }^2\le \dfrac{n \hat{\theta}}{\theta}\le \chi_{2n,1-\frac{\alpha}{2} }^2 \right) =1-\alpha\\
            \mathrm{Pr}\left( \dfrac{\chi_{2n,\frac{\alpha}{2} }^2}{n \hat{\theta}}\le \dfrac{1}{\theta}\le \dfrac{\chi_{2n,1-\frac{\alpha}{2} }^2}{n \hat{\theta}} \right) =1-\alpha\\
            \mathrm{Pr}\left( \dfrac{n \hat{\theta}}{\chi_{2n,1-\frac{\alpha}{2}}^2} \le \theta\le \dfrac{n \hat{\theta}}{\chi_{2n,\frac{\alpha}{2} }^2} \right) =1-\alpha
\end{array}
            \] 
            Intervalo de confianza: \[
            \left[ \dfrac{n \hat{\theta}}{\chi_{2n,1-\frac{\alpha}{2}}^2},\dfrac{n \hat{\theta}}{\chi_{2n,\frac{\alpha}{2}}^2} \right] 
            \] 
            Este es el intervalo de confianza para $\theta$ con nivel de confianza  $100(1-\alpha)\%$.
        \item \db{Obtener el test uniforme de máxima potencia y extensión $\alpha$ para el contraste \[
        H_0:\theta=\theta_0
        \] frente a \[
        H_1:\theta>\theta_0.
        \] } 
        Queremos testear: \[
        H_0:\theta=\theta_0\text{ vs }H_1:\theta>\theta_0
        \] 
        Sabemos que: \[
        \dfrac{n \hat{\theta}}{\theta}\sim \chi_{2n}^2\text{ bajo }H_0
        \] 
        Por lo tanto, la regla de decisión es:

        Rechazar $H_0$ si: \[
        \dfrac{n \hat{\theta}}{\theta_0}>\chi_{2n,1-\alpha}^2\implies \hat{\theta}>\dfrac{\theta_0}{n}\cdot \chi_{2n,1-\alpha}^2
        \] 
        Es decir: \[
        \text{Rechazar $H_0$ si }\hat{\theta}>\dfrac{\theta_0}{n}\cdot \chi_{2n,1-\alpha}
        \] 
    \end{enumerate}
\end{enumerate}
\end{document}
