# Estimación

## Introducción

-   Hemos modelizado un experimento con una variable aleatoria $X$.
-   La \textcolor[HTML]{007aff}{estimación} hace referencia al proceso de conseguir información sobre la distribución de $X$ a partir de los valores de una muestra, aproximando valores asociados a la distribución mediante el valor de un estadístico en un muestra concreta.

::: callout-important
# Dos situaciones

-   Nuestro modelo supone que la distribución de $X$ pertenece a una familia paramétrica de distribuciones: tienen una determinada forma con unos parámetros variables.
    -   Buscamos información sobre el valor de los parámetro. \textcolor[HTML]{007aff}{Estimación paramétrica}.
-   No limitamos la familia de distribuciones a la que pertenece nuestro modelo.
    -   Buscamos información sobre la distribución en sí (función de distribución, de densidad o función de probabilidad). \textcolor[HTML]{007aff}{Estimación no paramétrica}.
-   A lo largo de las prácticas veremos también la estimación de parámetros que no necesitan de una familia paramétrica, como es el caso de la mediana.
:::

## Ejemplos de estimación paramétrica

::: callout-note
# Sondeo sobre intención de participación en unas elecciones

-   Queremos estimar la tasa de participación antes de unas elecciones generales.
-   Formulamos un modelo: experimento: "escoger una persona al azar en el censo". $X$: variable dicotómica ("Sí" o "No"). $p=P(X=\text{Si})$.
-   El modelo pertenece a la familia paramétrica de Bernoulli.
:::

::: callout-note
# Determinación de la concrentación de un producto

-   Quiero determinar la concentración.
-   Formulo el modelo: experimento$=$"llevar a cabo una medición". $X$: "valor proporcionado por el aparato". $X\sim \mathcal{N}(\mu,\sigma^2)$.
-   El modelo pertenece a la familia paramétrica de las distribuciones normales.
:::

## Estimación paramétrica: estimación puntual

::: callout-note
# Ingredientes del modelo

-   Experimento aleatorio
-   Variable aleatoria $X$ con una distribución $f$ que pertenece a una familia paramétrica $\{f_\theta,\theta\in \Theta\}.$
-   Disponemos de una muestra de la distribución de $X$.
:::

\begin{definition}
    Cualquier estadístico diseñado para aproximar el valor de un parámetro $\theta$ del modelo, se llama \textcolor[HTML]{007aff}{estimador puntual} del parámetro $\theta$.
\end{definition}

::: callout-note
# Ejemplos de estimadores paramétricos

\begin{center}
    \begin{tabular}{cc}
        $\theta$ & \textbf{Estimador} \\ \hline
        $\mu$ & $\bar{X}$, media muestral\\ \hline
        $\sigma^2$ & $S^2$, varianza muestral\\ \hline
        $p$ &  $\hat{p}$, proporción muestral\\ 
    \end{tabular}
\end{center}
:::

::: callout-tip
# A tener en cuenta:

-   Un estimador es un variable aleatoria, su valor depende de la muestra concreta escogida.
-   Para controlar bondad de nuestra estimación, nos basaremos en el estudio de la distribución del estimador.
:::

## Métodos de contrucción de estimadores

Para $\mu,\sigma^2$ o $p$, es fácil pensar en estimadores naturales, pero para modelos o parámetros más sofisticados, vamos a ver métodos generales.

**Veremos dos métodos en este tema:**

-   El método de los momentos.
-   El método de la máxima verosimilitud.

## Método de los momentos

::: callout-note
# Contexto
-   Experimento con una variable aleatoria $X$, suponemos $f_X\in \{x\mapsto f_{\theta}(x),\theta\in \Theta\}$.
-   El parámetro $\theta$ tiene dimensión $p$.
-   Consideramos una muestra aleatoria simple $X_1,X_2,\dots,X_n$ de $X$.
:::
Si $\theta$ tiene dimensión $p$, igualamos los  $p$ primeros momentos de  $f_\theta$ con los equivalentes muestrales.

Sea $\mu_k(\theta)$ el momento de orden $k$ de la distribución  $f_{\theta,\mu_k}=E[X^k]$. Resolvemos:

$$
\begin{array}{r}
    \mu_1(\theta)=\overline{X},\\
    \mu_2(\theta)=\overline{X^2},\\
    \vdots\\
    \mu_p(\theta)=\overline{X^p}.
\end{array}
$$

#### Ejemplos #### {.unnumbered .unlisted}

:::{.callout-important}
# Calculad los estimadores usando el método de los momentos en los dos casos:
- Modelo normal: $X\sim \mathcal{N}(\mu,\sigma^2)$, donde $\theta=(\mu,\sigma^2)$.


$$
\begin{array}{ll}
X\leadsto \mathcal{N}(\mu,\sigma^2) & \mu=E[X]\\
\theta=(\mu,\sigma^2),\quad p=2 & \sigma^2=\mathrm{Var}[X]=E[X^2]-(E[X])^2\rightarrow E[X^2]=\sigma^2+\mu^2\\
\mu_1(\theta)=E[X]=\overline{x} & \hat{\mu}=\overline{x}\\
\mu_2(\theta)=E[X^2]=\overline{x^2} & \hat{\sigma}^2=\overline{x^2}-(\overline{x})^2
\end{array}
$$

- Modelo de Bernoulli: $X\sim \text{Bernoulli}(p)$, donde desconocemos $p$.
 
$$
\begin{array}{l}
X\leadsto \text{Bernoulli}(p),\quad 0<p<1\\
\theta=p\\
\mu(\theta)=E[X]=\bar{x}=p\\
\hat{p}=\bar{x} \text{ \textcolor[HTML]{007aff}{(proporción muestral)}  }
\end{array}
$$
:::

## Método de máxima verosimilitud ##
- El método más utilziado de construcción de un estimador puntual.
- Se basa en lo que se conoce como \textcolor[HTML]{007aff}{función de verosimilitud}.

\begin{definition}
    \begin{itemize}
    \item Sea $X$ una variable aleatoria, con distribución  $x\mapsto f_X(x;\theta)$ (función de densidad o función puntual de probabilidad), donde $\theta$ es de dimensión $p:\theta\in \Theta\subset\mathbb{R}^p$.
    \item Para un valor concreto de una muestra aleatoria simple $(X_1,\dots,X_n)$, que denotamos por $(x_1,\dots,x_n)$, consideramos la función de $\theta$: $$L_n:\begin{cases}\Theta\subset\mathbb{R}^p\rightarrow \mathbb{R}^+\\ \theta\mapsto L_n(\theta)=f_{X_1,\dots,X_n}(x_1,\dots,x_{n};\theta)=\prod_{i=1}^{n} f_X(x_i;\theta). \end{cases}$$ 
    \item La función $L_n$ es la  \textcolor[HTML]{007aff}{función de verosimilitud}. Nos dice lo creíbles (verosímiles) que son las observaciones para ese valor del parámetro. 
    \end{itemize}
\end{definition}

#### Ejemplo de cálculo de la verosimilitud #### {.unnumbered .unlisted}
- Tiramos 10 veces una moneda (1 es cara, 0 es cruz), y obtenemos: 0,0,1,0,1,1,1,1,1,1.
- La verosimilitud asocia a cada $p$ el valor de  $$\mathrm{Pr}(X_1=0,X_2=0,X_3=1,X_4=0,X_5=1,X_6=1,X_7=1,X_8=1,X_9=1,X_{10}=1),$$ por lo que $$L_n(p)=(1-p)(1-p)p(1-p)p^{6}=(1-p)^3\cdot p^7.$$ 

```{r}
library(tidyverse)
p <- seq(0, 1, by = 0.001)
n <- 10
n1 <- 7
l <- (1 - p)^(n - n1) * p^n1
tibble(p = p, l = l) |>
  ggplot(aes(p, l)) +
  geom_line() +
  labs(y = "Verosimilitud")
```

## Estimador de máxima verosimilitud ##
\begin{definition}
    El \textcolor[HTML]{007aff}{estimador de máxima verosimilitud} $\hat{\theta}$ de $\theta$ es cualquier valor de $\theta$ que maximiza $\theta\mapsto L_n(\theta)$, es decir, $$\hat{\theta}\mathrm{argmax}_{\theta\in \Theta}L_n(\theta).$$
\end{definition}

:::{.callout-important}
# Nota
- La maximización se realiza sobre todos los valores admisibles para el parámetro $\theta$.
- Podría haber de un máximo.
:::

### Estimación de la proporción ### {.unnumbered .unlisted}
Retomamos el ejemplo de las 10 monedas:

$$
p\mapsto L_n(p)=(1-p)(1-p)p(1-p)p^{6}=(1-p)^3\cdot p^7.
$$

```{r}
#| fig-cap: "Verosimilitud correspondiente al ejemplo de 10 tiradas de una moneda."
tibble(p = p, l = l) |>
  ggplot(aes(p, l)) +
  geom_line() +
  geom_vline(xintercept = n1 / n, col="red") +
  labs(y = "Verosimilitud")
```

#### Ejemplos #### {.unnumbered .unlisted}
:::{.callout-important}
# Ejemplos de estimación por máxima verosimilitud
Calculad los estimadores usando el método de máxima verosimilitud en los dos casos:

- $X\sim \mathrm{Bernoulli}(p)$, donde desconocemos $p$.
- $X\sim \mathcal{N}(\mu,\sigma^2)$, donde desconocemos $\theta=(\mu,\sigma^2)$.
:::

\quad \textcolor{red}{\textbullet}\quad \textcolor[HTML]{007aff}{En el primer caso anterior, calcular la distribución de Bernoulli, donde desconocemos $p$.}

$X\leadsto \mathrm{Bernoulli}(p),\quad 0<p<1$

$(X_1,\dots,X_N)$ m.a.s. de tamaño $n$

$L_n(\theta)=f_{X_1,\dots,X_n}(x_1,\dots,x_n;\theta)=\prod_{i=1}^{n} f_X(x_i;\theta)$

$L_n(p)=\prod_{i=1}^{n}f_X(x_i;p)=\prod_{i=1}^{n}p^{x_i}(1-p)^{1-x_i}$ 

$\ell(p)=\log L_n(p)=\log p^{\sum_i x_i}+\log(1-p)^{n-\sum_{i=1}^{n} x_i}=\left( \sum_i x_i \right)\cdot \log p+\left( n-\sum_{i=1}^{n} x_i \right)\cdot \log(1-p)$ 

$\begin{aligned}\frac{\partial \ell(p)}{\partial p} &=\left( \sum_{i=1}^{n} x_i \right)\cdot \dfrac{1}{p}+\left( n-\sum_{i=1}^{n} x_i \right)\cdot \left( -\dfrac{1}{1-p} \right)=(1-p)\cdot \sum_{i=1}^{n} x_i-\left( n-\sum_{i=1}^{n} x_i \right) \cdot p\\ &= \sum_{i=1}^{n} x_i-\cancel{p\cdot \sum_{i=1}^{n} x_i} -np+\cancel{p\cdot \sum_{i=1}^{n} x_{i}} =0\implies\bboxed{\hat{p}=\dfrac{1}{n}\sum_{i=1}^{n} x_i=\bar{x}} \\\end{aligned}$

\quad \textcolor{red}{\textbullet}\quad \textcolor[HTML]{007aff}{En el segundo caso anterior, calculad la esperanza del estimador de máxima verosimilitud de $\sigma^2$.}

La función de denisdad de una variable aleatoria $X$ con distribución normal es:
 
$$
f(x|\mu,\sigma^2)=\dfrac{1}{\sqrt{2\pi \sigma^2}}\exp\left( -\dfrac{(x-\mu)^2}{2\sigma^2} \right) 
$$

Si tenemos una muestra de tamaño $n$, es decir,  $X_1,X_2,\dots,X_n$ que son observaciones independientes y distribuidas como $\mathcal{N}(\mu,\sigma^2)$, entonces la función de verosimilitud $L(\mu,\sigma^2)$ es el producto de las funciones de densidad de cada observación 
$$
L(\mu,\sigma^2)=\prod_{i=1}^{n} f(x_i|\mu,\sigma^2)=\prod_{i=1}^{n} \dfrac{1}{\sqrt{2\pi \sigma^2}}\exp\left( -\dfrac{(x_i-\mu)^2}{2\sigma^2} \right)
$$
Para simplificar los cálculos, se toma el logaritmo de la función de verosimilitud, lo que da la función de log-verosimilitud $\ell(\mu,\sigma^2)$:
$$
\begin{aligned}
    \ell(\mu,\sigma^2)=\log L(\mu,\sigma^2)&= \sum_{i=1}^{n} \log\left( \dfrac{1}{\sqrt{2\pi \sigma^2} } \right) +\sum_{i=1}^{n} \log\left( \exp \left( -\dfrac{(x_i-\mu)^2}{2\sigma^2} \right)  \right)  \\
    &= \sum_{i=1}^{n} \log\left( (2\pi \sigma^2)^{-\frac{1}{2} } \right) +\sum_{i=1}^{n} -\dfrac{(x_i-\mu)^2}{2\sigma^2}=\sum_{i=1}^{n}-\dfrac{1}{2}\log(2\pi \sigma^2)-\dfrac{1}{2\sigma^2}\sum_{i=1}^{n} (x_i-\mu)^2 \\
    &= -\dfrac{n}{2}\cdot \log(2\pi)-\dfrac{n}{2}\cdot \log(\sigma^2)-\dfrac{1}{2\sigma^2}\sum_{i=1}^{n} (x_i-\mu)^2 \\
\end{aligned}
$$
Para encontrar los estimadores de máxima verosimilitud, derivamos $\ell(\mu,\sigma^2)$ con respecto a $\mu$ y $\sigma^2$, e igualamos a cero:

$$
\begin{array}{l}
    \frac{\partial \ell(\mu,\sigma^2)}{\partial \mu} =\dfrac{\cancel{2} }{\cancel{2} \sigma^2}\sum_{i=1}^{n} (x_i-\mu)=0\rightarrow \sum_{i=1}^{n} (x_i-\mu)=0\rightarrow \bboxed{\hat{\mu}=\dfrac{1}{n}\sum_{i=1}^{n} x_i=\bar{x}}\\
    \frac{\partial \ell(\mu,\sigma^2)}{\partial \sigma^2}=-\dfrac{n}{2\sigma^2}+\dfrac{1}{2\sigma^4}\sum_{i=1}^{n} (x_i-\mu)^2=0\rightarrow -n \sigma^2+\sum_{i=1}^{n} (x_i-\mu)^2=0\rightarrow \bboxed{\hat{\sigma}^2=\dfrac{1}{n}\sum_{i=1}^{n} (x_i-\hat{\mu})^2} 
\end{array}
$$

## Métodos para evaluar un estimador ##

:::{.callout-tip}
# Recordar
- Un estimador es una variable aleatoria.
- Es valioso disponer de conocimiento sobre la distribución del estimador (su \textcolor[HTML]{007aff}{distribución en el muestreo}) $\implies$ permite manejar el riesgo y el error que podemos cometer al aproxima $\theta$ por $\hat{\theta}$ asociado.
:::

**Consideramos dos aspectos de la distribución muestral de $\hat{\theta}$**

- Su localización: \textcolor[HTML]{007aff}{sesgo}.
- Su variabilidad: \textcolor[HTML]{007aff}{error cuadrático medio}.
- Mencionaremos su comportamiento cuando $n\to \infty$.

## Sesgo ##
\begin{definition}
Consideramos para un estimador $\hat{\theta}$ de un parámetro $\theta:\,E_\theta[\hat{\theta}]-\theta$.

Esta diferencia se llama el \textcolor[HTML]{007aff}{sesgo}. 
\end{definition}

:::{.callout-tip}
# Una propiedad deseable para un estimador
Si el sesgo de un estimador es nulo para todo valor de $\theta$, decimos que el estimador es **insesgado**.
:::

## Error cuadrático medio ##
Para medir la variabilidad en el muestreo de un estimador.
\begin{definition}
    El \textcolor[HTML]{007aff}{error cuadrático medio del estimador} $\hat{\theta}$ es la función de $\theta$ definida por
    
    $$
    \theta\mapsto E_\theta[(\hat{\theta}-\theta)^2]
    $$
    
\end{definition}

:::{.callout-tip}
# Para practicar
Calculad el error cuadrático medio del estimador de máxima verosimilitud (e.m.v.) de $\mu$ para una muestra aleatoria simple de $X\sim \mathcal{N}(\mu,\sigma^2)$.
:::

$X\leadsto \underbrace{\mathcal{N}(\mu,\sigma^2)}_{\text{desconocidos}}$

$\hat{\mu}=\bar{x}$ \textcolor[HTML]{007aff}{(estimador basado en los movimientos)} 

$E[\bar{X}]=\mu\rightarrow \hat{\mu}=\bar{X}$ es un estimador insesgado para $\mu$

$\begin{rcases}\mathrm{Var}[\bar{X}]=\dfrac{\sigma^2}{n}\\ \mathrm{Var}[\bar{X}]=E[(\bar{X}-\mu)^2]\end{rcases}\rightarrow E[(\bar{X}-\mu)^2]=\dfrac{\sigma^2}{n}$ \textcolor[HTML]{007aff}{(E.C.M.)} 
