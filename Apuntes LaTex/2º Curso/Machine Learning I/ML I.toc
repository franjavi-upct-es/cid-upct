\setcounter {tocdepth}{4}
\color {black}
\contentsline {section}{\numberline {1}Introducción al Machine Learning}{1}{section.1}%
\contentsline {subsection}{\numberline {1.1}Tareas básicas del Machine Learning}{1}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Generalización: subajuste y sobreajuste}{2}{subsection.1.2}%
\contentsline {subsubsection}{\numberline {1.2.1}Planteamiento del problema}{2}{subsubsection.1.2.1}%
\contentsline {subsubsection}{\numberline {1.2.2}Planteamiento de la solución}{3}{subsubsection.1.2.2}%
\contentsline {subsubsection}{\numberline {1.2.3}Peligros}{3}{subsubsection.1.2.3}%
\contentsline {subsubsection}{\numberline {1.2.4}Subajuste y sobreajuste}{3}{subsubsection.1.2.4}%
\contentsline {subsubsection}{\numberline {1.2.5}Complejidad del modelo vs número de datos}{4}{subsubsection.1.2.5}%
\contentsline {subsubsection}{\numberline {1.2.6}Conclusión}{4}{subsubsection.1.2.6}%
\contentsline {subsubsection}{\numberline {1.2.7}Descomposición sesgo-varianza. Coste cuadrático}{4}{subsubsection.1.2.7}%
\contentsline {subsubsection}{\numberline {1.2.8}Algunas técnicas de generalización}{8}{subsubsection.1.2.8}%
\contentsline {subsubsection}{\numberline {1.2.9}Evitar el sobreajuste: "early stopping"}{9}{subsubsection.1.2.9}%
\contentsline {subsubsection}{\numberline {1.2.10}Evitar el sobreajuste: "Weight Decay"}{10}{subsubsection.1.2.10}%
\contentsline {subsection}{\numberline {1.3}Evaluación de prestaciones}{11}{subsection.1.3}%
\contentsline {subsubsection}{\numberline {1.3.1}Regresión}{12}{subsubsection.1.3.1}%
\contentsline {subsubsection}{\numberline {1.3.2}Clasificación}{13}{subsubsection.1.3.2}%
\contentsline {section}{\numberline {2}Aprendizaje Supervisado}{14}{section.2}%
\contentsline {subsection}{\numberline {2.1}Árboles de Decisión}{14}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}Arquitectura}{14}{subsubsection.2.1.1}%
\contentsline {subsubsection}{\numberline {2.1.2}Ventajas y desventajas}{15}{subsubsection.2.1.2}%
\contentsline {subsubsection}{\numberline {2.1.3}Clasificación vs Regresión}{16}{subsubsection.2.1.3}%
\contentsline {subsection}{\numberline {2.2}Construcción de árboles de decisión}{16}{subsection.2.2}%
\contentsline {subsubsection}{\numberline {2.2.1}Particiones}{17}{subsubsection.2.2.1}%
\contentsline {subsubsection}{\numberline {2.2.2}Particiones posibles}{17}{subsubsection.2.2.2}%
\contentsline {subsection}{\numberline {2.3}ID3: Algoritmo básico de aprendizaje}{18}{subsection.2.3}%
\contentsline {subsubsection}{\numberline {2.3.1}Entropía}{18}{subsubsection.2.3.1}%
\contentsline {subsubsection}{\numberline {2.3.2}Ganancia de Información}{18}{subsubsection.2.3.2}%
\contentsline {subsubsection}{\numberline {2.3.3}Error global}{21}{subsubsection.2.3.3}%
\contentsline {subsubsection}{\numberline {2.3.4}Algoritmo}{21}{subsubsection.2.3.4}%
\contentsline {subsection}{\numberline {2.4}Sobre-ajuste}{22}{subsection.2.4}%
\contentsline {subsubsection}{\numberline {2.4.1}Espacio de hipótesis y sobre-ajuste}{22}{subsubsection.2.4.1}%
\contentsline {subsubsection}{\numberline {2.4.2}Proceso de poda}{22}{subsubsection.2.4.2}%
\contentsline {subsubsection}{\numberline {2.4.3}Otras medidas}{23}{subsubsection.2.4.3}%
\contentsline {subsection}{\numberline {2.5}Algoritmo CART y Otros}{23}{subsection.2.5}%
\contentsline {subsubsection}{\numberline {2.5.1}CART}{23}{subsubsection.2.5.1}%
\contentsline {subsubsection}{\numberline {2.5.2}C4.5, C5.0}{23}{subsubsection.2.5.2}%
\contentsline {subsection}{\numberline {2.6}Random Forests}{24}{subsection.2.6}%
\contentsline {subsubsection}{\numberline {2.6.1}Algoritmo}{24}{subsubsection.2.6.1}%
\contentsfinish 
