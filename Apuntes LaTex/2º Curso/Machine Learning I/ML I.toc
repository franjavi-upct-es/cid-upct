\setcounter {tocdepth}{4}
\color {black}
\contentsline {section}{\numberline {1}Introducción al Machine Learning}{1}{section.1}%
\contentsline {subsection}{\numberline {1.1}Tareas básicas del Machine Learning}{1}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Generalización: subajuste y sobreajuste}{2}{subsection.1.2}%
\contentsline {subsubsection}{\numberline {1.2.1}Planteamiento del problema}{2}{subsubsection.1.2.1}%
\contentsline {subsubsection}{\numberline {1.2.2}Planteamiento de la solución}{3}{subsubsection.1.2.2}%
\contentsline {subsubsection}{\numberline {1.2.3}Peligros}{3}{subsubsection.1.2.3}%
\contentsline {subsubsection}{\numberline {1.2.4}Subajuste y sobreajuste}{3}{subsubsection.1.2.4}%
\contentsline {subsubsection}{\numberline {1.2.5}Complejidad del modelo vs número de datos}{4}{subsubsection.1.2.5}%
\contentsline {subsubsection}{\numberline {1.2.6}Conclusión}{4}{subsubsection.1.2.6}%
\contentsline {subsubsection}{\numberline {1.2.7}Descomposición sesgo-varianza. Coste cuadrático}{4}{subsubsection.1.2.7}%
\contentsline {subsubsection}{\numberline {1.2.8}Algunas técnicas de generalización}{8}{subsubsection.1.2.8}%
\contentsline {subsubsection}{\numberline {1.2.9}Evitar el sobreajuste: "early stopping"}{9}{subsubsection.1.2.9}%
\contentsline {subsubsection}{\numberline {1.2.10}Evitar el sobreajuste: "Weight Decay"}{10}{subsubsection.1.2.10}%
\contentsline {subsection}{\numberline {1.3}Evaluación de prestaciones}{11}{subsection.1.3}%
\contentsline {subsubsection}{\numberline {1.3.1}Regresión}{12}{subsubsection.1.3.1}%
\contentsline {subsubsection}{\numberline {1.3.2}Clasificación}{13}{subsubsection.1.3.2}%
\contentsline {subsubsubsection}{\numberline {1.3.2.1)}Interpretación de la Precisión y la Sensibilidad}{14}{subsubsubsection.1.3.2.1}%
\contentsline {subsubsubsection}{\numberline {1.3.2.2)}Puntuación Kappa}{16}{subsubsubsection.1.3.2.2}%
\contentsline {subsubsection}{\numberline {1.3.3}Hold-out}{16}{subsubsection.1.3.3}%
\contentsline {section}{\numberline {2}Aprendizaje Supervisado}{18}{section.2}%
\contentsline {subsection}{\numberline {2.1}Árboles de Decisión}{18}{subsection.2.1}%
\contentsline {subsubsubsection}{\numberline {2.1.0.1)}Arquitectura}{18}{subsubsubsection.2.1.0.1}%
\contentsline {subsubsubsection}{\numberline {2.1.0.2)}Ventajas y desventajas}{19}{subsubsubsection.2.1.0.2}%
\contentsline {subsubsubsection}{\numberline {2.1.0.3)}Clasificación vs Regresión}{20}{subsubsubsection.2.1.0.3}%
\contentsline {subsubsection}{\numberline {2.1.1}Construcción de árboles de decisión}{20}{subsubsection.2.1.1}%
\contentsline {subsubsubsection}{\numberline {2.1.1.1)}Particiones}{21}{subsubsubsection.2.1.1.1}%
\contentsline {subsubsubsection}{\numberline {2.1.1.2)}Particiones posibles}{21}{subsubsubsection.2.1.1.2}%
\contentsline {subsubsection}{\numberline {2.1.2}ID3: Algoritmo básico de aprendizaje}{22}{subsubsection.2.1.2}%
\contentsline {subsubsubsection}{\numberline {2.1.2.1)}Entropía}{22}{subsubsubsection.2.1.2.1}%
\contentsline {subsubsubsection}{\numberline {2.1.2.2)}Ganancia de Información}{22}{subsubsubsection.2.1.2.2}%
\contentsline {subsubsubsection}{\numberline {2.1.2.3)}Error global}{25}{subsubsubsection.2.1.2.3}%
\contentsline {subsubsubsection}{\numberline {2.1.2.4)}Algoritmo}{25}{subsubsubsection.2.1.2.4}%
\contentsline {subsubsection}{\numberline {2.1.3}Sobre-ajuste}{26}{subsubsection.2.1.3}%
\contentsline {subsubsubsection}{\numberline {2.1.3.1)}Espacio de hipótesis y sobre-ajuste}{26}{subsubsubsection.2.1.3.1}%
\contentsline {subsubsubsection}{\numberline {2.1.3.2)}Proceso de poda}{26}{subsubsubsection.2.1.3.2}%
\contentsline {subsubsubsection}{\numberline {2.1.3.3)}Otras medidas}{27}{subsubsubsection.2.1.3.3}%
\contentsline {subsubsection}{\numberline {2.1.4}Algoritmo CART y Otros}{27}{subsubsection.2.1.4}%
\contentsline {subsubsubsection}{\numberline {2.1.4.1)}CART}{27}{subsubsubsection.2.1.4.1}%
\contentsline {subsubsubsection}{\numberline {2.1.4.2)}C4.5, C5.0}{27}{subsubsubsection.2.1.4.2}%
\contentsline {subsubsection}{\numberline {2.1.5}Random Forests}{28}{subsubsection.2.1.5}%
\contentsline {subsubsubsection}{\numberline {2.1.5.1)}Algoritmo}{28}{subsubsubsection.2.1.5.1}%
\contentsline {subsubsubsection}{\numberline {2.1.5.2)}OBB e importancia de las variables}{28}{subsubsubsection.2.1.5.2}%
\contentsline {subsubsection}{\numberline {2.1.6}Conclusiones}{28}{subsubsection.2.1.6}%
\contentsline {subsubsection}{\numberline {2.1.7}Bosques Aleatorios (\textit {"Random Forest"})}{29}{subsubsection.2.1.7}%
\contentsline {subsubsubsection}{\numberline {2.1.7.1)}Motivación}{29}{subsubsubsection.2.1.7.1}%
\contentsline {subsubsubsection}{\numberline {2.1.7.2)}Solución}{29}{subsubsubsection.2.1.7.2}%
\contentsline {subsubsubsection}{\numberline {2.1.7.3)}Número de árboles}{30}{subsubsubsection.2.1.7.3}%
\contentsline {subsubsubsection}{\numberline {2.1.7.4)}Generación conjuntos de entrenamiento}{31}{subsubsubsection.2.1.7.4}%
\contentsline {subsubsubsection}{\numberline {2.1.7.5)}Entrenamiento de los árboles}{31}{subsubsubsection.2.1.7.5}%
\contentsline {subsubsubsection}{\numberline {2.1.7.6)}Modo operación}{32}{subsubsubsection.2.1.7.6}%
\contentsline {subsubsubsection}{\numberline {2.1.7.7)}Bagging y Conjunto de Validación}{33}{subsubsubsection.2.1.7.7}%
\contentsline {subsubsubsection}{\numberline {2.1.7.8)}Selección del número de árboles}{33}{subsubsubsection.2.1.7.8}%
\contentsline {subsubsubsection}{\numberline {2.1.7.9)}Seleccionar del número de características}{33}{subsubsubsection.2.1.7.9}%
\contentsline {subsubsubsection}{\numberline {2.1.7.10)}Selección del criterio de parada}{34}{subsubsubsection.2.1.7.10}%
\contentsline {subsubsubsection}{\numberline {2.1.7.11)}Relevancia de las características}{34}{subsubsubsection.2.1.7.11}%
\contentsline {subsection}{\numberline {2.2}Perceptrón monocapa y multicapa (MLP)}{34}{subsection.2.2}%
\contentsline {subsubsection}{\numberline {2.2.1}Teoría de la decisión}{34}{subsubsection.2.2.1}%
\contentsline {subsubsubsection}{\numberline {2.2.1.1)}Decisión analítica}{35}{subsubsubsection.2.2.1.1}%
\contentsline {subsubsubsection}{\numberline {2.2.1.2)}Modelos discriminatorios}{35}{subsubsubsection.2.2.1.2}%
\contentsline {subsubsubsection}{\numberline {2.2.1.3)}Funciones discriminantes}{36}{subsubsubsection.2.2.1.3}%
\contentsline {subsubsection}{\numberline {2.2.2}Fundamento biológico}{36}{subsubsection.2.2.2}%
\contentsline {subsubsection}{\numberline {2.2.3}Perceptrón monocapa}{37}{subsubsection.2.2.3}%
\contentsline {subsubsubsection}{\numberline {2.2.3.1)}(Widrow): filtro transversal (adaptativo) + umbral duro}{37}{subsubsubsection.2.2.3.1}%
\contentsline {subsubsubsection}{\numberline {2.2.3.2)}(Rosenblatt): dados $N$ pares entrada-salida: $\{\mathbf {x}_k,\mathbf {d}_k\}_1^N$}{37}{subsubsubsection.2.2.3.2}%
\contentsfinish 
